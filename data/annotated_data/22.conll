-DOCSTART- -X- O
Visual -X- _ O
Commonsense -X- _ O
in -X- _ O
Pretrained -X- _ O
Unimodal -X- _ B-MethodName
and -X- _ O
Multimodal -X- _ B-MethodName
Models -X- _ O

Our -X- _ O
commonsense -X- _ O
knowledge -X- _ O
about -X- _ O
objects -X- _ O
includes -X- _ O
their -X- _ O
typical -X- _ O
visual -X- _ O
attributes -X- _ O
; -X- _ O
we -X- _ O
know -X- _ O
that -X- _ O
bananas -X- _ O
are -X- _ O
typically -X- _ O
yellow -X- _ O
or -X- _ O
green -X- _ O
, -X- _ O
and -X- _ O
not -X- _ O
purple -X- _ O
. -X- _ O
Text -X- _ O
and -X- _ O
image -X- _ O
corpora -X- _ O
, -X- _ O
being -X- _ O
subject -X- _ O
to -X- _ O
reporting -X- _ O
bias -X- _ O
, -X- _ O
represent -X- _ O
this -X- _ O
worldknowledge -X- _ O
to -X- _ O
varying -X- _ O
degrees -X- _ O
of -X- _ O
faithfulness -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
investigate -X- _ O
to -X- _ O
what -X- _ O
degree -X- _ O
unimodal -X- _ B-MethodName
( -X- _ O
language -X- _ O
- -X- _ O
only -X- _ O
) -X- _ O
and -X- _ O
multimodal -X- _ B-MethodName
( -X- _ O
image -X- _ O
and -X- _ O
language -X- _ O
) -X- _ O
models -X- _ O
capture -X- _ B-TaskName
a -X- _ I-TaskName
broad -X- _ I-TaskName
range -X- _ I-TaskName
of -X- _ I-TaskName
visually -X- _ I-TaskName
salient -X- _ I-TaskName
attributes -X- _ I-TaskName
. -X- _ O
To -X- _ O
that -X- _ O
end -X- _ O
, -X- _ O
we -X- _ O
create -X- _ O
the -X- _ O
Visual -X- _ B-DatasetName
Commonsense -X- _ I-DatasetName
Tests -X- _ I-DatasetName
( -X- _ O
ViComTe -X- _ B-DatasetName
) -X- _ O
dataset -X- _ O
covering -X- _ O
5 -X- _ O
property -X- _ O
types -X- _ O
( -X- _ O
color -X- _ O
, -X- _ O
shape -X- _ O
, -X- _ O
material -X- _ O
, -X- _ O
size -X- _ O
, -X- _ O
and -X- _ O
visual -X- _ O
co -X- _ O
- -X- _ O
occurrence -X- _ O
) -X- _ O
for -X- _ O
over -X- _ O
5000 -X- _ O
subjects -X- _ O
. -X- _ O
We -X- _ O
validate -X- _ O
this -X- _ O
dataset -X- _ O
by -X- _ O
showing -X- _ O
that -X- _ O
our -X- _ O
grounded -X- _ O
color -X- _ O
data -X- _ O
correlates -X- _ O
much -X- _ O
better -X- _ O
than -X- _ O
ungrounded -X- _ O
text -X- _ O
- -X- _ O
only -X- _ O
data -X- _ O
with -X- _ O
crowdsourced -X- _ O
color -X- _ O
judgments -X- _ O
provided -X- _ O
by -X- _ O
Paik -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
use -X- _ O
our -X- _ O
dataset -X- _ O
to -X- _ O
evaluate -X- _ O
pretrained -X- _ O
unimodal -X- _ B-MethodName
models -X- _ O
and -X- _ O
multimodal -X- _ B-MethodName
models -X- _ O
. -X- _ O
Our -X- _ O
results -X- _ O
indicate -X- _ O
that -X- _ O
multimodal -X- _ B-MethodName
models -X- _ O
better -X- _ O
reconstruct -X- _ O
attribute -X- _ O
distributions -X- _ O
, -X- _ O
but -X- _ O
are -X- _ O
still -X- _ O
subject -X- _ O
to -X- _ O
reporting -X- _ O
bias -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
increasing -X- _ O
model -X- _ O
size -X- _ O
does -X- _ O
not -X- _ O
enhance -X- _ O
performance -X- _ O
, -X- _ O
suggesting -X- _ O
that -X- _ O
the -X- _ O
key -X- _ O
to -X- _ O
visual -X- _ O
commonsense -X- _ O
lies -X- _ O
in -X- _ O
the -X- _ O
data -X- _ O
. -X- _ O
1 -X- _ O

Introduction -X- _ O

The -X- _ O
observation -X- _ O
that -X- _ O
human -X- _ O
language -X- _ O
understanding -X- _ O
happens -X- _ O
in -X- _ O
a -X- _ O
rich -X- _ O
multimodal -X- _ O
environment -X- _ O
has -X- _ O
led -X- _ O
to -X- _ O
an -X- _ O
increased -X- _ O
focus -X- _ O
on -X- _ O
visual -X- _ O
grounding -X- _ O
in -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
( -X- _ O
NLP -X- _ O
) -X- _ O
( -X- _ O
Baltrusaitis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Bisk -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
driving -X- _ O
comparisons -X- _ O
between -X- _ O
traditional -X- _ O
unimodal -X- _ B-MethodName
text -X- _ O
- -X- _ O
only -X- _ O
models -X- _ O
and -X- _ O
multimodal -X- _ B-MethodName
models -X- _ O
which -X- _ O
take -X- _ O
both -X- _ O
text -X- _ O
and -X- _ O
image -X- _ O
inputs -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
explore -X- _ O
to -X- _ O
what -X- _ O
extent -X- _ O
unimodal -X- _ B-MethodName
and -X- _ O
multimodal -X- _ B-MethodName
models -X- _ O
are -X- _ O
able -X- _ O
to -X- _ O
capture -X- _ O
commonsense -X- _ O
visual -X- _ O
concepts -X- _ O
across -X- _ O
five -X- _ O
types -X- _ O
of -X- _ O
relations -X- _ O
: -X- _ O
color -X- _ O
, -X- _ O
shape -X- _ O
, -X- _ O
material -X- _ O
, -X- _ O
size -X- _ O
, -X- _ O
and -X- _ O
visual -X- _ O
cooccurrence -X- _ O
( -X- _ O
cf -X- _ O
. -X- _ O
Fig -X- _ O
. -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
further -X- _ O
explore -X- _ O
how -X- _ O
this -X- _ O
ability -X- _ O
is -X- _ O
influenced -X- _ O
by -X- _ O
reporting -X- _ O
bias -X- _ O
( -X- _ O
Gordon -X- _ O
and -X- _ O
Van -X- _ O
Durme -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
tendency -X- _ O
of -X- _ O
large -X- _ O
corpora -X- _ O
to -X- _ O
over -X- _ O
- -X- _ O
or -X- _ O
under -X- _ O
- -X- _ O
report -X- _ O
events -X- _ O
. -X- _ O
We -X- _ O
define -X- _ O
visual -X- _ B-TaskName
commonsense -X- _ I-TaskName
as -X- _ O
knowledge -X- _ O
about -X- _ O
generic -X- _ O
visual -X- _ O
concepts -X- _ O
, -X- _ O
e.g. -X- _ O
" -X- _ O
knobs -X- _ O
are -X- _ O
usually -X- _ O
round -X- _ O
" -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
measure -X- _ O
this -X- _ O
knowledge -X- _ O
via -X- _ O
frequency -X- _ O
distributions -X- _ O
over -X- _ O
potential -X- _ O
properties -X- _ O
( -X- _ O
e.g. -X- _ O
round -X- _ O
, -X- _ O
square -X- _ O
, -X- _ O
etc -X- _ O
) -X- _ O
. -X- _ O
A -X- _ O
visually -X- _ O
- -X- _ O
informed -X- _ O
language -X- _ O
model -X- _ O
should -X- _ O
be -X- _ O
able -X- _ O
to -X- _ O
capture -X- _ O
such -X- _ O
properties -X- _ O
. -X- _ O
Our -X- _ O
color -X- _ O
, -X- _ O
shape -X- _ O
, -X- _ O
material -X- _ O
, -X- _ O
and -X- _ O
co -X- _ O
- -X- _ O
occurrence -X- _ O
data -X- _ O
are -X- _ O
mined -X- _ O
from -X- _ O
Visual -X- _ O
Genome -X- _ O
( -X- _ O
Krishna -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
our -X- _ O
size -X- _ O
data -X- _ O
are -X- _ O
created -X- _ O
from -X- _ O
object -X- _ O
lists -X- _ O
. -X- _ O
They -X- _ O
contain -X- _ O
a -X- _ O
large -X- _ O
number -X- _ O
of -X- _ O
examples -X- _ O
of -X- _ O
per -X- _ O
- -X- _ O
object -X- _ O
attribute -X- _ O
distributions -X- _ O
and -X- _ O
" -X- _ O
object -X- _ O
- -X- _ O
attribute -X- _ O
" -X- _ O
pairs -X- _ O
. -X- _ O
Paik -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
evaluate -X- _ O
language -X- _ O
models -X- _ O
' -X- _ O
color -X- _ O
perception -X- _ O
using -X- _ O
a -X- _ O
human -X- _ O
- -X- _ O
annotated -X- _ O
color -X- _ O
dataset -X- _ O
( -X- _ O
CoDa -X- _ O
) -X- _ O
, -X- _ O
finding -X- _ O
that -X- _ O
reporting -X- _ O
bias -X- _ O
negatively -X- _ O
influences -X- _ O
model -X- _ O
performance -X- _ O
and -X- _ O
that -X- _ O
multimodal -X- _ O
training -X- _ O
can -X- _ O
mitigate -X- _ O
those -X- _ O
effects -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
confirm -X- _ O
those -X- _ O
findings -X- _ O
while -X- _ O
extending -X- _ O
the -X- _ O
evaluation -X- _ O
to -X- _ O
a -X- _ O
broader -X- _ O
range -X- _ O
of -X- _ O
visually -X- _ O
salient -X- _ O
properties -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
a -X- _ O
more -X- _ O
comprehensive -X- _ O
metric -X- _ O
for -X- _ O
visual -X- _ O
commonsense -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
elicit -X- _ O
visual -X- _ B-TaskName
commonsense -X- _ I-TaskName
from -X- _ O
language -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
utilize -X- _ O
soft -X- _ O
prompt -X- _ O
tuning -X- _ O
( -X- _ O
Qin -X- _ O
and -X- _ O
Eisner -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
trains -X- _ O
optimal -X- _ O
templates -X- _ O
by -X- _ O
gradient -X- _ O
descent -X- _ O
for -X- _ O
each -X- _ O
model -X- _ O
and -X- _ O
relation -X- _ O
type -X- _ O
that -X- _ O
we -X- _ O
explore -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
utilize -X- _ O
knowledge -X- _ O
distillation -X- _ O
to -X- _ O
enhance -X- _ O
a -X- _ O
textonly -X- _ O
model -X- _ O
's -X- _ O
visual -X- _ B-TaskName
commonsense -X- _ I-TaskName
ability -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
vision -X- _ O
- -X- _ O
language -X- _ O
model -X- _ O
serves -X- _ O
as -X- _ O
the -X- _ O
teacher -X- _ O
. -X- _ O

The -X- _ O
major -X- _ O
contributions -X- _ O
of -X- _ O
this -X- _ O
work -X- _ O
are -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
we -X- _ O
design -X- _ O
a -X- _ O
comprehensive -X- _ O
analytic -X- _ O
dataset -X- _ O
, -X- _ O
Vi -X- _ B-DatasetName
- -X- _ I-DatasetName
ComTe -X- _ I-DatasetName
, -X- _ O
for -X- _ O
probing -X- _ O
English -X- _ O
visual -X- _ O
commonsense -X- _ O
, -X- _ O
that -X- _ O
is -X- _ O
applicable -X- _ O
to -X- _ O
any -X- _ O
language -X- _ O
model -X- _ O
; -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
we -X- _ O
use -X- _ O
ViComTe -X- _ B-DatasetName
to -X- _ O
study -X- _ O
models -X- _ O
' -X- _ O
ability -X- _ O
to -X- _ O
capture -X- _ O
empirical -X- _ O
distributions -X- _ O
of -X- _ O
visually -X- _ O
salient -X- _ O
properties -X- _ O
. -X- _ O
We -X- _ O
examine -X- _ O
unimodal -X- _ B-MethodName
language -X- _ O
models -X- _ O
, -X- _ O
multimodal -X- _ B-MethodName
vision -X- _ O
- -X- _ O
language -X- _ O
( -X- _ O
VL -X- _ O
) -X- _ O
models -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
knowledgedistilled -X- _ O
version -X- _ O
of -X- _ O
a -X- _ O
VL -X- _ O
model -X- _ O
; -X- _ O
and -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
we -X- _ O
analyze -X- _ O
the -X- _ O
effects -X- _ O
of -X- _ O
reporting -X- _ O
bias -X- _ O
on -X- _ O
the -X- _ O
visuallygrounded -X- _ O
vs. -X- _ O
ungrounded -X- _ O
datasets -X- _ O
and -X- _ O
models -X- _ O
. -X- _ O

Does -X- _ O
the -X- _ O
model -X- _ O
know -X- _ O
… -X- _ O

It -X- _ O
is -X- _ O
larger -X- _ O
than -X- _ O
: -X- _ O
It -X- _ O
is -X- _ O
smaller -X- _ O
than -X- _ O
: -X- _ O

Unimodal -X- _ B-MethodName
Multimodal -X- _ B-MethodName

BERT -X- _ B-MethodName
, -X- _ O
… -X- _ O
Oscar -X- _ B-MethodName
, -X- _ O
… -X- _ O

A -X- _ O
girl -X- _ O
is -X- _ O
looking -X- _ O
at -X- _ O
the -X- _ O
penguin -X- _ O
. -X- _ O

Penguins -X- _ O
are -X- _ O
a -X- _ O
group -X- _ O
of -X- _ O
aquatic -X- _ O
flightless -X- _ O
birds -X- _ O
. -X- _ O

The -X- _ O
word -X- _ O
penguin -X- _ O
first -X- _ O
appears -X- _ O
in -X- _ O
the -X- _ O
16th -X- _ O
century -X- _ O
as -X- _ O
a -X- _ O
name -X- _ O
for -X- _ O
the -X- _ O
great -X- _ O
auk -X- _ O
. -X- _ O
what -X- _ O
is -X- _ O
the -X- _ O
color -X- _ O
of -X- _ O
a -X- _ O
penguin -X- _ O
? -X- _ O

Figure -X- _ O
1 -X- _ O
: -X- _ O
We -X- _ O
compare -X- _ O
unimodal -X- _ B-MethodName
and -X- _ O
multimodal -X- _ B-MethodName
models -X- _ O
' -X- _ O
abilities -X- _ O
to -X- _ O
capture -X- _ O
visual -X- _ B-TaskName
commonsense -X- _ I-TaskName
knowledge -X- _ O
. -X- _ O
The -X- _ O
commonsense -X- _ O
knowledge -X- _ O
is -X- _ O
evaluated -X- _ O
on -X- _ O
five -X- _ O
relation -X- _ O
types -X- _ O
: -X- _ O
color -X- _ O
, -X- _ O
shape -X- _ O
, -X- _ O
material -X- _ O
, -X- _ O
size -X- _ O
, -X- _ O
and -X- _ O
visual -X- _ O
co -X- _ O
- -X- _ O
occurrence -X- _ O
. -X- _ O

We -X- _ O
compare -X- _ O
the -X- _ O
model -X- _ O
outputs -X- _ O
with -X- _ O
the -X- _ O
gold -X- _ O
distribution -X- _ O
from -X- _ O
ViComTe -X- _ B-DatasetName
, -X- _ O
which -X- _ O
is -X- _ O
mined -X- _ O
from -X- _ O
Visual -X- _ O
Genome -X- _ O
. -X- _ O

2 -X- _ O
Related -X- _ O
Work -X- _ O

Vision -X- _ O
- -X- _ O
Language -X- _ O
Modeling -X- _ O

Recent -X- _ O
advances -X- _ O
in -X- _ O
vision -X- _ O
- -X- _ O
language -X- _ O
( -X- _ O
VL -X- _ B-MethodName
) -X- _ O
modeling -X- _ O
have -X- _ O
led -X- _ O
to -X- _ O
increased -X- _ O
success -X- _ O
on -X- _ O
benchmark -X- _ O
tasks -X- _ O
. -X- _ O
Most -X- _ O
VL -X- _ O
models -X- _ O
learn -X- _ O
joint -X- _ O
image -X- _ O
and -X- _ O
text -X- _ O
representations -X- _ O
from -X- _ O
cross -X- _ O
- -X- _ O
modal -X- _ O
training -X- _ O
of -X- _ O
transformers -X- _ O
with -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
, -X- _ O
including -X- _ O
LXMERT -X- _ O
( -X- _ O
Tan -X- _ O
and -X- _ O
Bansal -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
ViLBERT -X- _ O
( -X- _ O
Lu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
VisualBERT -X- _ O
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
UNITER -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
Oscar -X- _ O
additionally -X- _ O
uses -X- _ O
object -X- _ O
tags -X- _ O
in -X- _ O
images -X- _ O
as -X- _ O
anchor -X- _ O
points -X- _ O
to -X- _ O
facilitate -X- _ O
the -X- _ O
learning -X- _ O
of -X- _ O
image -X- _ O
- -X- _ O
text -X- _ O
alignments -X- _ O
and -X- _ O
VinVL -X- _ O
presents -X- _ O
an -X- _ O
improved -X- _ O
object -X- _ O
detection -X- _ O
model -X- _ O
. -X- _ O
CLIP -X- _ O
( -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
learns -X- _ O
by -X- _ O
predicting -X- _ O
caption -X- _ O
- -X- _ O
image -X- _ O
alignment -X- _ O
from -X- _ O
a -X- _ O
large -X- _ O
internet -X- _ O
corpus -X- _ O
of -X- _ O
( -X- _ O
image -X- _ O
, -X- _ O
text -X- _ O
) -X- _ O
pairs -X- _ O
. -X- _ O
While -X- _ O
our -X- _ O
work -X- _ O
uses -X- _ O
textual -X- _ O
prompt -X- _ O
tuning -X- _ O
techniques -X- _ O
, -X- _ O
there -X- _ O
have -X- _ O
also -X- _ O
been -X- _ O
work -X- _ O
on -X- _ O
visual -X- _ O
prompt -X- _ O
engineering -X- _ O
to -X- _ O
enhance -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
pretrained -X- _ O
vision -X- _ O
- -X- _ O
language -X- _ O
models -X- _ O
. -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
model -X- _ O
context -X- _ O
in -X- _ O
prompts -X- _ O
as -X- _ O
continuous -X- _ O
representations -X- _ O
and -X- _ O
learn -X- _ O
to -X- _ O
optimize -X- _ O
that -X- _ O
context -X- _ O
. -X- _ O
Yao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
develop -X- _ O
a -X- _ O
cross -X- _ O
- -X- _ O
modal -X- _ O
prompt -X- _ O
tuning -X- _ O
framework -X- _ O
that -X- _ O
reformulates -X- _ O
visual -X- _ O
grounding -X- _ O
as -X- _ O
a -X- _ O
fill -X- _ O
- -X- _ O
in -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
blank -X- _ O
problem -X- _ O
for -X- _ O
both -X- _ O
image -X- _ O
and -X- _ O
text -X- _ O
. -X- _ O

Visual -X- _ B-TaskName
Commonsense -X- _ I-TaskName

In -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
early -X- _ O
attempts -X- _ O
at -X- _ O
learning -X- _ O
visual -X- _ B-TaskName
commonsense -X- _ I-TaskName
, -X- _ O
Vedantam -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2015 -X- _ O
) -X- _ O
measure -X- _ O
the -X- _ O
plausibility -X- _ O
of -X- _ O
a -X- _ O
commonsense -X- _ O
assertion -X- _ O
in -X- _ O
the -X- _ O
form -X- _ O
of -X- _ O
( -X- _ O
obj1 -X- _ O
, -X- _ O
relation -X- _ O
, -X- _ O
obj2 -X- _ O
) -X- _ O
based -X- _ O
on -X- _ O
its -X- _ O
similarity -X- _ O
to -X- _ O
known -X- _ O
plausible -X- _ O
assertions -X- _ O
, -X- _ O
using -X- _ O
both -X- _ O
visual -X- _ O
scenes -X- _ O
and -X- _ O
accompanying -X- _ O
text -X- _ O
. -X- _ O
Zellers -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
learn -X- _ O
physical -X- _ O
commonsense -X- _ O
via -X- _ O
interaction -X- _ O
, -X- _ O
and -X- _ O
use -X- _ O
this -X- _ O
knowledge -X- _ O
to -X- _ O
ground -X- _ O
language -X- _ O
. -X- _ O
Frank -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
probe -X- _ O
whether -X- _ O
VL -X- _ O
models -X- _ O
have -X- _ O
learned -X- _ O
to -X- _ O
construct -X- _ O
cross -X- _ O
- -X- _ O
modal -X- _ O
representations -X- _ O
from -X- _ O
both -X- _ O
modalities -X- _ O
via -X- _ O
cross -X- _ O
- -X- _ O
modal -X- _ O
input -X- _ O
ablation -X- _ O
. -X- _ O

Note -X- _ O
that -X- _ O
our -X- _ O
definition -X- _ O
of -X- _ O
visual -X- _ B-TaskName
commonsense -X- _ I-TaskName
differs -X- _ O
from -X- _ O
that -X- _ O
of -X- _ O
Zellers -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
required -X- _ O
to -X- _ O
perform -X- _ O
commonsense -X- _ O
reasoning -X- _ O
based -X- _ O
on -X- _ O
an -X- _ O
image -X- _ O
. -X- _ O
Our -X- _ O
definition -X- _ O
of -X- _ O
visual -X- _ O
commonsense -X- _ O
is -X- _ O
more -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
idea -X- _ O
of -X- _ O
stereotypic -X- _ O
tacit -X- _ O
assumptions -X- _ O
( -X- _ O
Prince -X- _ O
, -X- _ O
1978 -X- _ O
) -X- _ O
the -X- _ O
propositional -X- _ O
beliefs -X- _ O
that -X- _ O
humans -X- _ O
hold -X- _ O
about -X- _ O
generic -X- _ O
concepts -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
" -X- _ O
dogs -X- _ O
have -X- _ O
to -X- _ O
be -X- _ O
walked -X- _ O
" -X- _ O
. -X- _ O
Weir -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
probe -X- _ O
neural -X- _ O
language -X- _ O
models -X- _ O
for -X- _ O
such -X- _ O
human -X- _ O
tacit -X- _ O
assumptions -X- _ O
and -X- _ O
demonstrate -X- _ O
the -X- _ O
models -X- _ O
' -X- _ O
success -X- _ O
. -X- _ O
We -X- _ O
extend -X- _ O
this -X- _ O
intuition -X- _ O
to -X- _ O
visual -X- _ O
concepts -X- _ O
and -X- _ O
explore -X- _ O
how -X- _ O
visual -X- _ O
information -X- _ O
may -X- _ O
help -X- _ O
language -X- _ O
models -X- _ O
to -X- _ O
capture -X- _ O
such -X- _ O
assumptions -X- _ O
. -X- _ O

There -X- _ O
has -X- _ O
also -X- _ O
been -X- _ O
earlier -X- _ O
work -X- _ O
on -X- _ O
the -X- _ O
McRae -X- _ O
feature -X- _ O
norms -X- _ O
( -X- _ O
McRae -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
human -X- _ O
annotators -X- _ O
wrote -X- _ O
down -X- _ O
attributes -X- _ O
that -X- _ O
describe -X- _ O
the -X- _ O
meaning -X- _ O
of -X- _ O
words -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
" -X- _ O
car -X- _ O
" -X- _ O
can -X- _ O
be -X- _ O
labeled -X- _ O
as -X- _ O
" -X- _ O
has -X- _ O
four -X- _ O
wheels -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
apple -X- _ O
" -X- _ O
can -X- _ O
be -X- _ O
labeled -X- _ O
as -X- _ O
" -X- _ O
is -X- _ O
green -X- _ O
" -X- _ O
. -X- _ O
Silberer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2013 -X- _ O
) -X- _ O
expand -X- _ O
the -X- _ O
McRae -X- _ O
dataset -X- _ O
into -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
images -X- _ O
and -X- _ O
their -X- _ O
visual -X- _ O
attributes -X- _ O
and -X- _ O
construct -X- _ O
visually -X- _ O
grounded -X- _ O
distributional -X- _ O
models -X- _ O
that -X- _ O
can -X- _ O
represent -X- _ O
image -X- _ O
features -X- _ O
with -X- _ O
visual -X- _ O
attributes -X- _ O
. -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
examine -X- _ O
the -X- _ O
" -X- _ O
language -X- _ O
prior -X- _ O
" -X- _ O
problem -X- _ O
in -X- _ O
Visual -X- _ O
Question -X- _ O
Answering -X- _ O
models -X- _ O
, -X- _ O
where -X- _ O
models -X- _ O
tend -X- _ O
to -X- _ O
answer -X- _ O
based -X- _ O
on -X- _ O
word -X- _ O
frequencies -X- _ O
in -X- _ O
the -X- _ O
data -X- _ O
, -X- _ O
ignoring -X- _ O
the -X- _ O
image -X- _ O
contents -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
explore -X- _ O
to -X- _ O
what -X- _ O
extent -X- _ O
such -X- _ O
a -X- _ O
language -X- _ O
prior -X- _ O
is -X- _ O
recruited -X- _ O
absent -X- _ O
a -X- _ O
visual -X- _ O
input -X- _ O
. -X- _ O

Reporting -X- _ O
Bias -X- _ O

Pretrained -X- _ O
language -X- _ O
models -X- _ O
such -X- _ O
as -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
are -X- _ O
trained -X- _ O
on -X- _ O
billions -X- _ O
of -X- _ O
tokens -X- _ O
of -X- _ O
text -X- _ O
, -X- _ O
capturing -X- _ O
statistical -X- _ O
regularities -X- _ O
present -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
corpora -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
their -X- _ O
textual -X- _ O
training -X- _ O
data -X- _ O
can -X- _ O
suffer -X- _ O
from -X- _ O
reporting -X- _ O
bias -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
frequency -X- _ O
distribution -X- _ O
of -X- _ O
specific -X- _ O
events -X- _ O
and -X- _ O
properties -X- _ O
in -X- _ O
text -X- _ O
may -X- _ O
not -X- _ O
reflect -X- _ O
the -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
distribution -X- _ O
of -X- _ O
such -X- _ O
properties -X- _ O
( -X- _ O
Gordon -X- _ O
and -X- _ O
Van -X- _ O
Durme -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
while -X- _ O
grass -X- _ O
is -X- _ O
typically -X- _ O
green -X- _ O
, -X- _ O
this -X- _ O
may -X- _ O
be -X- _ O
under -X- _ O
- -X- _ O
reported -X- _ O
in -X- _ O
web -X- _ O
corpora -X- _ O
( -X- _ O
as -X- _ O
it -X- _ O
is -X- _ O
assumed -X- _ O
to -X- _ O
be -X- _ O
true -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
while -X- _ O
motorcycle -X- _ O
crashes -X- _ O
may -X- _ O
be -X- _ O
more -X- _ O
common -X- _ O
in -X- _ O
the -X- _ O
real -X- _ O
world -X- _ O
, -X- _ O
plane -X- _ O
crashes -X- _ O
are -X- _ O
mentioned -X- _ O
far -X- _ O
more -X- _ O
in -X- _ O
news -X- _ O
text -X- _ O
( -X- _ O
Gordon -X- _ O
and -X- _ O
Van -X- _ O
Durme -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
. -X- _ O
Misra -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
highlight -X- _ O
the -X- _ O
reporting -X- _ O
bias -X- _ O
in -X- _ O
" -X- _ O
human -X- _ O
- -X- _ O
centric -X- _ O
" -X- _ O
image -X- _ O
annotations -X- _ O
and -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
noise -X- _ O
in -X- _ O
annotations -X- _ O
exhibits -X- _ O
a -X- _ O
structure -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
modeled -X- _ O
. -X- _ O

3 -X- _ O
Dataset -X- _ O
: -X- _ O
ViComTe -X- _ B-DatasetName

Dataset -X- _ O
Mining -X- _ O

For -X- _ O
each -X- _ O
relation -X- _ O
color -X- _ O
, -X- _ O
shape -X- _ O
, -X- _ O
material -X- _ O
, -X- _ O
size -X- _ O
, -X- _ O
and -X- _ O
object -X- _ O
co -X- _ O
- -X- _ O
occurrence -X- _ O
, -X- _ O
our -X- _ O
data -X- _ O
take -X- _ O
the -X- _ O
form -X- _ O
of -X- _ O
( -X- _ O
subject -X- _ O
, -X- _ O
object -X- _ O
) -X- _ O
tuples -X- _ O
extracted -X- _ O
from -X- _ O
object -X- _ O
distributions -X- _ O
per -X- _ O
subject -X- _ O
. -X- _ O
The -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
object -X- _ O
and -X- _ O
its -X- _ O
distribution -X- _ O
from -X- _ O
the -X- _ O
subject -X- _ O
and -X- _ O
relation -X- _ O
. -X- _ O
Table -X- _ O
1 -X- _ O
summarizes -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
classes -X- _ O
and -X- _ O
subject -X- _ O
- -X- _ O
object -X- _ O
pairs -X- _ O
for -X- _ O
each -X- _ O
relation -X- _ O
. -X- _ O
2 -X- _ O
Color -X- _ O
, -X- _ O
Shape -X- _ O
, -X- _ O
Material -X- _ O
For -X- _ O
color -X- _ O
, -X- _ O
shape -X- _ O
, -X- _ O
and -X- _ O
material -X- _ O
, -X- _ O
the -X- _ O
subject -X- _ O
is -X- _ O
a -X- _ O
noun -X- _ O
and -X- _ O
the -X- _ O
object -X- _ O
is -X- _ O
the -X- _ O
color -X- _ O
, -X- _ O
shape -X- _ O
, -X- _ O
or -X- _ O
material -X- _ O
property -X- _ O
of -X- _ O
the -X- _ O
noun -X- _ O
, -X- _ O
mined -X- _ O
from -X- _ O
attributes -X- _ O
of -X- _ O
Visual -X- _ O
Genome -X- _ O
( -X- _ O
VG -X- _ O
) -X- _ O
( -X- _ O
Krishna -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
3 -X- _ O
We -X- _ O
manually -X- _ O
create -X- _ O
a -X- _ O
list -X- _ O
of -X- _ O
single -X- _ O
- -X- _ O
word -X- _ O
attributes -X- _ O
for -X- _ O
each -X- _ O
relation -X- _ O
, -X- _ O
and -X- _ O
only -X- _ O
VG -X- _ O
subjects -X- _ O
that -X- _ O
are -X- _ O
matched -X- _ O
with -X- _ O
a -X- _ O
specific -X- _ O
attribute -X- _ O
for -X- _ O
more -X- _ O
than -X- _ O
a -X- _ O
threshold -X- _ O
number -X- _ O
of -X- _ O
times -X- _ O
are -X- _ O
recorded -X- _ O
, -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
avoid -X- _ O
noise -X- _ O
in -X- _ O
the -X- _ O
dataset -X- _ O
. -X- _ O
The -X- _ O
thresholds -X- _ O
for -X- _ O
color -X- _ O
, -X- _ O
material -X- _ O
, -X- _ O
and -X- _ O
shape -X- _ O
are -X- _ O
5 -X- _ O
, -X- _ O
2 -X- _ O
, -X- _ O
and -X- _ O
1 -X- _ O
, -X- _ O
respectively -X- _ O
, -X- _ O
chosen -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
availability -X- _ O
of -X- _ O
attributes -X- _ O
of -X- _ O
each -X- _ O
relation -X- _ O
in -X- _ O
VG -X- _ O
. -X- _ O
VG -X- _ O
attributes -X- _ O
are -X- _ O
filtered -X- _ O
with -X- _ O
the -X- _ O
following -X- _ O
steps -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
attribute -X- _ O
" -X- _ O
Y -X- _ O
colored -X- _ O
/ -X- _ O
made -X- _ O
/ -X- _ O
shaped -X- _ O
" -X- _ O
is -X- _ O
treated -X- _ O
as -X- _ O
" -X- _ O
Y -X- _ O
" -X- _ O
; -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
select -X- _ O
only -X- _ O
the -X- _ O
last -X- _ O
word -X- _ O
for -X- _ O
compound -X- _ O
attributes -X- _ O
( -X- _ O
e.g. -X- _ O
treat -X- _ O
" -X- _ O
forest -X- _ O
green -X- _ O
" -X- _ O
as -X- _ O
" -X- _ O
green -X- _ O
" -X- _ O
) -X- _ O
; -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
similar -X- _ O
attributes -X- _ O
are -X- _ O
merged -X- _ O
into -X- _ O
a -X- _ O
main -X- _ O
attribute -X- _ O
class -X- _ O
( -X- _ O
e.g. -X- _ O
" -X- _ O
maroon -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
crimson -X- _ O
" -X- _ O
become -X- _ O
" -X- _ O
red -X- _ O
" -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
above -X- _ O
procedure -X- _ O
produces -X- _ O
a -X- _ O
distribution -X- _ O
over -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
attributes -X- _ O
for -X- _ O
each -X- _ O
subject -X- _ O
noun -X- _ O
. -X- _ O
From -X- _ O
that -X- _ O
distribution -X- _ O
, -X- _ O
a -X- _ O
( -X- _ O
subject -X- _ O
, -X- _ O
object -X- _ O
) -X- _ O
data -X- _ O
instance -X- _ O
is -X- _ O
generated -X- _ O
for -X- _ O
each -X- _ O
subject -X- _ O
where -X- _ O
the -X- _ O
object -X- _ O
is -X- _ O
the -X- _ O
attribute -X- _ O
that -X- _ O
associates -X- _ O
with -X- _ O
it -X- _ O
the -X- _ O
most -X- _ O
. -X- _ O
See -X- _ O
the -X- _ O
first -X- _ O
three -X- _ O
rows -X- _ O
of -X- _ O
Table -X- _ O
1 -X- _ O
for -X- _ O
examples -X- _ O
. -X- _ O

Size -X- _ O
Size -X- _ O
is -X- _ O
separated -X- _ O
into -X- _ O
size_smaller -X- _ O
and -X- _ O
size_larger -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
subject -X- _ O
is -X- _ O
a -X- _ O
noun -X- _ O
and -X- _ O
the -X- _ O
object -X- _ O
is -X- _ O
another -X- _ O
noun -X- _ O
that -X- _ O
is -X- _ O
smaller -X- _ O
or -X- _ O
larger -X- _ O
, -X- _ O
respectively -X- _ O
, -X- _ O
than -X- _ O
the -X- _ O
subject -X- _ O
. -X- _ O
To -X- _ O
form -X- _ O
the -X- _ O
size -X- _ O
dataset -X- _ O
, -X- _ O
we -X- _ O
obtain -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
concrete -X- _ O
nouns -X- _ O
that -X- _ O
appears -X- _ O
in -X- _ O
VG -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
manually -X- _ O
classify -X- _ O
into -X- _ O
5 -X- _ O
size -X- _ O
categories -X- _ O
( -X- _ O
tiny -X- _ O
, -X- _ O
small -X- _ O
, -X- _ O
medium -X- _ O
, -X- _ O
large -X- _ O
, -X- _ O
and -X- _ O
huge -X- _ O
) -X- _ O
. -X- _ O
Typical -X- _ O
objects -X- _ O
in -X- _ O
each -X- _ O
category -X- _ O
includes -X- _ O
pill -X- _ O
, -X- _ O
book -X- _ O
, -X- _ O
table -X- _ O
, -X- _ O
lion -X- _ O
, -X- _ O
mountain -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
We -X- _ O
randomly -X- _ O
pick -X- _ O
two -X- _ O
nouns -X- _ O
from -X- _ O
different -X- _ O
categories -X- _ O
to -X- _ O
form -X- _ O
a -X- _ O
( -X- _ O
subject -X- _ O
, -X- _ O
object -X- _ O
) -X- _ O
pair -X- _ O
. -X- _ O

Visual -X- _ O
Co -X- _ O
- -X- _ O
occurrence -X- _ O
The -X- _ O
visual -X- _ O
co -X- _ O
- -X- _ O
occurrence -X- _ O
dataset -X- _ O
is -X- _ O
generated -X- _ O
in -X- _ O
a -X- _ O
similar -X- _ O
way -X- _ O
to -X- _ O
the -X- _ O
color -X- _ O
, -X- _ O
shape -X- _ O
, -X- _ O
and -X- _ O
material -X- _ O
datasets -X- _ O
. -X- _ O
Co -X- _ O
- -X- _ O
occurrence -X- _ O
distribution -X- _ O
is -X- _ O
extracted -X- _ O
from -X- _ O
Visual -X- _ O
Genome -X- _ O
where -X- _ O
two -X- _ O
objects -X- _ O
that -X- _ O
occur -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
scene -X- _ O
graph -X- _ O
together -X- _ O
for -X- _ O
more -X- _ O
than -X- _ O
8 -X- _ O
times -X- _ O
are -X- _ O
recorded -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
( -X- _ O
subject -X- _ O
, -X- _ O
object -X- _ O
) -X- _ O
instance -X- _ O
is -X- _ O
generated -X- _ O
for -X- _ O
each -X- _ O
subject -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
object -X- _ O
is -X- _ O
the -X- _ O
noun -X- _ O
that -X- _ O
co -X- _ O
- -X- _ O
occurs -X- _ O
with -X- _ O
the -X- _ O
subject -X- _ O
the -X- _ O
most -X- _ O
. -X- _ O

Data -X- _ O
Grouping -X- _ O

Following -X- _ O
Paik -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
split -X- _ O
the -X- _ O
color -X- _ O
, -X- _ O
shape -X- _ O
, -X- _ O
and -X- _ O
material -X- _ O
datasets -X- _ O
each -X- _ O
into -X- _ O
three -X- _ O
groups -X- _ O
: -X- _ O
SINGLE -X- _ O
, -X- _ O
MULTI -X- _ O
, -X- _ O
and -X- _ O
ANY -X- _ O
. -X- _ O
The -X- _ O
SINGLE -X- _ O
group -X- _ O
is -X- _ O
for -X- _ O
subjects -X- _ O
whose -X- _ O
most -X- _ O
common -X- _ O
attribute -X- _ O
covers -X- _ O
more -X- _ O
than -X- _ O
80 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
probability -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
the -X- _ O
color -X- _ O
of -X- _ O
snow -X- _ O
is -X- _ O
almost -X- _ O
always -X- _ O
white -X- _ O
. -X- _ O
The -X- _ O
MULTI -X- _ O
group -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O
subjects -X- _ O
not -X- _ O
in -X- _ O
the -X- _ O
SINGLE -X- _ O
group -X- _ O
where -X- _ O
more -X- _ O
than -X- _ O
90 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
probability -X- _ O
falls -X- _ O
in -X- _ O
the -X- _ O
top -X- _ O
4 -X- _ O
attribute -X- _ O
classes -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
the -X- _ O
color -X- _ O
of -X- _ O
a -X- _ O
penguin -X- _ O
in -X- _ O
Fig -X- _ O
. -X- _ O
1 -X- _ O
. -X- _ O
The -X- _ O
rest -X- _ O
of -X- _ O
the -X- _ O
subjects -X- _ O
are -X- _ O
in -X- _ O
the -X- _ O
ANY -X- _ O
group -X- _ O
. -X- _ O
Lower -X- _ O
model -X- _ O
performance -X- _ O
for -X- _ O
the -X- _ O
SINGLE -X- _ O
group -X- _ O
would -X- _ O
indicate -X- _ O
the -X- _ O
influence -X- _ O
of -X- _ O
reporting -X- _ O
bias -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
if -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
unable -X- _ O
to -X- _ O
correctly -X- _ O
capture -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
the -X- _ O
color -X- _ O
of -X- _ O
snow -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
likely -X- _ O
because -X- _ O
the -X- _ O
color -X- _ O
of -X- _ O
snow -X- _ O
has -X- _ O
low -X- _ O
probability -X- _ O
of -X- _ O
being -X- _ O
reported -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
corpus -X- _ O
, -X- _ O
as -X- _ O
people -X- _ O
know -X- _ O
it -X- _ O
is -X- _ O
white -X- _ O
by -X- _ O
default -X- _ O
. -X- _ O

Templates -X- _ O

In -X- _ O
order -X- _ O
to -X- _ O
elicit -X- _ O
model -X- _ O
response -X- _ O
and -X- _ O
extract -X- _ O
target -X- _ O
objects -X- _ O
and -X- _ O
distributions -X- _ O
from -X- _ O
text -X- _ O
, -X- _ O
we -X- _ O
manually -X- _ O
design -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
templates -X- _ O
for -X- _ O
each -X- _ O
relation -X- _ O
. -X- _ O
There -X- _ O
are -X- _ O
7 -X- _ O
templates -X- _ O
for -X- _ O
color -X- _ O
, -X- _ O
shape -X- _ O
, -X- _ O
and -X- _ O
material -X- _ O
each -X- _ O
, -X- _ O
8 -X- _ O
for -X- _ O
size -X- _ O
, -X- _ O
and -X- _ O
4 -X- _ O
for -X- _ O
visual -X- _ O
co -X- _ O
- -X- _ O
occurrence -X- _ O
. -X- _ O
See -X- _ O
Table -X- _ O
1 -X- _ O
for -X- _ O
example -X- _ O
templates -X- _ O
. -X- _ O

Wikipedia -X- _ O
Data -X- _ O

In -X- _ O
order -X- _ O
to -X- _ O
compare -X- _ O
text -X- _ O
- -X- _ O
based -X- _ O
and -X- _ O
visuallygrounded -X- _ O
data -X- _ O
, -X- _ O
we -X- _ O
mine -X- _ O
the -X- _ O
color -X- _ O
, -X- _ O
shape -X- _ O
, -X- _ O
and -X- _ O
material -X- _ O
datasets -X- _ O
from -X- _ O
Wikipedia -X- _ O
data -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
typically -X- _ O
used -X- _ O
in -X- _ O
model -X- _ O
pretraining -X- _ O
. -X- _ O
To -X- _ O
mine -X- _ O
these -X- _ O
text -X- _ O
- -X- _ O
based -X- _ O
datasets -X- _ O
, -X- _ O
we -X- _ O
combine -X- _ O
the -X- _ O
sets -X- _ O
of -X- _ O
subjects -X- _ O
in -X- _ O
VG -X- _ O
, -X- _ O
take -X- _ O
the -X- _ O
manual -X- _ O
list -X- _ O
of -X- _ O
attributes -X- _ O
as -X- _ O
objects -X- _ O
again -X- _ O
, -X- _ O
and -X- _ O
extract -X- _ O
( -X- _ O
subject -X- _ O
, -X- _ O
object -X- _ O
) -X- _ O
pairs -X- _ O
if -X- _ O
the -X- _ O
pair -X- _ O
matches -X- _ O
any -X- _ O
of -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
defined -X- _ O
templates -X- _ O
. -X- _ O
In -X- _ O
Section -X- _ O
3.5 -X- _ O
we -X- _ O
will -X- _ O
show -X- _ O
the -X- _ O
advantages -X- _ O
of -X- _ O
the -X- _ O
VG -X- _ O
- -X- _ O
mined -X- _ O
dataset -X- _ O
over -X- _ O
this -X- _ O
text -X- _ O
- -X- _ O
based -X- _ O
dataset -X- _ O
. -X- _ O

Dataset -X- _ O
Evaluation -X- _ O

To -X- _ O
ensure -X- _ O
the -X- _ O
validity -X- _ O
of -X- _ O
ViComTe -X- _ B-DatasetName
, -X- _ O
we -X- _ O
compare -X- _ O
our -X- _ O
color -X- _ O
dataset -X- _ O
with -X- _ O
the -X- _ O
human -X- _ O
- -X- _ O
annotated -X- _ O
CoDa -X- _ B-DatasetName
dataset -X- _ O
( -X- _ O
Paik -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
assume -X- _ O
is -X- _ O
close -X- _ O
to -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
color -X- _ O
distributions -X- _ O
and -X- _ O
has -X- _ O
minimal -X- _ O
reporting -X- _ O
bias -X- _ O
. -X- _ O
We -X- _ O
see -X- _ O
a -X- _ O
reasonably -X- _ O
strong -X- _ O
correlation -X- _ O
with -X- _ O
CoDa -X- _ B-DatasetName
, -X- _ O
indicating -X- _ O
that -X- _ O
the -X- _ O
ViComTe -X- _ B-DatasetName
dataset -X- _ O
is -X- _ O
a -X- _ O
good -X- _ O
and -X- _ O
cost -X- _ O
- -X- _ O
effective -X- _ O
approximation -X- _ O
to -X- _ O
human -X- _ O
annotations -X- _ O
. -X- _ O

Metrics -X- _ O
We -X- _ O
report -X- _ O
the -X- _ O
Spearman -X- _ B-MetricName
's -X- _ I-MetricName
rank -X- _ I-MetricName
- -X- _ I-MetricName
order -X- _ I-MetricName
correlation -X- _ I-MetricName
between -X- _ O
the -X- _ O
two -X- _ O
distributions -X- _ O
in -X- _ O
comparison -X- _ O
, -X- _ O
averaged -X- _ O
across -X- _ O
all -X- _ O
subjects -X- _ O
. -X- _ O
The -X- _ O
Spearman -X- _ B-MetricName
correlation -X- _ I-MetricName
is -X- _ O
used -X- _ O
instead -X- _ O
of -X- _ O
the -X- _ O
Pearson -X- _ O
correlation -X- _ O
since -X- _ O
for -X- _ O
our -X- _ O
purpose -X- _ O
the -X- _ O
rank -X- _ O
of -X- _ O
the -X- _ O
object -X- _ O
distributions -X- _ O
is -X- _ O
more -X- _ O
important -X- _ O
than -X- _ O
the -X- _ O
exact -X- _ O
values -X- _ O
, -X- _ O
which -X- _ O
may -X- _ O
change -X- _ O
due -X- _ O
to -X- _ O
data -X- _ O
variability -X- _ O
. -X- _ O
The -X- _ O
top-1 -X- _ O
accuracy -X- _ B-MetricName
( -X- _ O
Acc -X- _ B-MetricName
@ -X- _ I-MetricName
1 -X- _ I-MetricName
) -X- _ O
is -X- _ O
the -X- _ O
percentage -X- _ O
of -X- _ O
the -X- _ O
objects -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
probability -X- _ O
in -X- _ O
the -X- _ O
source -X- _ O
distributions -X- _ O
matching -X- _ O
those -X- _ O
in -X- _ O
the -X- _ O
target -X- _ O
distributions -X- _ O
. -X- _ O
These -X- _ O
two -X- _ O
metrics -X- _ O
are -X- _ O
also -X- _ O
used -X- _ O
in -X- _ O
later -X- _ O
sections -X- _ O
when -X- _ O
evaluating -X- _ O
model -X- _ O
distributions -X- _ O
. -X- _ O

Analysis -X- _ O
Table -X- _ O
2 -X- _ O
shows -X- _ O
the -X- _ O
detailed -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
evaluation -X- _ O
of -X- _ O
the -X- _ O
ViComTe -X- _ B-DatasetName
and -X- _ O
Wikipedia -X- _ B-DatasetName
color -X- _ I-DatasetName
datasets -X- _ O
by -X- _ O
comparing -X- _ O
with -X- _ O
the -X- _ O
human -X- _ O
- -X- _ O
annotated -X- _ O
dataset -X- _ O
, -X- _ O
CoDa -X- _ B-DatasetName
. -X- _ O
We -X- _ O
can -X- _ O
see -X- _ O
that -X- _ O
ViComTe -X- _ B-DatasetName
has -X- _ O
much -X- _ O
higher -X- _ O
Spearman -X- _ B-MetricName
correlation -X- _ I-MetricName
with -X- _ O
CoDa -X- _ B-DatasetName
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
substantially -X- _ O
higher -X- _ O
top-1 -X- _ O
accuracy -X- _ B-MetricName
for -X- _ O
the -X- _ O
SINGLE -X- _ O
group -X- _ O
. -X- _ O
The -X- _ O
correlation -X- _ B-MetricName
is -X- _ O
expected -X- _ O
to -X- _ O
be -X- _ O
low -X- _ O
for -X- _ O
the -X- _ O
ANY -X- _ O
group -X- _ O
, -X- _ O
because -X- _ O
objects -X- _ O
in -X- _ O
the -X- _ O
ANY -X- _ O
group -X- _ O
can -X- _ O
have -X- _ O
many -X- _ O
possible -X- _ O
colors -X- _ O
. -X- _ O

Reporting -X- _ O
bias -X- _ O
is -X- _ O
present -X- _ O
in -X- _ O
both -X- _ O
datasets -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
average -X- _ O
number -X- _ O
of -X- _ O
occurrences -X- _ O
of -X- _ O
SINGLE -X- _ O
group -X- _ O
subjects -X- _ O
are -X- _ O
much -X- _ O
fewer -X- _ O
than -X- _ O
that -X- _ O
of -X- _ O
the -X- _ O
MULTI -X- _ O
and -X- _ O
ANY -X- _ O
group -X- _ O
subjects -X- _ O
. -X- _ O
Counter -X- _ O
- -X- _ O
intuitively -X- _ O
, -X- _ O
for -X- _ O
ViComTe -X- _ B-DatasetName
, -X- _ O
the -X- _ O
highly -X- _ O
- -X- _ O
correlated -X- _ O
SINGLE -X- _ O
group -X- _ O
subjects -X- _ O
have -X- _ O
fewer -X- _ O
average -X- _ O
occurrences -X- _ O
than -X- _ O
the -X- _ O
ones -X- _ O
with -X- _ O
low -X- _ O
correlations -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
contrary -X- _ O
to -X- _ O
our -X- _ O
expectation -X- _ O
that -X- _ O
more -X- _ O
frequent -X- _ O
objects -X- _ O
would -X- _ O
better -X- _ O
reflect -X- _ O
the -X- _ O
human -X- _ O
- -X- _ O
perceived -X- _ O
distribution -X- _ O
and -X- _ O
can -X- _ O
be -X- _ O
explained -X- _ O
by -X- _ O
SINGLE -X- _ O
subjects -X- _ O
being -X- _ O
easier -X- _ O
to -X- _ O
represent -X- _ O
even -X- _ O
without -X- _ O
a -X- _ O
large -X- _ O
amount -X- _ O
of -X- _ O
data -X- _ O
. -X- _ O

One -X- _ O
example -X- _ O
where -X- _ O
the -X- _ O
Wikipedia -X- _ B-DatasetName
distribution -X- _ O
diverges -X- _ O
from -X- _ O
the -X- _ O
CoDa -X- _ B-DatasetName
distribution -X- _ O
is -X- _ O
" -X- _ O
penguin -X- _ O
" -X- _ O
, -X- _ O
whose -X- _ O
most -X- _ O
likely -X- _ O
color -X- _ O
in -X- _ O
CoDa -X- _ B-DatasetName
is -X- _ O
black -X- _ O
, -X- _ O
followed -X- _ O
by -X- _ O
white -X- _ O
and -X- _ O
gray -X- _ O
; -X- _ O
however -X- _ O
, -X- _ O
its -X- _ O
top -X- _ O
color -X- _ O
in -X- _ O
Wikipedia -X- _ B-DatasetName
is -X- _ O
blue -X- _ O
, -X- _ O
because -X- _ O
" -X- _ O
blue -X- _ O
penguin -X- _ O
" -X- _ O
is -X- _ O
a -X- _ O
specific -X- _ O
species -X- _ O
with -X- _ O
an -X- _ O
entry -X- _ O
in -X- _ O
Wikipedia -X- _ B-DatasetName
, -X- _ O
even -X- _ O
if -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
as -X- _ O
common -X- _ O
as -X- _ O
black -X- _ O
and -X- _ O
white -X- _ O
penguins -X- _ O
. -X- _ O
One -X- _ O
example -X- _ O
where -X- _ O
the -X- _ O
VG -X- _ O
distributions -X- _ O
diverge -X- _ O
from -X- _ O
CoDa -X- _ B-DatasetName
is -X- _ O
" -X- _ O
mouse -X- _ O
" -X- _ O
, -X- _ O
because -X- _ O
in -X- _ O
VG -X- _ O
, -X- _ O
most -X- _ O
occurrences -X- _ O
of -X- _ O
" -X- _ O
mouse -X- _ O
" -X- _ O
are -X- _ O
computer -X- _ O
mice -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
most -X- _ O
commonly -X- _ O
black -X- _ O
, -X- _ O
whereas -X- _ O
when -X- _ O
asked -X- _ O
about -X- _ O
the -X- _ O
word -X- _ O
" -X- _ O
mouse -X- _ O
" -X- _ O
, -X- _ O
human -X- _ O
annotators -X- _ O
typically -X- _ O
think -X- _ O
about -X- _ O
the -X- _ O
animal -X- _ O
, -X- _ O
so -X- _ O
that -X- _ O
the -X- _ O
most -X- _ O
likely -X- _ O
colors -X- _ O
in -X- _ O
CoDa -X- _ B-DatasetName
are -X- _ O
white -X- _ O
and -X- _ O
gray -X- _ O
. -X- _ O
4 -X- _ O

Dataset -X- _ O
splits -X- _ O

Each -X- _ O
of -X- _ O
the -X- _ O
color -X- _ O
, -X- _ O
shape -X- _ O
, -X- _ O
material -X- _ O
, -X- _ O
size -X- _ O
, -X- _ O
and -X- _ O
cooccurrence -X- _ O
datasets -X- _ O
is -X- _ O
split -X- _ O
into -X- _ O
80 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
training -X- _ O
data -X- _ O
and -X- _ O
20 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
test -X- _ O
data -X- _ O
. -X- _ O
All -X- _ O
evaluation -X- _ O
metrics -X- _ O
are -X- _ O
reported -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
. -X- _ O
The -X- _ O
training -X- _ O
set -X- _ O
is -X- _ O
used -X- _ O
for -X- _ O
the -X- _ O
logistic -X- _ O
regression -X- _ O
and -X- _ O
the -X- _ O
soft -X- _ O
prompt -X- _ O
tuning -X- _ O
algorithm -X- _ O
( -X- _ O
Section -X- _ O
4.2 -X- _ O
) -X- _ O
. -X- _ O

Probing -X- _ O
Visual -X- _ B-TaskName
Commonsense -X- _ I-TaskName

Models -X- _ O

We -X- _ O
examine -X- _ O
7 -X- _ O
pretrained -X- _ O
transformer -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
and -X- _ O
2 -X- _ O
variations -X- _ O
of -X- _ O
them -X- _ O
, -X- _ O
trained -X- _ O
on -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
data -X- _ O
. -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
ALBERT -X- _ B-MethodName
( -X- _ O
Lan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
RoBERTa -X- _ B-MethodName
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
are -X- _ O
trained -X- _ O
on -X- _ O
text -X- _ O
only -X- _ O
using -X- _ O
a -X- _ O
masked -X- _ O
language -X- _ O
modeling -X- _ O
objective -X- _ O
( -X- _ O
MLM -X- _ O
) -X- _ O
. -X- _ O
Oscar -X- _ B-MethodName
) -X- _ O
is -X- _ O
a -X- _ O
vision -X- _ O
- -X- _ O
language -X- _ O
model -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
architecture -X- _ O
, -X- _ O
trained -X- _ O
with -X- _ O
an -X- _ O
combined -X- _ O
MLM -X- _ O
and -X- _ O
contrastive -X- _ O
loss -X- _ O
on -X- _ O
text -X- _ O
- -X- _ O
image -X- _ O
pairs -X- _ O
. -X- _ O
VisualBERT -X- _ B-MethodName
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
is -X- _ O
another -X- _ O
vision -X- _ O
- -X- _ O
language -X- _ O
model -X- _ O
based -X- _ O
on -X- _ O
BERT -X- _ B-MethodName
that -X- _ O
learns -X- _ O
joint -X- _ O
representation -X- _ O
of -X- _ O
images -X- _ O
and -X- _ O
text -X- _ O
. -X- _ O
Tan -X- _ O
and -X- _ O
Bansal -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
introduce -X- _ O
the -X- _ O
" -X- _ O
vokenization -X- _ B-MethodName
" -X- _ O
method -X- _ O
, -X- _ O
which -X- _ O
aligns -X- _ O
language -X- _ O
tokens -X- _ O
to -X- _ O
their -X- _ O
related -X- _ O
images -X- _ O
, -X- _ O
mitigating -X- _ O
the -X- _ O
shortcomings -X- _ O
of -X- _ O
models -X- _ O
trained -X- _ O
on -X- _ O
visually -X- _ O
- -X- _ O
grounded -X- _ O
datasets -X- _ O
in -X- _ O
text -X- _ O
- -X- _ O
only -X- _ O
tasks -X- _ O
. -X- _ O
Since -X- _ O
our -X- _ O
task -X- _ O
is -X- _ O
purely -X- _ O
text -X- _ O
- -X- _ O
based -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
experiment -X- _ O
with -X- _ O
a -X- _ O
pretrained -X- _ O
vokenization -X- _ O
model -X- _ O
( -X- _ O
BERT -X- _ B-MethodName
+ -X- _ I-MethodName
VLM -X- _ I-MethodName
on -X- _ O
Wiki -X- _ O
) -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
representations -X- _ O
from -X- _ O
CLIP -X- _ B-MethodName
( -X- _ O
ViT -X- _ O
- -X- _ O
B -X- _ O
/ -X- _ O
32 -X- _ O
) -X- _ O
( -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
trained -X- _ O
with -X- _ O
a -X- _ O
contrastive -X- _ O
image -X- _ O
- -X- _ O
caption -X- _ O
matching -X- _ O
loss -X- _ O
. -X- _ O

Distilled -X- _ B-MethodName
Oscar -X- _ I-MethodName

As -X- _ O
our -X- _ O
experiments -X- _ O
involve -X- _ O
exclusively -X- _ O
textual -X- _ O
inputs -X- _ O
, -X- _ O
we -X- _ O
develop -X- _ O
a -X- _ O
knowledgedistilled -X- _ O
version -X- _ O
of -X- _ O
Oscar -X- _ B-MethodName
( -X- _ O
" -X- _ O
Distilled -X- _ O
" -X- _ O
) -X- _ O
which -X- _ O
corrects -X- _ O
for -X- _ O
the -X- _ O
lack -X- _ O
of -X- _ O
image -X- _ O
input -X- _ O
in -X- _ O
our -X- _ O
task -X- _ O
. -X- _ O
Knowledge -X- _ O
distillation -X- _ O
( -X- _ O
Hinton -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Sanh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
process -X- _ O
of -X- _ O
transferring -X- _ O
knowledge -X- _ O
from -X- _ O
one -X- _ O
model -X- _ O
to -X- _ O
another -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
to -X- _ O
produce -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
. -X- _ O
Here -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
Oscar -X- _ B-MethodName
as -X- _ O
the -X- _ O
teacher -X- _ O
and -X- _ O
BERT -X- _ B-MethodName
as -X- _ O
the -X- _ O
student -X- _ O
. -X- _ O
The -X- _ O
training -X- _ O
data -X- _ O
is -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
Oscar -X- _ B-MethodName
pretraining -X- _ O
corpus -X- _ O
: -X- _ O
COCO -X- _ O
( -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
, -X- _ O
Flickr30k -X- _ O
( -X- _ O
Young -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
GQA -X- _ O
( -X- _ O
Hudson -X- _ O
and -X- _ O
Manning -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
Distilled -X- _ B-MethodName
Oscar -X- _ I-MethodName
model -X- _ O
has -X- _ O
access -X- _ O
to -X- _ O
the -X- _ O
text -X- _ O
data -X- _ O
only -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
Kullback -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
Leibler -X- _ I-HyperparameterName
loss -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
divergence -X- _ O
between -X- _ O
the -X- _ O
output -X- _ O
logits -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
Oscar -X- _ B-MethodName
, -X- _ O
and -X- _ O
optimize -X- _ O
the -X- _ O
pretrained -X- _ O
BERT -X- _ B-MethodName
on -X- _ O
that -X- _ O
loss -X- _ O
to -X- _ O
match -X- _ O
the -X- _ O
outputs -X- _ O
of -X- _ O
Oscar -X- _ O
. -X- _ O
Configurable -X- _ O
parameters -X- _ O
are -X- _ O
set -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
for -X- _ O
Oscar -X- _ B-MethodName
pretraining -X- _ O
. -X- _ O

CaptionBERT -X- _ B-MethodName
Since -X- _ O
VL -X- _ O
models -X- _ O
are -X- _ O
trained -X- _ O
largely -X- _ O
on -X- _ O
caption -X- _ O
data -X- _ O
, -X- _ O
it -X- _ O
could -X- _ O
be -X- _ O
that -X- _ O
the -X- _ O
differences -X- _ O
between -X- _ O
a -X- _ O
text -X- _ O
- -X- _ O
only -X- _ O
model -X- _ O
and -X- _ O
a -X- _ O
VL -X- _ O
model -X- _ O
come -X- _ O
not -X- _ O
from -X- _ O
a -X- _ O
difference -X- _ O
in -X- _ O
modalities -X- _ O
-text -X- _ O
vs. -X- _ O
images -X- _ O
and -X- _ O
text -X- _ O
-but -X- _ O
from -X- _ O
a -X- _ O
difference -X- _ O
in -X- _ O
domainwebtext -X- _ O
vs. -X- _ O
image -X- _ O
captions -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
disentangle -X- _ O
the -X- _ O
effects -X- _ O
of -X- _ O
the -X- _ O
domain -X- _ O
difference -X- _ O
from -X- _ O
those -X- _ O
of -X- _ O
visual -X- _ O
inputs -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
a -X- _ O
BERT -X- _ O
model -X- _ O
from -X- _ O
scratch -X- _ O
( -X- _ O
" -X- _ O
CaptionBERT -X- _ B-MethodName
" -X- _ O
) -X- _ O
on -X- _ O
Oscar -X- _ O
's -X- _ O
caption -X- _ O
- -X- _ O
based -X- _ O
text -X- _ O
data -X- _ O
( -X- _ O
the -X- _ O
same -X- _ O
data -X- _ O
as -X- _ O
for -X- _ O
the -X- _ O
Distilled -X- _ O
model -X- _ O
) -X- _ O
. -X- _ O
If -X- _ O
CaptionBERT -X- _ B-MethodName
, -X- _ O
which -X- _ O
does -X- _ O
not -X- _ O
have -X- _ O
exposure -X- _ O
to -X- _ O
visual -X- _ O
inputs -X- _ O
, -X- _ O
performs -X- _ O
better -X- _ O
than -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
similarly -X- _ O
to -X- _ O
VL -X- _ O
models -X- _ O
( -X- _ O
which -X- _ O
are -X- _ O
trained -X- _ O
with -X- _ O
visual -X- _ O
inputs -X- _ O
) -X- _ O
, -X- _ O
it -X- _ O
would -X- _ O
suggest -X- _ O
that -X- _ O
the -X- _ O
training -X- _ O
domain -X- _ O
matters -X- _ O
more -X- _ O
than -X- _ O
the -X- _ O
modality -X- _ O
. -X- _ O
If -X- _ O
, -X- _ O
on -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
CaptionBERT -X- _ B-MethodName
performs -X- _ O
worse -X- _ O
than -X- _ O
VL -X- _ O
models -X- _ O
, -X- _ O
it -X- _ O
would -X- _ O
highlight -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
modality -X- _ O
. -X- _ O

Evaluation -X- _ O
Methods -X- _ O

We -X- _ O
compare -X- _ O
the -X- _ O
visual -X- _ B-TaskName
commonsense -X- _ I-TaskName
abilities -X- _ O
of -X- _ O
pretrained -X- _ O
unimodal -X- _ B-MethodName
and -X- _ O
multimodal -X- _ B-MethodName
models -X- _ O
. -X- _ O
Given -X- _ O
a -X- _ O
list -X- _ O
of -X- _ O
prompts -X- _ O
and -X- _ O
a -X- _ O
subject -X- _ O
word -X- _ O
, -X- _ O
each -X- _ O
model -X- _ O
outputs -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
word -X- _ O
. -X- _ O
Following -X- _ O
Paik -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
zero -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
shot -X- _ I-HyperparameterName
probes -X- _ I-HyperparameterName
to -X- _ O
models -X- _ O
that -X- _ O
are -X- _ O
trained -X- _ O
on -X- _ O
a -X- _ O
language -X- _ O
modeling -X- _ O
objective -X- _ O
, -X- _ O
and -X- _ O
conduct -X- _ O
representation -X- _ O
probes -X- _ O
for -X- _ O
those -X- _ O
that -X- _ O
are -X- _ O
not -X- _ O
. -X- _ O
We -X- _ O
report -X- _ O
the -X- _ O
prediction -X- _ O
accuracy -X- _ O
and -X- _ O
the -X- _ O
Spearman -X- _ B-MetricName
correlation -X- _ I-MetricName
of -X- _ O
the -X- _ O
output -X- _ O
distribution -X- _ O
with -X- _ O
the -X- _ O
true -X- _ O
distribution -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
models -X- _ O
trained -X- _ O
with -X- _ O
an -X- _ O
MLM -X- _ O
objective -X- _ O
( -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
Distilled -X- _ B-MethodName
, -X- _ O
etc -X- _ O
) -X- _ O
directly -X- _ O
for -X- _ O
zero -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
shot -X- _ I-HyperparameterName
predic -X- _ I-HyperparameterName
- -X- _ I-HyperparameterName
tion -X- _ I-HyperparameterName
of -X- _ O
masked -X- _ O
tokens -X- _ O
. -X- _ O
5 -X- _ O
For -X- _ O
Oscar -X- _ B-MethodName
we -X- _ O
add -X- _ O
a -X- _ O
wordprediction -X- _ O
head -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
it -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
across -X- _ O
templates -X- _ O
are -X- _ O
aggregated -X- _ O
in -X- _ O
two -X- _ O
modes -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
" -X- _ O
best -X- _ O
template -X- _ O
" -X- _ O
mode -X- _ O
, -X- _ O
for -X- _ O
each -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
highest -X- _ O
Spearman -X- _ B-MetricName
correlation -X- _ I-MetricName
among -X- _ O
all -X- _ O
templates -X- _ O
is -X- _ O
reported -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
top-1 -X- _ B-MetricName
result -X- _ O
is -X- _ O
regarded -X- _ O
as -X- _ O
correct -X- _ O
if -X- _ O
the -X- _ O
true -X- _ O
target -X- _ O
object -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
the -X- _ O
top-1 -X- _ B-MetricName
result -X- _ O
of -X- _ O
any -X- _ O
of -X- _ O
the -X- _ O
templates -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
" -X- _ O
average -X- _ O
template -X- _ O
" -X- _ O
mode -X- _ O
, -X- _ O
the -X- _ O
output -X- _ O
distribution -X- _ O
is -X- _ O
the -X- _ O
mean -X- _ O
of -X- _ O
the -X- _ O
distributions -X- _ O
across -X- _ O
all -X- _ O
templates -X- _ O
. -X- _ O

Since -X- _ O
CLIP -X- _ B-MethodName
is -X- _ O
not -X- _ O
trained -X- _ O
on -X- _ O
a -X- _ O
token -X- _ O
- -X- _ O
prediction -X- _ O
objective -X- _ O
, -X- _ O
we -X- _ O
implement -X- _ O
logistic -X- _ O
regression -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
the -X- _ O
frozen -X- _ O
encoder -X- _ O
output -X- _ O
, -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
target -X- _ O
attribute -X- _ O
or -X- _ O
object -X- _ O
. -X- _ O
The -X- _ O
input -X- _ O
is -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
templates -X- _ O
with -X- _ O
the -X- _ O
subject -X- _ O
[ -X- _ O
X -X- _ O
] -X- _ O
filled -X- _ O
with -X- _ O
an -X- _ O
input -X- _ O
in -X- _ O
the -X- _ O
dataset -X- _ O
. -X- _ O
Like -X- _ O
Paik -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
to -X- _ O
give -X- _ O
the -X- _ O
model -X- _ O
ample -X- _ O
chance -X- _ O
of -X- _ O
success -X- _ O
, -X- _ O
we -X- _ O
take -X- _ O
the -X- _ O
template -X- _ O
that -X- _ O
results -X- _ O
in -X- _ O
the -X- _ O
best -X- _ O
test -X- _ O
accuracy -X- _ O
score -X- _ O
, -X- _ O
report -X- _ O
that -X- _ O
accuracy -X- _ O
and -X- _ O
the -X- _ O
Spearman -X- _ O
correlation -X- _ O
associated -X- _ O
with -X- _ O
that -X- _ O
template -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
classification -X- _ O
head -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
Scikit -X- _ O
- -X- _ O
Learn -X- _ O
implementation -X- _ O
of -X- _ O
Logistic -X- _ O
Regression -X- _ O
( -X- _ O
random_state=0 -X- _ O
, -X- _ O
C=0.316 -X- _ O
, -X- _ O
max_iter=2000 -X- _ O
) -X- _ O
( -X- _ O
Pedregosa -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
. -X- _ O

Soft -X- _ O
prompt -X- _ O
tuning -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
overcome -X- _ O
the -X- _ O
limitation -X- _ O
of -X- _ O
self -X- _ O
- -X- _ O
designed -X- _ O
prompts -X- _ O
, -X- _ O
we -X- _ O
incorporate -X- _ O
prompt -X- _ O
tuning -X- _ O
technique -X- _ O
that -X- _ O
learns -X- _ O
soft -X- _ O
prompts -X- _ O
by -X- _ O
gradient -X- _ O
descent -X- _ O
, -X- _ O
from -X- _ O
Qin -X- _ O
and -X- _ O
Eisner -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
6 -X- _ O
The -X- _ O
algorithm -X- _ O
minimizes -X- _ O
the -X- _ O
log -X- _ O
loss -X- _ O
: -X- _ O

( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
∈Er -X- _ O
− -X- _ O
log -X- _ O
t∈Tr -X- _ O
p -X- _ O
( -X- _ O
y|t -X- _ O
, -X- _ O
x -X- _ O
) -X- _ O

for -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
example -X- _ O
pairs -X- _ O
E -X- _ O
r -X- _ O
and -X- _ O
template -X- _ O
set -X- _ O
T -X- _ O
r -X- _ O
. -X- _ O

Size -X- _ O
Evaluation -X- _ O

The -X- _ O
size -X- _ O
dataset -X- _ O
differs -X- _ O
from -X- _ O
the -X- _ O
other -X- _ O
datasets -X- _ O
in -X- _ O
that -X- _ O
we -X- _ O
use -X- _ O
relative -X- _ O
sizes -X- _ O
( -X- _ O
X -X- _ O
is -X- _ O
larger -X- _ O
/ -X- _ O
smaller -X- _ O
than -X- _ O
Y -X- _ O
) -X- _ O
, -X- _ O
as -X- _ O
absolute -X- _ O
size -X- _ O
information -X- _ O
is -X- _ O
hard -X- _ O
to -X- _ O
obtain -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
two -X- _ O
evaluation -X- _ O
strategies -X- _ O
for -X- _ O
size -X- _ O
. -X- _ O

Rank -X- _ O
partition -X- _ O
First -X- _ O
, -X- _ O
as -X- _ O
in -X- _ O
the -X- _ O
previous -X- _ O
prediction -X- _ O
task -X- _ O
, -X- _ O
given -X- _ O
a -X- _ O
template -X- _ O
such -X- _ O
as -X- _ O
" -X- _ O
[ -X- _ O
X -X- _ O
] -X- _ O
is -X- _ O
larger -X- _ O
than -X- _ O
[ -X- _ O
Y -X- _ O
] -X- _ O
" -X- _ O
and -X- _ O
an -X- _ O
object -X- _ O
[ -X- _ O
X -X- _ O
] -X- _ O
, -X- _ O
we -X- _ O
ask -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
[ -X- _ O
Y -X- _ O
] -X- _ O
, -X- _ O
taking -X- _ O
only -X- _ O
the -X- _ O
distribution -X- _ O
D -X- _ O
of -X- _ O
nouns -X- _ O
in -X- _ O
the -X- _ O
size -X- _ O
dataset -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
current -X- _ O
object -X- _ O
[ -X- _ O
X -X- _ O
] -X- _ O
, -X- _ O
we -X- _ O
take -X- _ O
the -X- _ O
nouns -X- _ O
in -X- _ O
size -X- _ O
categories -X- _ O
that -X- _ O
are -X- _ O
smaller -X- _ O
than -X- _ O
the -X- _ O
category -X- _ O
of -X- _ O
[ -X- _ O
X -X- _ O
] -X- _ O
( -X- _ O
N -X- _ O
sm -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
those -X- _ O
that -X- _ O
are -X- _ O
in -X- _ O
larger -X- _ O
categories -X- _ O
( -X- _ O
N -X- _ O
lg -X- _ O
) -X- _ O
. -X- _ O

Let -X- _ O
the -X- _ O
length -X- _ O
of -X- _ O
N -X- _ O
sm -X- _ O
be -X- _ O
m -X- _ O
and -X- _ O
the -X- _ O
length -X- _ O
of -X- _ O
N -X- _ O
lg -X- _ O
be -X- _ O
n. -X- _ O
Then -X- _ O
for -X- _ O
the -X- _ O
" -X- _ O
larger -X- _ O
" -X- _ O
templates -X- _ O
, -X- _ O
we -X- _ O
compute -X- _ O
the -X- _ O
average -X- _ O
percentage -X- _ O
of -X- _ O
overlap -X- _ O
between -X- _ O
the -X- _ O
top -X- _ O
n -X- _ O
objects -X- _ O
in -X- _ O
D -X- _ O
and -X- _ O
N -X- _ O
lg -X- _ O
and -X- _ O
that -X- _ O
between -X- _ O
the -X- _ O
bottom -X- _ O
m -X- _ O
objects -X- _ O
in -X- _ O
D -X- _ O
and -X- _ O
and -X- _ O
N -X- _ O
sm -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
" -X- _ O
smaller -X- _ O
" -X- _ O
templates -X- _ O
, -X- _ O
the -X- _ O
" -X- _ O
top -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
bottom -X- _ O
" -X- _ O
are -X- _ O
reversed -X- _ O
. -X- _ O

Adjective -X- _ O
projection -X- _ O

The -X- _ O
second -X- _ O
approach -X- _ O
follows -X- _ O
that -X- _ O
of -X- _ O
van -X- _ O
Paridon -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
projects -X- _ O
the -X- _ O
word -X- _ O
to -X- _ O
be -X- _ O
evaluated -X- _ O
onto -X- _ O
an -X- _ O
adjective -X- _ O
scale -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
case -X- _ O
, -X- _ O
we -X- _ O
compute -X- _ O
the -X- _ O
word -X- _ O
embeddings -X- _ O
of -X- _ O
the -X- _ O
adjectives -X- _ O
" -X- _ O
small -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
large -X- _ O
" -X- _ O
and -X- _ O
the -X- _ O
nouns -X- _ O
from -X- _ O
models -X- _ O
, -X- _ O
so -X- _ O
the -X- _ O
scale -X- _ O
is -X- _ O
−−→ -X- _ O
large -X- _ O
− -X- _ O
− -X- _ O
−− -X- _ O
→ -X- _ O
small -X- _ O
and -X- _ O
the -X- _ O
projection -X- _ O
is -X- _ O
calculated -X- _ O
by -X- _ O
cosine -X- _ O
similarity -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
for -X- _ O
the -X- _ O
example -X- _ O
noun -X- _ O
" -X- _ O
bear -X- _ O
" -X- _ O
, -X- _ O
the -X- _ O
projection -X- _ O
score -X- _ O
is -X- _ O
given -X- _ O
by -X- _ O
: -X- _ O

cos_sim -X- _ O
( -X- _ O
−−→ -X- _ O
large -X- _ O
− -X- _ O
− -X- _ O
−− -X- _ O
→ -X- _ O
small -X- _ O
, -X- _ O
− -X- _ O
− -X- _ O
→ -X- _ O
bear -X- _ O
) -X- _ O

With -X- _ O
good -X- _ O
word -X- _ O
embeddings -X- _ O
, -X- _ O
larger -X- _ O
nouns -X- _ O
are -X- _ O
expected -X- _ O
to -X- _ O
have -X- _ O
higher -X- _ O
projection -X- _ O
scores -X- _ O
. -X- _ O
The -X- _ O
validity -X- _ O
of -X- _ O
the -X- _ O
adjective -X- _ O
scales -X- _ O
from -X- _ O
word -X- _ O
representations -X- _ O
is -X- _ O
shown -X- _ O
by -X- _ O
Kim -X- _ O
and -X- _ O
de -X- _ O
Marneffe -X- _ O
( -X- _ O
2013 -X- _ O
) -X- _ O
. -X- _ O

Measuring -X- _ O
Model -X- _ O
Reporting -X- _ O
Bias -X- _ O

We -X- _ O
measure -X- _ O
the -X- _ O
reporting -X- _ O
bias -X- _ O
of -X- _ O
our -X- _ O
models -X- _ O
by -X- _ O
comparing -X- _ O
model -X- _ O
performance -X- _ O
on -X- _ O
datasets -X- _ O
with -X- _ O
different -X- _ O
levels -X- _ O
of -X- _ O
reporting -X- _ O
bias -X- _ O
and -X- _ O
on -X- _ O
the -X- _ O
SINGLE -X- _ O
, -X- _ O
MULTI -X- _ O
, -X- _ O
ANY -X- _ O
groups -X- _ O
of -X- _ O
the -X- _ O
ViComTe -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O
We -X- _ O
assume -X- _ O
that -X- _ O
CoDa -X- _ B-DatasetName
contains -X- _ O
no -X- _ O
reporting -X- _ O
bias -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
case -X- _ O
we -X- _ O
can -X- _ O
interpret -X- _ O
Table -X- _ O
2 -X- _ O
as -X- _ O
showing -X- _ O
that -X- _ O
ViComTe -X- _ B-DatasetName
contains -X- _ O
a -X- _ O
relatively -X- _ O
small -X- _ O
amount -X- _ O
of -X- _ O
it -X- _ O
, -X- _ O
and -X- _ O
Wikipedia -X- _ B-DatasetName
contains -X- _ O
a -X- _ O
relatively -X- _ O
large -X- _ O
amount -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
a -X- _ O
larger -X- _ O
correlation -X- _ O
of -X- _ O
model -X- _ O
outputs -X- _ O
with -X- _ O
ViComTe -X- _ B-DatasetName
and -X- _ O
a -X- _ O
smaller -X- _ O
one -X- _ O
with -X- _ O
Wikipedia -X- _ B-DatasetName
would -X- _ O
indicate -X- _ O
less -X- _ O
model -X- _ O
reporting -X- _ O
bias -X- _ O
. -X- _ O

Also -X- _ O
, -X- _ O
since -X- _ O
the -X- _ O
SINGLE -X- _ O
group -X- _ O
subjects -X- _ O
are -X- _ O
those -X- _ O
whose -X- _ O
attribute -X- _ O
distribution -X- _ O
concentrates -X- _ O
on -X- _ O
a -X- _ O
single -X- _ O
attribute -X- _ O
, -X- _ O
these -X- _ O
subject -X- _ O
- -X- _ O
attribute -X- _ O
pairs -X- _ O
are -X- _ O
less -X- _ O
likely -X- _ O
to -X- _ O
be -X- _ O
reported -X- _ O
in -X- _ O
text -X- _ O
corpora -X- _ O
or -X- _ O
even -X- _ O
image -X- _ O
annotations -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
lower -X- _ O
model -X- _ O
correlation -X- _ O
on -X- _ O
the -X- _ O
SINGLE -X- _ O
group -X- _ O
than -X- _ O
the -X- _ O
MULTI -X- _ O
and -X- _ O
the -X- _ O
ANY -X- _ O
groups -X- _ O
would -X- _ O
be -X- _ O
a -X- _ O
sign -X- _ O
of -X- _ O
model -X- _ O
reporting -X- _ O
bias -X- _ O
. -X- _ O

Results -X- _ O

The -X- _ O
experimental -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
multimodal -X- _ B-MethodName
models -X- _ O
outperform -X- _ O
text -X- _ O
- -X- _ O
only -X- _ O
models -X- _ O
, -X- _ O
suggesting -X- _ O
their -X- _ O
advantage -X- _ O
in -X- _ O
capturing -X- _ O
visual -X- _ B-TaskName
commonsense -X- _ I-TaskName
. -X- _ O
However -X- _ O
, -X- _ O
all -X- _ O
models -X- _ O
are -X- _ O
subject -X- _ O
to -X- _ O
the -X- _ O
influence -X- _ O
of -X- _ O
reporting -X- _ O
bias -X- _ O
, -X- _ O
as -X- _ O
they -X- _ O
correlate -X- _ B-MetricName
better -X- _ O
with -X- _ O
the -X- _ O
distributions -X- _ O
from -X- _ O
Wikipedia -X- _ B-DatasetName
than -X- _ O
those -X- _ O
from -X- _ O
CoDa -X- _ B-DatasetName
Table -X- _ O
3 -X- _ O
: -X- _ O
Spearman -X- _ B-MetricName
correlation -X- _ I-MetricName
and -X- _ O
top-1 -X- _ B-MetricName
accuracy -X- _ I-MetricName
( -X- _ O
both -X- _ O
× -X- _ O
100 -X- _ O
) -X- _ O
of -X- _ O
zero -X- _ O
shot -X- _ O
probing -X- _ O
, -X- _ O
before -X- _ O
and -X- _ O
after -X- _ O
soft -X- _ O
prompt -X- _ O
tuning -X- _ O
( -X- _ O
" -X- _ O
N -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
Y -X- _ O
" -X- _ O
for -X- _ O
the -X- _ O
" -X- _ O
Tune -X- _ O
" -X- _ O
column -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
the -X- _ O
" -X- _ O
average -X- _ O
template -X- _ O
" -X- _ O
case -X- _ O
where -X- _ O
the -X- _ O
output -X- _ O
distribution -X- _ O
is -X- _ O
the -X- _ O
mean -X- _ O
of -X- _ O
distributions -X- _ O
across -X- _ O
all -X- _ O
templates -X- _ O
. -X- _ O
The -X- _ O
Spearman -X- _ B-MetricName
correlation -X- _ I-MetricName
reported -X- _ O
is -X- _ O
the -X- _ O
mean -X- _ O
across -X- _ O
all -X- _ O
subjects -X- _ O
± -X- _ O
standard -X- _ O
deviation -X- _ O
, -X- _ O
comparing -X- _ O
the -X- _ O
output -X- _ O
distribution -X- _ O
and -X- _ O
the -X- _ O
Visual -X- _ O
Genome -X- _ O
distribution -X- _ O
. -X- _ O
The -X- _ O
subscripts -X- _ O
b -X- _ O
and -X- _ O
l -X- _ O
indicate -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
, -X- _ O
and -X- _ O
Distilled -X- _ B-MethodName
is -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
after -X- _ O
distilling -X- _ O
from -X- _ O
Oscar -X- _ B-MethodName
. -X- _ O
Asterisk -X- _ O
indicates -X- _ O
where -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
significant -X- _ O
difference -X- _ O
between -X- _ O
BERT -X- _ B-MethodName
b -X- _ O
and -X- _ O
Oscar -X- _ B-MethodName
b -X- _ O
( -X- _ O
t -X- _ O
- -X- _ O
test -X- _ O
p -X- _ O
- -X- _ O
value -X- _ O
> -X- _ O
0.05 -X- _ O
) -X- _ O
. -X- _ O

and -X- _ O
ViComTe -X- _ B-DatasetName
. -X- _ O
Prompt -X- _ O
tuning -X- _ O
and -X- _ O
knowledge -X- _ O
distillation -X- _ O
substantially -X- _ O
enhance -X- _ O
model -X- _ O
performance -X- _ O
, -X- _ O
while -X- _ O
increasing -X- _ O
model -X- _ O
size -X- _ O
does -X- _ O
not -X- _ O
. -X- _ O

Color -X- _ O
, -X- _ O
Shape -X- _ O
, -X- _ O
Material -X- _ O
The -X- _ O
resulting -X- _ O
model -X- _ O
performance -X- _ O
for -X- _ O
the -X- _ O
" -X- _ O
average -X- _ O
template -X- _ O
" -X- _ O
mode -X- _ O
is -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
. -X- _ O
Prompt -X- _ O
tuning -X- _ O
is -X- _ O
done -X- _ O
in -X- _ O
this -X- _ O
mode -X- _ O
only -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
because -X- _ O
the -X- _ O
top-1 -X- _ B-MetricName
accuracy -X- _ I-MetricName
is -X- _ O
taken -X- _ O
among -X- _ O
all -X- _ O
possible -X- _ O
classes -X- _ O
of -X- _ O
each -X- _ O
relation -X- _ O
, -X- _ O
it -X- _ O
should -X- _ O
be -X- _ O
interpreted -X- _ O
together -X- _ O
with -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
classes -X- _ O
( -X- _ O
Table -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
can -X- _ O
see -X- _ O
from -X- _ O
Table -X- _ O
3 -X- _ O
that -X- _ O
Oscar -X- _ B-MethodName
does -X- _ O
better -X- _ O
than -X- _ O
BERT -X- _ B-MethodName
in -X- _ O
almost -X- _ O
all -X- _ O
cases -X- _ O
. -X- _ O
Significant -X- _ O
difference -X- _ O
between -X- _ O
Oscar -X- _ B-MethodName
( -X- _ O
base -X- _ O
) -X- _ O
and -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
base -X- _ O
) -X- _ O
is -X- _ O
seen -X- _ O
in -X- _ O
most -X- _ O
cases -X- _ O
. -X- _ O
Also -X- _ O
, -X- _ O
after -X- _ O
soft -X- _ O
prompt -X- _ O
tuning -X- _ O
, -X- _ O
both -X- _ O
the -X- _ O
Spearman -X- _ B-MetricName
correlation -X- _ I-MetricName
and -X- _ O
the -X- _ O
accuracy -X- _ B-MetricName
substantially -X- _ O
improved -X- _ O
. -X- _ O
Although -X- _ O
there -X- _ O
is -X- _ O
considerable -X- _ O
variation -X- _ O
of -X- _ O
the -X- _ O
Spearman -X- _ B-MetricName
correlations -X- _ I-MetricName
, -X- _ O
we -X- _ O
find -X- _ O
consistent -X- _ O
improvement -X- _ O
per -X- _ O
example -X- _ O
with -X- _ O
both -X- _ O
prompt -X- _ B-HyperparameterName
tuning -X- _ I-HyperparameterName
and -X- _ O
multimodal -X- _ B-HyperparameterName
pretraining -X- _ I-HyperparameterName
( -X- _ O
Appendix -X- _ O
A.2 -X- _ O
) -X- _ O
. -X- _ O

Table -X- _ O
3 -X- _ O
also -X- _ O
shows -X- _ O
that -X- _ O
knowledge -X- _ O
distillation -X- _ O
helps -X- _ O
improve -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
in -X- _ O
all -X- _ O
cases -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
distilled -X- _ O
model -X- _ O
can -X- _ O
sometimes -X- _ O
even -X- _ O
outperform -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
, -X- _ O
Oscar -X- _ B-MethodName
. -X- _ O
Moreover -X- _ O
, -X- _ O
the -X- _ O
large -X- _ O
version -X- _ O
of -X- _ O
each -X- _ O
model -X- _ O
does -X- _ O
not -X- _ O
always -X- _ O
outperform -X- _ O
its -X- _ O
base -X- _ O
counterpart -X- _ O
, -X- _ O
suggesting -X- _ O
that -X- _ O
increasing -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
does -X- _ O
not -X- _ O
enhance -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
ability -X- _ O
to -X- _ O
understand -X- _ O
visual -X- _ B-TaskName
commonsense -X- _ I-TaskName
. -X- _ O
Instead -X- _ O
, -X- _ O
training -X- _ O
with -X- _ O
visually -X- _ O
grounded -X- _ O
data -X- _ O
does -X- _ O
. -X- _ O

Fig -X- _ O
. -X- _ O
2 -X- _ O
illustrates -X- _ O
the -X- _ O
Spearman -X- _ B-MetricName
correlations -X- _ I-MetricName
of -X- _ O
different -X- _ O
models -X- _ O
with -X- _ O
the -X- _ O
color -X- _ O
distributions -X- _ O
from -X- _ O
CoDa -X- _ B-DatasetName
, -X- _ O
ViComTe -X- _ B-DatasetName
and -X- _ O
Wikipedia -X- _ B-DatasetName
, -X- _ O
under -X- _ O
the -X- _ O
" -X- _ O
best -X- _ O
template -X- _ O
" -X- _ O
mode -X- _ O
. -X- _ O
7 -X- _ O
All -X- _ O
models -X- _ O
correlate -X- _ O
moderately -X- _ O
Table -X- _ O
5 -X- _ O
: -X- _ O
Per -X- _ B-MetricName
- -X- _ I-MetricName
group -X- _ I-MetricName
Spearman -X- _ I-MetricName
correlation -X- _ I-MetricName
and -X- _ O
top-1 -X- _ B-MetricName
accuracy -X- _ I-MetricName
( -X- _ O
both -X- _ O
× -X- _ O
100 -X- _ O
) -X- _ O
with -X- _ O
a -X- _ O
logistic -X- _ O
regression -X- _ O
head -X- _ O
on -X- _ O
model -X- _ O
encoder -X- _ O
outputs -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
the -X- _ O
ANY -X- _ O
group -X- _ O
for -X- _ O
shape -X- _ O
only -X- _ O
has -X- _ O
one -X- _ O
example -X- _ O
, -X- _ O
so -X- _ O
the -X- _ O
accuracy -X- _ O
is -X- _ O
less -X- _ O
meaningful -X- _ O
and -X- _ O
is -X- _ O
omitted -X- _ O
. -X- _ O
All -X- _ O
models -X- _ O
have -X- _ O
higher -X- _ O
correlations -X- _ O
in -X- _ O
the -X- _ O
MULTI -X- _ O
and -X- _ O
ANY -X- _ O
groups -X- _ O
than -X- _ O
the -X- _ O
SINGLE -X- _ O
group -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
sign -X- _ O
of -X- _ O
reporting -X- _ O
bias -X- _ O
. -X- _ O

Results -X- _ O
with -X- _ O
Classification -X- _ O
Head -X- _ O

Table -X- _ O
4 -X- _ O
shows -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
CLIP -X- _ B-MethodName
, -X- _ O
and -X- _ O
Oscar -X- _ B-MethodName
when -X- _ O
topped -X- _ O
with -X- _ O
a -X- _ O
classification -X- _ O
head -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
Oscar -X- _ B-MethodName
and -X- _ O
CLIP -X- _ B-MethodName
achieve -X- _ O
similar -X- _ O
performance -X- _ O
and -X- _ O
both -X- _ O
outperform -X- _ O
BERT -X- _ B-MethodName
. -X- _ O
Note -X- _ O
that -X- _ O
, -X- _ O
while -X- _ O
Visual -X- _ O
Genome -X- _ O
is -X- _ O
part -X- _ O
of -X- _ O
Oscar -X- _ B-MethodName
's -X- _ O
pretraining -X- _ O
corpus -X- _ O
and -X- _ O
one -X- _ O
might -X- _ O
suspect -X- _ O
that -X- _ O
that -X- _ O
gives -X- _ O
it -X- _ O
an -X- _ O
advantage -X- _ O
, -X- _ O
CLIP -X- _ B-MethodName
is -X- _ O
trained -X- _ O
on -X- _ O
a -X- _ O
large -X- _ O
corpus -X- _ O
from -X- _ O
web -X- _ O
search -X- _ O
that -X- _ O
is -X- _ O
unrelated -X- _ O
to -X- _ O
Visual -X- _ O
Genome -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
conclude -X- _ O
that -X- _ O
multimodal -X- _ O
models -X- _ O
pretrained -X- _ O
on -X- _ O
both -X- _ O
images -X- _ O
and -X- _ O
text -X- _ O
outperform -X- _ O
text -X- _ O
- -X- _ O
only -X- _ O
models -X- _ O
. -X- _ O
Table -X- _ O
5 -X- _ O
breaks -X- _ O
down -X- _ O
the -X- _ O
results -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
into -X- _ O
three -X- _ O
subject -X- _ O
groups -X- _ O
. -X- _ O
Oscar -X- _ B-MethodName
and -X- _ O
CLIP -X- _ B-MethodName
outperform -X- _ O
BERT -X- _ B-MethodName
in -X- _ O
almost -X- _ O
all -X- _ O
cases -X- _ O
. -X- _ O
The -X- _ O
top-1 -X- _ O
accuracy -X- _ O
is -X- _ O
higher -X- _ O
for -X- _ O
the -X- _ O
SINGLE -X- _ O
group -X- _ O
than -X- _ O
for -X- _ O
the -X- _ O
MULTI -X- _ O
and -X- _ O
ANY -X- _ O
groups -X- _ O
, -X- _ O
perhaps -X- _ O
because -X- _ O
the -X- _ O
SINGLE -X- _ O
group -X- _ O
subjects -X- _ O
have -X- _ O
only -X- _ O
one -X- _ O
most -X- _ O
likely -X- _ O
target -X- _ O
attribute -X- _ O
, -X- _ O
which -X- _ O
may -X- _ O
be -X- _ O
easier -X- _ O
to -X- _ O
predict -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
the -X- _ O
Spearman -X- _ O
correlations -X- _ O
for -X- _ O
all -X- _ O
three -X- _ O
models -X- _ O
become -X- _ O
higher -X- _ O
from -X- _ O
group -X- _ O
SINGLE -X- _ O
to -X- _ O
MULTI -X- _ O
to -X- _ O
ANY -X- _ O
. -X- _ O
Paik -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
argue -X- _ O
that -X- _ O
higher -X- _ O
correlation -X- _ O
for -X- _ O
the -X- _ O
ANY -X- _ O
and -X- _ O
MULTI -X- _ O
groups -X- _ O
is -X- _ O
a -X- _ O
sign -X- _ O
of -X- _ O
model -X- _ O
reporting -X- _ O
bias -X- _ O
, -X- _ O
as -X- _ O
objects -X- _ O
in -X- _ O
those -X- _ O
two -X- _ O
groups -X- _ O
are -X- _ O
more -X- _ O
often -X- _ O
reported -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
the -X- _ O
results -X- _ O
here -X- _ O
indicate -X- _ O
that -X- _ O
reporting -X- _ O
bias -X- _ O
is -X- _ O
still -X- _ O
present -X- _ O
in -X- _ O
multimodal -X- _ O
models -X- _ O
. -X- _ O

Results -X- _ O
: -X- _ O
Size -X- _ O
Relation -X- _ O

Table -X- _ O
6 -X- _ O
shows -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
rank -X- _ B-HyperparameterName
partition -X- _ I-HyperparameterName
method -X- _ O
( -X- _ O
Section -X- _ O
4.3 -X- _ O
) -X- _ O
, -X- _ O
before -X- _ O
and -X- _ O
after -X- _ O
prompt -X- _ B-HyperparameterName
tuning -X- _ I-HyperparameterName
. -X- _ O
Sur- -X- _ O
prisingly -X- _ O
, -X- _ O
prompt -X- _ O
tuning -X- _ O
does -X- _ O
not -X- _ O
help -X- _ O
in -X- _ O
this -X- _ O
case -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
for -X- _ O
the -X- _ O
" -X- _ O
larger -X- _ O
" -X- _ O
templates -X- _ O
is -X- _ O
higher -X- _ O
than -X- _ O
that -X- _ O
of -X- _ O
the -X- _ O
" -X- _ O
smaller -X- _ O
" -X- _ O
templates -X- _ O
, -X- _ O
suggesting -X- _ O
that -X- _ O
the -X- _ O
models -X- _ O
contain -X- _ O
inherent -X- _ O
preference -X- _ O
towards -X- _ O
the -X- _ O
" -X- _ O
larger -X- _ O
" -X- _ O
templates -X- _ O
. -X- _ O
Fig -X- _ O
. -X- _ O
3 -X- _ O
shows -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
adjective -X- _ O
projection -X- _ O
method -X- _ O
. -X- _ O
8 -X- _ O
For -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
Oscar -X- _ B-MethodName
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
average -X- _ O
embedding -X- _ O
of -X- _ O
the -X- _ O
subword -X- _ O
tokens -X- _ O
of -X- _ O
the -X- _ O
nouns -X- _ O
projected -X- _ O
onto -X- _ O
that -X- _ O
of -X- _ O
the -X- _ O
adjectives -X- _ O
" -X- _ O
large -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
small -X- _ O
" -X- _ O
. -X- _ O
For -X- _ O
CLIP -X- _ B-MethodName
, -X- _ O
we -X- _ O
take -X- _ O
the -X- _ O
textual -X- _ O
encoder -X- _ O
outputs -X- _ O
as -X- _ O
the -X- _ O
embeddings -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
a -X- _ O
different -X- _ O
score -X- _ O
range -X- _ O
from -X- _ O
that -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
Oscar -X- _ B-MethodName
. -X- _ O
The -X- _ O
results -X- _ O
show -X- _ O
the -X- _ O
following -X- _ O
trend -X- _ O
: -X- _ O
larger -X- _ O
objects -X- _ O
are -X- _ O
projected -X- _ O
onto -X- _ O
the -X- _ O
" -X- _ O
large -X- _ O
" -X- _ O
end -X- _ O
of -X- _ O
the -X- _ O
spectrum -X- _ O
, -X- _ O
although -X- _ O
the -X- _ O
trend -X- _ O
is -X- _ O
sometimes -X- _ O
broken -X- _ O
towards -X- _ O
the -X- _ O
" -X- _ O
huge -X- _ O
" -X- _ O
end -X- _ O
. -X- _ O
This -X- _ O
may -X- _ O
be -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
" -X- _ O
huge -X- _ O
" -X- _ O
group -X- _ O
including -X- _ O
nouns -X- _ O
such -X- _ O
as -X- _ O
" -X- _ O
pool -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
house -X- _ O
" -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
modified -X- _ O
by -X- _ O
a -X- _ O
relative -X- _ O
size -X- _ O
indicator -X- _ O
" -X- _ O
small -X- _ O
" -X- _ O
. -X- _ O

Analysis -X- _ O
and -X- _ O
Limitations -X- _ O

In -X- _ O
Table -X- _ O
3 -X- _ O
, -X- _ O
the -X- _ O
accuracy -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
for -X- _ O
shape -X- _ O
is -X- _ O
particularly -X- _ O
low -X- _ O
( -X- _ O
only -X- _ O
6.7 -X- _ O
% -X- _ O
) -X- _ O
, -X- _ O
despite -X- _ O
that -X- _ O
shape -X- _ O
has -X- _ O
only -X- _ O
12 -X- _ O
classes -X- _ O
. -X- _ O
We -X- _ O
hypothesize -X- _ O
that -X- _ O
this -X- _ O
is -X- _ O
due -X- _ O
to -X- _ O
reporting -X- _ O
bias -X- _ O
on -X- _ O
shape -X- _ O
in -X- _ O
the -X- _ O
text -X- _ O
corpora -X- _ O
that -X- _ O
BERT -X- _ B-MethodName
is -X- _ O
trained -X- _ O
on -X- _ O
. -X- _ O
This -X- _ O
hypothesis -X- _ O
is -X- _ O
supported -X- _ O
by -X- _ O
mining -X- _ O
sentences -X- _ O
from -X- _ O
Wikipedia -X- _ B-DatasetName
that -X- _ O
contain -X- _ O
( -X- _ O
noun -X- _ O
, -X- _ O
attribute -X- _ O
) -X- _ O
pairs -X- _ O
, -X- _ O
where -X- _ O
we -X- _ O
see -X- _ O
that -X- _ O
the -X- _ O
relation -X- _ O
shape -X- _ O
has -X- _ O
fewer -X- _ O
number -X- _ O
of -X- _ O
occurrences -X- _ O
than -X- _ O
material -X- _ O
and -X- _ O
color -X- _ O
( -X- _ O
Appendix -X- _ O
A.3 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
investigate -X- _ O
whether -X- _ O
the -X- _ O
advantage -X- _ O
of -X- _ O
the -X- _ O
visually -X- _ O
- -X- _ O
grounded -X- _ O
models -X- _ O
over -X- _ O
pure -X- _ O
- -X- _ O
language -X- _ O
models -X- _ O
comes -X- _ O
from -X- _ O
the -X- _ O
domain -X- _ O
difference -X- _ O
between -X- _ O
web -X- _ O
corpora -X- _ O
and -X- _ O
image -X- _ O
captions -X- _ O
, -X- _ O
or -X- _ O
the -X- _ O
presence -X- _ O
of -X- _ O
actual -X- _ O
visual -X- _ O
input -X- _ O
. -X- _ O
Although -X- _ O
its -X- _ O
teacher -X- _ O
is -X- _ O
trained -X- _ O
with -X- _ O
visual -X- _ O
inputs -X- _ O
, -X- _ O
the -X- _ O
Distilled -X- _ B-MethodName
model -X- _ O
is -X- _ O
trained -X- _ O
only -X- _ O
on -X- _ O
captions -X- _ O
data -X- _ O
and -X- _ O
its -X- _ O
performance -X- _ O
matches -X- _ O
that -X- _ O
of -X- _ O
Oscar -X- _ B-MethodName
, -X- _ O
so -X- _ O
we -X- _ O
hypothesize -X- _ O
that -X- _ O
grounded -X- _ O
training -X- _ O
data -X- _ O
enhance -X- _ O
models -X- _ O
' -X- _ O
ability -X- _ O
to -X- _ O
capture -X- _ O
visual -X- _ O
commonsense -X- _ O
. -X- _ O
The -X- _ O
CaptionBERT -X- _ B-MethodName
results -X- _ O
support -X- _ O
the -X- _ O
hypothesis -X- _ O
in -X- _ O
favor -X- _ O
of -X- _ O
domain -X- _ O
difference -X- _ O
, -X- _ O
since -X- _ O
it -X- _ O
performs -X- _ O
better -X- _ O
than -X- _ O
BERT -X- _ B-MethodName
in -X- _ O
both -X- _ O
CoDa -X- _ B-DatasetName
and -X- _ O
VG -X- _ O
( -X- _ O
Fig -X- _ O
. -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O
Nevertheless -X- _ O
, -X- _ O
the -X- _ O
visual -X- _ O
inputs -X- _ O
also -X- _ O
have -X- _ O
an -X- _ O
effect -X- _ O
, -X- _ O
as -X- _ O
Oscar -X- _ B-MethodName
has -X- _ O
a -X- _ O
higher -X- _ O
correlation -X- _ O
than -X- _ O
CaptionBERT -X- _ B-MethodName
on -X- _ O
CoDa -X- _ B-DatasetName
. -X- _ O
Thus -X- _ O
, -X- _ O
it -X- _ O
seems -X- _ O
that -X- _ O
both -X- _ O
domain -X- _ O
and -X- _ O
modality -X- _ O
affect -X- _ O
the -X- _ O
ultimate -X- _ O
model -X- _ O
performance -X- _ O
. -X- _ O

Finally -X- _ O
, -X- _ O
although -X- _ O
multimodal -X- _ B-MethodName
models -X- _ O
show -X- _ O
improvement -X- _ O
on -X- _ O
the -X- _ O
task -X- _ O
, -X- _ O
sometimes -X- _ O
the -X- _ O
improvement -X- _ O
is -X- _ O
not -X- _ O
significant -X- _ O
and -X- _ O
the -X- _ O
resulting -X- _ O
correlations -X- _ B-MetricName
are -X- _ O
still -X- _ O
weak -X- _ O
. -X- _ O
Further -X- _ O
work -X- _ O
is -X- _ O
needed -X- _ O
to -X- _ O
enhance -X- _ O
the -X- _ O
visual -X- _ O
commonsense -X- _ O
abilities -X- _ O
of -X- _ O
the -X- _ O
models -X- _ O
and -X- _ O
mitigate -X- _ O
reporting -X- _ O
bias -X- _ O
, -X- _ O
and -X- _ O
our -X- _ O
datasets -X- _ O
can -X- _ O
serve -X- _ O
as -X- _ O
an -X- _ O
evaluation -X- _ O
method -X- _ O
. -X- _ O

Conclusion -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
probe -X- _ O
knowledge -X- _ O
about -X- _ O
visually -X- _ O
salient -X- _ O
properties -X- _ O
from -X- _ O
pretrained -X- _ O
neural -X- _ O
networks -X- _ O
. -X- _ O
We -X- _ O
automatically -X- _ O
extract -X- _ O
dataset -X- _ O
of -X- _ O
five -X- _ O
visual -X- _ O
relations -X- _ O
: -X- _ O
color -X- _ O
, -X- _ O
shape -X- _ O
, -X- _ O
material -X- _ O
, -X- _ O
size -X- _ O
, -X- _ O
and -X- _ O
cooccurrence -X- _ O
, -X- _ O
and -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
ViComTe -X- _ B-DatasetName
dataset -X- _ O
has -X- _ O
a -X- _ O
much -X- _ O
higher -X- _ O
correlation -X- _ B-MetricName
with -X- _ O
human -X- _ O
perception -X- _ O
data -X- _ O
for -X- _ O
color -X- _ O
than -X- _ O
data -X- _ O
mined -X- _ O
from -X- _ O
Wikipedia -X- _ B-DatasetName
. -X- _ O
We -X- _ O
then -X- _ O
apply -X- _ O
several -X- _ O
probing -X- _ O
techniques -X- _ O
and -X- _ O
discover -X- _ O
that -X- _ O
visually -X- _ O
- -X- _ O
supervised -X- _ O
models -X- _ O
perform -X- _ O
better -X- _ O
than -X- _ O
pure -X- _ O
language -X- _ O
models -X- _ O
, -X- _ O
which -X- _ O
indicates -X- _ O
that -X- _ O
they -X- _ O
can -X- _ O
better -X- _ O
capture -X- _ O
such -X- _ O
visual -X- _ O
properties -X- _ O
. -X- _ O
Distilling -X- _ O
the -X- _ O
knowledge -X- _ O
from -X- _ O
a -X- _ O
visually -X- _ O
- -X- _ O
supervised -X- _ O
model -X- _ O
into -X- _ O
a -X- _ O
pure -X- _ O
language -X- _ O
model -X- _ O
results -X- _ O
in -X- _ O
comparable -X- _ O
performance -X- _ O
with -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
observe -X- _ O
less -X- _ O
reporting -X- _ O
bias -X- _ O
in -X- _ O
both -X- _ O
visually -X- _ O
- -X- _ O
grounded -X- _ O
text -X- _ O
( -X- _ O
VG -X- _ O
- -X- _ O
mined -X- _ O
datasets -X- _ O
) -X- _ O
than -X- _ O
Wikipedia -X- _ O
text -X- _ O
and -X- _ O
visually -X- _ O
- -X- _ O
grounded -X- _ O
models -X- _ O
( -X- _ O
Oscar -X- _ B-MethodName
, -X- _ O
DistilledOscar -X- _ B-MethodName
, -X- _ O
VisualBERT -X- _ B-MethodName
, -X- _ O
and -X- _ O
CLIP -X- _ B-MethodName
) -X- _ O
than -X- _ O
pure -X- _ O
language -X- _ O
models -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
visuallygrounded -X- _ O
models -X- _ O
are -X- _ O
still -X- _ O
subject -X- _ O
to -X- _ O
the -X- _ O
influence -X- _ O
of -X- _ O
reporting -X- _ O
bias -X- _ O
, -X- _ O
as -X- _ O
seen -X- _ O
in -X- _ O
the -X- _ O
per -X- _ O
- -X- _ O
group -X- _ O
analysis -X- _ O
, -X- _ O
where -X- _ O
both -X- _ O
types -X- _ O
of -X- _ O
models -X- _ O
perform -X- _ O
better -X- _ O
for -X- _ O
the -X- _ O
MULTI -X- _ O
group -X- _ O
than -X- _ O
the -X- _ O
SINGLE -X- _ O
group -X- _ O
. -X- _ O

A -X- _ O
Appendix -X- _ O

A.1 -X- _ O
List -X- _ O
of -X- _ O
Objects -X- _ O

Table -X- _ O
7 -X- _ O
shows -X- _ O
the -X- _ O
list -X- _ O
of -X- _ O
all -X- _ O
possible -X- _ O
attributes -X- _ O
for -X- _ O
relations -X- _ O
color -X- _ O
, -X- _ O
shape -X- _ O
, -X- _ O
and -X- _ O
material -X- _ O
. -X- _ O
Table -X- _ O
8 -X- _ O
shows -X- _ O
the -X- _ O
list -X- _ O
of -X- _ O
objects -X- _ O
in -X- _ O
the -X- _ O
five -X- _ O
categories -X- _ O
of -X- _ O
relation -X- _ O
size -X- _ O
. -X- _ O
Visual -X- _ O
co -X- _ O
- -X- _ O
ocurrence -X- _ O
has -X- _ O
a -X- _ O
large -X- _ O
number -X- _ O
of -X- _ O
objects -X- _ O
that -X- _ O
are -X- _ O
not -X- _ O
listed -X- _ O
here -X- _ O
for -X- _ O
space -X- _ O
reasons -X- _ O
. -X- _ O

A.2 -X- _ O
Additional -X- _ O
Probing -X- _ O

Best -X- _ O
template -X- _ O
mode -X- _ O
Table -X- _ O
9 -X- _ O
contains -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
results -X- _ O
under -X- _ O
the -X- _ O
" -X- _ O
best -X- _ O
template -X- _ O
" -X- _ O
mode -X- _ O
, -X- _ O
for -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
base -X- _ O
) -X- _ O
, -X- _ O
Oscar -X- _ B-MethodName
( -X- _ O
base -X- _ O
) -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
distilled -X- _ O
from -X- _ O
Oscar -X- _ B-MethodName
, -X- _ O
RoBERTa -X- _ B-MethodName
( -X- _ O
base -X- _ O
) -X- _ O
, -X- _ O
ALBERT -X- _ B-MethodName
( -X- _ O
base -X- _ O
) -X- _ O
, -X- _ O
Vokenization -X- _ B-MethodName
, -X- _ O
and -X- _ O
VisualBERT -X- _ B-MethodName
( -X- _ O
base -X- _ O
) -X- _ O
. -X- _ O
These -X- _ O
results -X- _ O
demonstrate -X- _ O
similar -X- _ O
trends -X- _ O
as -X- _ O
the -X- _ O
ones -X- _ O
in -X- _ O
the -X- _ O
" -X- _ O
average -X- _ O
template -X- _ O
" -X- _ O
mode -X- _ O
. -X- _ O
Per -X- _ O
- -X- _ O
object -X- _ O
analysis -X- _ O
Fig -X- _ O
. -X- _ O
4 -X- _ O
illustrates -X- _ O
the -X- _ O
finegrained -X- _ O
Spearman -X- _ B-MetricName
correlation -X- _ I-MetricName
± -X- _ O
standard -X- _ O
deviation -X- _ O
per -X- _ O
object -X- _ O
group -X- _ O
for -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
CLIP -X- _ O
. -X- _ O
Size -X- _ O
per -X- _ O
- -X- _ O
object -X- _ O
Fig -X- _ O
. -X- _ O
5 -X- _ O
shows -X- _ O
how -X- _ O
the -X- _ O
per -X- _ O
- -X- _ O
object -X- _ O
projection -X- _ O
scores -X- _ O
on -X- _ O
the -X- _ O
size -X- _ O
spectrum -X- _ O
from -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
Oscar -X- _ O
are -X- _ O
correlated -X- _ O
. -X- _ O
Per -X- _ O
- -X- _ O
Subject -X- _ O
Comparison -X- _ O
Fig -X- _ O
. -X- _ O
6 -X- _ O
and -X- _ O
Fig -X- _ O
. -X- _ O
7 -X- _ O
show -X- _ O
how -X- _ O
the -X- _ O
Spearman -X- _ B-MetricName
correlations -X- _ I-MetricName
of -X- _ O
10 -X- _ O
individual -X- _ O
subjects -X- _ O
improve -X- _ O
after -X- _ O
soft -X- _ O
prompt -X- _ O
tuning -X- _ O
and -X- _ O
after -X- _ O
multimodal -X- _ O
pretraining -X- _ O
. -X- _ O
Consistent -X- _ O
improvement -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
in -X- _ O
color -X- _ O
, -X- _ O
material -X- _ O
, -X- _ O
and -X- _ O
cooccurrence -X- _ O
. -X- _ O
Although -X- _ O
we -X- _ O
report -X- _ O
average -X- _ O
Spearman -X- _ B-MetricName
correlations -X- _ I-MetricName
in -X- _ O
Table -X- _ O
3 -X- _ O
and -X- _ O
there -X- _ O
are -X- _ O
large -X- _ O
standard -X- _ O
deviations -X- _ O
, -X- _ O
here -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
when -X- _ O
improvement -X- _ O
is -X- _ O
observed -X- _ O
collectively -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
also -X- _ O
consistent -X- _ O
across -X- _ O
subjects -X- _ O
. -X- _ O
With -X- _ O
shape -X- _ O
, -X- _ O
the -X- _ O
improvement -X- _ O
is -X- _ O
less -X- _ O
obvious -X- _ O
( -X- _ O
45.9 -X- _ B-MetricValue
to -X- _ O
50.4 -X- _ B-MetricValue
for -X- _ O
prompt -X- _ B-HyperparameterName
tuning -X- _ I-HyperparameterName
and -X- _ O
49.2 -X- _ B-MetricValue
to -X- _ O
50.4 -X- _ B-MetricValue
for -X- _ O
multimodal -X- _ B-HyperparameterName
pretraining -X- _ I-HyperparameterName
) -X- _ O
. -X- _ O

A.3 -X- _ O
Error -X- _ O
Analysis -X- _ O

Data -X- _ O
The -X- _ O
three -X- _ O
subjects -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
and -X- _ O
lowest -X- _ O
Spearman -X- _ B-MetricName
correlation -X- _ I-MetricName
are -X- _ O
shown -X- _ O
in -X- _ O
Fig -X- _ O
. -X- _ O
8 -X- _ O
and -X- _ O
Fig -X- _ O
. -X- _ O
9 -X- _ O
. -X- _ O

Wikipedia -X- _ B-DatasetName
Table -X- _ O
10 -X- _ O
shows -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
( -X- _ O
noun -X- _ O
, -X- _ O
attribute -X- _ O
) -X- _ O
pairs -X- _ O
of -X- _ O
the -X- _ O
three -X- _ O
relation -X- _ O
types -X- _ O
in -X- _ O
Wikipedia -X- _ B-DatasetName
. -X- _ O
Shape -X- _ O
has -X- _ O
fewer -X- _ O
occurrences -X- _ O
than -X- _ O
material -X- _ O
and -X- _ O
color -X- _ O
. -X- _ O
Model -X- _ O
Table -X- _ O
11 -X- _ O
shows -X- _ O
the -X- _ O
errors -X- _ O
made -X- _ O
by -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
Oscar -X- _ B-MethodName
in -X- _ O
the -X- _ O
" -X- _ O
average -X- _ O
template -X- _ O
" -X- _ O
mode -X- _ O
before -X- _ O
prompt -X- _ O
tuning -X- _ O
. -X- _ O
Overall -X- _ O
, -X- _ O
subjects -X- _ O
with -X- _ O
low -X- _ O
correlation -X- _ O
are -X- _ O
those -X- _ O
that -X- _ O
are -X- _ O
less -X- _ O
often -X- _ O
reported -X- _ O
in -X- _ O
Visual -X- _ O
Genome -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
in -X- _ O
textual -X- _ O
data -X- _ O
. -X- _ O

Acknowledgments -X- _ O

We -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
thank -X- _ O
the -X- _ O
reviewers -X- _ O
for -X- _ O
their -X- _ O
comments -X- _ O
and -X- _ O
suggestions -X- _ O
. -X- _ O
Chenyu -X- _ O
Zhang -X- _ O
is -X- _ O
supported -X- _ O
by -X- _ O
the -X- _ O
Pistritto -X- _ O
Research -X- _ O
Fellowship -X- _ O
. -X- _ O
Elias -X- _ O
Stengel -X- _ O
- -X- _ O
Eskin -X- _ O
is -X- _ O
supported -X- _ O
by -X- _ O
an -X- _ O
NSF -X- _ O
Graduate -X- _ O
Research -X- _ O
Fellowship -X- _ O
. -X- _ O
Zhuowan -X- _ O
Li -X- _ O
is -X- _ O
supported -X- _ O
by -X- _ O
NSF -X- _ O
1763705 -X- _ O
. -X- _ O

