-DOCSTART- -X- O
Zero -X- _ O
- -X- _ O
Shot -X- _ O
Cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
Semantic -X- _ I-TaskName
Parsing -X- _ I-TaskName

Recent -X- _ O
work -X- _ O
in -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
semantic -X- _ I-TaskName
parsing -X- _ I-TaskName
has -X- _ O
successfully -X- _ O
applied -X- _ O
machine -X- _ O
translation -X- _ O
to -X- _ O
localize -X- _ O
parsers -X- _ O
to -X- _ O
new -X- _ O
languages -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
these -X- _ O
advances -X- _ O
assume -X- _ O
access -X- _ O
to -X- _ O
highquality -X- _ O
machine -X- _ O
translation -X- _ O
systems -X- _ O
and -X- _ O
word -X- _ O
alignment -X- _ O
tools -X- _ O
. -X- _ O
We -X- _ O
remove -X- _ O
these -X- _ O
assumptions -X- _ O
and -X- _ O
study -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
semantic -X- _ I-TaskName
parsing -X- _ I-TaskName
as -X- _ O
a -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
problem -X- _ O
, -X- _ O
without -X- _ O
parallel -X- _ O
data -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
utterance -X- _ O
- -X- _ O
logical -X- _ O
form -X- _ O
pairs -X- _ O
) -X- _ O
for -X- _ O
new -X- _ O
languages -X- _ O
. -X- _ O
We -X- _ O
propose -X- _ O
a -X- _ O
multi -X- _ B-MethodName
- -X- _ I-MethodName
task -X- _ I-MethodName
encoderdecoder -X- _ I-MethodName
model -X- _ O
to -X- _ O
transfer -X- _ O
parsing -X- _ O
knowledge -X- _ O
to -X- _ O
additional -X- _ O
languages -X- _ O
using -X- _ O
only -X- _ O
Englishlogical -X- _ O
form -X- _ O
paired -X- _ O
data -X- _ O
and -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
natural -X- _ O
language -X- _ O
corpora -X- _ O
in -X- _ O
each -X- _ O
new -X- _ O
language -X- _ O
. -X- _ O
Our -X- _ O
model -X- _ O
encourages -X- _ O
language -X- _ B-MethodName
- -X- _ I-MethodName
agnostic -X- _ I-MethodName
encodings -X- _ I-MethodName
by -X- _ O
jointly -X- _ O
optimizing -X- _ O
for -X- _ O
logical -X- _ O
- -X- _ O
form -X- _ O
generation -X- _ O
with -X- _ O
auxiliary -X- _ O
objectives -X- _ O
designed -X- _ O
for -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
latent -X- _ O
representation -X- _ O
alignment -X- _ O
. -X- _ O
Our -X- _ O
parser -X- _ O
performs -X- _ O
significantly -X- _ O
above -X- _ O
translation -X- _ O
- -X- _ O
based -X- _ O
baselines -X- _ O
and -X- _ O
, -X- _ O
in -X- _ O
some -X- _ O
cases -X- _ O
, -X- _ O
competes -X- _ O
with -X- _ O
the -X- _ O
supervised -X- _ O
upper -X- _ O
- -X- _ O
bound -X- _ O
. -X- _ O
1 -X- _ O

Introduction -X- _ O

Executable -X- _ O
semantic -X- _ O
parsing -X- _ O
maps -X- _ O
a -X- _ O
natural -X- _ O
language -X- _ O
utterance -X- _ O
to -X- _ O
a -X- _ O
logical -X- _ O
form -X- _ O
( -X- _ O
LF -X- _ O
) -X- _ O
for -X- _ O
execution -X- _ O
in -X- _ O
some -X- _ O
knowledge -X- _ O
base -X- _ O
to -X- _ O
return -X- _ O
a -X- _ O
denotation -X- _ O
. -X- _ O
The -X- _ O
parsing -X- _ O
task -X- _ O
renders -X- _ O
an -X- _ O
utterance -X- _ O
as -X- _ O
a -X- _ O
semantically -X- _ O
identical -X- _ O
, -X- _ O
but -X- _ O
machine -X- _ O
- -X- _ O
interpretable -X- _ O
, -X- _ O
expression -X- _ O
grounded -X- _ O
in -X- _ O
a -X- _ O
denotation -X- _ O
. -X- _ O
The -X- _ O
transduction -X- _ O
between -X- _ O
natural -X- _ O
and -X- _ O
formal -X- _ O
languages -X- _ O
has -X- _ O
allowed -X- _ O
semantic -X- _ O
parsers -X- _ O
to -X- _ O
become -X- _ O
critical -X- _ O
infrastructure -X- _ O
in -X- _ O
building -X- _ O
human -X- _ O
- -X- _ O
computer -X- _ O
interfaces -X- _ O
for -X- _ O
question -X- _ O
answering -X- _ O
, -X- _ O
( -X- _ O
Berant -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
; -X- _ O
Liang -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Kollar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
dialog -X- _ O
systems -X- _ O
( -X- _ O
Artzi -X- _ O
and -X- _ O
Zettlemoyer -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
robotics -X- _ O
( -X- _ O
Dukes -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O

Recent -X- _ O
advances -X- _ O
in -X- _ O
semantic -X- _ B-TaskName
parsing -X- _ I-TaskName
have -X- _ O
improved -X- _ O
accuracy -X- _ O
for -X- _ O
neural -X- _ O
parsers -X- _ O
( -X- _ O
Jia -X- _ O
and -X- _ O
Liang -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Dong -X- _ O
and -X- _ O
Lapata -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
and -X- _ O
examined -X- _ O
their -X- _ O
generalization -X- _ O
capabilities -X- _ O
with -X- _ O
new -X- _ O
dataset -X- _ O
challenges -X- _ O
( -X- _ O
Zhong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Yu -X- _ O
1 -X- _ O
Our -X- _ O
code -X- _ O
and -X- _ O
data -X- _ O
are -X- _ O
available -X- _ O
at -X- _ O
github.com -X- _ O
/ -X- _ O
tomsherborne -X- _ O
/ -X- _ O
zx-parse -X- _ O
. -X- _ O
The -X- _ O
encoder -X- _ O
generates -X- _ O
a -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
English -X- _ O
utterance -X- _ O
( -X- _ O
blue -X- _ O
points -X- _ O
) -X- _ O
to -X- _ O
condition -X- _ O
upon -X- _ O
during -X- _ O
decoding -X- _ O
. -X- _ O
Producing -X- _ O
the -X- _ O
same -X- _ O
logical -X- _ O
form -X- _ O
from -X- _ O
the -X- _ O
equivalent -X- _ O
Chinese -X- _ O
utterance -X- _ O
requires -X- _ O
a -X- _ O
similar -X- _ O
encoding -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
without -X- _ O
alignment -X- _ O
, -X- _ O
the -X- _ O
representation -X- _ O
may -X- _ O
partially -X- _ O
match -X- _ O
( -X- _ O
purple -X- _ O
points -X- _ O
) -X- _ O
or -X- _ O
not -X- _ O
at -X- _ O
all -X- _ O
( -X- _ O
red -X- _ O
points -X- _ O
) -X- _ O
, -X- _ O
leading -X- _ O
the -X- _ O
decoder -X- _ O
to -X- _ O
generate -X- _ O
an -X- _ O
inaccurate -X- _ O
, -X- _ O
ill -X- _ O
- -X- _ O
formed -X- _ O
query -X- _ O
. -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
in -X- _ O
addition -X- _ O
to -X- _ O
considering -X- _ O
languages -X- _ O
other -X- _ O
than -X- _ O
English -X- _ O
( -X- _ O
Duong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
inter -X- _ O
alia -X- _ O
. -X- _ O
) -X- _ O
. -X- _ O

Prior -X- _ O
work -X- _ O
largely -X- _ O
assumes -X- _ O
that -X- _ O
utterance -X- _ O
- -X- _ O
logical -X- _ O
form -X- _ O
training -X- _ O
data -X- _ O
is -X- _ O
parallel -X- _ O
in -X- _ O
all -X- _ O
languages -X- _ O
( -X- _ O
Jie -X- _ O
and -X- _ O
Lu -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
, -X- _ O
or -X- _ O
must -X- _ O
be -X- _ O
created -X- _ O
with -X- _ O
human -X- _ O
translation -X- _ O
( -X- _ O
Susanto -X- _ O
and -X- _ O
Lu -X- _ O
, -X- _ O
2017a -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
entry -X- _ O
barrier -X- _ O
to -X- _ O
localization -X- _ O
for -X- _ O
new -X- _ O
languages -X- _ O
has -X- _ O
motivated -X- _ O
the -X- _ O
exploration -X- _ O
of -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
( -X- _ O
MT -X- _ B-TaskName
) -X- _ O
as -X- _ O
an -X- _ O
economical -X- _ O
alternative -X- _ O
( -X- _ O
Sherborne -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Moradshahi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
MT -X- _ B-TaskName
can -X- _ O
introduce -X- _ O
performance -X- _ O
- -X- _ O
limiting -X- _ O
artifacts -X- _ O
and -X- _ O
struggle -X- _ O
to -X- _ O
accurately -X- _ O
model -X- _ O
native -X- _ O
speakers -X- _ O
( -X- _ O
Riley -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
high -X- _ O
- -X- _ O
quality -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
is -X- _ O
less -X- _ O
viable -X- _ O
for -X- _ O
lower -X- _ O
resource -X- _ O
languages -X- _ O
, -X- _ O
further -X- _ O
limiting -X- _ O
the -X- _ O
appeal -X- _ O
of -X- _ O
MT -X- _ B-TaskName
- -X- _ O
based -X- _ O
approaches -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
new -X- _ O
approach -X- _ O
for -X- _ O
zero -X- _ B-MethodName
- -X- _ I-MethodName
shot -X- _ I-MethodName
executable -X- _ I-MethodName
semantic -X- _ I-MethodName
parsing -X- _ I-MethodName
. -X- _ O
Our -X- _ O
method -X- _ O
maximizes -X- _ O
the -X- _ O
success -X- _ O
of -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
transfer -X- _ O
for -X- _ O
a -X- _ O
parser -X- _ O
, -X- _ O
trained -X- _ O
on -X- _ O
English -X- _ O
paired -X- _ O
data -X- _ O
( -X- _ O
EN -X- _ O
→ -X- _ O
LF -X- _ O
) -X- _ O
, -X- _ O
to -X- _ O
accurately -X- _ O
generate -X- _ O
logical -X- _ O
forms -X- _ O
from -X- _ O
new -X- _ O
languages -X- _ O
( -X- _ O
X -X- _ O
→ -X- _ O
LF -X- _ O
) -X- _ O
. -X- _ O
Our -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
parse -X- _ O
utterances -X- _ O
in -X- _ O
a -X- _ O
new -X- _ O
language -X- _ O
, -X- _ O
l -X- _ O
, -X- _ O
without -X- _ O
observing -X- _ O
paired -X- _ O
training -X- _ O
data -X- _ O
for -X- _ O
this -X- _ O
language -X- _ O
, -X- _ O
suitable -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
, -X- _ O
or -X- _ O
bilingual -X- _ O
dictionaries -X- _ O
between -X- _ O
l -X- _ O
and -X- _ O
English -X- _ O
. -X- _ O
Our -X- _ O
critical -X- _ O
dependencies -X- _ O
are -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
model -X- _ O
and -X- _ O
utterancelogical -X- _ O
form -X- _ O
paired -X- _ O
data -X- _ O
for -X- _ O
a -X- _ O
source -X- _ O
language -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
English -X- _ O
) -X- _ O
. -X- _ O
Aside -X- _ O
from -X- _ O
the -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
problem -X- _ O
which -X- _ O
is -X- _ O
hard -X- _ O
on -X- _ O
its -X- _ O
own -X- _ O
( -X- _ O
since -X- _ O
paired -X- _ O
data -X- _ O
is -X- _ O
not -X- _ O
available -X- _ O
for -X- _ O
new -X- _ O
languages -X- _ O
) -X- _ O
, -X- _ O
our -X- _ O
semantic -X- _ B-TaskName
parsing -X- _ I-TaskName
challenge -X- _ O
is -X- _ O
further -X- _ O
compounded -X- _ O
with -X- _ O
the -X- _ O
difficulties -X- _ O
inherent -X- _ O
to -X- _ O
structured -X- _ O
prediction -X- _ O
and -X- _ O
the -X- _ O
deficiency -X- _ O
of -X- _ O
copying -X- _ O
strategies -X- _ O
without -X- _ O
gold -X- _ O
tokenlevel -X- _ O
alignment -X- _ O
( -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
conceptualize -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
semantic -X- _ I-TaskName
parsing -X- _ I-TaskName
as -X- _ O
a -X- _ O
latent -X- _ O
representation -X- _ O
alignment -X- _ O
problem -X- _ O
. -X- _ O
As -X- _ O
illustrated -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
we -X- _ O
wish -X- _ O
to -X- _ O
encode -X- _ O
different -X- _ O
languages -X- _ O
to -X- _ O
an -X- _ O
overlapping -X- _ O
latent -X- _ O
space -X- _ O
for -X- _ O
the -X- _ O
decoder -X- _ O
to -X- _ O
have -X- _ O
any -X- _ O
chance -X- _ O
at -X- _ O
generating -X- _ O
accurate -X- _ O
logical -X- _ O
forms -X- _ O
. -X- _ O
To -X- _ O
achieve -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
a -X- _ O
decoder -X- _ O
, -X- _ O
conditioned -X- _ O
upon -X- _ O
encodings -X- _ O
from -X- _ O
a -X- _ O
source -X- _ O
language -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
English -X- _ O
) -X- _ O
, -X- _ O
to -X- _ O
generate -X- _ O
logical -X- _ O
forms -X- _ O
and -X- _ O
simultaneously -X- _ O
train -X- _ O
encodings -X- _ O
of -X- _ O
a -X- _ O
new -X- _ O
language -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
Chinese -X- _ O
) -X- _ O
to -X- _ O
be -X- _ O
maximally -X- _ O
similar -X- _ O
to -X- _ O
English -X- _ O
. -X- _ O
We -X- _ O
hypothesize -X- _ O
that -X- _ O
if -X- _ O
latent -X- _ O
representations -X- _ O
are -X- _ O
aligned -X- _ O
from -X- _ O
a -X- _ O
language -X- _ O
- -X- _ O
agnostic -X- _ O
encoder -X- _ O
, -X- _ O
one -X- _ O
can -X- _ O
generate -X- _ O
accurate -X- _ O
logical -X- _ O
forms -X- _ O
from -X- _ O
a -X- _ O
new -X- _ O
language -X- _ O
without -X- _ O
semantic -X- _ B-TaskName
parsing -X- _ I-TaskName
training -X- _ O
data -X- _ O
and -X- _ O
thus -X- _ O
eliminate -X- _ O
the -X- _ O
errors -X- _ O
outlined -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
. -X- _ O

Our -X- _ O
approach -X- _ O
adopts -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
learning -X- _ O
paradigm -X- _ O
and -X- _ O
trains -X- _ O
a -X- _ O
parser -X- _ O
with -X- _ O
auxiliary -X- _ O
objectives -X- _ O
, -X- _ O
optimized -X- _ O
to -X- _ O
converge -X- _ O
representations -X- _ O
of -X- _ O
additional -X- _ O
new -X- _ O
languages -X- _ O
. -X- _ O
We -X- _ O
encourage -X- _ O
languageagnostic -X- _ O
representations -X- _ O
by -X- _ O
jointly -X- _ O
optimizing -X- _ O
for -X- _ O
generating -X- _ O
logical -X- _ O
forms -X- _ O
, -X- _ O
reconstructing -X- _ O
natural -X- _ O
language -X- _ O
, -X- _ O
and -X- _ O
promoting -X- _ O
language -X- _ O
invariance -X- _ O
. -X- _ O
Our -X- _ O
intuition -X- _ O
is -X- _ O
that -X- _ O
auxiliary -X- _ O
losses -X- _ O
can -X- _ O
be -X- _ O
exploited -X- _ O
to -X- _ O
induce -X- _ O
similarity -X- _ O
in -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
lingual -X- _ O
latent -X- _ O
space -X- _ O
. -X- _ O
The -X- _ O
effect -X- _ O
of -X- _ O
such -X- _ O
alignment -X- _ O
is -X- _ O
that -X- _ O
a -X- _ O
decoder -X- _ O
, -X- _ O
trained -X- _ O
only -X- _ O
on -X- _ O
English -X- _ O
, -X- _ O
can -X- _ O
recognize -X- _ O
an -X- _ O
encoding -X- _ O
from -X- _ O
another -X- _ O
language -X- _ O
and -X- _ O
generate -X- _ O
the -X- _ O
relevant -X- _ O
logical -X- _ O
form -X- _ O
. -X- _ O
Similar -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
approaches -X- _ O
have -X- _ O
been -X- _ O
successful -X- _ O
in -X- _ O
spoken -X- _ O
- -X- _ O
language -X- _ O
understanding -X- _ O
( -X- _ O
van -X- _ O
der -X- _ O
Goot -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
text -X- _ O
simplification -X- _ O
( -X- _ O
Mallinson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
, -X- _ O
dependency -X- _ O
parsing -X- _ O
( -X- _ O
Ahmad -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019b -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
machine -X- _ O
translation -X- _ O
( -X- _ O
Arivazhagan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
work -X- _ O
, -X- _ O
to -X- _ O
our -X- _ O
knowledge -X- _ O
is -X- _ O
the -X- _ O
first -X- _ O
attempt -X- _ O
to -X- _ O
devise -X- _ O
auxiliary -X- _ O
objectives -X- _ O
for -X- _ O
executable -X- _ O
semantic -X- _ B-TaskName
parsing -X- _ I-TaskName
as -X- _ O
a -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
task -X- _ O
. -X- _ O
Our -X- _ O
framework -X- _ O
and -X- _ O
hypothesis -X- _ O
are -X- _ O
also -X- _ O
sufficiently -X- _ O
flexible -X- _ O
for -X- _ O
application -X- _ O
in -X- _ O
additional -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
sequence -X- _ O
transduction -X- _ O
tasks -X- _ O
. -X- _ O

Our -X- _ O
motivation -X- _ O
is -X- _ O
to -X- _ O
improve -X- _ O
parsing -X- _ O
for -X- _ O
non -X- _ O
- -X- _ O
English -X- _ O
languages -X- _ O
with -X- _ O
maximal -X- _ O
resource -X- _ O
efficiency -X- _ O
and -X- _ O
minimal -X- _ O
external -X- _ O
dependencies -X- _ O
beyond -X- _ O
native -X- _ O
- -X- _ O
speaker -X- _ O
utterances -X- _ O
. -X- _ O
We -X- _ O
, -X- _ O
therefore -X- _ O
, -X- _ O
induce -X- _ O
a -X- _ O
shared -X- _ O
multilingual -X- _ O
space -X- _ O
without -X- _ O
resorting -X- _ O
to -X- _ O
machine -X- _ O
translation -X- _ O
( -X- _ O
Sherborne -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Moradshahi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
argue -X- _ O
that -X- _ O
our -X- _ O
approach -X- _ O
is -X- _ O
superior -X- _ O
because -X- _ O
it -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
nullifies -X- _ O
the -X- _ O
introduction -X- _ O
of -X- _ O
translation -X- _ O
or -X- _ O
word -X- _ O
alignment -X- _ O
errors -X- _ O
and -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
scales -X- _ O
to -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
languages -X- _ O
without -X- _ O
reliable -X- _ O
MT -X- _ B-TaskName
. -X- _ O
Experimental -X- _ O
results -X- _ O
on -X- _ O
Overnight -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Sherborne -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
a -X- _ O
new -X- _ O
executable -X- _ O
version -X- _ O
of -X- _ O
MultiATIS++ -X- _ B-DatasetName
show -X- _ O
that -X- _ O
our -X- _ O
parser -X- _ O
generates -X- _ O
more -X- _ O
accurate -X- _ O
logical -X- _ O
forms -X- _ O
with -X- _ O
a -X- _ O
minimized -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
transfer -X- _ O
penalty -X- _ O
from -X- _ O
English -X- _ O
to -X- _ O
French -X- _ O
( -X- _ O
FR -X- _ O
) -X- _ O
, -X- _ O
Portuguese -X- _ O
( -X- _ O
PT -X- _ O
) -X- _ O
, -X- _ O
Spanish -X- _ O
( -X- _ O
ES -X- _ O
) -X- _ O
, -X- _ O
German -X- _ O
( -X- _ O
DE -X- _ O
) -X- _ O
, -X- _ O
Chinese -X- _ O
( -X- _ O
ZH -X- _ O
) -X- _ O
, -X- _ O
Hindi -X- _ O
( -X- _ O
HI -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
Turkish -X- _ O
( -X- _ O
TR -X- _ O
) -X- _ O
. -X- _ O

Related -X- _ O
Work -X- _ O

Cross -X- _ O
- -X- _ O
lingual -X- _ O
Modeling -X- _ O
This -X- _ O
area -X- _ O
has -X- _ O
recently -X- _ O
gained -X- _ O
increased -X- _ O
interest -X- _ O
across -X- _ O
several -X- _ O
natural -X- _ O
language -X- _ O
understanding -X- _ O
settings -X- _ O
( -X- _ O
Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
; -X- _ O
Nooralahzadeh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
with -X- _ O
benchmarks -X- _ O
such -X- _ O
as -X- _ O
XGLUE -X- _ O
( -X- _ O
Liang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
XTREME -X- _ O
( -X- _ O
Hu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
allowing -X- _ O
to -X- _ O
study -X- _ O
classification -X- _ O
and -X- _ O
generation -X- _ O
tasks -X- _ O
for -X- _ O
multiple -X- _ O
languages -X- _ O
. -X- _ O
Crosslingual -X- _ O
approaches -X- _ O
have -X- _ O
also -X- _ O
been -X- _ O
developed -X- _ O
for -X- _ O
dependency -X- _ O
parsing -X- _ O
( -X- _ O
Tiedemann -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
; -X- _ O
Schuster -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
sentence -X- _ O
simplification -X- _ O
( -X- _ O
Mallinson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
spoken -X- _ O
- -X- _ O
language -X- _ O
understanding -X- _ O
( -X- _ O
SLU -X- _ O
; -X- _ O
He -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
; -X- _ O
Upadhyay -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

Pre -X- _ O
- -X- _ O
training -X- _ O
has -X- _ O
shown -X- _ O
to -X- _ O
be -X- _ O
widely -X- _ O
beneficial -X- _ O
for -X- _ O
a -X- _ O
wide -X- _ O
range -X- _ O
of -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
models -X- _ O
Conneau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
. -X- _ O
By -X- _ O
virtue -X- _ O
of -X- _ O
being -X- _ O
trained -X- _ O
on -X- _ O
massive -X- _ O
corpora -X- _ O
, -X- _ O
these -X- _ O
models -X- _ O
purportedly -X- _ O
learn -X- _ O
an -X- _ O
overlapping -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
latent -X- _ O
space -X- _ O
( -X- _ O
Conneau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
but -X- _ O
have -X- _ O
also -X- _ O
been -X- _ O
identified -X- _ O
as -X- _ O
under -X- _ O
- -X- _ O
trained -X- _ O
for -X- _ O
some -X- _ O
tasks -X- _ O
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
shown -X- _ O
poor -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
performance -X- _ O
, -X- _ O
especially -X- _ O
for -X- _ O
languages -X- _ O
dissimilar -X- _ O
to -X- _ O
English -X- _ O
( -X- _ O
Pires -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
high -X- _ O
variance -X- _ O
( -X- _ O
Keung -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

Semantic -X- _ B-TaskName
Parsing -X- _ I-TaskName
Most -X- _ O
previous -X- _ O
work -X- _ O
( -X- _ O
Lu -X- _ O
, -X- _ O
2014 -X- _ O
; -X- _ O
Susanto -X- _ O
and -X- _ O
Lu -X- _ O
, -X- _ O
2017b -X- _ O
, -X- _ O
a -X- _ O
) -X- _ O
has -X- _ O
focused -X- _ O
on -X- _ O
multilingual -X- _ O
semantic -X- _ O
parsing -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
learning -X- _ O
from -X- _ O
multiple -X- _ O
natural -X- _ O
languages -X- _ O
in -X- _ O
parallel -X- _ O
, -X- _ O
largely -X- _ O
affirming -X- _ O
the -X- _ O
benefit -X- _ O
of -X- _ O
" -X- _ O
high -X- _ O
- -X- _ O
resource -X- _ O
" -X- _ O
multilingual -X- _ O
data -X- _ O
and -X- _ O
multi -X- _ O
- -X- _ O
language -X- _ O
ensemble -X- _ O
training -X- _ O
( -X- _ O
Jie -X- _ O
and -X- _ O
Lu -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O
Shao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
further -X- _ O
improved -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
similarity -X- _ O
with -X- _ O
adversarial -X- _ O
language -X- _ O
identification -X- _ O
across -X- _ O
such -X- _ O
ensembled -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
Code -X- _ O
- -X- _ O
switching -X- _ O
in -X- _ O
multilingual -X- _ O
parsing -X- _ O
has -X- _ O
also -X- _ O
been -X- _ O
explored -X- _ O
through -X- _ O
mixed -X- _ O
- -X- _ O
language -X- _ O
training -X- _ O
datasets -X- _ O
( -X- _ O
Duong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Einolghozati -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
adapt -X- _ O
a -X- _ O
parser -X- _ O
to -X- _ O
new -X- _ O
languages -X- _ O
, -X- _ O
machine -X- _ O
translation -X- _ O
has -X- _ O
been -X- _ O
used -X- _ O
as -X- _ O
a -X- _ O
reasonable -X- _ O
proxy -X- _ O
for -X- _ O
in -X- _ O
- -X- _ O
language -X- _ O
data -X- _ O
( -X- _ O
Sherborne -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Moradshahi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
machine -X- _ O
translation -X- _ O
, -X- _ O
in -X- _ O
either -X- _ O
direction -X- _ O
can -X- _ O
introduce -X- _ O
limiting -X- _ O
artifacts -X- _ O
( -X- _ O
Artetxe -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
with -X- _ O
poor -X- _ O
generalization -X- _ O
due -X- _ O
to -X- _ O
how -X- _ O
" -X- _ O
translationese -X- _ O
" -X- _ O
training -X- _ O
data -X- _ O
diverges -X- _ O
from -X- _ O
gold -X- _ O
test -X- _ O
utterances -X- _ O
( -X- _ O
Riley -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

Zero -X- _ B-MethodName
- -X- _ I-MethodName
shot -X- _ I-MethodName
parsing -X- _ I-MethodName
has -X- _ O
primarily -X- _ O
focused -X- _ O
on -X- _ O
' -X- _ O
cross -X- _ O
- -X- _ O
domain -X- _ O
' -X- _ O
challenges -X- _ O
to -X- _ O
improve -X- _ O
generalization -X- _ O
across -X- _ O
varying -X- _ O
query -X- _ O
structures -X- _ O
and -X- _ O
lexicons -X- _ O
( -X- _ O
Herzig -X- _ O
and -X- _ O
Berant -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Givoli -X- _ O
and -X- _ O
Reichart -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
or -X- _ O
different -X- _ O
databases -X- _ O
( -X- _ O
Zhong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Suhr -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Yu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
combination -X- _ O
of -X- _ O
zero -X- _ B-MethodName
- -X- _ I-MethodName
shot -X- _ I-MethodName
parsing -X- _ I-MethodName
with -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
modeling -X- _ O
has -X- _ O
also -X- _ O
been -X- _ O
examined -X- _ O
for -X- _ O
the -X- _ O
UCCA -X- _ O
formalism -X- _ O
( -X- _ O
Hershcovich -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
for -X- _ O
task -X- _ O
- -X- _ O
oriented -X- _ O
dialogue -X- _ O
systems -X- _ O
( -X- _ O
see -X- _ O
below -X- _ O
) -X- _ O
. -X- _ O

Dialog -X- _ O
Modeling -X- _ O
Cross -X- _ O
- -X- _ O
lingual -X- _ O
transfer -X- _ O
has -X- _ O
been -X- _ O
studied -X- _ O
in -X- _ O
the -X- _ O
context -X- _ O
of -X- _ O
goal -X- _ O
- -X- _ O
oriented -X- _ O
dialog -X- _ O
for -X- _ O
the -X- _ O
spoken -X- _ O
language -X- _ O
understanding -X- _ O
( -X- _ O
SLU -X- _ O
) -X- _ O
tasks -X- _ O
of -X- _ O
intent -X- _ O
classification -X- _ O
and -X- _ O
slot -X- _ O
labeling -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
parsing -X- _ O
an -X- _ O
utterance -X- _ O
into -X- _ O
a -X- _ O
semantic -X- _ O
frame -X- _ O
identifying -X- _ O
the -X- _ O
user -X- _ O
's -X- _ O
intent -X- _ O
and -X- _ O
its -X- _ O
arguments -X- _ O
) -X- _ O
. -X- _ O
Recently -X- _ O
released -X- _ O
multilingual -X- _ O
datasets -X- _ O
like -X- _ O
MultiATIS++ -X- _ B-DatasetName
and -X- _ O
MTOP -X- _ O
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
have -X- _ O
facilitated -X- _ O
the -X- _ O
study -X- _ O
of -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
transfer -X- _ O
through -X- _ O
the -X- _ O
combination -X- _ O
of -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
machine -X- _ O
translation -X- _ O
, -X- _ O
and -X- _ O
word -X- _ O
alignment -X- _ O
( -X- _ O
to -X- _ O
project -X- _ O
annotations -X- _ O
between -X- _ O
languages -X- _ O
) -X- _ O
. -X- _ O
Recent -X- _ O
work -X- _ O
in -X- _ O
this -X- _ O
setting -X- _ O
( -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Krishnan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Nicosia -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
identifies -X- _ O
a -X- _ O
penalty -X- _ O
for -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
transfer -X- _ O
that -X- _ O
neither -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
nor -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
can -X- _ O
fully -X- _ O
overcome -X- _ O
. -X- _ O

Problem -X- _ O
Formulation -X- _ O

The -X- _ O
primary -X- _ O
challenge -X- _ O
for -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
parsing -X- _ I-TaskName
is -X- _ O
learning -X- _ O
parameters -X- _ O
that -X- _ O
can -X- _ O
parse -X- _ O
an -X- _ O
utterance -X- _ O
, -X- _ O
x -X- _ O
, -X- _ O
from -X- _ O
an -X- _ O
unseen -X- _ O
test -X- _ O
language -X- _ O
to -X- _ O
an -X- _ O
accurate -X- _ O
logical -X- _ O
form -X- _ O
( -X- _ O
LF -X- _ O
) -X- _ O
. -X- _ O
Typically -X- _ O
, -X- _ O
a -X- _ O
parser -X- _ O
trained -X- _ O
on -X- _ O
language -X- _ O
l -X- _ O
, -X- _ O
or -X- _ O
multiple -X- _ O
languages -X- _ O
{ -X- _ O
l -X- _ O
1 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
l -X- _ O
N -X- _ O
} -X- _ O
, -X- _ O
is -X- _ O
only -X- _ O
capable -X- _ O
for -X- _ O
these -X- _ O
languages -X- _ O
and -X- _ O
performs -X- _ O
poorly -X- _ O
outside -X- _ O
this -X- _ O
set -X- _ O
. -X- _ O
For -X- _ O
a -X- _ O
new -X- _ O
language -X- _ O
, -X- _ O
prior -X- _ O
approaches -X- _ O
require -X- _ O
parallel -X- _ O
datasets -X- _ O
and -X- _ O
models -X- _ O
( -X- _ O
Jie -X- _ O
and -X- _ O
Lu -X- _ O
, -X- _ O
2014 -X- _ O
; -X- _ O
Haas -X- _ O
and -X- _ O
Riezler -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Duong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
our -X- _ O
work -X- _ O
, -X- _ O
zero -X- _ B-MethodName
- -X- _ I-MethodName
shot -X- _ I-MethodName
parsing -X- _ I-MethodName
refers -X- _ O
to -X- _ O
parsing -X- _ O
utterances -X- _ O
in -X- _ O
new -X- _ O
languages -X- _ O
without -X- _ O
paired -X- _ O
data -X- _ O
during -X- _ O
training -X- _ O
, -X- _ O
For -X- _ O
some -X- _ O
language -X- _ O
, -X- _ O
l -X- _ O
, -X- _ O
there -X- _ O
exists -X- _ O
no -X- _ O
pairing -X- _ O
of -X- _ O
x -X- _ O
l -X- _ O
to -X- _ O
a -X- _ O
logical -X- _ O
form -X- _ O
, -X- _ O
y -X- _ O
, -X- _ O
except -X- _ O
for -X- _ O
English -X- _ O
. -X- _ O
2 -X- _ O
This -X- _ O
setting -X- _ O
also -X- _ O
excludes -X- _ O
" -X- _ O
silver -X- _ O
- -X- _ O
standard -X- _ O
" -X- _ O
training -X- _ O
pairs -X- _ O
created -X- _ O
using -X- _ O
machine -X- _ O
- -X- _ O
translation -X- _ O
. -X- _ O
As -X- _ O
these -X- _ O
models -X- _ O
have -X- _ O
ultimately -X- _ O
observed -X- _ O
some -X- _ O
form -X- _ O
of -X- _ O
utterance -X- _ O
- -X- _ O
logical -X- _ O
form -X- _ O
pairs -X- _ O
for -X- _ O
each -X- _ O
new -X- _ O
language -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
consider -X- _ O
such -X- _ O
approaches -X- _ O
here -X- _ O
and -X- _ O
refer -X- _ O
to -X- _ O
Sherborne -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
as -X- _ O
an -X- _ O
example -X- _ O
of -X- _ O
using -X- _ O
MT -X- _ B-TaskName
for -X- _ O
this -X- _ O
task -X- _ O
. -X- _ O

It -X- _ O
might -X- _ O
be -X- _ O
tempting -X- _ O
to -X- _ O
approach -X- _ O
this -X- _ O
problem -X- _ O
as -X- _ O
a -X- _ O
case -X- _ O
of -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
( -X- _ O
English -X- _ O
) -X- _ O
decoder -X- _ O
for -X- _ O
LF -X- _ B-TaskName
generation -X- _ I-TaskName
. -X- _ O
Problematically -X- _ O
, -X- _ O
the -X- _ O
output -X- _ O
target -X- _ O
is -X- _ O
expressed -X- _ O
in -X- _ O
a -X- _ O
formally -X- _ O
defined -X- _ O
language -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
SQL -X- _ O
or -X- _ O
λ−DCS -X- _ O
) -X- _ O
which -X- _ O
models -X- _ O
the -X- _ O
semantics -X- _ O
of -X- _ O
questions -X- _ O
very -X- _ O
differently -X- _ O
to -X- _ O
natural -X- _ O
language -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
without -X- _ O
presumption -X- _ O
or -X- _ O
co -X- _ O
- -X- _ O
operation -X- _ O
; -X- _ O
Kaplan -X- _ O
1978 -X- _ O
) -X- _ O
. -X- _ O
Formal -X- _ O
languages -X- _ O
( -X- _ O
Kamp -X- _ O
and -X- _ O
Reyle -X- _ O
, -X- _ O
1993 -X- _ O
) -X- _ O
additionally -X- _ O
present -X- _ O
artifacts -X- _ O
which -X- _ O
render -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
challenging -X- _ O
such -X- _ O
as -X- _ O
unfamiliar -X- _ O
syntax -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
table -X- _ O
aliases -X- _ O
or -X- _ O
explicit -X- _ O
recursion -X- _ O
) -X- _ O
and -X- _ O
long -X- _ O
output -X- _ O
sequences -X- _ O
. -X- _ O
In -X- _ O
practice -X- _ O
, -X- _ O
we -X- _ O
observed -X- _ O
finetuning -X- _ O
leads -X- _ O
to -X- _ O
poor -X- _ O
performance -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
< -X- _ O
1 -X- _ O
% -X- _ O
accuracy -X- _ O
on -X- _ O
all -X- _ O
languages -X- _ O
) -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
model -X- _ O
insisting -X- _ O
on -X- _ O
hallucinating -X- _ O
natural -X- _ O
language -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
seemingly -X- _ O
at -X- _ O
odds -X- _ O
with -X- _ O
adjacent -X- _ O
work -X- _ O
in -X- _ O
dialog -X- _ O
modeling -X- _ O
, -X- _ O
which -X- _ O
has -X- _ O
found -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
decoders -X- _ O
to -X- _ O
be -X- _ O
beneficial -X- _ O
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
SLU -X- _ O
requires -X- _ O
learning -X- _ O
a -X- _ O
lightweight -X- _ O
label -X- _ O
vocabulary -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
200 -X- _ O
+ -X- _ O
tokens -X- _ O
required -X- _ O
in -X- _ O
LFs -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
SLU -X- _ O
typically -X- _ O
maintains -X- _ O
output -X- _ O
sequences -X- _ O
of -X- _ O
similar -X- _ O
size -X- _ O
to -X- _ O
natural -X- _ O
language -X- _ O
inputs -X- _ O
( -X- _ O
with -X- _ O
tightly -X- _ O
coupled -X- _ O
syntactic -X- _ O
compositionality -X- _ O
between -X- _ O
the -X- _ O
two -X- _ O
) -X- _ O
, -X- _ O
whereas -X- _ O
the -X- _ O
syntactic -X- _ O
and -X- _ O
structural -X- _ O
demands -X- _ O
of -X- _ O
LF -X- _ O
generation -X- _ O
are -X- _ O
largely -X- _ O
divorced -X- _ O
from -X- _ O
the -X- _ O
input -X- _ O
utterance -X- _ O
. -X- _ O

In -X- _ O
our -X- _ O
solution -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
to -X- _ O
parse -X- _ O
from -X- _ O
utterance -X- _ O
- -X- _ O
logical -X- _ O
forms -X- _ O
pairs -X- _ O
only -X- _ O
in -X- _ O
English -X- _ O
. -X- _ O
Other -X- _ O
languages -X- _ O
are -X- _ O
incorporated -X- _ O
using -X- _ O
auxiliary -X- _ O
objectives -X- _ O
and -X- _ O
data -X- _ O
detailed -X- _ O
in -X- _ O
Section -X- _ O
4 -X- _ O
. -X- _ O
We -X- _ O
explore -X- _ O
the -X- _ O
hypothesis -X- _ O
that -X- _ O
an -X- _ O
overlapping -X- _ O
multi -X- _ O
- -X- _ O
lingual -X- _ O
latent -X- _ O
space -X- _ O
can -X- _ O
be -X- _ O
learned -X- _ O
through -X- _ O
auxiliary -X- _ O
objectives -X- _ O
in -X- _ O
tandem -X- _ O
with -X- _ O
logical -X- _ O
form -X- _ O
generation -X- _ O
( -X- _ O
see -X- _ O
Figure -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O
Our -X- _ O
intuition -X- _ O
is -X- _ O
that -X- _ O
introducing -X- _ O
these -X- _ O
additional -X- _ O
losses -X- _ O
minimizes -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
variance -X- _ O
in -X- _ O
latent -X- _ O
encoding -X- _ O
space -X- _ O
by -X- _ O
optimizing -X- _ O
for -X- _ O
language -X- _ O
- -X- _ O
agnostic -X- _ O
representations -X- _ O
with -X- _ O
high -X- _ O
similarity -X- _ O
to -X- _ O
the -X- _ O
source -X- _ O
language -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
English -X- _ O
) -X- _ O
. -X- _ O
Our -X- _ O
approach -X- _ O
minimizes -X- _ O
the -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
transfer -X- _ O
penalty -X- _ O
such -X- _ O
that -X- _ O
the -X- _ O
zeroshot -X- _ O
parser -X- _ O
predicts -X- _ O
logical -X- _ O
forms -X- _ O
from -X- _ O
test -X- _ O
inputs -X- _ O
regardless -X- _ O
of -X- _ O
utterance -X- _ O
language -X- _ O
. -X- _ O
By -X- _ O
framing -X- _ O
the -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
parsing -X- _ O
task -X- _ O
as -X- _ O
a -X- _ O
latent -X- _ O
representation -X- _ O
alignment -X- _ O
challenge -X- _ O
, -X- _ O
we -X- _ O
explore -X- _ O
a -X- _ O
possible -X- _ O
upper -X- _ O
bound -X- _ O
of -X- _ O
parsing -X- _ O
accuracy -X- _ O
without -X- _ O
errors -X- _ O
from -X- _ O
external -X- _ O
dependencies -X- _ O
. -X- _ O
Section -X- _ O
6 -X- _ O
demonstrates -X- _ O
that -X- _ O
our -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
model -X- _ O
, -X- _ O
using -X- _ O
only -X- _ O
English -X- _ O
paired -X- _ O
data -X- _ O
and -X- _ O
a -X- _ O
small -X- _ O
additional -X- _ O
corpus -X- _ O
, -X- _ O
can -X- _ O
generate -X- _ O
accurate -X- _ O
logical -X- _ O
forms -X- _ O
above -X- _ O
translation -X- _ O
baselines -X- _ O
to -X- _ O
compete -X- _ O
with -X- _ O
fully -X- _ O
supervised -X- _ O
in -X- _ O
- -X- _ O
language -X- _ O
training -X- _ O
. -X- _ O

Our -X- _ O
Zero -X- _ O
- -X- _ O
shot -X- _ O
Model -X- _ O
: -X- _ O
ZX -X- _ B-MethodName
- -X- _ I-MethodName
PARSE -X- _ I-MethodName

We -X- _ O
adopt -X- _ O
a -X- _ O
multi -X- _ B-MethodName
- -X- _ I-MethodName
task -X- _ I-MethodName
sequence -X- _ I-MethodName
- -X- _ I-MethodName
to -X- _ I-MethodName
- -X- _ I-MethodName
sequence -X- _ I-MethodName
model -X- _ O
( -X- _ O
Luong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
which -X- _ O
combines -X- _ O
logical -X- _ B-TaskName
form -X- _ I-TaskName
generation -X- _ I-TaskName
with -X- _ O
two -X- _ O
auxiliary -X- _ O
objectives -X- _ O
. -X- _ O
The -X- _ O
first -X- _ O
is -X- _ O
a -X- _ O
language -X- _ O
identification -X- _ O
discriminator -X- _ O
and -X- _ O
the -X- _ O
second -X- _ O
is -X- _ O
a -X- _ O
reconstruction -X- _ O
or -X- _ O
translation -X- _ O
decoder -X- _ O
. -X- _ O
An -X- _ O
overview -X- _ O
of -X- _ O
our -X- _ O
semantic -X- _ O
parser -X- _ O
is -X- _ O
given -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
; -X- _ O
we -X- _ O
describe -X- _ O
each -X- _ O
component -X- _ O
below -X- _ O
. -X- _ O

Generating -X- _ B-TaskName
Logical -X- _ I-TaskName
Forms -X- _ I-TaskName
Predicting -X- _ B-TaskName
logical -X- _ I-TaskName
forms -X- _ I-TaskName
is -X- _ O
the -X- _ O
primary -X- _ O
objective -X- _ O
for -X- _ O
our -X- _ O
model -X- _ O
. -X- _ O
Given -X- _ O
an -X- _ O
utterance -X- _ O
x -X- _ O
= -X- _ O
( -X- _ O
x -X- _ O
1 -X- _ O
, -X- _ O
x -X- _ O
2 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
x -X- _ O
T -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
wish -X- _ O
to -X- _ O
generate -X- _ O
logical -X- _ O
form -X- _ O
y -X- _ O
= -X- _ O
( -X- _ O
y -X- _ O
1 -X- _ O
, -X- _ O
y -X- _ O
2 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
y -X- _ O
M -X- _ O
) -X- _ O
representing -X- _ O
the -X- _ O
same -X- _ O
meaning -X- _ O
in -X- _ O
a -X- _ O
machine -X- _ O
- -X- _ O
executable -X- _ O
language -X- _ O
. -X- _ O
We -X- _ O
model -X- _ O
this -X- _ O
transduction -X- _ O
task -X- _ O
using -X- _ O
an -X- _ O
encoder -X- _ O
- -X- _ O
decoder -X- _ O
neural -X- _ O
network -X- _ O
( -X- _ O
Sutskever -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
based -X- _ O
upon -X- _ O
the -X- _ O
Transformer -X- _ B-MethodName
architecture -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
sequence -X- _ O
x -X- _ O
is -X- _ O
encoded -X- _ O
to -X- _ O
a -X- _ O
latent -X- _ O
representation -X- _ O
z -X- _ O
= -X- _ O
( -X- _ O
z -X- _ O
1 -X- _ O
, -X- _ O
z -X- _ O
2 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
z -X- _ O
T -X- _ O
) -X- _ O
through -X- _ O
Equation -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
using -X- _ O
a -X- _ O
stacked -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
Transformer -X- _ B-MethodName
encoder -X- _ O
, -X- _ O
E -X- _ O
, -X- _ O
with -X- _ O
weights -X- _ O
θ -X- _ O
E -X- _ O
. -X- _ O

z -X- _ O
= -X- _ O
E -X- _ O
( -X- _ O
x|θ -X- _ O
E -X- _ O
) -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
p -X- _ O
( -X- _ O
y|x -X- _ O
) -X- _ O
= -X- _ O
M -X- _ O
i=0 -X- _ O
p -X- _ O
( -X- _ O
y -X- _ O
i -X- _ O
|y -X- _ O
< -X- _ O
i -X- _ O
, -X- _ O
x -X- _ O
) -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
p -X- _ O
( -X- _ O
y -X- _ O
i -X- _ O
|y -X- _ O
< -X- _ O
i -X- _ O
, -X- _ O
x -X- _ O
) -X- _ O
= -X- _ O
soft -X- _ O
( -X- _ O
D -X- _ O
LF -X- _ O
( -X- _ O
y -X- _ O
< -X- _ O
i -X- _ O
|z -X- _ O
, -X- _ O
θ -X- _ O
D -X- _ O
LF -X- _ O
) -X- _ O
) -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
L -X- _ O
LF -X- _ O
= -X- _ O
− -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
∈S -X- _ O
LF -X- _ O
log -X- _ O
p -X- _ O
( -X- _ O
y|x -X- _ O
) -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O

The -X- _ O
conditional -X- _ O
probability -X- _ O
of -X- _ O
the -X- _ O
output -X- _ O
sequence -X- _ O
y -X- _ O
is -X- _ O
expressed -X- _ O
in -X- _ O
Equation -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
as -X- _ O
each -X- _ O
token -X- _ O
y -X- _ O
i -X- _ O
is -X- _ O
autoregressively -X- _ O
generated -X- _ O
based -X- _ O
upon -X- _ O
z -X- _ O
and -X- _ O
prior -X- _ O
outputs -X- _ O
, -X- _ O
y -X- _ O
< -X- _ O
i -X- _ O
. -X- _ O
Equation -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
models -X- _ O
distribution -X- _ O
p -X- _ O
( -X- _ O
y -X- _ O
i -X- _ O
|y -X- _ O
< -X- _ O
i -X- _ O
, -X- _ O
x -X- _ O
) -X- _ O
using -X- _ O
a -X- _ O
Transformer -X- _ O
decoder -X- _ O
for -X- _ O
logical -X- _ O
forms -X- _ O
, -X- _ O
D -X- _ O
LF -X- _ O
, -X- _ O
with -X- _ O
associated -X- _ O
weights -X- _ O
θ -X- _ O
D -X- _ O
LF -X- _ O
where -X- _ O
soft -X- _ O
is -X- _ O
the -X- _ O
softmax -X- _ O
function -X- _ O
. -X- _ O

We -X- _ O
predict -X- _ O
an -X- _ O
output -X- _ O
, -X- _ O
ŷ -X- _ O
, -X- _ O
for -X- _ O
semantic -X- _ O
parsing -X- _ O
dataset -X- _ O
S -X- _ O
LF -X- _ O
= -X- _ O
{ -X- _ O
x -X- _ O
n -X- _ O
, -X- _ O
y -X- _ O
n -X- _ O
} -X- _ O
N -X- _ O
n=0 -X- _ O
, -X- _ O
through -X- _ O
the -X- _ O
encoder -X- _ O
and -X- _ O
logical -X- _ O
form -X- _ O
decoder -X- _ O
, -X- _ O
{ -X- _ O
E -X- _ O
, -X- _ O
D -X- _ O
LF -X- _ O
} -X- _ O
. -X- _ O
Equation -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
describes -X- _ O
the -X- _ O
loss -X- _ O
objective -X- _ O
minimizing -X- _ O
the -X- _ O
crossentropy -X- _ O
between -X- _ O
y -X- _ O
andŷ -X- _ O
. -X- _ O

Language -X- _ B-TaskName
Prediction -X- _ I-TaskName
Our -X- _ O
first -X- _ O
additional -X- _ O
objective -X- _ O
encourages -X- _ O
language -X- _ O
- -X- _ O
agnostic -X- _ O
representations -X- _ O
by -X- _ O
reducing -X- _ O
the -X- _ O
discriminability -X- _ O
of -X- _ O
the -X- _ O
source -X- _ O
language -X- _ O
, -X- _ O
l -X- _ O
, -X- _ O
from -X- _ O
z. -X- _ O
Equation -X- _ O
( -X- _ O
5 -X- _ O
) -X- _ O
defines -X- _ O
a -X- _ O
Language -X- _ B-TaskName
Prediction -X- _ I-TaskName
( -X- _ O
LP -X- _ B-TaskName
) -X- _ O
network -X- _ O
to -X- _ O
predict -X- _ O
l -X- _ O
from -X- _ O
z -X- _ O
using -X- _ O
a -X- _ O
linear -X- _ O
classifier -X- _ O
over -X- _ O
L -X- _ O
training -X- _ O
languages -X- _ O
: -X- _ O

LP -X- _ B-TaskName
( -X- _ O
x -X- _ O
) -X- _ O
= -X- _ O
W -X- _ O
i -X- _ O
x -X- _ O
+ -X- _ O
b -X- _ O
i -X- _ O
( -X- _ O
5 -X- _ O
) -X- _ O

where -X- _ O
W -X- _ O
i -X- _ O
∈ -X- _ O
R -X- _ O
L×|z| -X- _ O
and -X- _ O
b -X- _ O
i -X- _ O
∈ -X- _ O
R -X- _ O
L -X- _ O
are -X- _ O
a -X- _ O
weight -X- _ O
and -X- _ O
bias -X- _ O
respectively -X- _ O
. -X- _ O
We -X- _ O
follow -X- _ O
the -X- _ O
best -X- _ O
model -X- _ O
from -X- _ O
Ahmad -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019b -X- _ O
) -X- _ O
. -X- _ O
Equation -X- _ O
( -X- _ O
6 -X- _ O
) -X- _ O
describes -X- _ O
the -X- _ O
conditional -X- _ O
model -X- _ O
for -X- _ O
the -X- _ O
output -X- _ O
distribution -X- _ O
where -X- _ O
a -X- _ O
language -X- _ O
label -X- _ O
is -X- _ O
predicted -X- _ O
using -X- _ O
the -X- _ O
time -X- _ O
- -X- _ O
average -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
encoding -X- _ O
z -X- _ O
of -X- _ O
length -X- _ O
T -X- _ O
: -X- _ O

p -X- _ O
( -X- _ O
l|x -X- _ O
) -X- _ O
= -X- _ O
soft -X- _ O
LP -X- _ B-TaskName
1 -X- _ O
T -X- _ O
t -X- _ O
z -X- _ O
t -X- _ O
( -X- _ O
6 -X- _ O
) -X- _ O

Finally -X- _ O
, -X- _ O
Equation -X- _ O
( -X- _ O
7 -X- _ O
) -X- _ O
describes -X- _ O
the -X- _ O
objective -X- _ O
function -X- _ O
for -X- _ O
the -X- _ O
LP -X- _ B-TaskName
network -X- _ O
: -X- _ O

L -X- _ O
LP -X- _ B-TaskName
= -X- _ O
− -X- _ O
x -X- _ O
log -X- _ O
p -X- _ O
( -X- _ O
l|x -X- _ O
) -X- _ O
( -X- _ O
7 -X- _ O
) -X- _ O

However -X- _ O
, -X- _ O
we -X- _ O
reverse -X- _ O
this -X- _ O
gradient -X- _ O
in -X- _ O
the -X- _ O
backward -X- _ O
pass -X- _ O
before -X- _ O
the -X- _ O
LP -X- _ B-TaskName
network -X- _ O
, -X- _ O
to -X- _ O
encourage -X- _ O
the -X- _ O
encoder -X- _ O
to -X- _ O
produce -X- _ O
language -X- _ O
invariant -X- _ O
representations -X- _ O
( -X- _ O
Ganin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
LP -X- _ B-TaskName
network -X- _ O
is -X- _ O
optimized -X- _ O
to -X- _ O
discriminate -X- _ O
the -X- _ O
source -X- _ O
language -X- _ O
from -X- _ O
z -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
encoder -X- _ O
is -X- _ O
now -X- _ O
optimized -X- _ O
adversarially -X- _ O
against -X- _ O
this -X- _ O
objective -X- _ O
. -X- _ O
Our -X- _ O
intuition -X- _ O
is -X- _ O
that -X- _ O
discouraging -X- _ O
language -X- _ O
discriminability -X- _ O
in -X- _ O
z -X- _ O
encourages -X- _ O
latent -X- _ O
representation -X- _ O
similarity -X- _ O
across -X- _ O
languages -X- _ O
, -X- _ O
and -X- _ O
therefore -X- _ O
reduces -X- _ O
the -X- _ O
penalty -X- _ O
for -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
transfer -X- _ O
. -X- _ O

Generating -X- _ B-TaskName
Natural -X- _ I-TaskName
Language -X- _ I-TaskName
The -X- _ O
final -X- _ O
objective -X- _ O
acts -X- _ O
towards -X- _ O
both -X- _ O
regularization -X- _ O
and -X- _ O
crosslingual -X- _ O
similarity -X- _ O
. -X- _ O
Motivated -X- _ O
by -X- _ O
domain -X- _ O
- -X- _ O
adaptive -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
( -X- _ O
Gururangan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
further -X- _ O
adapt -X- _ O
the -X- _ O
encoder -X- _ O
towards -X- _ O
question -X- _ O
- -X- _ O
style -X- _ O
utterances -X- _ O
from -X- _ O
native -X- _ O
speakers -X- _ O
of -X- _ O
each -X- _ O
test -X- _ O
language -X- _ O
lacking -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
We -X- _ O
add -X- _ O
an -X- _ O
additional -X- _ O
Transformer -X- _ B-MethodName
decoder -X- _ O
optimized -X- _ O
to -X- _ O
reconstruct -X- _ O
a -X- _ O
noisy -X- _ O
input -X- _ O
from -X- _ O
latent -X- _ O
representation -X- _ O
z -X- _ O
, -X- _ O
in -X- _ O
Equation -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
Utterance -X- _ O
, -X- _ O
x -X- _ O
, -X- _ O
is -X- _ O
input -X- _ O
to -X- _ O
the -X- _ O
encoder -X- _ O
, -X- _ O
E -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
separate -X- _ O
decoder -X- _ O
, -X- _ O
D -X- _ O
NL -X- _ O
, -X- _ O
then -X- _ O
reconstructs -X- _ O
x -X- _ O
from -X- _ O
z. -X- _ O
We -X- _ O
follow -X- _ O
the -X- _ O
denoising -X- _ O
objective -X- _ O
from -X- _ O
and -X- _ O
replace -X- _ O
x -X- _ O
with -X- _ O
noised -X- _ O
inputx -X- _ O
= -X- _ O
N -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
with -X- _ O
noising -X- _ O
function -X- _ O
N. -X- _ O
The -X- _ O
output -X- _ O
probability -X- _ O
of -X- _ O
reconstruction -X- _ O
is -X- _ O
given -X- _ O
in -X- _ O
Equation -X- _ O
( -X- _ O
9 -X- _ O
) -X- _ O
with -X- _ O
each -X- _ O
token -X- _ O
predicted -X- _ O
through -X- _ O
Equation -X- _ O
( -X- _ O
10 -X- _ O
) -X- _ O
using -X- _ O
decoder -X- _ O
, -X- _ O
D -X- _ O
NL -X- _ O
, -X- _ O
with -X- _ O
weights -X- _ O
θ -X- _ O
D -X- _ O
NL -X- _ O
: -X- _ O

z -X- _ O
= -X- _ O
E -X- _ O
( -X- _ O
x|θ -X- _ O
E -X- _ O
) -X- _ O
( -X- _ O
8 -X- _ O
) -X- _ O

p -X- _ O
( -X- _ O
x|x -X- _ O
) -X- _ O
= -X- _ O
T -X- _ O
i=0 -X- _ O
p -X- _ O
( -X- _ O
x -X- _ O
i -X- _ O
|x -X- _ O
< -X- _ O
i -X- _ O
, -X- _ O
x -X- _ O
) -X- _ O
( -X- _ O
9 -X- _ O
) -X- _ O
p -X- _ O
( -X- _ O
x -X- _ O
i -X- _ O
|x -X- _ O
< -X- _ O
i -X- _ O
, -X- _ O
x -X- _ O
) -X- _ O
=soft -X- _ O
( -X- _ O
D -X- _ O
NL -X- _ O
( -X- _ O
x -X- _ O
< -X- _ O
i -X- _ O
|ẑ -X- _ O
, -X- _ O
θ -X- _ O
D -X- _ O
NL -X- _ O
) -X- _ O
) -X- _ O
( -X- _ O
10 -X- _ O
) -X- _ O

The -X- _ O
auxiliary -X- _ O
objectives -X- _ O
are -X- _ O
trained -X- _ O
using -X- _ O
both -X- _ O
the -X- _ O
utterances -X- _ O
from -X- _ O
S -X- _ O
LF -X- _ O
and -X- _ O
monolingual -X- _ O
data -X- _ O
, -X- _ O

S -X- _ O
NL -X- _ O
= -X- _ O
{ -X- _ O
{ -X- _ O
x -X- _ O
n -X- _ O
} -X- _ O
N -X- _ O
n=0 -X- _ O
} -X- _ O
L -X- _ O
l=0 -X- _ O

, -X- _ O
in -X- _ O
L -X- _ O
languages -X- _ O
( -X- _ O
see -X- _ O
Section -X- _ O
5 -X- _ O
) -X- _ O
. -X- _ O
Submodel -X- _ O
, -X- _ O
{ -X- _ O
E -X- _ O
, -X- _ O
D -X- _ O
NL -X- _ O
} -X- _ O
, -X- _ O
predicts -X- _ O
the -X- _ O
reconstruction -X- _ O
of -X- _ O
x -X- _ O
fromx -X- _ O
with -X- _ O
the -X- _ O
following -X- _ O
objective -X- _ O
: -X- _ O

L -X- _ O
NL -X- _ O
= -X- _ O
− -X- _ O
x -X- _ O
log -X- _ O
p -X- _ O
( -X- _ O
x|x -X- _ O
) -X- _ O
( -X- _ O
11 -X- _ O
) -X- _ O

In -X- _ O
the -X- _ O
form -X- _ O
described -X- _ O
above -X- _ O
, -X- _ O
this -X- _ O
objective -X- _ O
requires -X- _ O
only -X- _ O
unlabeled -X- _ O
, -X- _ O
monolingual -X- _ O
utterances -X- _ O
in -X- _ O
each -X- _ O
target -X- _ O
language -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
also -X- _ O
augment -X- _ O
it -X- _ O
with -X- _ O
a -X- _ O
translation -X- _ O
component -X- _ O
to -X- _ O
exploit -X- _ O
natural -X- _ O
language -X- _ O
bi -X- _ O
- -X- _ O
text -X- _ O
between -X- _ O
the -X- _ O
new -X- _ O
language -X- _ O
and -X- _ O
English -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O

S -X- _ O
NL -X- _ O
= -X- _ O
{ -X- _ O
{ -X- _ O
x -X- _ O
n -X- _ O
EN -X- _ O
, -X- _ O
x -X- _ O
n -X- _ O
l -X- _ O
} -X- _ O
N -X- _ O
n=0 -X- _ O
} -X- _ O
L -X- _ O
l=0 -X- _ O

) -X- _ O
to -X- _ O
further -X- _ O
promote -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
similarity -X- _ O
. -X- _ O
According -X- _ O
to -X- _ O
some -X- _ O
sampling -X- _ O
factor -X- _ O
τ -X- _ O
, -X- _ O
we -X- _ O
randomly -X- _ O
choose -X- _ O
whether -X- _ O
to -X- _ O
reconstruct -X- _ O
an -X- _ O
utterance -X- _ O
( -X- _ O
as -X- _ O
above -X- _ O
) -X- _ O
or -X- _ O
translate -X- _ O
to -X- _ O
the -X- _ O
parallel -X- _ O
English -X- _ O
utterance -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
replace -X- _ O
x -X- _ O
in -X- _ O
Equation -X- _ O
( -X- _ O
11 -X- _ O
) -X- _ O
with -X- _ O
x -X- _ O
EN -X- _ O
) -X- _ O
. -X- _ O

Combined -X- _ O
Model -X- _ O

The -X- _ O
combined -X- _ O
model -X- _ O
uses -X- _ O
a -X- _ O
single -X- _ O
encoder -X- _ O
, -X- _ O
E -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
three -X- _ O
objective -X- _ O
decoders -X- _ O
{ -X- _ O
D -X- _ O
LF -X- _ O
, -X- _ O
D -X- _ O
NL -X- _ O
, -X- _ O
LP -X- _ O
} -X- _ O
( -X- _ O
see -X- _ O
Figure -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O
During -X- _ O
training -X- _ O
, -X- _ O
an -X- _ O
English -X- _ O
query -X- _ O
is -X- _ O
encoded -X- _ O
and -X- _ O
input -X- _ O
to -X- _ O
all -X- _ O
three -X- _ O
objectives -X- _ O
to -X- _ O
express -X- _ O
output -X- _ O
loss -X- _ O
as -X- _ O
L -X- _ O
LF -X- _ O
+ -X- _ O
L -X- _ O
NL -X- _ O
+ -X- _ O
L -X- _ O
LP -X- _ O
. -X- _ O
For -X- _ O
new -X- _ O
languages -X- _ O
without -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
pairs -X- _ O
, -X- _ O
the -X- _ O
utterance -X- _ O
is -X- _ O
encoded -X- _ O
and -X- _ O
input -X- _ O
only -X- _ O
to -X- _ O
the -X- _ O
auxiliary -X- _ O
objectives -X- _ O
for -X- _ O
a -X- _ O
combined -X- _ O
loss -X- _ O
as -X- _ O
L -X- _ O
NL -X- _ O
+ -X- _ O
L -X- _ O
LP -X- _ O
. -X- _ O
During -X- _ O
inference -X- _ O
, -X- _ O
an -X- _ O
utterance -X- _ O
is -X- _ O
encoded -X- _ O
and -X- _ O
always -X- _ O
input -X- _ O
to -X- _ O
D -X- _ O
LF -X- _ O
to -X- _ O
predict -X- _ O
a -X- _ O
logical -X- _ O
form -X- _ O
, -X- _ O
ŷ -X- _ O
, -X- _ O
regardless -X- _ O
of -X- _ O
test -X- _ O
language -X- _ O
, -X- _ O
l. -X- _ O
During -X- _ O
the -X- _ O
backward -X- _ O
pass -X- _ O
, -X- _ O
each -X- _ O
output -X- _ O
loss -X- _ O
back -X- _ O
- -X- _ O
propagates -X- _ O
the -X- _ O
gradient -X- _ O
signal -X- _ O
from -X- _ O
the -X- _ O
respective -X- _ O
objective -X- _ O
function -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
encoder -X- _ O
, -X- _ O
these -X- _ O
signals -X- _ O
are -X- _ O
combined -X- _ O
as -X- _ O
: -X- _ O

∂L -X- _ O
∂θ -X- _ O
E -X- _ O
= -X- _ O
∂L -X- _ O
LF -X- _ O
∂θ -X- _ O
E -X- _ O
− -X- _ O
λα -X- _ O
LP -X- _ O
∂L -X- _ O
LP -X- _ O
∂θ -X- _ O
E -X- _ O
+ -X- _ O
α -X- _ O
NL -X- _ O
∂L -X- _ O
NL -X- _ O
∂θ -X- _ O
E -X- _ O
( -X- _ O
12 -X- _ O
) -X- _ O
λ -X- _ O
= -X- _ O
2 -X- _ O
1 -X- _ O
+ -X- _ O
e -X- _ O
−γp -X- _ O
− -X- _ O
1 -X- _ O
( -X- _ O
13 -X- _ O

) -X- _ O

where -X- _ O
α -X- _ O
{ -X- _ O
LP -X- _ O
, -X- _ O
NL -X- _ O
} -X- _ O
are -X- _ O
loss -X- _ O
weightings -X- _ O
for -X- _ O
auxiliary -X- _ O
objectives -X- _ O
and -X- _ O
λ -X- _ O
is -X- _ O
the -X- _ O
reversed -X- _ O
gradient -X- _ O
scheduling -X- _ O
parameter -X- _ O
from -X- _ O
Ganin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
λ -X- _ O
value -X- _ O
increments -X- _ O
with -X- _ O
training -X- _ O
progress -X- _ O
p -X- _ O
, -X- _ O
scaled -X- _ O
by -X- _ O
γ -X- _ O
, -X- _ O
according -X- _ O
to -X- _ O
Equation -X- _ O
( -X- _ O
13 -X- _ O
) -X- _ O
, -X- _ O
to -X- _ O
limit -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
noisy -X- _ O
predictions -X- _ O
during -X- _ O
early -X- _ O
training -X- _ O
. -X- _ O

We -X- _ O
expect -X- _ O
that -X- _ O
the -X- _ O
parser -X- _ O
will -X- _ O
adapt -X- _ O
and -X- _ O
recognize -X- _ O
an -X- _ O
encoding -X- _ O
from -X- _ O
an -X- _ O
unfamiliar -X- _ O
language -X- _ O
through -X- _ O
our -X- _ O
joint -X- _ O
training -X- _ O
process -X- _ O
, -X- _ O
and -X- _ O
successfully -X- _ O
connect -X- _ O
new -X- _ O
language -X- _ O
representations -X- _ O
to -X- _ O
the -X- _ O
logical -X- _ O
- -X- _ O
form -X- _ O
decoder -X- _ O
at -X- _ O
test -X- _ O
time -X- _ O
. -X- _ O
This -X- _ O
sequenceto -X- _ B-MethodName
- -X- _ I-MethodName
sequence -X- _ I-MethodName
approach -X- _ O
is -X- _ O
highly -X- _ O
flexible -X- _ O
and -X- _ O
may -X- _ O
be -X- _ O
useful -X- _ O
for -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
approaches -X- _ O
to -X- _ O
additional -X- _ O
generation -X- _ B-TaskName
tasks -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
paraphrasing -X- _ O
) -X- _ O
. -X- _ O

Experimental -X- _ O
Setup -X- _ O

Semantic -X- _ B-TaskName
Parsing -X- _ I-TaskName
Datasets -X- _ O
Our -X- _ O
experiments -X- _ O
examine -X- _ O
whether -X- _ O
our -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
approach -X- _ O
generalizes -X- _ O
across -X- _ O
languages -X- _ O
and -X- _ O
domains -X- _ O
. -X- _ O
We -X- _ O
evaluate -X- _ O
performance -X- _ O
on -X- _ O
a -X- _ O
new -X- _ O
version -X- _ O
of -X- _ O
the -X- _ O
ATIS -X- _ B-DatasetName
dataset -X- _ O
of -X- _ O
travel -X- _ O
queries -X- _ O
( -X- _ O
Hemphill -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
1990 -X- _ O
; -X- _ O
Dahl -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
1994 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
align -X- _ O
existing -X- _ O
English -X- _ O
utterances -X- _ O
and -X- _ O
SQL -X- _ O
logical -X- _ O
forms -X- _ O
from -X- _ O
Iyer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
to -X- _ O
the -X- _ O
multi -X- _ O
- -X- _ O
lingual -X- _ O
utterances -X- _ O
from -X- _ O
the -X- _ O
MultiATIS++ -X- _ B-DatasetName
dataset -X- _ O
for -X- _ O
spoken -X- _ O
language -X- _ O
understanding -X- _ O
. -X- _ O
This -X- _ O
alignment -X- _ O
adds -X- _ O
executable -X- _ O
SQL -X- _ O
queries -X- _ O
to -X- _ O
utterances -X- _ O
in -X- _ O
Chinese -X- _ O
( -X- _ O
ZH -X- _ O
) -X- _ O
, -X- _ O
German -X- _ O
( -X- _ O
DE -X- _ O
) -X- _ O
, -X- _ O
French -X- _ O
( -X- _ O
FR -X- _ O
) -X- _ O
, -X- _ O
Spanish -X- _ O
( -X- _ O
ES -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
Portuguese -X- _ O
( -X- _ O
PT -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
4,473 -X- _ B-HyperparameterValue
/ -X- _ I-HyperparameterValue
493 -X- _ I-HyperparameterValue
/ -X- _ I-HyperparameterValue
448 -X- _ I-HyperparameterValue
dataset -X- _ O
split -X- _ O
for -X- _ O
training -X- _ B-HyperparameterName
/ -X- _ I-HyperparameterName
validation -X- _ I-HyperparameterName
/ -X- _ I-HyperparameterName
test -X- _ I-HyperparameterName
as -X- _ O
Kwiatkowski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2011 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
add -X- _ O
to -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
Hindi -X- _ O
( -X- _ O
HI -X- _ O
) -X- _ O
and -X- _ O
Turkish -X- _ O
( -X- _ O
TR -X- _ O
) -X- _ O
utterances -X- _ O
from -X- _ O
Upadhyay -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
3 -X- _ O
We -X- _ O
can -X- _ O
now -X- _ O
predict -X- _ O
SQL -X- _ O
from -X- _ O
the -X- _ O
ATIS -X- _ B-DatasetName
test -X- _ O
questions -X- _ O
in -X- _ O
eight -X- _ O
natural -X- _ O
languages -X- _ O
. -X- _ O
The -X- _ O
Multi -X- _ B-DatasetName
- -X- _ I-DatasetName
ATIS++ -X- _ I-DatasetName
Japanese -X- _ O
set -X- _ O
was -X- _ O
excluded -X- _ O
as -X- _ O
the -X- _ O
utterance -X- _ O
alignment -X- _ O
to -X- _ O
this -X- _ O
language -X- _ O
was -X- _ O
not -X- _ O
recoverable -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
examine -X- _ O
Overnight -X- _ B-DatasetName
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
, -X- _ O
an -X- _ O
eight -X- _ O
- -X- _ O
domain -X- _ O
dataset -X- _ O
covering -X- _ O
Basketball -X- _ O
, -X- _ O
Blocks -X- _ O
, -X- _ O
Calendar -X- _ O
, -X- _ O
Housing -X- _ O
, -X- _ O
Publications -X- _ O
, -X- _ O
Recipes -X- _ O
, -X- _ O
Restaurants -X- _ O
, -X- _ O
and -X- _ O
Social -X- _ O
Network -X- _ O
domains -X- _ O
. -X- _ O
Overnight -X- _ B-DatasetName
comprises -X- _ O
13,682 -X- _ O
English -X- _ O
utterances -X- _ O
paired -X- _ O
with -X- _ O
λ−DCS -X- _ O
logical -X- _ O
forms -X- _ O
, -X- _ O
executable -X- _ O
in -X- _ O
SEMPRE -X- _ O
( -X- _ O
Berant -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
We -X- _ O
measure -X- _ O
performance -X- _ O
with -X- _ O
denotation -X- _ O
accuracy -X- _ O
as -X- _ O
all -X- _ O
inferred -X- _ O
logical -X- _ O
forms -X- _ O
are -X- _ O
executable -X- _ O
in -X- _ O
some -X- _ O
knowledge -X- _ O
base -X- _ O
. -X- _ O
This -X- _ O
metric -X- _ O
compares -X- _ O
the -X- _ O
retrieved -X- _ O
denotation -X- _ O
from -X- _ O
the -X- _ O
prediction -X- _ O
, -X- _ O
ŷ -X- _ O
, -X- _ O
to -X- _ O
that -X- _ O
from -X- _ O
executing -X- _ O
the -X- _ O
gold -X- _ O
- -X- _ O
standard -X- _ O
logical -X- _ O
form -X- _ O
. -X- _ O
Dataset -X- _ O
sizes -X- _ O
are -X- _ O
outlined -X- _ O
in -X- _ O
Appendix -X- _ O
A -X- _ O
. -X- _ O

Natural -X- _ O
Language -X- _ O
Data -X- _ O
For -X- _ O
the -X- _ O
reconstruction -X- _ B-TaskName
objective -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
the -X- _ O
MKQA -X- _ B-DatasetName
corpus -X- _ O
( -X- _ O
Longpre -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
lingual -X- _ O
translation -X- _ O
of -X- _ O
10,000 -X- _ O
samples -X- _ O
from -X- _ O
NaturalQuestions -X- _ O
( -X- _ O
Kwiatkowski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
suitable -X- _ O
for -X- _ O
our -X- _ O
auxiliary -X- _ O
objective -X- _ O
as -X- _ O
the -X- _ O
utterances -X- _ O
are -X- _ O
native -X- _ O
- -X- _ O
speaker -X- _ O
question -X- _ O
surface -X- _ O
forms -X- _ O
, -X- _ O
matching -X- _ O
our -X- _ O
test -X- _ O
set -X- _ O
while -X- _ O
varying -X- _ O
in -X- _ O
subject -X- _ O
. -X- _ O
MKQA -X- _ B-DatasetName
is -X- _ O
also -X- _ O
balanced -X- _ O
across -X- _ O
new -X- _ O
languages -X- _ O
to -X- _ O
limit -X- _ O
overexposure -X- _ O
bias -X- _ O
to -X- _ O
one -X- _ O
new -X- _ O
language -X- _ O
. -X- _ O
For -X- _ O
bi -X- _ O
- -X- _ O
text -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
original -X- _ O
English -X- _ O
and -X- _ O
the -X- _ O
professionally -X- _ O
translated -X- _ O
question -X- _ O
as -X- _ O
a -X- _ O
pair -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
report -X- _ O
experiments -X- _ O
using -X- _ O
a -X- _ O
sample -X- _ O
of -X- _ O
crawled -X- _ O
data -X- _ O
from -X- _ O
ParaCrawl -X- _ B-DatasetName
7.1 -X- _ O
( -X- _ O
Bañón -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
sample -X- _ O
comprises -X- _ O
10,000 -X- _ O
web -X- _ O
scraped -X- _ O
sentences -X- _ O
paired -X- _ O
with -X- _ O
equivalent -X- _ O
English -X- _ O
to -X- _ O
form -X- _ O
bitext -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
these -X- _ O
samples -X- _ O
are -X- _ O
mostly -X- _ O
declarative -X- _ O
sentences -X- _ O
and -X- _ O
as -X- _ O
such -X- _ O
do -X- _ O
not -X- _ O
match -X- _ O
the -X- _ O
surface -X- _ O
form -X- _ O
of -X- _ O
our -X- _ O
test -X- _ O
inputs -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
questions -X- _ O
) -X- _ O
and -X- _ O
are -X- _ O
also -X- _ O
not -X- _ O
parallel -X- _ O
between -X- _ O
sampled -X- _ O
languages -X- _ O
. -X- _ O
We -X- _ O
contrast -X- _ O
this -X- _ O
to -X- _ O
MKQA -X- _ B-DatasetName
to -X- _ O
examine -X- _ O
how -X- _ O
the -X- _ O
style -X- _ O
of -X- _ O
natural -X- _ O
language -X- _ O
data -X- _ O
influences -X- _ O
performance -X- _ O
. -X- _ O

For -X- _ O
ATIS -X- _ B-DatasetName
experiments -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
60,000 -X- _ O
utterances -X- _ O
from -X- _ O
each -X- _ O
source -X- _ O
in -X- _ O
languages -X- _ O
with -X- _ O
training -X- _ O
data -X- _ O
( -X- _ O
EN -X- _ O
, -X- _ O
FR -X- _ O
, -X- _ O
PT -X- _ O
, -X- _ O
ES -X- _ O
, -X- _ O
DE -X- _ O
, -X- _ O
ZH -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
Overnight -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
3 -X- _ O
Misalignment -X- _ O
between -X- _ O
ATIS -X- _ B-DatasetName
versions -X- _ O
result -X- _ O
in -X- _ O
the -X- _ O
test -X- _ O
sets -X- _ O
containing -X- _ O
442 -X- _ O
and -X- _ O
381 -X- _ O
utterances -X- _ O
for -X- _ O
HI -X- _ O
and -X- _ O
TR -X- _ O
respectively -X- _ O
. -X- _ O

30,000 -X- _ O
utterances -X- _ O
in -X- _ O
EN -X- _ O
, -X- _ O
DE -X- _ O
, -X- _ O
and -X- _ O
ZH -X- _ O
. -X- _ O

Model -X- _ O
Configuration -X- _ O

The -X- _ O
implementation -X- _ O
of -X- _ O
ZX -X- _ B-MethodName
- -X- _ I-MethodName
PARSE -X- _ I-MethodName
( -X- _ O
see -X- _ O
Section -X- _ O
4 -X- _ O
) -X- _ O
largely -X- _ O
follows -X- _ O
parameter -X- _ O
settings -X- _ O
from -X- _ O
for -X- _ O
Transformer -X- _ O
encoder -X- _ O
and -X- _ O
decoder -X- _ O
layers -X- _ O
( -X- _ O
see -X- _ O
Appendix -X- _ O
A -X- _ O
for -X- _ O
details -X- _ O
on -X- _ O
model -X- _ O
configuration -X- _ O
) -X- _ O
. -X- _ O
ZX -X- _ B-MethodName
- -X- _ I-MethodName
PARSE -X- _ I-MethodName
requires -X- _ O
an -X- _ O
encoder -X- _ O
model -X- _ O
to -X- _ O
generate -X- _ O
multi -X- _ O
- -X- _ O
lingual -X- _ O
latent -X- _ O
representations -X- _ O
for -X- _ O
all -X- _ O
objectives -X- _ O
. -X- _ O
Our -X- _ O
main -X- _ O
results -X- _ O
use -X- _ O
only -X- _ O
the -X- _ O
encoder -X- _ O
component -X- _ O
of -X- _ O
mBART50 -X- _ B-MethodName
( -X- _ O
Tang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
we -X- _ O
present -X- _ O
experiments -X- _ O
using -X- _ O
other -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
in -X- _ O
Appendix -X- _ O
B. -X- _ O
We -X- _ O
use -X- _ O
all -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
encoder -X- _ O
layers -X- _ O
and -X- _ O
append -X- _ O
one -X- _ O
additional -X- _ O
learnable -X- _ O
layer -X- _ O
. -X- _ O
All -X- _ O
decoders -X- _ O
are -X- _ O
randomly -X- _ O
initialized -X- _ O
six -X- _ O
- -X- _ O
layer -X- _ O
stacks -X- _ O
. -X- _ O
Early -X- _ O
experiments -X- _ O
found -X- _ O
this -X- _ O
approach -X- _ O
superior -X- _ O
to -X- _ O
any -X- _ O
pretrained -X- _ O
decoder -X- _ O
initialization -X- _ O
. -X- _ O

The -X- _ O
language -X- _ O
predictor -X- _ O
follows -X- _ O
from -X- _ O
Ahmad -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019b -X- _ O
) -X- _ O
as -X- _ O
a -X- _ O
single -X- _ O
linear -X- _ O
classification -X- _ O
layer -X- _ O
mapping -X- _ O
from -X- _ O
1,024 -X- _ O
inputs -X- _ O
to -X- _ O
L -X- _ O
output -X- _ O
languages -X- _ O
. -X- _ O
Earlier -X- _ O
findings -X- _ O
supported -X- _ O
that -X- _ O
if -X- _ O
the -X- _ O
LP -X- _ B-TaskName
network -X- _ O
is -X- _ O
larger -X- _ O
, -X- _ O
then -X- _ O
the -X- _ O
reversed -X- _ O
gradient -X- _ O
signal -X- _ O
is -X- _ O
too -X- _ O
strong -X- _ O
and -X- _ O
therefore -X- _ O
less -X- _ O
useful -X- _ O
as -X- _ O
the -X- _ O
LP -X- _ B-TaskName
network -X- _ O
can -X- _ O
memorize -X- _ O
the -X- _ O
language -X- _ O
. -X- _ O

Comparison -X- _ O
Models -X- _ O
We -X- _ O
primarily -X- _ O
compare -X- _ O
to -X- _ O
a -X- _ O
" -X- _ O
Translate -X- _ B-MethodName
- -X- _ I-MethodName
Test -X- _ I-MethodName
" -X- _ O
back -X- _ O
- -X- _ O
translation -X- _ O
baseline -X- _ O
wherein -X- _ O
the -X- _ O
new -X- _ O
language -X- _ O
test -X- _ O
set -X- _ O
is -X- _ O
translated -X- _ O
to -X- _ O
English -X- _ O
using -X- _ O
Google -X- _ O
Translate -X- _ O
( -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
and -X- _ O
input -X- _ O
to -X- _ O
a -X- _ O
reference -X- _ O
sequence -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
sequence -X- _ O
model -X- _ O
trained -X- _ O
on -X- _ O
English -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
compare -X- _ O
to -X- _ O
" -X- _ O
Translate -X- _ B-MethodName
- -X- _ I-MethodName
Train -X- _ I-MethodName
" -X- _ O
, -X- _ O
where -X- _ O
we -X- _ O
use -X- _ O
MT -X- _ B-TaskName
from -X- _ O
English -X- _ O
to -X- _ O
generate -X- _ O
a -X- _ O
proxy -X- _ O
dataset -X- _ O
in -X- _ O
each -X- _ O
new -X- _ O
language -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
French -X- _ O
, -X- _ O
Portuguese -X- _ O
, -X- _ O
Spanish -X- _ O
, -X- _ O
German -X- _ O
, -X- _ O
Chinese -X- _ O
, -X- _ O
Hindi -X- _ O
and -X- _ O
Turkish -X- _ O
) -X- _ O
to -X- _ O
train -X- _ O
a -X- _ O
monolingual -X- _ O
parser -X- _ O
. -X- _ O
We -X- _ O
consider -X- _ O
improving -X- _ O
upon -X- _ O
these -X- _ O
" -X- _ O
minimum -X- _ O
effort -X- _ O
" -X- _ O
baselines -X- _ O
as -X- _ O
a -X- _ O
lower -X- _ O
bound -X- _ O
for -X- _ O
justifying -X- _ O
our -X- _ O
approach -X- _ O
. -X- _ O

Additionally -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
to -X- _ O
an -X- _ O
upper -X- _ O
- -X- _ O
bound -X- _ O
monolingual -X- _ O
model -X- _ O
trained -X- _ O
on -X- _ O
professional -X- _ O
translations -X- _ O
of -X- _ O
the -X- _ O
new -X- _ O
languages -X- _ O
. -X- _ O
We -X- _ O
report -X- _ O
results -X- _ O
on -X- _ O
MultiATIS++ -X- _ B-DatasetName
for -X- _ O
FR -X- _ O
, -X- _ O
PT -X- _ O
, -X- _ O
ES -X- _ O
, -X- _ O
DE -X- _ O
, -X- _ O
and -X- _ O
ZH -X- _ O
( -X- _ O
professional -X- _ O
translations -X- _ O
are -X- _ O
not -X- _ O
available -X- _ O
for -X- _ O
Overnight -X- _ O
training -X- _ O
data -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
the -X- _ O
" -X- _ O
maximum -X- _ O
effort -X- _ O
" -X- _ O
strategy -X- _ O
that -X- _ O
we -X- _ O
desire -X- _ O
to -X- _ O
avoid -X- _ O
. -X- _ O
Parameters -X- _ O
for -X- _ O
these -X- _ O
reference -X- _ O
systems -X- _ O
match -X- _ O
those -X- _ O
outlined -X- _ O
above -X- _ O
e.g. -X- _ O
, -X- _ O
mBART50 -X- _ O
encoder -X- _ O
to -X- _ O
logical -X- _ O
form -X- _ O
decoder -X- _ O
. -X- _ O

Results -X- _ O

Our -X- _ O
results -X- _ O
are -X- _ O
outlined -X- _ O
to -X- _ O
answer -X- _ O
four -X- _ O
core -X- _ O
questions -X- _ O
, -X- _ O
with -X- _ O
additional -X- _ O
ablations -X- _ O
in -X- _ O
Appendix -X- _ O
B. -X- _ O
Our -X- _ O
findings -X- _ O
support -X- _ O
the -X- _ O
hypothesis -X- _ O
that -X- _ O
we -X- _ O
can -X- _ O
minimize -X- _ O
the -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
transfer -X- _ O
penalty -X- _ O
by -X- _ O
im- -X- _ O
( -X- _ O
Dahl -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
1994 -X- _ O
) -X- _ O
and -X- _ O
Overnight -X- _ B-DatasetName
( -X- _ O
eight -X- _ O
- -X- _ O
domain -X- _ O
average -X- _ O
; -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
for -X- _ O
supervised -X- _ O
monolingual -X- _ O
upper -X- _ O
- -X- _ O
bound -X- _ O
, -X- _ O
Translate -X- _ B-MethodName
- -X- _ I-MethodName
Test -X- _ I-MethodName
, -X- _ O
and -X- _ O
our -X- _ O
best -X- _ O
ZX -X- _ B-MethodName
- -X- _ I-MethodName
PARSE -X- _ I-MethodName
model -X- _ O
. -X- _ O
Results -X- _ O
for -X- _ O
English -X- _ O
( -X- _ O
EN -X- _ O
) -X- _ O
, -X- _ O
French -X- _ O
( -X- _ O
FR -X- _ O
) -X- _ O
, -X- _ O
Portuguese -X- _ O
( -X- _ O
PT -X- _ O
) -X- _ O
, -X- _ O
Spanish -X- _ O
( -X- _ O
ES -X- _ O
) -X- _ O
, -X- _ O
German -X- _ O
( -X- _ O
DE -X- _ O
) -X- _ O
, -X- _ O
Chinese -X- _ O
( -X- _ O
ZH -X- _ O
) -X- _ O
, -X- _ O
Hindi -X- _ O
( -X- _ O
HI -X- _ O
) -X- _ O
and -X- _ O
Turkish -X- _ O
( -X- _ O
TR -X- _ O
) -X- _ O
ranked -X- _ O
by -X- _ O
similarity -X- _ O
to -X- _ O
English -X- _ O
( -X- _ O
Ahmad -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019a -X- _ O
) -X- _ O
. -X- _ O
Best -X- _ O
results -X- _ O
compared -X- _ O
to -X- _ O
baselines -X- _ O
are -X- _ O
bolded -X- _ O
. -X- _ O
proving -X- _ O
latent -X- _ O
alignment -X- _ O
with -X- _ O
auxiliary -X- _ O
objectives -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
examine -X- _ O
the -X- _ O
latent -X- _ O
space -X- _ O
directly -X- _ O
and -X- _ O
find -X- _ O
ZX -X- _ B-MethodName
- -X- _ I-MethodName
PARSE -X- _ I-MethodName
learns -X- _ O
more -X- _ O
similar -X- _ O
representations -X- _ O
between -X- _ O
languages -X- _ O
. -X- _ O
Our -X- _ O
parser -X- _ O
achieves -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
theart -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
results -X- _ O
for -X- _ O
all -X- _ O
non -X- _ O
- -X- _ O
English -X- _ O
languages -X- _ O
in -X- _ O
the -X- _ O
MultiATIS++ -X- _ B-DatasetName
and -X- _ O
Overnight -X- _ B-DatasetName
benchmarks -X- _ O
. -X- _ O

Better -X- _ O
than -X- _ O
Translation -X- _ B-TaskName
? -X- _ O
We -X- _ O
compare -X- _ O
between -X- _ O
ZX -X- _ B-MethodName
- -X- _ I-MethodName
PARSE -X- _ I-MethodName
and -X- _ O
the -X- _ O
upper -X- _ O
- -X- _ O
and -X- _ O
lower -X- _ O
- -X- _ O
bounds -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O
Our -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
approach -X- _ O
significantly -X- _ O
improves -X- _ O
upon -X- _ O
" -X- _ O
Translate -X- _ B-MethodName
- -X- _ I-MethodName
Test -X- _ I-MethodName
" -X- _ O
for -X- _ O
all -X- _ O
languages -X- _ O
included -X- _ O
within -X- _ O
the -X- _ O
auxiliary -X- _ O
objectives -X- _ O
( -X- _ O
p -X- _ O
< -X- _ O
0.01 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
ATIS -X- _ B-DatasetName
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
" -X- _ O
Translate -X- _ B-MethodName
- -X- _ I-MethodName
Train -X- _ I-MethodName
" -X- _ O
performs -X- _ O
below -X- _ O
" -X- _ O
Translate -X- _ B-MethodName
- -X- _ I-MethodName
Test -X- _ I-MethodName
" -X- _ O
for -X- _ O
languages -X- _ O
similar -X- _ O
to -X- _ O
English -X- _ O
( -X- _ O
FR -X- _ O
, -X- _ O
ES -X- _ O
, -X- _ O
PT -X- _ O
) -X- _ O
but -X- _ O
worse -X- _ O
for -X- _ O
more -X- _ O
distant -X- _ O
languages -X- _ O
( -X- _ O
DE -X- _ O
, -X- _ O
ZH -X- _ O
) -X- _ O
. -X- _ O
ZX -X- _ B-MethodName
- -X- _ I-MethodName
PARSE -X- _ I-MethodName
performance -X- _ O
improves -X- _ O
on -X- _ O
" -X- _ O
Translate -X- _ B-MethodName
- -X- _ I-MethodName
Train -X- _ I-MethodName
" -X- _ O
for -X- _ O
all -X- _ O
languages -X- _ O
included -X- _ O
in -X- _ O
reconstruction -X- _ O
( -X- _ O
EN -X- _ O
, -X- _ O
FR -X- _ O
, -X- _ O
PT -X- _ O
, -X- _ O
ES -X- _ O
, -X- _ O
DE -X- _ O
, -X- _ O
ZH -X- _ O
) -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
the -X- _ O
general -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
improvement -X- _ O
insufficiently -X- _ O
extends -X- _ O
to -X- _ O
additional -X- _ O
languages -X- _ O
( -X- _ O
HI -X- _ O
, -X- _ O
TR -X- _ O
) -X- _ O
to -X- _ O
perform -X- _ O
above -X- _ O
baselines -X- _ O
. -X- _ O

Within -X- _ O
ZX -X- _ B-MethodName
- -X- _ I-MethodName
PARSE -X- _ I-MethodName
, -X- _ O
French -X- _ O
and -X- _ O
German -X- _ O
demonstrate -X- _ O
the -X- _ O
strongest -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
accuracy -X- _ B-MetricName
-+2.4 -X- _ B-DatasetName
% -X- _ I-DatasetName
and -X- _ O
+2.7 -X- _ B-MetricValue
% -X- _ I-MetricValue
above -X- _ O
the -X- _ O
monolingual -X- _ O
upper -X- _ O
bound -X- _ O
for -X- _ O
ATIS -X- _ B-DatasetName
. -X- _ O
We -X- _ O
do -X- _ O
not -X- _ O
observe -X- _ O
similar -X- _ O
improvement -X- _ O
for -X- _ O
Portuguese -X- _ O
or -X- _ O
Spanish -X- _ O
despite -X- _ O
their -X- _ O
similarity -X- _ O
to -X- _ O
English -X- _ O
. -X- _ O
This -X- _ O
may -X- _ O
be -X- _ O
a -X- _ O
result -X- _ O
of -X- _ O
German -X- _ O
and -X- _ O
French -X- _ O
dominating -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
corpora -X- _ O
com -X- _ O
- -X- _ O
pared -X- _ O
to -X- _ O
other -X- _ O
new -X- _ O
languages -X- _ O
. -X- _ O
( -X- _ O
Tang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
, -X- _ O
their -X- _ O
Table -X- _ O
6 -X- _ O
) -X- _ O
. -X- _ O

Our -X- _ O
model -X- _ O
demonstrates -X- _ O
similar -X- _ O
significant -X- _ O
improvement -X- _ O
for -X- _ O
Overnight -X- _ B-DatasetName
( -X- _ O
p -X- _ O
< -X- _ O
0.01 -X- _ O
) -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
lesser -X- _ O
gain -X- _ O
compared -X- _ O
to -X- _ O
ATIS -X- _ B-DatasetName
. -X- _ O
This -X- _ O
may -X- _ O
be -X- _ O
a -X- _ O
consequence -X- _ O
of -X- _ O
the -X- _ O
compounded -X- _ O
challenge -X- _ O
of -X- _ O
evaluating -X- _ O
eight -X- _ O
varied -X- _ O
domains -X- _ O
of -X- _ O
complex -X- _ O
linguistic -X- _ O
constructs -X- _ O
. -X- _ O
Here -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
" -X- _ O
Translate -X- _ B-MethodName
- -X- _ I-MethodName
Train -X- _ I-MethodName
" -X- _ O
is -X- _ O
a -X- _ O
stronger -X- _ O
approach -X- _ O
than -X- _ O
" -X- _ O
Translate -X- _ B-MethodName
- -X- _ I-MethodName
Test -X- _ I-MethodName
" -X- _ O
, -X- _ O
which -X- _ O
may -X- _ O
be -X- _ O
a -X- _ O
consequence -X- _ O
of -X- _ O
machine -X- _ B-TaskName
- -X- _ I-TaskName
translation -X- _ I-TaskName
direction -X- _ O
. -X- _ O
Our -X- _ O
best -X- _ O
approach -X- _ O
on -X- _ O
German -X- _ O
still -X- _ O
improves -X- _ O
above -X- _ O
" -X- _ O
Translate -X- _ B-MethodName
- -X- _ I-MethodName
Train -X- _ I-MethodName
" -X- _ O
( -X- _ O
+4.0 -X- _ B-MetricValue
% -X- _ I-MetricValue
) -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
performance -X- _ O
on -X- _ O
Chinese -X- _ O
to -X- _ O
be -X- _ O
only -X- _ O
marginally -X- _ O
improved -X- _ O
by -X- _ O
comparison -X- _ O
( -X- _ O
+0.6 -X- _ B-MetricValue
% -X- _ I-MetricValue
) -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
observe -X- _ O
some -X- _ O
contrast -X- _ O
in -X- _ O
ZX -X- _ B-MethodName
- -X- _ I-MethodName
PARSE -X- _ I-MethodName
performance -X- _ O
related -X- _ O
to -X- _ O
orthographic -X- _ O
similarity -X- _ O
to -X- _ O
English -X- _ O
. -X- _ O
Parsing -X- _ O
accuracy -X- _ B-MetricName
on -X- _ O
Overnight -X- _ B-DatasetName
in -X- _ O
German -X- _ O
is -X- _ O
+6.2 -X- _ B-MetricValue
% -X- _ I-MetricValue
above -X- _ O
Chinese -X- _ O
, -X- _ O
with -X- _ O
a -X- _ O
similar -X- _ O
+9.1 -X- _ B-MetricValue
% -X- _ I-MetricValue
gap -X- _ O
between -X- _ O
these -X- _ O
same -X- _ O
languages -X- _ O
for -X- _ O
ATIS -X- _ B-DatasetName
. -X- _ O

Which -X- _ O
Objective -X- _ O
Matters -X- _ O
? -X- _ O
Ablations -X- _ O
to -X- _ O
the -X- _ O
model -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
, -X- _ O
identifying -X- _ O
the -X- _ O
contributions -X- _ O
of -X- _ O
different -X- _ O
objectives -X- _ O
. -X- _ O
Model -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
shows -X- _ O
that -X- _ O
without -X- _ O
auxiliary -X- _ O
objectives -X- _ O
, -X- _ O
performance -X- _ O
in -X- _ O
new -X- _ O
languages -X- _ O
is -X- _ O
generally -X- _ O
below -X- _ O
Translate -X- _ B-MethodName
- -X- _ I-MethodName
Test -X- _ I-MethodName
. -X- _ O
This -X- _ O
is -X- _ O
unsurprising -X- _ O
, -X- _ O
as -X- _ O
this -X- _ O
approach -X- _ O
uses -X- _ O
only -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
information -X- _ O
without -X- _ O
additional -X- _ O
effort -X- _ O
to -X- _ O
improve -X- _ O
similarity -X- _ O
. -X- _ O
Such -X- _ O
efforts -X- _ O
are -X- _ O
incorporated -X- _ O
in -X- _ O
Model -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
using -X- _ O
the -X- _ O
additional -X- _ O
reconstruction -X- _ O
decoder -X- _ O
. -X- _ O
Even -X- _ O
without -X- _ O
the -X- _ O
LP -X- _ B-TaskName
loss -X- _ O
, -X- _ O
domain -X- _ O
targeted -X- _ O
adaptation -X- _ O
( -X- _ O
with -X- _ O
translation -X- _ O
) -X- _ O
improves -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
parsing -X- _ I-TaskName
by -X- _ O
an -X- _ O
average -X- _ O
across -X- _ O
new -X- _ O
languages -X- _ O
of -X- _ O
+9.3 -X- _ B-MetricValue
% -X- _ I-MetricValue
for -X- _ O
ATIS -X- _ B-DatasetName
and -X- _ O
+2.9 -X- _ B-MetricValue
% -X- _ I-MetricValue
for -X- _ O
Overnight -X- _ B-DatasetName
. -X- _ O
Notably -X- _ O
, -X- _ O
we -X- _ O
identified -X- _ O
an -X- _ O
optimal -X- _ O
ratio -X- _ O
of -X- _ O
translation -X- _ O
to -X- _ O
reconstruction -X- _ O
of -X- _ O
50 -X- _ O
% -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
τ -X- _ O
= -X- _ O
0.5 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
suggests -X- _ O
that -X- _ O
both -X- _ O
monolingual -X- _ O
utterances -X- _ O
( -X- _ O
for -X- _ O
domain -X- _ O
- -X- _ O
adaptive -X- _ O
tuning -X- _ O
) -X- _ O
and -X- _ O
bi -X- _ O
- -X- _ O
text -X- _ O
( -X- _ O
for -X- _ O
translation -X- _ B-TaskName
) -X- _ O
contribute -X- _ O
to -X- _ O
the -X- _ O
utility -X- _ O
of -X- _ O
our -X- _ O
method -X- _ O
beyond -X- _ O
reliance -X- _ O
on -X- _ O
one -X- _ O
technique -X- _ O
. -X- _ O

Evaluating -X- _ O
the -X- _ O
LP -X- _ B-DatasetName
objective -X- _ O
within -X- _ O
Model -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
and -X- _ O
( -X- _ O
d -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
the -X- _ O
reversed -X- _ O
gradient -X- _ O
successfully -X- _ O
reduces -X- _ O
language -X- _ O
discriminability -X- _ O
. -X- _ O
For -X- _ O
Model -X- _ O
( -X- _ O
d -X- _ O
) -X- _ O
, -X- _ O
language -X- _ O
prediction -X- _ O
accuracy -X- _ B-MetricName
during -X- _ O
training -X- _ O
peaks -X- _ O
at -X- _ O
93 -X- _ B-MetricValue
% -X- _ I-MetricValue
after -X- _ O
2 -X- _ B-MetricValue
% -X- _ I-MetricValue
progress -X- _ O
and -X- _ O
subsequently -X- _ O
decreases -X- _ O
to -X- _ O
< -X- _ O
8 -X- _ B-MetricValue
% -X- _ I-MetricValue
beyond -X- _ O
10 -X- _ B-MetricValue
% -X- _ I-MetricValue
of -X- _ O
training -X- _ O
. -X- _ O
Language -X- _ B-TaskName
prediction -X- _ I-TaskName
accuracy -X- _ B-MetricName
for -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
is -X- _ O
7.2 -X- _ B-MetricValue
% -X- _ I-MetricValue
. -X- _ O
We -X- _ O
observe -X- _ O
a -X- _ O
similar -X- _ O
trend -X- _ O
for -X- _ O
Model -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
. -X- _ O
Comparing -X- _ O
individual -X- _ O
objectives -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
the -X- _ O
addition -X- _ O
of -X- _ O
the -X- _ O
language -X- _ O
predictor -X- _ O
alone -X- _ O
less -X- _ O
helpful -X- _ O
than -X- _ O
the -X- _ O
reconstruction -X- _ O
decoder -X- _ O
. -X- _ O
Comparing -X- _ O
Model -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
and -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
a -X- _ O
smaller -X- _ O
average -X- _ O
improvement -X- _ O
on -X- _ O
new -X- _ O
languages -X- _ O
of -X- _ O
+4.3 -X- _ B-MetricValue
% -X- _ I-MetricValue
for -X- _ O
ATIS -X- _ B-DatasetName
and -X- _ O
+1.8 -X- _ B-MetricValue
% -X- _ I-MetricValue
for -X- _ O
Overnight -X- _ B-DatasetName
. -X- _ O
This -X- _ O
suggests -X- _ O
adaptation -X- _ O
towards -X- _ O
specific -X- _ O
surface -X- _ O
form -X- _ O
patterns -X- _ O
can -X- _ O
be -X- _ O
more -X- _ O
effective -X- _ O
here -X- _ O
than -X- _ O
modeling -X- _ O
languages -X- _ O
as -X- _ O
discrete -X- _ O
labels -X- _ O
. -X- _ O

Considering -X- _ O
the -X- _ O
combination -X- _ O
of -X- _ O
objectives -X- _ O
in -X- _ O
Model -X- _ O
( -X- _ O
d -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
identify -X- _ O
cumulative -X- _ O
benefit -X- _ O
to -X- _ O
parsing -X- _ O
with -X- _ O
both -X- _ O
objectives -X- _ O
. -X- _ O
Compared -X- _ O
to -X- _ O
Model -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
full -X- _ O
model -X- _ O
improves -X- _ O
by -X- _ O
an -X- _ O
average -X- _ O
of -X- _ O
+16.3 -X- _ B-MetricValue
% -X- _ I-MetricValue
for -X- _ O
ATIS -X- _ B-DatasetName
and -X- _ O
+9.9 -X- _ B-MetricValue
% -X- _ I-MetricValue
for -X- _ O
Overnight -X- _ B-DatasetName
across -X- _ O
new -X- _ O
languages -X- _ O
. -X- _ O
Our -X- _ O
findings -X- _ O
support -X- _ O
our -X- _ O
claim -X- _ O
that -X- _ O
latent -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
similarity -X- _ O
can -X- _ O
be -X- _ O
improved -X- _ O
using -X- _ O
auxiliary -X- _ O
objectives -X- _ O
and -X- _ O
we -X- _ O
specifically -X- _ O
identify -X- _ O
that -X- _ O
a -X- _ O
combination -X- _ O
of -X- _ O
approaches -X- _ O
yields -X- _ O
superior -X- _ O
parsing -X- _ O
. -X- _ O
We -X- _ O
suggest -X- _ O
that -X- _ O
this -X- _ O
combination -X- _ O
benefits -X- _ O
from -X- _ O
constructive -X- _ O
interference -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
language -X- _ B-TaskName
prediction -X- _ I-TaskName
loss -X- _ O
promotes -X- _ O
invariance -X- _ O
in -X- _ O
tandem -X- _ O
with -X- _ O
multilingual -X- _ B-TaskName
generation -X- _ I-TaskName
tasks -X- _ O
adapting -X- _ O
the -X- _ O
encoder -X- _ O
to -X- _ O
improve -X- _ O
modeling -X- _ O
the -X- _ O
surface -X- _ O
form -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
questions -X- _ O
from -X- _ O
native -X- _ O
speakers -X- _ O
) -X- _ O
of -X- _ O
the -X- _ O
new -X- _ O
language -X- _ O
test -X- _ O
data -X- _ O
. -X- _ O

Additional -X- _ O
objectives -X- _ O
also -X- _ O
improve -X- _ O
parsing -X- _ B-TaskName
for -X- _ O
Hindi -X- _ O
and -X- _ O
Turkish -X- _ O
despite -X- _ O
neither -X- _ O
being -X- _ O
included -X- _ O
within -X- _ O
auxiliary -X- _ O
training -X- _ O
data -X- _ O
( -X- _ O
see -X- _ O
HI -X- _ O
and -X- _ O
TR -X- _ O
columns -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
) -X- _ O
. -X- _ O
By -X- _ O
adapting -X- _ O
our -X- _ O
latent -X- _ O
representation -X- _ O
to -X- _ O
encourage -X- _ O
similarity -X- _ O
, -X- _ O
we -X- _ O
improve -X- _ O
parsing -X- _ O
accuracy -X- _ B-MetricName
for -X- _ O
two -X- _ O
typologically -X- _ O
diverse -X- _ O
languages -X- _ O
without -X- _ O
explicit -X- _ O
guidance -X- _ O
. -X- _ O
To -X- _ O
further -X- _ O
examine -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
visualize -X- _ O
the -X- _ O
MultiATIS++ -X- _ B-DatasetName
test -X- _ O
set -X- _ O
in -X- _ O
Figure -X- _ O
3 -X- _ O
from -X- _ O
ZX -X- _ B-MethodName
- -X- _ I-MethodName
PARSE -X- _ I-MethodName
compared -X- _ O
to -X- _ O
mBART50 -X- _ B-MethodName
. -X- _ O
Quantitatively -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
the -X- _ O
average -X- _ O
cosine -X- _ B-MetricName
distance -X- _ I-MetricName
between -X- _ O
the -X- _ O
sentence -X- _ O
- -X- _ O
mean -X- _ O
of -X- _ O
parallel -X- _ O
utterances -X- _ O
reduces -X- _ O
from -X- _ O
0.58 -X- _ B-MetricValue
to -X- _ O
0.47 -X- _ B-MetricValue
. -X- _ O
Similarly -X- _ O
, -X- _ O
the -X- _ O
average -X- _ O
tokenlevel -X- _ O
symmetric -X- _ O
Hausdorff -X- _ B-MetricName
distance -X- _ I-MetricName
( -X- _ O
Taha -X- _ O
and -X- _ O
Hanbury -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
between -X- _ O
languages -X- _ O
reduces -X- _ O
from -X- _ O
0.72 -X- _ B-MetricValue
to -X- _ O
0.41 -X- _ B-MetricValue
. -X- _ O
This -X- _ O
further -X- _ O
supports -X- _ O
that -X- _ O
we -X- _ O
learn -X- _ O
more -X- _ O
similar -X- _ O
representations -X- _ O
and -X- _ O
our -X- _ O
method -X- _ O
has -X- _ O
wider -X- _ O
utility -X- _ O
beyond -X- _ O
explicitly -X- _ O
targeted -X- _ O
languages -X- _ O
. -X- _ O

Does -X- _ O
Language -X- _ O
Style -X- _ O
Matter -X- _ O
? -X- _ O

In -X- _ O
Table -X- _ O
3 -X- _ O
we -X- _ O
examine -X- _ O
whether -X- _ O
our -X- _ O
auxiliary -X- _ O
objectives -X- _ O
are -X- _ O
influenced -X- _ O
by -X- _ O
the -X- _ O
style -X- _ O
of -X- _ O
natural -X- _ O
language -X- _ O
corpora -X- _ O
for -X- _ O
reconstruction -X- _ O
. -X- _ O
We -X- _ O
find -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
questions -X- _ O
positively -X- _ O
improves -X- _ O
performance -X- _ O
compared -X- _ O
to -X- _ O
crawled -X- _ O
sentences -X- _ O
. -X- _ O
Using -X- _ O
questions -X- _ O
either -X- _ O
as -X- _ O
monolingual -X- _ O
utterances -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
no -X- _ O
translation -X- _ O
in -X- _ O
D -X- _ O
NL -X- _ O
) -X- _ O
or -X- _ O
with -X- _ O
as -X- _ O
a -X- _ O
bi -X- _ O
- -X- _ O
text -X- _ O
sample -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
reconstruction -X- _ O
and -X- _ O
translation -X- _ O
in -X- _ O
D -X- _ O
NL -X- _ O
) -X- _ O
improves -X- _ O
above -X- _ O
the -X- _ O
Translate -X- _ B-MethodName
- -X- _ I-MethodName
Test -X- _ I-MethodName
baseline -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
modest -X- _ O
improvements -X- _ O
with -X- _ O
ParaCrawl -X- _ B-DatasetName
, -X- _ O
especially -X- _ O
when -X- _ O
introducing -X- _ O
bitext -X- _ O
into -X- _ O
D -X- _ O
NL -X- _ O
, -X- _ O
but -X- _ O
this -X- _ O
is -X- _ O
less -X- _ O
consistent -X- _ O
across -X- _ O
languages -X- _ O
. -X- _ O
Overall -X- _ O
, -X- _ O
our -X- _ O
results -X- _ O
suggest -X- _ O
that -X- _ O
ZX -X- _ B-MethodName
- -X- _ I-MethodName
PARSE -X- _ I-MethodName
is -X- _ O
robust -X- _ O
even -X- _ O
when -X- _ O
question -X- _ O
- -X- _ O
style -X- _ O
data -X- _ O
is -X- _ O
unavailable -X- _ O
but -X- _ O
can -X- _ O
be -X- _ O
particularly -X- _ O
effective -X- _ O
when -X- _ O
adapting -X- _ O
towards -X- _ O
both -X- _ O
new -X- _ O
languages -X- _ O
and -X- _ O
domains -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
examined -X- _ O
the -X- _ O
influence -X- _ O
of -X- _ O
language -X- _ O
family -X- _ O
on -X- _ O
performance -X- _ O
( -X- _ O
see -X- _ O
Appendix -X- _ O
B -X- _ O
) -X- _ O
and -X- _ O
found -X- _ O
that -X- _ O
best -X- _ O
performance -X- _ O
utilizes -X- _ O
a -X- _ O
linguistically -X- _ O
varied -X- _ O
ensemble -X- _ O
of -X- _ O
languages -X- _ O
. -X- _ O
model -X- _ O
and -X- _ O
simplest -X- _ O
approach -X- _ O
( -X- _ O
Model -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
more -X- _ O
well -X- _ O
- -X- _ O
formed -X- _ O
logical -X- _ O
forms -X- _ O
account -X- _ O
for -X- _ O
the -X- _ O
largest -X- _ O
improvement -X- _ O
( -X- _ O
32.5 -X- _ B-MetricValue
% -X- _ I-MetricValue
fewer -X- _ O
ill -X- _ O
- -X- _ O
formed -X- _ O
SQL -X- _ O
queries -X- _ O
for -X- _ O
ATIS -X- _ B-DatasetName
and -X- _ O
35.2 -X- _ B-MetricValue
% -X- _ I-MetricValue
fewer -X- _ O
ill -X- _ O
- -X- _ O
formed -X- _ O
λ -X- _ O
- -X- _ O
DCS -X- _ O
queries -X- _ O
for -X- _ O
Overnight -X- _ B-DatasetName
) -X- _ O
. -X- _ O
This -X- _ O
supports -X- _ O
our -X- _ O
notion -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
that -X- _ O
better -X- _ O
latent -X- _ O
alignment -X- _ O
can -X- _ O
minimize -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
penalty -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
improved -X- _ O
structure -X- _ O
prediction -X- _ O
is -X- _ O
insufficient -X- _ O
to -X- _ O
solve -X- _ O
this -X- _ O
task -X- _ O
on -X- _ O
its -X- _ O
own -X- _ O
; -X- _ O
58.7 -X- _ B-MetricValue
% -X- _ I-MetricValue
of -X- _ O
remaining -X- _ O
errors -X- _ B-MetricName
in -X- _ O
the -X- _ O
best -X- _ O
model -X- _ O
are -X- _ O
due -X- _ O
to -X- _ O
mishandled -X- _ O
entities -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
entity -X- _ O
errors -X- _ O
for -X- _ O
Chinese -X- _ O
( -X- _ O
60.2 -X- _ B-MetricValue
% -X- _ I-MetricValue
) -X- _ O
and -X- _ O
lowest -X- _ O
for -X- _ O
French -X- _ O
( -X- _ O
36.7 -X- _ B-MetricValue
% -X- _ I-MetricValue
) -X- _ O
. -X- _ O
This -X- _ O
suggests -X- _ O
that -X- _ O
aligning -X- _ O
entities -X- _ O
across -X- _ O
languages -X- _ O
might -X- _ O
be -X- _ O
necessary -X- _ O
for -X- _ O
further -X- _ O
improvement -X- _ O
. -X- _ O

Conclusion -X- _ O

We -X- _ O
presented -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
model -X- _ O
for -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
semantic -X- _ I-TaskName
parsing -X- _ I-TaskName
which -X- _ O
combines -X- _ O
logical -X- _ O
form -X- _ O
generation -X- _ O
with -X- _ O
auxiliary -X- _ O
objectives -X- _ O
that -X- _ O
require -X- _ O
only -X- _ O
modest -X- _ O
natural -X- _ O
language -X- _ O
corpora -X- _ O
for -X- _ O
localization -X- _ O
. -X- _ O
Through -X- _ O
aligning -X- _ O
latent -X- _ O
representations -X- _ O
, -X- _ O
ZX -X- _ B-MethodName
- -X- _ I-MethodName
PARSE -X- _ I-MethodName
minimizes -X- _ O
the -X- _ O
error -X- _ O
from -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
transfer -X- _ I-TaskName
and -X- _ O
improves -X- _ O
accuracy -X- _ B-MetricName
across -X- _ O
languages -X- _ O
unseen -X- _ O
during -X- _ O
training -X- _ O
. -X- _ O

Although -X- _ O
we -X- _ O
focused -X- _ O
exclusively -X- _ O
on -X- _ O
executable -X- _ O
semantic -X- _ B-TaskName
parsing -X- _ I-TaskName
, -X- _ O
our -X- _ O
approach -X- _ O
is -X- _ O
general -X- _ O
and -X- _ O
potentially -X- _ O
relevant -X- _ O
for -X- _ O
linguistically -X- _ O
motivated -X- _ O
frameworks -X- _ O
such -X- _ O
as -X- _ O
Abstract -X- _ O
Meaning -X- _ O
Representation -X- _ O
( -X- _ O
Banarescu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
; -X- _ O
Damonte -X- _ O
and -X- _ O
Cohen -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
or -X- _ O
Discourse -X- _ O
Representation -X- _ O
Theory -X- _ O
( -X- _ O
Kamp -X- _ O
and -X- _ O
Reyle -X- _ O
, -X- _ O
1993 -X- _ O
; -X- _ O
Evang -X- _ O
and -X- _ O
Bos -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
future -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
investigate -X- _ O
a -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
scenario -X- _ O
and -X- _ O
study -X- _ O
sample -X- _ O
efficient -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
transfer -X- _ O
by -X- _ O
explicitly -X- _ O
promoting -X- _ O
generalization -X- _ O
using -X- _ O
techniques -X- _ O
such -X- _ O
as -X- _ O
meta -X- _ O
- -X- _ O
learning -X- _ O
( -X- _ O
Finn -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

Ethics -X- _ O
Statement -X- _ O

A -X- _ O
key -X- _ O
limitation -X- _ O
of -X- _ O
our -X- _ O
work -X- _ O
is -X- _ O
the -X- _ O
limited -X- _ O
coverage -X- _ O
of -X- _ O
eight -X- _ O
higher -X- _ O
- -X- _ O
resource -X- _ O
languages -X- _ O
. -X- _ O
As -X- _ O
such -X- _ O
, -X- _ O
we -X- _ O
are -X- _ O
unable -X- _ O
to -X- _ O
test -X- _ O
our -X- _ O
approach -X- _ O
in -X- _ O
a -X- _ O
genuinely -X- _ O
lowresource -X- _ O
scenario -X- _ O
. -X- _ O
We -X- _ O
must -X- _ O
also -X- _ O
consider -X- _ O
the -X- _ O
risk -X- _ O
of -X- _ O
over -X- _ O
- -X- _ O
generalization -X- _ O
to -X- _ O
dominant -X- _ O
dialects -X- _ O
within -X- _ O
each -X- _ O
language -X- _ O
as -X- _ O
we -X- _ O
lack -X- _ O
an -X- _ O
evaluation -X- _ O
of -X- _ O
additional -X- _ O
dialects -X- _ O
( -X- _ O
e.g. -X- _ O
our -X- _ O
English -X- _ O
dataset -X- _ O
is -X- _ O
representative -X- _ O
of -X- _ O
American -X- _ O
English -X- _ O
but -X- _ O
not -X- _ O
Indian -X- _ O
English -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
hope -X- _ O
that -X- _ O
such -X- _ O
issues -X- _ O
can -X- _ O
be -X- _ O
addressed -X- _ O
with -X- _ O
additional -X- _ O
data -X- _ O
collection -X- _ O
. -X- _ O

Our -X- _ O
training -X- _ O
requirements -X- _ O
are -X- _ O
detailed -X- _ O
in -X- _ O
Appendix -X- _ O
A. -X- _ O
We -X- _ O
hope -X- _ O
our -X- _ O
work -X- _ O
contributes -X- _ O
to -X- _ O
further -X- _ O
usage -X- _ O
and -X- _ O
development -X- _ O
of -X- _ O
singular -X- _ O
multilingual -X- _ O
models -X- _ O
as -X- _ O
opposed -X- _ O
to -X- _ O
learning -X- _ O
N -X- _ O
monolingual -X- _ O
models -X- _ O
for -X- _ O
N -X- _ O
languages -X- _ O
. -X- _ O
( -X- _ O
Dahl -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
1994 -X- _ O
; -X- _ O
Upadhyay -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
and -X- _ O
Overnight -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Sherborne -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Each -X- _ O
example -X- _ O
is -X- _ O
an -X- _ O
utterance -X- _ O
paired -X- _ O
with -X- _ O
a -X- _ O
logical -X- _ O
form -X- _ O
. -X- _ O
Table -X- _ O
5 -X- _ O
: -X- _ O
Pretrained -X- _ O
model -X- _ O
configurations -X- _ O
and -X- _ O
configuration -X- _ O
for -X- _ O
the -X- _ O
trainable -X- _ O
components -X- _ O
of -X- _ O
ZX -X- _ B-MethodName
- -X- _ I-MethodName
PARSE -X- _ I-MethodName
( -X- _ O
e.g. -X- _ O
, -X- _ O
the -X- _ O
objectives -X- _ O
) -X- _ O
. -X- _ O
All -X- _ O
models -X- _ O
use -X- _ O
a -X- _ O
hidden -X- _ B-HyperparameterName
dimension -X- _ I-HyperparameterName
of -X- _ O
1,024 -X- _ B-HyperparameterValue
, -X- _ O
a -X- _ O
feed -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
forward -X- _ I-HyperparameterName
hidden -X- _ I-HyperparameterName
projection -X- _ I-HyperparameterName
of -X- _ O
4,096 -X- _ B-HyperparameterValue
and -X- _ O
16 -X- _ B-HyperparameterName
heads -X- _ B-HyperparameterValue
per -X- _ O
multi -X- _ O
- -X- _ O
head -X- _ O
attention -X- _ O
layer -X- _ O
. -X- _ O
For -X- _ O
natural -X- _ O
language -X- _ O
, -X- _ O
all -X- _ O
models -X- _ O
use -X- _ O
byte -X- _ O
- -X- _ O
level -X- _ O
BPE -X- _ O
tokenization -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
and -X- _ O
logical -X- _ O
forms -X- _ O
are -X- _ O
tokenized -X- _ O
using -X- _ O
whitespace -X- _ O
. -X- _ O

A -X- _ O
Experimental -X- _ O
Setup -X- _ O

Zero -X- _ O
- -X- _ O
shot -X- _ O
Model -X- _ O
Configuration -X- _ O
The -X- _ O
encoder -X- _ O
, -X- _ O
E -X- _ O
, -X- _ O
decoders -X- _ O
, -X- _ O
{ -X- _ O
D -X- _ O
LF -X- _ O
, -X- _ O
D -X- _ O
NL -X- _ O
} -X- _ O
, -X- _ O
and -X- _ O
embedding -X- _ O
matrices -X- _ O
all -X- _ O
use -X- _ O
a -X- _ O
dimension -X- _ B-HyperparameterName
size -X- _ O
of -X- _ O
1,024 -X- _ B-HyperparameterValue
with -X- _ O
the -X- _ O
self -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
attention -X- _ I-HyperparameterName
projection -X- _ I-HyperparameterName
of -X- _ O
4,096 -X- _ B-HyperparameterValue
and -X- _ O
16 -X- _ B-HyperparameterValue
heads -X- _ B-HyperparameterName
per -X- _ O
layer -X- _ O
. -X- _ O
Both -X- _ O
decoders -X- _ O
are -X- _ O
6 -X- _ O
- -X- _ O
layer -X- _ O
stacks -X- _ O
. -X- _ O

Weights -X- _ O
were -X- _ O
initialized -X- _ O
by -X- _ O
sampling -X- _ O
from -X- _ O
normal -X- _ O
distribution -X- _ O
N -X- _ O
( -X- _ O
0 -X- _ O
, -X- _ O
0.02 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
language -X- _ O
prediction -X- _ O
network -X- _ O
is -X- _ O
a -X- _ O
two -X- _ O
- -X- _ O
layer -X- _ O
feed -X- _ O
- -X- _ O
forward -X- _ O
network -X- _ O
projecting -X- _ O
from -X- _ O
z -X- _ O
to -X- _ O
1,024 -X- _ B-HyperparameterValue
hidden -X- _ B-HyperparameterName
units -X- _ I-HyperparameterName
then -X- _ O
to -X- _ O
|L| -X- _ O
for -X- _ O
L -X- _ O
languages -X- _ O
. -X- _ O
L -X- _ B-HyperparameterName
is -X- _ O
six -X- _ B-HyperparameterValue
for -X- _ O
experiments -X- _ O
on -X- _ O
ATIS -X- _ B-DatasetName
and -X- _ O
three -X- _ B-HyperparameterValue
for -X- _ O
experiments -X- _ O
on -X- _ O
Overnight -X- _ B-DatasetName
. -X- _ O

Configurations -X- _ O
for -X- _ O
models -X- _ O
used -X- _ O
in -X- _ O
this -X- _ O
work -X- _ O
are -X- _ O
reported -X- _ O
in -X- _ O
Table -X- _ O
5 -X- _ O
with -X- _ O
similar -X- _ O
details -X- _ O
for -X- _ O
the -X- _ O
objective -X- _ O
components -X- _ O
of -X- _ O
ZX -X- _ B-MethodName
- -X- _ I-MethodName
PARSE -X- _ I-MethodName
. -X- _ O
Initial -X- _ O
experiments -X- _ O
examined -X- _ O
XLM -X- _ O
- -X- _ O
R -X- _ O
- -X- _ O
base -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
12 -X- _ O
layers -X- _ O
opposed -X- _ O
to -X- _ O
24 -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
performance -X- _ O
was -X- _ O
significantly -X- _ O
worse -X- _ O
and -X- _ O
, -X- _ O
therefore -X- _ O
, -X- _ O
this -X- _ O
model -X- _ O
was -X- _ O
not -X- _ O
considered -X- _ O
further -X- _ O
. -X- _ O
Experiments -X- _ O
reported -X- _ O
in -X- _ O
Section -X- _ O
6 -X- _ O
all -X- _ O
use -X- _ O
mBART50 -X- _ B-MethodName
as -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
encoder -X- _ O
as -X- _ O
all -X- _ O
other -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
performed -X- _ O
significantly -X- _ O
worse -X- _ O
( -X- _ O
see -X- _ O
Appendix -X- _ O
B -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
all -X- _ O
our -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
found -X- _ O
that -X- _ O
a -X- _ O
randomly -X- _ O
initialized -X- _ O
decoder -X- _ O
was -X- _ O
superior -X- _ O
to -X- _ O
using -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
weights -X- _ O
. -X- _ O

A -X- _ O
complete -X- _ O
outline -X- _ O
of -X- _ O
dataset -X- _ O
partitions -X- _ O
per -X- _ O
language -X- _ O
is -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
for -X- _ O
both -X- _ O
datasets -X- _ O
. -X- _ O
ZX -X- _ B-MethodName
- -X- _ I-MethodName
PARSE -X- _ I-MethodName
uses -X- _ O
only -X- _ O
English -X- _ O
training -X- _ O
and -X- _ O
validation -X- _ O
data -X- _ O
and -X- _ O
tests -X- _ O
on -X- _ O
all -X- _ O
additional -X- _ O
languages -X- _ O
. -X- _ O
We -X- _ O
did -X- _ O
not -X- _ O
use -X- _ O
multi -X- _ O
- -X- _ O
lingual -X- _ O
validation -X- _ O
data -X- _ O
as -X- _ O
recommended -X- _ O
in -X- _ O
Keung -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
as -X- _ O
this -X- _ O
approach -X- _ O
did -X- _ O
not -X- _ O
prove -X- _ O
critically -X- _ O
beneficial -X- _ O
in -X- _ O
early -X- _ O
experiments -X- _ O
and -X- _ O
doing -X- _ O
so -X- _ O
would -X- _ O
explode -X- _ O
the -X- _ O
data -X- _ O
requirements -X- _ O
for -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
lingual -X- _ O
system -X- _ O
. -X- _ O

Experimental -X- _ O
Setting -X- _ O

The -X- _ O
system -X- _ O
was -X- _ O
trained -X- _ O
using -X- _ O
the -X- _ O
Adam -X- _ O
optimizer -X- _ O
( -X- _ O
Kingma -X- _ O
and -X- _ O
Ba -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
with -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
1 -X- _ B-HyperparameterValue
× -X- _ I-HyperparameterValue
10 -X- _ I-HyperparameterValue
−4 -X- _ I-HyperparameterValue
, -X- _ O
and -X- _ O
a -X- _ O
weight -X- _ B-HyperparameterName
decay -X- _ I-HyperparameterName
factor -X- _ O
of -X- _ O
0.1 -X- _ B-HyperparameterValue
. -X- _ O
We -X- _ O
use -X- _ O
a -X- _ O
" -X- _ O
Noam -X- _ O
" -X- _ O
schedule -X- _ O
for -X- _ O
the -X- _ O
learning -X- _ O
rate -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
with -X- _ O
a -X- _ O
warmup -X- _ B-HyperparameterName
of -X- _ O
5,000 -X- _ B-HyperparameterValue
steps -X- _ I-HyperparameterValue
. -X- _ O
For -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
components -X- _ O
, -X- _ O
we -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
XLM -X- _ B-MethodName
- -X- _ I-MethodName
R -X- _ I-MethodName
and -X- _ O
mBART -X- _ B-MethodName
encoders -X- _ O
with -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
1 -X- _ B-HyperparameterValue
× -X- _ I-HyperparameterValue
10 -X- _ I-HyperparameterValue
−5 -X- _ I-HyperparameterValue
but -X- _ O
freeze -X- _ O
the -X- _ O
encoder -X- _ O
when -X- _ O
using -X- _ O
mBART50 -X- _ B-MethodName
. -X- _ O
Loss -X- _ B-HyperparameterName
weighting -X- _ I-HyperparameterName
values -X- _ O
for -X- _ O
α -X- _ O
{ -X- _ O
LP -X- _ O
, -X- _ O
NL -X- _ O
} -X- _ O
were -X- _ O
empirically -X- _ O
optimized -X- _ O
to -X- _ O
{ -X- _ O
0.33 -X- _ B-HyperparameterValue
, -X- _ O
0.1 -X- _ B-HyperparameterValue
} -X- _ O
respectively -X- _ O
from -X- _ O
a -X- _ O
range -X- _ O
{ -X- _ O
0.5 -X- _ O
, -X- _ O
0.33 -X- _ O
, -X- _ O
0.1 -X- _ O
, -X- _ O
0.05 -X- _ O
, -X- _ O
0.01 -X- _ O
, -X- _ O
0.005 -X- _ O
, -X- _ O
0.001 -X- _ O
} -X- _ O
. -X- _ O
Batches -X- _ B-HyperparameterName
during -X- _ O
training -X- _ O
were -X- _ O
size -X- _ O
50 -X- _ B-HyperparameterValue
and -X- _ O
homogeneously -X- _ O
sampled -X- _ O
from -X- _ O
either -X- _ O
S -X- _ O
LF -X- _ O
or -X- _ O
S -X- _ O
NL -X- _ O
, -X- _ O
with -X- _ O
an -X- _ O
epoch -X- _ O
consuming -X- _ O
one -X- _ O
pass -X- _ O
over -X- _ O
both -X- _ O
. -X- _ O
Models -X- _ O
were -X- _ O
trained -X- _ O
for -X- _ O
a -X- _ O
maximum -X- _ O
of -X- _ O
100 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
with -X- _ O
early -X- _ O
stopping -X- _ O
. -X- _ O
Model -X- _ O
selection -X- _ O
and -X- _ O
hyper -X- _ O
- -X- _ O
parameters -X- _ O
were -X- _ O
tuned -X- _ O
on -X- _ O
the -X- _ O
S -X- _ O
LF -X- _ O
validation -X- _ O
set -X- _ O
in -X- _ O
English -X- _ O
e.g. -X- _ O
, -X- _ O
validation -X- _ O
only -X- _ O
evaluates -X- _ O
performance -X- _ O
on -X- _ O
logical -X- _ O
- -X- _ O
form -X- _ O
generation -X- _ O
and -X- _ O
not -X- _ O
additional -X- _ O
objectives -X- _ O
. -X- _ O
Test -X- _ O
predictions -X- _ O
were -X- _ O
generated -X- _ O
using -X- _ O
beam -X- _ O
search -X- _ O
with -X- _ O
5 -X- _ O
hypotheses -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
reconstruction -X- _ O
noising -X- _ O
function -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
token -X- _ O
masking -X- _ O
to -X- _ O
randomly -X- _ O
replace -X- _ O
u -X- _ O
tokens -X- _ O
in -X- _ O
x -X- _ O
with -X- _ O
" -X- _ O
< -X- _ O
mask -X- _ O
> -X- _ O
" -X- _ O
where -X- _ O
u -X- _ O
is -X- _ O
sampled -X- _ O
from -X- _ O
U -X- _ O
( -X- _ O
0 -X- _ O
, -X- _ O
v -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
found -X- _ O
v -X- _ B-HyperparameterName
= -X- _ O
3 -X- _ B-HyperparameterValue
as -X- _ O
the -X- _ O
empirically -X- _ O
optimal -X- _ O
maximum -X- _ O
tokens -X- _ O
to -X- _ O
mask -X- _ O
in -X- _ O
an -X- _ O
input -X- _ O
. -X- _ O
Similarly -X- _ O
, -X- _ O
we -X- _ O
found -X- _ O
γ -X- _ B-HyperparameterName
= -X- _ O
40 -X- _ B-HyperparameterValue
optimal -X- _ O
for -X- _ O
the -X- _ O
language -X- _ O
prediction -X- _ O
loss -X- _ O
and -X- _ O
τ -X- _ B-HyperparameterName
= -X- _ O
0.5 -X- _ B-HyperparameterValue
as -X- _ O
the -X- _ O
optimal -X- _ O
sampling -X- _ O
factor -X- _ O
for -X- _ O
translation -X- _ O
versus -X- _ O
reconstruction -X- _ O
. -X- _ O
This -X- _ O
value -X- _ O
of -X- _ O
τ -X- _ B-HyperparameterName
corresponds -X- _ O
to -X- _ O
using -X- _ O
half -X- _ O
the -X- _ O
reconstruction -X- _ O
data -X- _ O
as -X- _ O
mono -X- _ O
- -X- _ O
lingual -X- _ O
utterances -X- _ O
and -X- _ O
half -X- _ O
as -X- _ O
bi -X- _ O
- -X- _ O
text -X- _ O
paired -X- _ O
with -X- _ O
English -X- _ O
. -X- _ O

Reproducibility -X- _ O
All -X- _ O
models -X- _ O
were -X- _ O
implemented -X- _ O
using -X- _ O
AllenNLP -X- _ B-MethodName
( -X- _ O
Gardner -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
and -X- _ O
Py -X- _ B-MethodName
- -X- _ I-MethodName
Torch -X- _ I-MethodName
( -X- _ O
Paszke -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
using -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
from -X- _ O
HuggingFace -X- _ B-MethodName
( -X- _ O
Wolf -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Each -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
1 -X- _ O
NVIDIA -X- _ O
RTX3090 -X- _ O
GPU -X- _ O
in -X- _ O
a -X- _ O
cluster -X- _ O
configuration -X- _ O
, -X- _ O
with -X- _ O
no -X- _ O
model -X- _ O
requiring -X- _ O
over -X- _ O
24 -X- _ O
hours -X- _ O
to -X- _ O
complete -X- _ O
training -X- _ O
. -X- _ O
Hyperparameters -X- _ O
were -X- _ O
chosen -X- _ O
by -X- _ O
training -X- _ O
a -X- _ O
reference -X- _ O
model -X- _ O
for -X- _ O
parsing -X- _ O
English -X- _ O
utterances -X- _ O
and -X- _ O
selecting -X- _ O
the -X- _ O
system -X- _ O
with -X- _ O
minimum -X- _ O
validation -X- _ O
loss -X- _ O
. -X- _ O
Our -X- _ O
optimization -X- _ O
grid -X- _ O
- -X- _ O
search -X- _ O
explored -X- _ O
: -X- _ O
{ -X- _ O
6 -X- _ B-HyperparameterValue
, -X- _ O
9 -X- _ B-HyperparameterValue
, -X- _ O
12 -X- _ B-HyperparameterValue
} -X- _ O
decoder -X- _ B-HyperparameterName
layers -X- _ I-HyperparameterName
; -X- _ O
freezing -X- _ O
or -X- _ O
unfreezing -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
encoder -X- _ O
; -X- _ O
{ -X- _ O
0 -X- _ B-HyperparameterValue
, -X- _ O
1 -X- _ B-HyperparameterValue
, -X- _ O
2 -X- _ B-HyperparameterValue
} -X- _ O
additional -X- _ B-HyperparameterName
encoder -X- _ I-HyperparameterName
layers -X- _ I-HyperparameterName
ap -X- _ O
- -X- _ O
pended -X- _ O
to -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
encoder -X- _ O
; -X- _ O
learning -X- _ B-HyperparameterName
rates -X- _ I-HyperparameterName
of -X- _ O
1 -X- _ B-HyperparameterValue
× -X- _ I-HyperparameterValue
10 -X- _ I-HyperparameterValue
{ -X- _ O
−3 -X- _ B-HyperparameterValue
, -X- _ O
−4 -X- _ B-HyperparameterValue
, -X- _ O
−5 -X- _ B-HyperparameterValue
} -X- _ O
and -X- _ O
a -X- _ O
weight -X- _ B-HyperparameterName
decay -X- _ I-HyperparameterName
factor -X- _ O
of -X- _ O
{ -X- _ O
0 -X- _ B-HyperparameterValue
, -X- _ O
0.1 -X- _ B-HyperparameterValue
, -X- _ O
0.01 -X- _ B-HyperparameterValue
} -X- _ O
. -X- _ O
Optimal -X- _ O
parameters -X- _ O
in -X- _ O
these -X- _ O
early -X- _ O
tests -X- _ O
were -X- _ O
carried -X- _ O
through -X- _ O
for -X- _ O
all -X- _ O
additional -X- _ O
models -X- _ O
. -X- _ O

Additionally -X- _ O
, -X- _ O
we -X- _ O
optimized -X- _ O
hyper -X- _ O
- -X- _ O
parameters -X- _ O
for -X- _ O
auxiliary -X- _ O
objectives -X- _ O
through -X- _ O
linear -X- _ O
search -X- _ O
with -X- _ O
all -X- _ O
other -X- _ O
factors -X- _ O
fixed -X- _ O
. -X- _ O
The -X- _ O
upper -X- _ O
limit -X- _ O
, -X- _ O
v -X- _ B-HyperparameterName
, -X- _ O
for -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
tokens -X- _ I-HyperparameterName
to -X- _ I-HyperparameterName
mask -X- _ I-HyperparameterName
during -X- _ O
reconstruction -X- _ O
, -X- _ O
U -X- _ O
( -X- _ O
0 -X- _ O
, -X- _ O
v -X- _ O
) -X- _ O
, -X- _ O
was -X- _ O
optimized -X- _ O
from -X- _ O
integers -X- _ O
1 -X- _ B-HyperparameterValue
- -X- _ O
6 -X- _ B-HyperparameterValue
. -X- _ O
The -X- _ O
MKQA -X- _ B-DatasetName
dataset -X- _ O
used -X- _ O
for -X- _ O
auxiliary -X- _ O
tasks -X- _ O
contains -X- _ O
shorter -X- _ O
sentences -X- _ O
than -X- _ O
prior -X- _ O
work -X- _ O
using -X- _ O
masking -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
observed -X- _ O
that -X- _ O
high -X- _ O
levels -X- _ O
of -X- _ O
masking -X- _ O
ultimately -X- _ O
destroys -X- _ O
the -X- _ O
input -X- _ O
sentence -X- _ O
and -X- _ O
handicaps -X- _ O
the -X- _ O
overall -X- _ O
task -X- _ O
. -X- _ O
τ -X- _ B-HyperparameterName
was -X- _ O
optimized -X- _ O
between -X- _ O
values -X- _ O
of -X- _ O
0.0 -X- _ B-HyperparameterValue
( -X- _ O
e.g. -X- _ O
ignore -X- _ O
bi -X- _ O
- -X- _ O
text -X- _ O
) -X- _ O
to -X- _ O
1.0 -X- _ B-HyperparameterValue
( -X- _ O
e.g. -X- _ O
all -X- _ O
data -X- _ O
is -X- _ O
used -X- _ O
as -X- _ O
bi -X- _ O
- -X- _ O
text -X- _ O
) -X- _ O
in -X- _ O
increments -X- _ O
of -X- _ O
0.1 -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
optimize -X- _ O
the -X- _ O
γ -X- _ B-HyperparameterName
parameter -X- _ O
within -X- _ O
Equation -X- _ O
7 -X- _ O
between -X- _ O
{ -X- _ O
0 -X- _ B-HyperparameterValue
, -X- _ O
5 -X- _ B-HyperparameterValue
, -X- _ O
10 -X- _ B-HyperparameterValue
, -X- _ O
20 -X- _ B-HyperparameterValue
, -X- _ O
40 -X- _ B-HyperparameterValue
, -X- _ O
50 -X- _ B-HyperparameterValue
, -X- _ O
100 -X- _ B-HyperparameterValue
} -X- _ O
on -X- _ O
an -X- _ O
approximately -X- _ O
logarithmic -X- _ O
scale -X- _ O
. -X- _ O
The -X- _ O
optimal -X- _ O
value -X- _ O
of -X- _ O
γ -X- _ B-HyperparameterName
= -X- _ O
40 -X- _ B-HyperparameterValue
results -X- _ O
in -X- _ O
loss -X- _ O
L -X- _ O
LF -X- _ O
reaching -X- _ O
99 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
maximum -X- _ O
value -X- _ O
at -X- _ O
approximately -X- _ O
13.6 -X- _ O
% -X- _ O
of -X- _ O
training -X- _ O
progress -X- _ O
. -X- _ O

B -X- _ O
Additional -X- _ O
Results -X- _ O

We -X- _ O
extend -X- _ O
the -X- _ O
results -X- _ O
in -X- _ O
Section -X- _ O
6 -X- _ O
to -X- _ O
include -X- _ O
additional -X- _ O
ablations -X- _ O
for -X- _ O
all -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
. -X- _ O
Table -X- _ O
6 -X- _ O
details -X- _ O
all -X- _ O
results -X- _ O
for -X- _ O
ATIS -X- _ B-DatasetName
across -X- _ O
eight -X- _ O
test -X- _ O
languages -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
complete -X- _ O
results -X- _ O
across -X- _ O
all -X- _ O
domains -X- _ O
in -X- _ O
Overnight -X- _ B-DatasetName
are -X- _ O
reported -X- _ O
for -X- _ O
English -X- _ O
in -X- _ O
Table -X- _ O
7 -X- _ O
, -X- _ O
German -X- _ O
in -X- _ O
Table -X- _ O
8 -X- _ O
, -X- _ O
and -X- _ O
Chinese -X- _ O
in -X- _ O
Table -X- _ O
9 -X- _ O
. -X- _ O
Table -X- _ O
3 -X- _ O
, -X- _ O
comparing -X- _ O
between -X- _ O
reconstruction -X- _ O
data -X- _ O
sources -X- _ O
, -X- _ O
is -X- _ O
expanded -X- _ O
on -X- _ O
for -X- _ O
Overnight -X- _ B-DatasetName
in -X- _ O
Table -X- _ O
10 -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
additional -X- _ O
ablations -X- _ O
to -X- _ O
our -X- _ O
model -X- _ O
considering -X- _ O
reconstruction -X- _ O
language -X- _ O
families -X- _ O
in -X- _ O
Table -X- _ O
11 -X- _ O
and -X- _ O
12 -X- _ O
. -X- _ O
Which -X- _ O
Pre -X- _ O
- -X- _ O
trained -X- _ O
Encoder -X- _ O
? -X- _ O
Our -X- _ O
full -X- _ O
results -X- _ O
using -X- _ O
three -X- _ O
different -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
encoders -X- _ O
are -X- _ O
outlined -X- _ O
in -X- _ O
Tables -X- _ O
6 -X- _ O
- -X- _ O
9 -X- _ O
. -X- _ O
Our -X- _ O
experiments -X- _ O
identify -X- _ O
mBART -X- _ B-MethodName
as -X- _ O
the -X- _ O
weakest -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
model -X- _ O
, -X- _ O
reporting -X- _ O
the -X- _ O
lowest -X- _ O
accuracies -X- _ O
for -X- _ O
all -X- _ O
ATIS -X- _ B-DatasetName
test -X- _ O
languages -X- _ O
. -X- _ O
ZX -X- _ B-MethodName
- -X- _ I-MethodName
PARSE -X- _ I-MethodName
using -X- _ O
XLM -X- _ B-MethodName
- -X- _ I-MethodName
R -X- _ I-MethodName
generally -X- _ O
improved -X- _ O
upon -X- _ O
mBART -X- _ B-MethodName
for -X- _ O
ATIS -X- _ B-DatasetName
but -X- _ O
proved -X- _ O
worse -X- _ O
for -X- _ O
Overnight -X- _ B-DatasetName
. -X- _ O
As -X- _ O
XLM -X- _ B-MethodName
- -X- _ I-MethodName
R -X- _ I-MethodName
is -X- _ O
not -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
for -X- _ O
sequence -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
sequence -X- _ O
tasks -X- _ O
, -X- _ O
this -X- _ O
result -X- _ O
suggests -X- _ O
this -X- _ O
model -X- _ O
could -X- _ O
be -X- _ O
poorer -X- _ O
at -X- _ O
representing -X- _ O
input -X- _ O
content -X- _ O
in -X- _ O
more -X- _ O
complex -X- _ O
queries -X- _ O
. -X- _ O
Despite -X- _ O
being -X- _ O
half -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
XLM -X- _ B-MethodName
- -X- _ I-MethodName
R -X- _ I-MethodName
, -X- _ O
mBART50 -X- _ B-MethodName
is -X- _ O
the -X- _ O
only -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
encoder -X- _ O
able -X- _ O
to -X- _ O
perform -X- _ O
competitively -X- _ O
across -X- _ O
all -X- _ O
languages -X- _ O
. -X- _ O
Despite -X- _ O
lower -X- _ O
performance -X- _ O
with -X- _ O
different -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
identify -X- _ O
that -X- _ O
introducing -X- _ O
additional -X- _ O
objectives -X- _ O
yields -X- _ O
improved -X- _ O
accuracy -X- _ B-MetricName
in -X- _ O
most -X- _ O
cases -X- _ O
. -X- _ O
Similar -X- _ O
to -X- _ O
our -X- _ O
results -X- _ O
using -X- _ O
mBART50 -X- _ B-MethodName
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
combining -X- _ O
tasks -X- _ O
is -X- _ O
the -X- _ O
optimal -X- _ O
strategy -X- _ O
for -X- _ O
ZX -X- _ B-MethodName
- -X- _ I-MethodName
PARSE -X- _ I-MethodName
using -X- _ O
either -X- _ O
XLM -X- _ B-MethodName
- -X- _ I-MethodName
R -X- _ I-MethodName
or -X- _ O
mBART -X- _ B-MethodName
as -X- _ O
an -X- _ O
encoder -X- _ O
. -X- _ O

We -X- _ O
additionally -X- _ O
explored -X- _ O
if -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
is -X- _ O
required -X- _ O
for -X- _ O
our -X- _ O
approach -X- _ O
by -X- _ O
training -X- _ O
a -X- _ O
comparable -X- _ O
model -X- _ O
from -X- _ O
scratch -X- _ O
. -X- _ O
While -X- _ O
performance -X- _ O
on -X- _ O
English -X- _ O
was -X- _ O
similar -X- _ O
to -X- _ O
our -X- _ O
best -X- _ O
results -X- _ O
, -X- _ O
we -X- _ O
found -X- _ O
that -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
transfer -X- _ O
was -X- _ O
extremely -X- _ O
poor -X- _ O
and -X- _ O
these -X- _ O
results -X- _ O
are -X- _ O
omitted -X- _ O
due -X- _ O
to -X- _ O
negligible -X- _ O
accuracies -X- _ B-MetricName
( -X- _ O
< -X- _ O
2 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
) -X- _ O
for -X- _ O
non -X- _ O
- -X- _ O
English -X- _ O
languages -X- _ O
. -X- _ O
Overall -X- _ O
, -X- _ O
this -X- _ O
suggests -X- _ O
that -X- _ O
our -X- _ O
methodology -X- _ O
is -X- _ O
optimal -X- _ O
when -X- _ O
aligning -X- _ O
an -X- _ O
existing -X- _ O
multi -X- _ O
- -X- _ O
lingual -X- _ O
latent -X- _ O
space -X- _ O
rather -X- _ O
than -X- _ O
inducing -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
lingual -X- _ O
latent -X- _ O
space -X- _ O
from -X- _ O
scratch -X- _ O
. -X- _ O

Ablations -X- _ O
of -X- _ O
Reconstruction -X- _ O
Language -X- _ O
Data -X- _ O

We -X- _ O
present -X- _ O
ablations -X- _ O
to -X- _ O
our -X- _ O
main -X- _ O
experiments -X- _ O
examining -X- _ O
the -X- _ O
influence -X- _ O
of -X- _ O
language -X- _ O
similarity -X- _ O
in -X- _ O
reconstruction -X- _ O
data -X- _ O
for -X- _ O
ATIS -X- _ B-DatasetName
in -X- _ O
Table -X- _ O
11 -X- _ O
and -X- _ O
for -X- _ O
Overnight -X- _ B-DatasetName
in -X- _ O
Table -X- _ O
12 -X- _ O
. -X- _ O
Similar -X- _ O
to -X- _ O
our -X- _ O
results -X- _ O
for -X- _ O
Hindi -X- _ O
and -X- _ O
Turkish -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
using -X- _ O
our -X- _ O
auxiliary -X- _ O
objectives -X- _ O
in -X- _ O
our -X- _ O
model -X- _ O
improves -X- _ O
overall -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
alignment -X- _ O
in -X- _ O
languages -X- _ O
that -X- _ O
we -X- _ O
did -X- _ O
not -X- _ O
intentionally -X- _ O
target -X- _ O
with -X- _ O
reconstruction -X- _ O
data -X- _ O
. -X- _ O

In -X- _ O
our -X- _ O
first -X- _ O
case -X- _ O
, -X- _ O
we -X- _ O
consider -X- _ O
omitting -X- _ O
the -X- _ O
Romance -X- _ O
genus -X- _ O
languages -X- _ O
( -X- _ O
French -X- _ O
, -X- _ O
Spanish -X- _ O
, -X- _ O
Portuguese -X- _ O
) -X- _ O
from -X- _ O
the -X- _ O
reconstruction -X- _ O
corpus -X- _ O
for -X- _ O
experiments -X- _ O
on -X- _ O
ATIS -X- _ B-DatasetName
. -X- _ O
The -X- _ O
observed -X- _ O
reduction -X- _ O
in -X- _ O
performance -X- _ O
across -X- _ O
all -X- _ O
languages -X- _ O
is -X- _ O
likely -X- _ O
a -X- _ O
consequence -X- _ O
of -X- _ O
reduced -X- _ O
training -X- _ O
data -X- _ O
leading -X- _ O
to -X- _ O
weaker -X- _ O
crosslingual -X- _ O
alignment -X- _ O
. -X- _ O
Notably -X- _ O
, -X- _ O
this -X- _ O
drop -X- _ O
is -X- _ O
largest -X- _ O
for -X- _ O
French -X- _ O
( -X- _ O
−11.2 -X- _ B-MetricValue
% -X- _ I-MetricValue
) -X- _ O
and -X- _ O
Spanish -X- _ O
( -X- _ O
−7.1 -X- _ B-MetricValue
% -X- _ I-MetricValue
) -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
the -X- _ O
smallest -X- _ O
reduction -X- _ O
is -X- _ O
for -X- _ O
Chinese -X- _ O
( -X- _ O
−3.9 -X- _ B-MetricValue
% -X- _ I-MetricValue
) -X- _ O
and -X- _ O
English -X- _ O
( -X- _ O
−2.8 -X- _ B-MetricValue
% -X- _ I-MetricValue
) -X- _ O
. -X- _ O
We -X- _ O
additionally -X- _ O
examine -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
omitting -X- _ O
the -X- _ O
only -X- _ O
Sino -X- _ O
- -X- _ O
Tibetan -X- _ O
language -X- _ O
( -X- _ O
Chinese -X- _ O
) -X- _ O
from -X- _ O
experiments -X- _ O
on -X- _ O
both -X- _ O
ATIS -X- _ O
and -X- _ O
Overnight -X- _ O
. -X- _ O
While -X- _ O
we -X- _ O
observe -X- _ O
a -X- _ O
similar -X- _ O
overall -X- _ O
reduction -X- _ O
in -X- _ O
performance -X- _ O
here -X- _ O
-our -X- _ O
notable -X- _ O
finding -X- _ O
is -X- _ O
a -X- _ O
larger -X- _ O
reduction -X- _ O
in -X- _ O
parsing -X- _ O
accuracy -X- _ O
for -X- _ O
Chinese -X- _ O
across -X- _ O
both -X- _ O
ATIS -X- _ B-DatasetName
( -X- _ O
−17.0 -X- _ B-MetricValue
% -X- _ I-MetricValue
) -X- _ O
and -X- _ O
Overnight -X- _ B-DatasetName
( -X- _ O
−11.1 -X- _ B-MetricValue
% -X- _ I-MetricValue
) -X- _ O
. -X- _ O
Without -X- _ O
a -X- _ O
similar -X- _ O
language -X- _ O
to -X- _ O
Chinese -X- _ O
( -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
family -X- _ O
or -X- _ O
with -X- _ O
a -X- _ O
similar -X- _ O
orthography -X- _ O
) -X- _ O
in -X- _ O
this -X- _ O
experiment -X- _ O
, -X- _ O
we -X- _ O
suggest -X- _ O
there -X- _ O
is -X- _ O
little -X- _ O
to -X- _ O
" -X- _ O
support -X- _ O
" -X- _ O
better -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
alignment -X- _ O
for -X- _ O
Chinese -X- _ O
relative -X- _ O
to -X- _ O
others -X- _ O
. -X- _ O
This -X- _ O
contrasts -X- _ O
with -X- _ O
the -X- _ O
performance -X- _ O
drop -X- _ O
for -X- _ O
Romance -X- _ O
languages -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
still -X- _ O
relatively -X- _ O
similar -X- _ O
to -X- _ O
English -X- _ O
and -X- _ O
German -X- _ O
. -X- _ O

Overall -X- _ O
, -X- _ O
these -X- _ O
ablations -X- _ O
support -X- _ O
that -X- _ O
both -X- _ O
variety -X- _ O
and -X- _ O
similarity -X- _ O
are -X- _ O
important -X- _ O
for -X- _ O
considering -X- _ O
language -X- _ O
data -X- _ O
for -X- _ O
auxiliary -X- _ O
objectives -X- _ O
. -X- _ O
Performance -X- _ O
on -X- _ O
omitted -X- _ O
languages -X- _ O
can -X- _ O
improve -X- _ O
from -X- _ O
a -X- _ O
base- -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
compared -X- _ O
across -X- _ O
reconstruction -X- _ O
data -X- _ O
usage -X- _ O
for -X- _ O
English -X- _ O
, -X- _ O
German -X- _ O
and -X- _ O
Chinese -X- _ O
. -X- _ O
We -X- _ O
compare -X- _ O
between -X- _ O
MKQA -X- _ B-DatasetName
( -X- _ O
Longpre -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
ParaCrawl -X- _ B-DatasetName
( -X- _ O
Bañón -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
with -X- _ O
additional -X- _ O
contrast -X- _ O
between -X- _ O
using -X- _ O
reconstruction -X- _ O
data -X- _ O
as -X- _ O
monolingual -X- _ O
utterances -X- _ O
( -X- _ O
e.g. -X- _ O
τ -X- _ B-HyperparameterName
= -X- _ O
0.0 -X- _ B-HyperparameterValue
) -X- _ O
or -X- _ O
with -X- _ O
some -X- _ O
proportion -X- _ O
as -X- _ O
bi -X- _ O
- -X- _ O
text -X- _ O
where -X- _ O
the -X- _ O
target -X- _ O
sequence -X- _ O
is -X- _ O
replaced -X- _ O
with -X- _ O
the -X- _ O
parallel -X- _ O
English -X- _ O
utterance -X- _ O
( -X- _ O
e.g. -X- _ O
τ -X- _ B-HyperparameterName
= -X- _ O
0.5 -X- _ B-HyperparameterValue
) -X- _ O
. -X- _ O
Domains -X- _ O
are -X- _ O
Basketball -X- _ O
, -X- _ O
Blocks -X- _ O
, -X- _ O
Calendar -X- _ O
, -X- _ O
Housing -X- _ O
, -X- _ O
Publications -X- _ O
, -X- _ O
Recipes -X- _ O
, -X- _ O
Restaurants -X- _ O
and -X- _ O
Social -X- _ O
Network -X- _ O
. -X- _ O
Best -X- _ O
results -X- _ O
for -X- _ O
each -X- _ O
language -X- _ O
are -X- _ O
bolded -X- _ O
. -X- _ O

Acknowledgements -X- _ O

We -X- _ O
thank -X- _ O
the -X- _ O
anonymous -X- _ O
reviewers -X- _ O
for -X- _ O
their -X- _ O
feedback -X- _ O
and -X- _ O
Bailin -X- _ O
Wang -X- _ O
, -X- _ O
Kate -X- _ O
McCurdy -X- _ O
, -X- _ O
and -X- _ O
Rui -X- _ O
Zhang -X- _ O
for -X- _ O
insightful -X- _ O
discussion -X- _ O
. -X- _ O
The -X- _ O
authors -X- _ O
gratefully -X- _ O
acknowledge -X- _ O
the -X- _ O
support -X- _ O
of -X- _ O
the -X- _ O
UK -X- _ O
Engineering -X- _ O
and -X- _ O
Physical -X- _ O
Sciences -X- _ O
Research -X- _ O
Council -X- _ O
( -X- _ O
grant -X- _ O
EP -X- _ O
/ -X- _ O
L016427 -X- _ O
/ -X- _ O
1 -X- _ O
; -X- _ O
Sherborne -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
European -X- _ O
Research -X- _ O
Council -X- _ O
( -X- _ O
award -X- _ O
number -X- _ O
681760 -X- _ O
; -X- _ O
Lapata -X- _ O
) -X- _ O
. -X- _ O

