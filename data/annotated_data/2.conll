-DOCSTART- -X- O
PVGRU -X- _ B-MethodName
: -X- _ O
Generating -X- _ O
Diverse -X- _ O
and -X- _ O
Relevant -X- _ O
Dialogue -X- _ O
Responses -X- _ O
via -X- _ O
Pseudo -X- _ O
- -X- _ O
Variational -X- _ O
Mechanism -X- _ O

We -X- _ O
investigate -X- _ O
response -X- _ B-TaskName
generation -X- _ I-TaskName
for -X- _ I-TaskName
multiturn -X- _ I-TaskName
dialogue -X- _ I-TaskName
in -X- _ O
generative -X- _ O
chatbots -X- _ O
. -X- _ O
Existing -X- _ O
generative -X- _ O
models -X- _ O
based -X- _ O
on -X- _ O
RNNs -X- _ B-MethodName
( -X- _ O
Recurrent -X- _ B-MethodName
Neural -X- _ I-MethodName
Networks -X- _ I-MethodName
) -X- _ O
usually -X- _ O
employ -X- _ O
the -X- _ O
last -X- _ O
hidden -X- _ O
state -X- _ O
to -X- _ O
summarize -X- _ O
the -X- _ O
history -X- _ O
, -X- _ O
which -X- _ O
makes -X- _ O
models -X- _ O
unable -X- _ O
to -X- _ O
capture -X- _ O
the -X- _ O
subtle -X- _ O
variability -X- _ O
observed -X- _ O
in -X- _ O
different -X- _ O
dialogues -X- _ O
and -X- _ O
can -X- _ O
not -X- _ O
distinguish -X- _ O
the -X- _ O
differences -X- _ O
between -X- _ O
dialogues -X- _ O
that -X- _ O
are -X- _ O
similar -X- _ O
in -X- _ O
composition -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
Pseudo -X- _ B-MethodName
- -X- _ I-MethodName
Variational -X- _ I-MethodName
Gated -X- _ I-MethodName
Recurrent -X- _ I-MethodName
Unit -X- _ I-MethodName
( -X- _ O
PVGRU -X- _ B-MethodName
) -X- _ O
. -X- _ O
The -X- _ O
key -X- _ O
novelty -X- _ O
of -X- _ O
PVGRU -X- _ B-MethodName
is -X- _ O
a -X- _ O
recurrent -X- _ O
summarizing -X- _ O
variable -X- _ O
that -X- _ O
aggregates -X- _ O
the -X- _ O
accumulated -X- _ O
distribution -X- _ O
variations -X- _ O
of -X- _ O
subsequences -X- _ O
. -X- _ O
We -X- _ O
train -X- _ O
PVGRU -X- _ B-MethodName
without -X- _ O
relying -X- _ O
on -X- _ O
posterior -X- _ O
knowledge -X- _ O
, -X- _ O
thus -X- _ O
avoiding -X- _ O
the -X- _ O
training -X- _ O
- -X- _ O
inference -X- _ O
inconsistency -X- _ O
problem -X- _ O
. -X- _ O
PVGRU -X- _ B-MethodName
can -X- _ O
perceive -X- _ O
subtle -X- _ O
semantic -X- _ O
variability -X- _ O
through -X- _ O
summarizing -X- _ O
variables -X- _ O
that -X- _ O
are -X- _ O
optimized -X- _ O
by -X- _ O
two -X- _ O
objectives -X- _ O
we -X- _ O
employ -X- _ O
for -X- _ O
training -X- _ O
: -X- _ O
distribution -X- _ O
consistency -X- _ O
and -X- _ O
reconstruction -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
we -X- _ O
build -X- _ O
a -X- _ O
Pseudo -X- _ B-MethodName
- -X- _ I-MethodName
Variational -X- _ I-MethodName
Hierarchical -X- _ I-MethodName
Dialogue -X- _ I-MethodName
( -X- _ O
PVHD -X- _ B-MethodName
) -X- _ O
model -X- _ O
based -X- _ O
on -X- _ O
PVGRU -X- _ B-MethodName
. -X- _ O
Experimental -X- _ O
results -X- _ O
demonstrate -X- _ O
that -X- _ O
PVGRU -X- _ B-MethodName
can -X- _ O
broadly -X- _ O
improve -X- _ O
the -X- _ O
diversity -X- _ O
and -X- _ O
relevance -X- _ O
of -X- _ O
responses -X- _ O
on -X- _ O
two -X- _ O
benchmark -X- _ O
datasets -X- _ O
. -X- _ O

Introduction -X- _ O

The -X- _ O
structure -X- _ O
of -X- _ O
natural -X- _ O
language -X- _ O
discourse -X- _ O
is -X- _ O
complex -X- _ O
and -X- _ O
highly -X- _ O
variable -X- _ O
( -X- _ O
Gormley -X- _ O
and -X- _ O
Tong -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Chung -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Nie -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
; -X- _ O
this -X- _ O
is -X- _ O
especially -X- _ O
true -X- _ O
for -X- _ O
dialogue -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
examples -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
and -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
have -X- _ O
the -X- _ O
same -X- _ O
dialogue -X- _ O
history -X- _ O
but -X- _ O
they -X- _ O
end -X- _ O
with -X- _ O
different -X- _ O
responses -X- _ O
: -X- _ O
utterances -X- _ O
u -X- _ O
a -X- _ O
6 -X- _ O
vs. -X- _ O
u -X- _ O
b -X- _ O
6 -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
two -X- _ O
dialogues -X- _ O
with -X- _ O
semantically -X- _ O
similar -X- _ O
utterances -X- _ O
may -X- _ O
express -X- _ O
quite -X- _ O
different -X- _ O
context -X- _ O
meanings -X- _ O
. -X- _ O
Because -X- _ O
of -X- _ O
this -X- _ O
variability -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
simple -X- _ O
one -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
one -X- _ O
mapping -X- _ O
between -X- _ O
dialogue -X- _ O
context -X- _ O
and -X- _ O
response -X- _ O
. -X- _ O
The -X- _ O
mapping -X- _ O
can -X- _ O
be -X- _ O
one -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
many -X- _ O
-as -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
different -X- _ O
responses -X- _ O
to -X- _ O
the -X- _ O
same -X- _ O
dialogue -X- _ O
context -X- _ O
-as -X- _ O
well -X- _ O
as -X- _ O
many -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
one -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
different -X- _ O
context -X- _ O
histories -X- _ O
requiring -X- _ O
the -X- _ O
same -X- _ O
response -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
a -X- _ O
dialogue -X- _ O
context -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
N -X- _ O
a -X- _ O
6 -X- _ O
and -X- _ O
N -X- _ O
b -X- _ O
6 -X- _ O
in -X- _ O
the -X- _ O
figure -X- _ O
) -X- _ O
is -X- _ O
composed -X- _ O
of -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
its -X- _ O
utterances -X- _ O
and -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
each -X- _ O
utterance -X- _ O
is -X- _ O
composed -X- _ O
of -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
its -X- _ O
words -X- _ O
. -X- _ O
A -X- _ O
good -X- _ O
model -X- _ O
of -X- _ O
word -X- _ O
level -X- _ O
and -X- _ O
utterance -X- _ O
level -X- _ O
variation -X- _ O
is -X- _ O
a -X- _ O
key -X- _ O
requirement -X- _ O
for -X- _ O
improving -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
responses -X- _ O
in -X- _ O
dialogue -X- _ O
. -X- _ O

One -X- _ O
line -X- _ O
of -X- _ O
research -X- _ O
( -X- _ O
Henderson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
; -X- _ O
Shang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Luo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
employs -X- _ O
recurrent -X- _ B-MethodName
neural -X- _ I-MethodName
networks -X- _ I-MethodName
( -X- _ O
RNNs -X- _ B-MethodName
) -X- _ O
to -X- _ O
model -X- _ O
dialogue -X- _ O
context -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
standard -X- _ O
RNNs -X- _ B-MethodName
are -X- _ O
not -X- _ O
well -X- _ O
suited -X- _ O
for -X- _ O
dialogue -X- _ O
context -X- _ O
variability -X- _ O
( -X- _ O
Chung -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
because -X- _ O
the -X- _ O
internal -X- _ O
transition -X- _ O
structure -X- _ O
of -X- _ O
RNNs -X- _ B-MethodName
is -X- _ O
deterministic -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
RNNs -X- _ B-MethodName
can -X- _ O
not -X- _ O
effectively -X- _ O
model -X- _ O
randomness -X- _ O
and -X- _ O
variability -X- _ O
in -X- _ O
dialogue -X- _ O
context -X- _ O
( -X- _ O
Chung -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O

Variational -X- _ O
mechanism -X- _ O
has -X- _ O
been -X- _ O
shown -X- _ O
to -X- _ O
be -X- _ O
well -X- _ O
suited -X- _ O
for -X- _ O
modeling -X- _ O
variability -X- _ O
-from -X- _ O
both -X- _ O
theoretical -X- _ O
and -X- _ O
practical -X- _ O
perspectives -X- _ O
( -X- _ O
Kingma -X- _ O
and -X- _ O
Welling -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O
Methods -X- _ O
based -X- _ O
on -X- _ O
variational -X- _ O
mechanism -X- _ O
Gu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Khan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
introduce -X- _ O
latent -X- _ O
variables -X- _ O
into -X- _ O
RNNs -X- _ B-MethodName
to -X- _ O
model -X- _ O
one -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
many -X- _ O
and -X- _ O
many -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
one -X- _ O
phenomena -X- _ O
in -X- _ O
dialogue -X- _ O
. -X- _ O
Although -X- _ O
these -X- _ O
approaches -X- _ O
achieve -X- _ O
promising -X- _ O
results -X- _ O
, -X- _ O
they -X- _ O
still -X- _ O
have -X- _ O
defects -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
these -X- _ O
methods -X- _ O
face -X- _ O
the -X- _ O
dilemma -X- _ O
that -X- _ O
latent -X- _ O
variables -X- _ O
may -X- _ O
vanish -X- _ O
because -X- _ O
of -X- _ O
the -X- _ O
posterior -X- _ O
collapse -X- _ O
issue -X- _ O
( -X- _ O
Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
( -X- _ O
Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
, -X- _ O
2018Shi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Variational -X- _ O
mechanism -X- _ O
can -X- _ O
work -X- _ O
only -X- _ O
when -X- _ O
latent -X- _ O
variables -X- _ O
with -X- _ O
intractable -X- _ O
posterior -X- _ O
distributions -X- _ O
exist -X- _ O
( -X- _ O
Kingma -X- _ O
and -X- _ O
Welling -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O
Second -X- _ O
, -X- _ O
the -X- _ O
sampled -X- _ O
latent -X- _ O
variables -X- _ O
may -X- _ O
not -X- _ O
correctly -X- _ O
reflect -X- _ O
the -X- _ O
relationship -X- _ O
between -X- _ O
dialogue -X- _ O
context -X- _ O
and -X- _ O
response -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
one -X- _ O
- -X- _ O
tomany -X- _ O
and -X- _ O
many -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
one -X- _ O
phenomena -X- _ O
observed -X- _ O
in -X- _ O
dialogue -X- _ O
( -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Third -X- _ O
, -X- _ O
posterior -X- _ O
knowledge -X- _ O
is -X- _ O
employed -X- _ O
in -X- _ O
training -X- _ O
while -X- _ O
prior -X- _ O
knowledge -X- _ O
is -X- _ O
used -X- _ O
in -X- _ O
inference -X- _ O
; -X- _ O
this -X- _ O
causes -X- _ O
an -X- _ O
inconsistency -X- _ O
problem -X- _ O
between -X- _ O
training -X- _ O
and -X- _ O
inference -X- _ O
( -X- _ O
Shang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Shi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
a -X- _ O
man -X- _ O
is -X- _ O
making -X- _ O
a -X- _ O
sandwich -X- _ O
while -X- _ O
sitting -X- _ O
at -X- _ O
a -X- _ O
dresser -X- _ O
he -X- _ O
gets -X- _ O
up -X- _ O
and -X- _ O
brings -X- _ O
the -X- _ O
sandwich -X- _ O
to -X- _ O
… -X- _ O
can -X- _ O
you -X- _ O
see -X- _ O
the -X- _ O
guy -X- _ O
? -X- _ O
yes -X- _ O
, -X- _ O
i -X- _ O
see -X- _ O
one -X- _ O
man -X- _ O
what -X- _ O
is -X- _ O
he -X- _ O
doing -X- _ O
? -X- _ O
he -X- _ O
was -X- _ O
sitting -X- _ O
on -X- _ O
a -X- _ O
chair -X- _ O
and -X- _ O
applying -X- _ O
jam -X- _ O
on -X- _ O
a -X- _ O
bread -X- _ O
. -X- _ O

1 -X- _ O
: -X- _ O
To -X- _ O
tackle -X- _ O
these -X- _ O
problems -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
Pseudo -X- _ B-MethodName
- -X- _ I-MethodName
Variational -X- _ I-MethodName
Gated -X- _ I-MethodName
Recurrent -X- _ I-MethodName
Unit -X- _ I-MethodName
( -X- _ O
PVGRU -X- _ B-MethodName
) -X- _ O
component -X- _ O
based -X- _ O
on -X- _ O
pseudo -X- _ B-MethodName
- -X- _ I-MethodName
variational -X- _ I-MethodName
mechanism -X- _ I-MethodName
. -X- _ O
PVGRU -X- _ B-MethodName
introduces -X- _ O
a -X- _ O
recurrent -X- _ O
summarizing -X- _ O
variable -X- _ O
into -X- _ O
the -X- _ O
GRU -X- _ B-MethodName
. -X- _ O
This -X- _ O
summarizing -X- _ O
variable -X- _ O
can -X- _ O
aggregate -X- _ O
the -X- _ O
accumulated -X- _ O
distribution -X- _ O
variations -X- _ O
of -X- _ O
subsequences -X- _ O
. -X- _ O
The -X- _ O
methods -X- _ O
based -X- _ O
on -X- _ O
PVGRU -X- _ B-MethodName
can -X- _ O
model -X- _ O
the -X- _ O
subtle -X- _ O
semantic -X- _ O
differences -X- _ O
between -X- _ O
different -X- _ O
sequences -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
pseudovariational -X- _ B-MethodName
mechanism -X- _ I-MethodName
adopts -X- _ O
the -X- _ O
idea -X- _ O
of -X- _ O
latent -X- _ O
variables -X- _ O
but -X- _ O
does -X- _ O
not -X- _ O
adopt -X- _ O
posterior -X- _ O
mechanism -X- _ O
( -X- _ O
Serban -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Park -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
PVGRU -X- _ B-MethodName
does -X- _ O
not -X- _ O
suffer -X- _ O
from -X- _ O
the -X- _ O
posterior -X- _ O
collapse -X- _ O
issue -X- _ O
( -X- _ O
Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
( -X- _ O
Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
, -X- _ O
2018Shi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Second -X- _ O
, -X- _ O
we -X- _ O
design -X- _ O
consistency -X- _ O
and -X- _ O
reconstruction -X- _ O
objectives -X- _ O
to -X- _ O
optimize -X- _ O
the -X- _ O
recurrent -X- _ O
summarizing -X- _ O
variable -X- _ O
in -X- _ O
PV -X- _ B-MethodName
- -X- _ I-MethodName
GRU -X- _ I-MethodName
; -X- _ O
this -X- _ O
ensures -X- _ O
that -X- _ O
the -X- _ O
recurrent -X- _ O
variable -X- _ O
can -X- _ O
reflect -X- _ O
the -X- _ O
semantics -X- _ O
of -X- _ O
dialogue -X- _ O
context -X- _ O
on -X- _ O
both -X- _ O
the -X- _ O
word -X- _ O
level -X- _ O
and -X- _ O
the -X- _ O
utterance -X- _ O
level -X- _ O
. -X- _ O
The -X- _ O
consistency -X- _ O
objective -X- _ O
makes -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
the -X- _ O
incremental -X- _ O
information -X- _ O
consistent -X- _ O
with -X- _ O
the -X- _ O
corresponding -X- _ O
input -X- _ O
at -X- _ O
each -X- _ O
time -X- _ O
step -X- _ O
. -X- _ O
Third -X- _ O
, -X- _ O
we -X- _ O
guarantee -X- _ O
the -X- _ O
consistency -X- _ O
between -X- _ O
training -X- _ O
and -X- _ O
inference -X- _ O
since -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
employ -X- _ O
posterior -X- _ O
knowledge -X- _ O
when -X- _ O
optimizing -X- _ O
the -X- _ O
summarizing -X- _ O
variable -X- _ O
. -X- _ O

Our -X- _ O
proposed -X- _ O
method -X- _ O
avoids -X- _ O
the -X- _ O
problems -X- _ O
caused -X- _ O
by -X- _ O
variational -X- _ O
optimization -X- _ O
and -X- _ O
can -X- _ O
model -X- _ O
the -X- _ O
diversity -X- _ O
problem -X- _ O
in -X- _ O
dialogue -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
examples -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
and -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
have -X- _ O
the -X- _ O
same -X- _ O
dialogue -X- _ O
history -X- _ O
but -X- _ O
different -X- _ O
responses -X- _ O
. -X- _ O
N -X- _ O
a -X- _ O
6 -X- _ O
and -X- _ O
N -X- _ O
b -X- _ O
6 -X- _ O
can -X- _ O
learn -X- _ O
the -X- _ O
distribution -X- _ O
differences -X- _ O
caused -X- _ O
by -X- _ O
u -X- _ O
a -X- _ O
6 -X- _ O
and -X- _ O
u -X- _ O
b -X- _ O
6 -X- _ O
. -X- _ O
Simultaneously -X- _ O
, -X- _ O
semantic -X- _ O
reconstruction -X- _ O
can -X- _ O
enhance -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
perception -X- _ O
of -X- _ O
semantic -X- _ O
changes -X- _ O
, -X- _ O
which -X- _ O
in -X- _ O
turn -X- _ O
can -X- _ O
strengthen -X- _ O
the -X- _ O
distribution -X- _ O
differences -X- _ O
caused -X- _ O
by -X- _ O
semantic -X- _ O
changes -X- _ O
. -X- _ O
Although -X- _ O
the -X- _ O
example -X- _ O
only -X- _ O
shows -X- _ O
diversity -X- _ O
at -X- _ O
the -X- _ O
utterance -X- _ O
level -X- _ O
, -X- _ O
similar -X- _ O
diversity -X- _ O
issues -X- _ O
exist -X- _ O
at -X- _ O
the -X- _ O
word -X- _ O
level -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
build -X- _ O
a -X- _ O
Pseudo -X- _ B-MethodName
- -X- _ I-MethodName
Variational -X- _ I-MethodName
Hierarchical -X- _ I-MethodName
Dialogue -X- _ I-MethodName
model -X- _ I-MethodName
( -X- _ O
PVHD -X- _ B-MethodName
) -X- _ O
based -X- _ O
on -X- _ O
PVGRU -X- _ B-MethodName
to -X- _ O
model -X- _ O
both -X- _ O
word -X- _ O
level -X- _ O
and -X- _ O
utterance -X- _ O
level -X- _ O
variation -X- _ O
. -X- _ O

To -X- _ O
summarize -X- _ O
, -X- _ O
we -X- _ O
make -X- _ O
the -X- _ O
following -X- _ O
contributions -X- _ O
: -X- _ O

• -X- _ O
We -X- _ O
analyze -X- _ O
the -X- _ O
reasons -X- _ O
for -X- _ O
one -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
many -X- _ O
and -X- _ O
many -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
one -X- _ O
issues -X- _ O
from -X- _ O
high -X- _ O
variability -X- _ O
of -X- _ O
dialogue -X- _ O
corpus -X- _ O
and -X- _ O
propose -X- _ O
PVGRU -X- _ B-MethodName
with -X- _ O
a -X- _ O
recurrent -X- _ O
summarizing -X- _ O
variable -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
variability -X- _ O
of -X- _ O
dialogue -X- _ O
sequences -X- _ O
. -X- _ O
• -X- _ O
We -X- _ O
propose -X- _ O
to -X- _ O
optimize -X- _ O
the -X- _ O
recurrent -X- _ O
summarizing -X- _ O
variable -X- _ O
using -X- _ O
consistency -X- _ O
and -X- _ O
reconstruction -X- _ O
objectives -X- _ O
, -X- _ O
which -X- _ O
guarantees -X- _ O
that -X- _ O
the -X- _ O
summarizing -X- _ O
variable -X- _ O
can -X- _ O
reflect -X- _ O
the -X- _ O
semantics -X- _ O
of -X- _ O
the -X- _ O
dialogue -X- _ O
context -X- _ O
and -X- _ O
maintain -X- _ O
the -X- _ O
consistency -X- _ O
between -X- _ O
training -X- _ O
and -X- _ O
inference -X- _ O
processes -X- _ O
. -X- _ O
• -X- _ O
We -X- _ O
propose -X- _ O
the -X- _ O
PVHD -X- _ B-MethodName
model -X- _ O
based -X- _ O
on -X- _ O
PVGRU -X- _ B-MethodName
. -X- _ O

PVHD -X- _ B-MethodName
significantly -X- _ O
outperforms -X- _ O
strong -X- _ O
baselines -X- _ O
with -X- _ O
RNN -X- _ B-MethodName
and -X- _ O
Transformer -X- _ B-MethodName
architectures -X- _ O
on -X- _ O
two -X- _ O
benchmark -X- _ O
datasets -X- _ O
. -X- _ O
The -X- _ O
code -X- _ O
including -X- _ O
baselines -X- _ O
for -X- _ O
comparison -X- _ O
is -X- _ O
available -X- _ O
on -X- _ O
Github -X- _ O
1 -X- _ O
. -X- _ O

RELATED -X- _ O
WORK -X- _ O

Dialogue -X- _ B-TaskName
Generation -X- _ I-TaskName

As -X- _ O
an -X- _ O
important -X- _ O
task -X- _ O
in -X- _ O
Natural -X- _ O
Language -X- _ O
Processing -X- _ O
, -X- _ O
dialogue -X- _ B-TaskName
generation -X- _ I-TaskName
systems -X- _ O
aim -X- _ O
to -X- _ O
generate -X- _ O
fluent -X- _ O
and -X- _ O
informative -X- _ O
responses -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
dialogue -X- _ O
context -X- _ O
( -X- _ O
Ke -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
Early -X- _ O
dialogue -X- _ B-TaskName
generation -X- _ I-TaskName
models -X- _ O
( -X- _ O
Henderson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
; -X- _ O
Shang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Luo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
usually -X- _ O
adopt -X- _ O
the -X- _ O
simple -X- _ O
seq2seq -X- _ B-MethodName
( -X- _ O
Sutskever -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
framework -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
relationship -X- _ O
between -X- _ O
dialogue -X- _ O
context -X- _ O
and -X- _ O
response -X- _ O
in -X- _ O
the -X- _ O
manner -X- _ O
of -X- _ O
machine -X- _ O
translation -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
vanilla -X- _ O
seq2seq -X- _ B-MethodName
structure -X- _ O
tends -X- _ O
to -X- _ O
generate -X- _ O
dull -X- _ O
and -X- _ O
generic -X- _ O
responses -X- _ O
. -X- _ O
To -X- _ O
generate -X- _ O
informative -X- _ O
responses -X- _ O
, -X- _ O
hierarchical -X- _ O
structures -X- _ O
Song -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
and -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
techniques -X- _ O
( -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
are -X- _ O
employed -X- _ O
to -X- _ O
capture -X- _ O
the -X- _ O
hierarchical -X- _ O
dependencies -X- _ O
of -X- _ O
dialogue -X- _ O
context -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
of -X- _ O
these -X- _ O
methods -X- _ O
do -X- _ O
not -X- _ O
meet -X- _ O
expectations -X- _ O
( -X- _ O
Wei -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
main -X- _ O
reason -X- _ O
is -X- _ O
that -X- _ O
there -X- _ O
are -X- _ O
one -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
many -X- _ O
and -X- _ O
many -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
one -X- _ O
relationships -X- _ O
between -X- _ O
dialogue -X- _ O
context -X- _ O
and -X- _ O
responses -X- _ O
. -X- _ O
Modeling -X- _ O
the -X- _ O
multimapping -X- _ O
relationship -X- _ O
is -X- _ O
crucial -X- _ O
for -X- _ O
improving -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
the -X- _ O
dialog -X- _ B-TaskName
generation -X- _ I-TaskName
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
PVGRU -X- _ B-MethodName
component -X- _ O
by -X- _ O
introducing -X- _ O
recurrent -X- _ O
summarizing -X- _ O
variables -X- _ O
into -X- _ O
GRU -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
model -X- _ O
the -X- _ O
varieties -X- _ O
of -X- _ O
dialogue -X- _ O
context -X- _ O
. -X- _ O

Variational -X- _ O
Mechanism -X- _ O

Variational -X- _ O
mechanisms -X- _ O
enable -X- _ O
efficient -X- _ O
working -X- _ O
in -X- _ O
directed -X- _ O
probabilistic -X- _ O
models -X- _ O
when -X- _ O
latent -X- _ O
variables -X- _ O
with -X- _ O
intractable -X- _ O
posterior -X- _ O
distributions -X- _ O
existing -X- _ O
( -X- _ O
Kingma -X- _ O
and -X- _ O
Welling -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O
Variational -X- _ O
mechanisms -X- _ O
can -X- _ O
learn -X- _ O
the -X- _ O
latent -X- _ O
relationship -X- _ O
between -X- _ O
dialogue -X- _ O
context -X- _ O
and -X- _ O
responses -X- _ O
by -X- _ O
introducing -X- _ O
latent -X- _ O
variables -X- _ O
. -X- _ O
Most -X- _ O
existing -X- _ O
methods -X- _ O
( -X- _ O
Serban -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Bao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
based -X- _ O
on -X- _ O
variational -X- _ O
mechanisms -X- _ O
employ -X- _ O
prior -X- _ O
to -X- _ O
approximate -X- _ O
true -X- _ O
posterior -X- _ O
probability -X- _ O
. -X- _ O
These -X- _ O
methods -X- _ O
not -X- _ O
only -X- _ O
encounter -X- _ O
the -X- _ O
problem -X- _ O
of -X- _ O
posterior -X- _ O
collapse -X- _ O
issue -X- _ O
but -X- _ O
also -X- _ O
the -X- _ O
problem -X- _ O
of -X- _ O
inconsistency -X- _ O
between -X- _ O
training -X- _ O
and -X- _ O
inference -X- _ O
( -X- _ O
Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Shi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
employ -X- _ O
consistency -X- _ O
and -X- _ O
reconstruction -X- _ O
objectives -X- _ O
to -X- _ O
optimize -X- _ O
the -X- _ O
summarizing -X- _ O
variable -X- _ O
different -X- _ O
from -X- _ O
variational -X- _ O
mechanism -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
model -X- _ O
the -X- _ O
multi -X- _ O
- -X- _ O
mapping -X- _ O
phenomena -X- _ O
in -X- _ O
dialogues -X- _ O
. -X- _ O

Preliminary -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
employ -X- _ O
GRU -X- _ B-MethodName
( -X- _ O
Gated -X- _ B-MethodName
Recurrent -X- _ I-MethodName
Unit -X- _ I-MethodName
) -X- _ O
( -X- _ O
Cho -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
as -X- _ O
the -X- _ O
implementation -X- _ O
of -X- _ O
recurrent -X- _ B-MethodName
neural -X- _ I-MethodName
network -X- _ I-MethodName
( -X- _ O
RNN -X- _ B-MethodName
) -X- _ O
. -X- _ O
The -X- _ O
reset -X- _ O
gate -X- _ O
r -X- _ O
t -X- _ O
is -X- _ O
computed -X- _ O
by -X- _ O
: -X- _ O

rt -X- _ O
= -X- _ O
σ -X- _ O
( -X- _ O
Wrxt -X- _ O
+ -X- _ O
Urht−1 -X- _ O
) -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O

where -X- _ O
σ -X- _ O
is -X- _ O
the -X- _ O
logistic -X- _ O
sigmoid -X- _ O
function -X- _ O
. -X- _ O
x -X- _ O
t -X- _ O
represents -X- _ O
the -X- _ O
input -X- _ O
at -X- _ O
time -X- _ O
step -X- _ O
t -X- _ O
and -X- _ O
h -X- _ O
t−1 -X- _ O
denotes -X- _ O
the -X- _ O
hidden -X- _ O
state -X- _ O
at -X- _ O
time -X- _ O
step -X- _ O
t-1 -X- _ O
. -X- _ O
W -X- _ O
r -X- _ O
and -X- _ O
U -X- _ O
r -X- _ O
are -X- _ O
parameter -X- _ O
matrices -X- _ O
which -X- _ O
are -X- _ O
learned -X- _ O
. -X- _ O
Similarly -X- _ O
, -X- _ O
the -X- _ O
updated -X- _ O
gate -X- _ O
z -X- _ O
t -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O
: -X- _ O

zt -X- _ O
= -X- _ O
σ -X- _ O
( -X- _ O
Wzxt -X- _ O
+ -X- _ O
Uzht−1 -X- _ O
) -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O

The -X- _ O
hidden -X- _ O
state -X- _ O
h -X- _ O
t -X- _ O
at -X- _ O
the -X- _ O
time -X- _ O
step -X- _ O
t -X- _ O
is -X- _ O
then -X- _ O
computed -X- _ O
by -X- _ O
: -X- _ O

ht -X- _ O
= -X- _ O
ztht−1 -X- _ O
+ -X- _ O
( -X- _ O
1 -X- _ O
− -X- _ O
zt -X- _ O
) -X- _ O
ht -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
ht -X- _ O
= -X- _ O
ϕ -X- _ O
( -X- _ O
W -X- _ O
xt -X- _ O
+ -X- _ O
U -X- _ O
( -X- _ O
rt -X- _ O
⊙ -X- _ O
ht−1 -X- _ O
) -X- _ O
) -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O

where -X- _ O
ϕ -X- _ O
( -X- _ O
• -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
tanh -X- _ O
function -X- _ O
, -X- _ O
W -X- _ O
and -X- _ O
U -X- _ O
are -X- _ O
weight -X- _ O
matrices -X- _ O
which -X- _ O
are -X- _ O
learned -X- _ O
. -X- _ O
GRU -X- _ B-MethodName
is -X- _ O
considered -X- _ O
as -X- _ O
a -X- _ O
classic -X- _ O
implementation -X- _ O
of -X- _ O
RNN -X- _ B-MethodName
, -X- _ O
which -X- _ O
is -X- _ O
widely -X- _ O
employed -X- _ O
in -X- _ O
generative -X- _ O
tasks -X- _ O
. -X- _ O
2 -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
, -X- _ O
PVGRU -X- _ B-MethodName
introduces -X- _ O
a -X- _ O
recurrent -X- _ O
summarizing -X- _ O
variable -X- _ O
v -X- _ O
based -X- _ O
on -X- _ O
GRU -X- _ B-MethodName
. -X- _ O
The -X- _ O
recurrent -X- _ O
summarizing -X- _ O
variable -X- _ O
v -X- _ O
is -X- _ O
obtained -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
incremental -X- _ O
information -X- _ O
of -X- _ O
hidden -X- _ O
state -X- _ O
h -X- _ O
and -X- _ O
the -X- _ O
previous -X- _ O
state -X- _ O
of -X- _ O
summarizing -X- _ O
variable -X- _ O
. -X- _ O
Specially -X- _ O
, -X- _ O
the -X- _ O
summarizing -X- _ O
variable -X- _ O
v -X- _ O
0 -X- _ O
is -X- _ O
initialized -X- _ O
with -X- _ O
standard -X- _ O
Gaussian -X- _ O
distribution -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
Figure -X- _ O
3 -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
assume -X- _ O
the -X- _ O
input -X- _ O
is -X- _ O
x -X- _ O
t -X- _ O
at -X- _ O
the -X- _ O
time -X- _ O
step -X- _ O
t -X- _ O
, -X- _ O
the -X- _ O
reset -X- _ O
gate -X- _ O
r -X- _ O
t -X- _ O
is -X- _ O
rewrited -X- _ O
as -X- _ O
: -X- _ O

rt -X- _ O
= -X- _ O
σ -X- _ O
( -X- _ O
Wrxt -X- _ O
+ -X- _ O
Urht−1 -X- _ O
+ -X- _ O
Vrvt−1 -X- _ O
) -X- _ O
( -X- _ O
5 -X- _ O
) -X- _ O

where -X- _ O
W -X- _ O
r -X- _ O
, -X- _ O
U -X- _ O
r -X- _ O
and -X- _ O
V -X- _ O
r -X- _ O
are -X- _ O
parameter -X- _ O
matrices -X- _ O
, -X- _ O
and -X- _ O
v -X- _ O
t−1 -X- _ O
is -X- _ O
the -X- _ O
previous -X- _ O
summarizing -X- _ O
variable -X- _ O
state -X- _ O
. -X- _ O

Similarly -X- _ O
, -X- _ O
the -X- _ O
update -X- _ O
gate -X- _ O
z -X- _ O
t -X- _ O
is -X- _ O
computed -X- _ O
by -X- _ O
: -X- _ O
We -X- _ O
introduce -X- _ O
a -X- _ O
gate -X- _ O
g -X- _ O
t -X- _ O
for -X- _ O
summarizing -X- _ O
variable -X- _ O
factor -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

zt -X- _ O
= -X- _ O
σ -X- _ O
( -X- _ O
Wzxt -X- _ O
+ -X- _ O
Uzht−1 -X- _ O
+ -X- _ O
Vzvt−1 -X- _ O
) -X- _ O
( -X- _ O
6 -X- _ O
) -X- _ O
1- -X- _ O
tanh -X- _ O
1- -X- _ O
RE -X- _ O
sam -X- _ O
1- -X- _ O
ℎ -X- _ O
ℎ -X- _ O
−1 -X- _ O
−1 -X- _ O
ℎ -X- _ O
−1 -X- _ O
ℎ -X- _ O
( -X- _ O
0,1 -X- _ O
) -X- _ O
0 -X- _ O
1 -X- _ O
2 -X- _ O
… -X- _ O
1 -X- _ O
2 -X- _ O
Encoder -X- _ O
PVGRU -X- _ B-MethodName
… -X- _ O
( -X- _ O
0,1 -X- _ O
) -X- _ O
0 -X- _ O
… -X- _ O
1 -X- _ O
2 -X- _ O
Context -X- _ O
PVGRU -X- _ B-MethodName
… -X- _ O
1 -X- _ O
2 -X- _ O
… -X- _ O
ℎ -X- _ O
1 -X- _ O
ℎ -X- _ O
2 -X- _ O
ℎ -X- _ O
0 -X- _ O
… -X- _ O
1 -X- _ O
2 -X- _ O
… -X- _ O
Decoder -X- _ O
ℎ -X- _ O
0 -X- _ O
0 -X- _ O
1 -X- _ O
1 -X- _ O
2 -X- _ O
+1 -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O

b -X- _ O
) -X- _ O
Recurrence -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
Init -X- _ O
( -X- _ O
0,1 -X- _ O
) -X- _ O
0 -X- _ O
1 -X- _ O
ℎ -X- _ O
0 -X- _ O
ℎ -X- _ O
1 -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
Training -X- _ O
ℎ -X- _ O
−1 -X- _ O
ℎ -X- _ O
−1 -X- _ O
RE -X- _ O
≈ -X- _ O
ℎ -X- _ O
−1 -X- _ O
ℎ -X- _ O
−1 -X- _ O
+1 -X- _ O

gt -X- _ O
= -X- _ O
σ -X- _ O
( -X- _ O
Wgxt -X- _ O
+ -X- _ O
Ught−1 -X- _ O
+ -X- _ O
Vgvt−1 -X- _ O
) -X- _ O
( -X- _ O
7 -X- _ O
) -X- _ O

The -X- _ O
updated -X- _ O
gate -X- _ O
of -X- _ O
summarizing -X- _ O
factor -X- _ O
controls -X- _ O
how -X- _ O
much -X- _ O
information -X- _ O
from -X- _ O
the -X- _ O
previous -X- _ O
variable -X- _ O
will -X- _ O
carry -X- _ O
over -X- _ O
to -X- _ O
the -X- _ O
current -X- _ O
summarizing -X- _ O
variable -X- _ O
state -X- _ O
. -X- _ O
Under -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
g -X- _ O
t -X- _ O
, -X- _ O
theh -X- _ O
t -X- _ O
follows -X- _ O
the -X- _ O
equation -X- _ O
: -X- _ O

ht -X- _ O
= -X- _ O
ϕ -X- _ O
( -X- _ O
W -X- _ O
xt -X- _ O
+ -X- _ O
U -X- _ O
( -X- _ O
rt -X- _ O
⊙ -X- _ O
ht−1 -X- _ O
) -X- _ O
+ -X- _ O
V -X- _ O
( -X- _ O
gt -X- _ O
⊙ -X- _ O
vt−1 -X- _ O
) -X- _ O
) -X- _ O
( -X- _ O
8 -X- _ O
) -X- _ O

Then -X- _ O
the -X- _ O
PVGRU -X- _ B-MethodName
updates -X- _ O
its -X- _ O
hidden -X- _ O
state -X- _ O
h -X- _ O
t -X- _ O
using -X- _ O
the -X- _ O
same -X- _ O
recurrence -X- _ O
equation -X- _ O
as -X- _ O
GRU -X- _ B-MethodName
. -X- _ O
The -X- _ O
summarizing -X- _ O
variable -X- _ O
v -X- _ O
t -X- _ O
at -X- _ O
the -X- _ O
time -X- _ O
step -X- _ O
t -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O
: -X- _ O
ṽ -X- _ O

where -X- _ O
φ -X- _ O
( -X- _ O
• -X- _ O
) -X- _ O
represents -X- _ O
a -X- _ O
nonlinear -X- _ O
neural -X- _ O
network -X- _ O
approximator -X- _ O
andṽ -X- _ O
t -X- _ O
denotes -X- _ O
the -X- _ O
variations -X- _ O
between -X- _ O
time -X- _ O
t -X- _ O
and -X- _ O
time -X- _ O
t -X- _ O
− -X- _ O
1 -X- _ O
. -X- _ O
The -X- _ O
variations -X- _ O
across -X- _ O
subsequent -X- _ O
up -X- _ O
to -X- _ O
time -X- _ O
t -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O
: -X- _ O

vt -X- _ O
= -X- _ O
gt -X- _ O
⊙ṽt -X- _ O
+ -X- _ O
( -X- _ O
1 -X- _ O
− -X- _ O
gt -X- _ O
) -X- _ O
⊙ -X- _ O
vt−1 -X- _ O
( -X- _ O
10 -X- _ O
) -X- _ O

Figure -X- _ O
3 -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
demonstrates -X- _ O
the -X- _ O
schematic -X- _ O
diagram -X- _ O
of -X- _ O
the -X- _ O
recurrent -X- _ O
process -X- _ O
of -X- _ O
PVGRU -X- _ B-MethodName
described -X- _ O
above -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
observe -X- _ O
that -X- _ O
PVGRU -X- _ B-MethodName
does -X- _ O
not -X- _ O
adopt -X- _ O
posterior -X- _ O
knowledge -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
guarantee -X- _ O
the -X- _ O
consistency -X- _ O
between -X- _ O
training -X- _ O
and -X- _ O
inference -X- _ O
. -X- _ O

Optimization -X- _ O
Summarizing -X- _ O
Variable -X- _ O

Based -X- _ O
on -X- _ O
but -X- _ O
different -X- _ O
from -X- _ O
traditional -X- _ O
variational -X- _ O
mechanism -X- _ O
, -X- _ O
we -X- _ O
design -X- _ O
the -X- _ O
consistency -X- _ O
and -X- _ O
reconstruction -X- _ O
objectives -X- _ O
to -X- _ O
optimize -X- _ O
the -X- _ O
summarizing -X- _ O
variable -X- _ O
. -X- _ O
The -X- _ O
consistency -X- _ O
objective -X- _ O
ensures -X- _ O
that -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
the -X- _ O
information -X- _ O
increment -X- _ O
of -X- _ O
hidden -X- _ O
state -X- _ O
at -X- _ O
each -X- _ O
time -X- _ O
step -X- _ O
is -X- _ O
consistent -X- _ O
with -X- _ O
the -X- _ O
input -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
keep -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
information -X- _ O
increment -X- _ O
h -X- _ O
t -X- _ O
− -X- _ O
h -X- _ O
t−1 -X- _ O
at -X- _ O
time -X- _ O
t -X- _ O
consistent -X- _ O
with -X- _ O
x -X- _ O
t -X- _ O
. -X- _ O
The -X- _ O
consistency -X- _ O
objective -X- _ O
function -X- _ O
at -X- _ O
time -X- _ O
step -X- _ O
t -X- _ O
is -X- _ O
denoted -X- _ O
as -X- _ O
: -X- _ O

ℓ -X- _ O
t -X- _ O
c -X- _ O
= -X- _ O
KL -X- _ O
( -X- _ O
p -X- _ O
( -X- _ O
xt -X- _ O
) -X- _ O
||p -X- _ O
( -X- _ O
ht -X- _ O
− -X- _ O
ht−1 -X- _ O
) -X- _ O
) -X- _ O
= -X- _ O
KL -X- _ O
( -X- _ O
p -X- _ O
( -X- _ O
xt -X- _ O
) -X- _ O
||ṽt -X- _ O
) -X- _ O
( -X- _ O
11 -X- _ O
) -X- _ O

where -X- _ O
KL -X- _ O
( -X- _ O
• -X- _ O
) -X- _ O
represents -X- _ O
Kullback -X- _ O
- -X- _ O
Leibler -X- _ O
divergence -X- _ O
( -X- _ O
Barz -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
and -X- _ O
p -X- _ O
( -X- _ O
• -X- _ O
) -X- _ O
represents -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
the -X- _ O
vector -X- _ O
. -X- _ O
We -X- _ O
employ -X- _ O
" -X- _ O
sam -X- _ O
" -X- _ O
to -X- _ O
represent -X- _ O
this -X- _ O
process -X- _ O
of -X- _ O
distribution -X- _ O
sampling -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
reconstruction -X- _ O
optimization -X- _ O
objective -X- _ O
ensures -X- _ O
that -X- _ O
the -X- _ O
summarizing -X- _ O
variable -X- _ O
can -X- _ O
correctly -X- _ O
reflect -X- _ O
the -X- _ O
semantic -X- _ O
of -X- _ O
the -X- _ O
dialogue -X- _ O
context -X- _ O
from -X- _ O
the -X- _ O
whole -X- _ O
perspective -X- _ O
, -X- _ O
which -X- _ O
requires -X- _ O
PVGRU -X- _ B-MethodName
reconstructs -X- _ O
the -X- _ O
sequence -X- _ O
information -X- _ O
from -X- _ O
the -X- _ O
accumulated -X- _ O
distribution -X- _ O
variable -X- _ O
. -X- _ O
The -X- _ O
reconstruction -X- _ O
loss -X- _ O
at -X- _ O
time -X- _ O
step -X- _ O
t -X- _ O
is -X- _ O
described -X- _ O
as -X- _ O
: -X- _ O

ℓ -X- _ O
t -X- _ O
r -X- _ O
( -X- _ O
vt -X- _ O
, -X- _ O
ht -X- _ O
) -X- _ O
= -X- _ O
1 -X- _ O
2 -X- _ O
|f -X- _ O
( -X- _ O
vt -X- _ O
) -X- _ O
− -X- _ O
ht| -X- _ O
, -X- _ O
|vt -X- _ O
− -X- _ O
ht| -X- _ O
≤ -X- _ O
δ -X- _ O
δ|f -X- _ O
( -X- _ O
vt -X- _ O
) -X- _ O
− -X- _ O
ht| -X- _ O
− -X- _ O
1 -X- _ O
2 -X- _ O
δ -X- _ O
2 -X- _ O
, -X- _ O
|vt -X- _ O
− -X- _ O
ht| -X- _ O
> -X- _ O
δ -X- _ O
( -X- _ O
12 -X- _ O

) -X- _ O

where -X- _ O
f -X- _ O
( -X- _ O
• -X- _ O
) -X- _ O
stands -X- _ O
for -X- _ O
decoder -X- _ O
using -X- _ O
MLP -X- _ O
, -X- _ O
δ -X- _ O
is -X- _ O
a -X- _ O
hyperparameter -X- _ O
and -X- _ O
| -X- _ O
• -X- _ O
| -X- _ O
represents -X- _ O
the -X- _ O
absolute -X- _ O
value -X- _ O
. -X- _ O
We -X- _ O
employ -X- _ O
" -X- _ O
RE -X- _ O
" -X- _ O
to -X- _ O
represent -X- _ O
the -X- _ O
reconstruction -X- _ O
process -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
. -X- _ O
Figure -X- _ O
3 -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
demonstrates -X- _ O
the -X- _ O
schematic -X- _ O
diagram -X- _ O
of -X- _ O
optimizing -X- _ O
summarizing -X- _ O
variable -X- _ O
. -X- _ O
Reconstruction -X- _ O
and -X- _ O
consistency -X- _ O
objectives -X- _ O
ensure -X- _ O
that -X- _ O
summarizing -X- _ O
variable -X- _ O
can -X- _ O
correctly -X- _ O
reflect -X- _ O
the -X- _ O
semantics -X- _ O
of -X- _ O
the -X- _ O
dialogue -X- _ O
context -X- _ O
. -X- _ O

Hierarchical -X- _ O
Pseudo -X- _ O
- -X- _ O
variational -X- _ O
Model -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
the -X- _ O
dialogues -X- _ O
contain -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
and -X- _ O
sentence -X- _ O
- -X- _ O
level -X- _ O
variability -X- _ O
. -X- _ O
We -X- _ O
follow -X- _ O
previous -X- _ O
studies -X- _ O
( -X- _ O
Serban -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
, -X- _ O
2017Huang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O

, -X- _ O
u -X- _ O
2 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
u -X- _ O
m -X- _ O
} -X- _ O
to -X- _ O
utterance -X- _ O
vec- -X- _ O
tors -X- _ O
{ -X- _ O
h -X- _ O
u -X- _ O
1 -X- _ O
, -X- _ O
h -X- _ O
u -X- _ O
2 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
h -X- _ O
u -X- _ O
m -X- _ O
} -X- _ O
. -X- _ O

At -X- _ O
the -X- _ O
same -X- _ O
time -X- _ O
, -X- _ O
v -X- _ O
t -X- _ O
records -X- _ O
the -X- _ O
accumulated -X- _ O
distribution -X- _ O
variations -X- _ O
of -X- _ O
the -X- _ O
subsequence -X- _ O
at -X- _ O
time -X- _ O
step -X- _ O
t. -X- _ O
The -X- _ O
context -X- _ O
PVGRU -X- _ B-MethodName
takes -X- _ O
charge -X- _ O
of -X- _ O
capturing -X- _ O
the -X- _ O
utterance -X- _ O
- -X- _ O
level -X- _ O
variabilities -X- _ O
. -X- _ O
The -X- _ O
last -X- _ O
hidden -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
context -X- _ O
PVGRU -X- _ B-MethodName
represents -X- _ O
a -X- _ O
summary -X- _ O
of -X- _ O
the -X- _ O
dialogue -X- _ O
. -X- _ O
The -X- _ O
last -X- _ O
summarizing -X- _ O
variable -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
context -X- _ O
PVGRU -X- _ B-MethodName
stands -X- _ O
for -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
dialogue -X- _ O
. -X- _ O
The -X- _ O
decoder -X- _ O
PVGRU -X- _ B-MethodName
takes -X- _ O
the -X- _ O
last -X- _ O
states -X- _ O
of -X- _ O
context -X- _ O
PVGRU -X- _ B-MethodName
and -X- _ O
produces -X- _ O
a -X- _ O
probability -X- _ O
distribution -X- _ O
over -X- _ O
the -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
response -X- _ O
{ -X- _ O
y -X- _ O
1 -X- _ O
, -X- _ O
y -X- _ O
2 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
y -X- _ O
n -X- _ O
} -X- _ O
. -X- _ O
The -X- _ O
generation -X- _ O
process -X- _ O
of -X- _ O
training -X- _ O
and -X- _ O
inference -X- _ O
can -X- _ O
be -X- _ O
formally -X- _ O
described -X- _ O
as -X- _ O
: -X- _ O

p -X- _ O
( -X- _ O
y -X- _ O
≤T -X- _ O
, -X- _ O
v -X- _ O
≤n -X- _ O
) -X- _ O
= -X- _ O
n -X- _ O
t=1 -X- _ O
p -X- _ O
( -X- _ O
yt|y -X- _ O
< -X- _ O
t -X- _ O
, -X- _ O
v -X- _ O
< -X- _ O
t -X- _ O
) -X- _ O
( -X- _ O
13 -X- _ O
) -X- _ O

The -X- _ O
log -X- _ O
- -X- _ O
likelihood -X- _ O
loss -X- _ O
of -X- _ O
predicting -X- _ O
reponse -X- _ O
is -X- _ O
formalized -X- _ O
as -X- _ O
: -X- _ O

ℓ -X- _ O
t -X- _ O
ll -X- _ O
= -X- _ O
logp -X- _ O
( -X- _ O
yt|y -X- _ O
< -X- _ O
t -X- _ O
, -X- _ O
v -X- _ O
< -X- _ O
t -X- _ O
) -X- _ O
( -X- _ O
14 -X- _ O
) -X- _ O

The -X- _ O
total -X- _ O
loss -X- _ O
can -X- _ O
be -X- _ O
written -X- _ O
as -X- _ O
: -X- _ O

ℓ -X- _ O
total -X- _ O
= -X- _ O
E -X- _ O
T -X- _ O
t=1 -X- _ O
( -X- _ O
ℓ -X- _ O
t -X- _ O
ll -X- _ O
+ -X- _ O
ℓ -X- _ O
t -X- _ O
r -X- _ O
+ -X- _ O
ℓ -X- _ O
t -X- _ O
c -X- _ O
) -X- _ O
( -X- _ O
15 -X- _ O
) -X- _ O

5 -X- _ O
Experiments -X- _ O

For -X- _ O
descriptions -X- _ O
of -X- _ O
the -X- _ O
datasets -X- _ O
, -X- _ O
please -X- _ O
refer -X- _ O
to -X- _ O
the -X- _ O
Appendix -X- _ O
A.1 -X- _ O
. -X- _ O
Please -X- _ O
refer -X- _ O
to -X- _ O
Appendix -X- _ O
A.2 -X- _ O
for -X- _ O
implementation -X- _ O
details -X- _ O
. -X- _ O
In -X- _ O
Appendix -X- _ O
A.5 -X- _ O
we -X- _ O
show -X- _ O
the -X- _ O
ablation -X- _ O
results -X- _ O
of -X- _ O
two -X- _ O
objective -X- _ O
functions -X- _ O
, -X- _ O
showing -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
objective -X- _ O
functions -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
experimental -X- _ O
results -X- _ O
, -X- _ O
we -X- _ O
performed -X- _ O
a -X- _ O
significance -X- _ O
test -X- _ O
in -X- _ O
Appendix -X- _ O
A.6 -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
pvalues -X- _ O
of -X- _ O
PVHD -X- _ B-MethodName
are -X- _ O
less -X- _ O
than -X- _ O
0.05 -X- _ O
compared -X- _ O
with -X- _ O
other -X- _ O
models -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
case -X- _ O
studies -X- _ O
in -X- _ O
Appendix -X- _ O
A.7 -X- _ O
and -X- _ O
discuss -X- _ O
model -X- _ O
limitations -X- _ O
in -X- _ O
Appendix -X- _ O
7 -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O

Baselines -X- _ O

The -X- _ O
automatic -X- _ O
evaluation -X- _ O
metrics -X- _ O
is -X- _ O
employed -X- _ O
to -X- _ O
verify -X- _ O
the -X- _ O
generality -X- _ O
of -X- _ O
PVGRU -X- _ B-MethodName
, -X- _ O
we -X- _ O
select -X- _ O
the -X- _ O
following -X- _ O
RNN -X- _ B-MethodName
- -X- _ O
based -X- _ O
dialogue -X- _ O
generation -X- _ O
models -X- _ O
as -X- _ O
baselines -X- _ O
: -X- _ O
seq2seq -X- _ B-MethodName
: -X- _ O
sequence -X- _ B-MethodName
- -X- _ I-MethodName
to -X- _ I-MethodName
- -X- _ I-MethodName
sequence -X- _ I-MethodName
model -X- _ O
GRU -X- _ B-MethodName
- -X- _ O
based -X- _ O
with -X- _ O
attention -X- _ O
mechanisms -X- _ O
( -X- _ O
Bahdanau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O
HRED -X- _ B-MethodName
: -X- _ O
hierarchical -X- _ B-MethodName
recurrent -X- _ I-MethodName
encoder -X- _ I-MethodName
- -X- _ I-MethodName
decoder -X- _ I-MethodName
on -X- _ O
recurrent -X- _ B-MethodName
neural -X- _ I-MethodName
network -X- _ I-MethodName
( -X- _ O
Serban -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
for -X- _ O
dialogue -X- _ B-TaskName
generation -X- _ I-TaskName
. -X- _ O
HRAN -X- _ B-MethodName
: -X- _ O
hierarchical -X- _ B-MethodName
recurrent -X- _ I-MethodName
neural -X- _ I-MethodName
network -X- _ I-MethodName
dialogue -X- _ I-MethodName
generation -X- _ I-MethodName
model -X- _ I-MethodName
based -X- _ I-MethodName
on -X- _ I-MethodName
attentiom -X- _ I-MethodName
mechanism -X- _ I-MethodName
( -X- _ O
Xing -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
CSG -X- _ B-MethodName
: -X- _ O
hierarchical -X- _ B-MethodName
recurrent -X- _ I-MethodName
neural -X- _ I-MethodName
network -X- _ I-MethodName
model -X- _ I-MethodName
using -X- _ I-MethodName
static -X- _ I-MethodName
attention -X- _ I-MethodName
for -X- _ I-MethodName
contextsensitive -X- _ I-MethodName
generation -X- _ I-MethodName
of -X- _ I-MethodName
dialogue -X- _ I-MethodName
responses -X- _ I-MethodName
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

To -X- _ O
evaluate -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
PVHD -X- _ B-MethodName
, -X- _ O
we -X- _ O
choose -X- _ O
dialogue -X- _ O
generation -X- _ O
model -X- _ O
based -X- _ O
on -X- _ O
variational -X- _ O
mechanism -X- _ O
as -X- _ O
baselines -X- _ O
: -X- _ O
HVRNN -X- _ B-MethodName
: -X- _ O
VRNN -X- _ B-MethodName
( -X- _ O
Variational -X- _ B-MethodName
Recurrent -X- _ I-MethodName
Neural -X- _ I-MethodName
Network -X- _ I-MethodName
) -X- _ O
( -X- _ O
Chung -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
recurrent -X- _ O
version -X- _ O
of -X- _ O
the -X- _ O
VAE -X- _ O
. -X- _ O
We -X- _ O
combine -X- _ O
VRNN -X- _ B-MethodName
( -X- _ O
Chung -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
and -X- _ O
HRED -X- _ B-MethodName
to -X- _ O
construct -X- _ O
the -X- _ O
HVRNN -X- _ B-MethodName
. -X- _ O
CVAE -X- _ B-MethodName
: -X- _ O
hierarchical -X- _ O
dialogue -X- _ O
generation -X- _ O
model -X- _ O
based -X- _ O
on -X- _ O
conditional -X- _ B-MethodName
variational -X- _ I-MethodName
autoencoders -X- _ I-MethodName
( -X- _ O
Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
implement -X- _ O
CVAE -X- _ B-MethodName
with -X- _ O
bag -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
word -X- _ O
loss -X- _ O
and -X- _ O
KL -X- _ O
annealing -X- _ O
technique -X- _ O
. -X- _ O
VAD -X- _ B-MethodName
: -X- _ O
hierarchical -X- _ O
dialogue -X- _ O
generation -X- _ O
model -X- _ O
introducing -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
latent -X- _ O
variables -X- _ O
( -X- _ O
Du -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
VHCR -X- _ B-MethodName
: -X- _ O
hierarchical -X- _ O
dialogue -X- _ O
generation -X- _ O
model -X- _ O
using -X- _ O
global -X- _ O
and -X- _ O
local -X- _ O
latent -X- _ O
variables -X- _ O
( -X- _ O
Park -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
SepaCVAE -X- _ B-MethodName
: -X- _ O
self -X- _ B-MethodName
- -X- _ I-MethodName
separated -X- _ I-MethodName
conditional -X- _ I-MethodName
variational -X- _ I-MethodName
autoencoder -X- _ I-MethodName
introducing -X- _ O
group -X- _ O
information -X- _ O
to -X- _ O
regularize -X- _ O
the -X- _ O
latent -X- _ O
variables -X- _ O
( -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
SVT -X- _ B-MethodName
: -X- _ O
sequential -X- _ B-MethodName
variational -X- _ I-MethodName
transformer -X- _ I-MethodName
augmenting -X- _ O
deocder -X- _ O
with -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
latent -X- _ O
variables -X- _ O
( -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
GVT -X- _ B-MethodName
: -X- _ O
global -X- _ B-MethodName
variational -X- _ I-MethodName
transformer -X- _ I-MethodName
modeling -X- _ O
the -X- _ O
discourselevel -X- _ O
diversity -X- _ O
with -X- _ O
a -X- _ O
global -X- _ O
latent -X- _ O
variable -X- _ O
( -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Different -X- _ O
from -X- _ O
original -X- _ O
implementation -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
use -X- _ O
knowledge -X- _ O
on -X- _ O
the -X- _ O
DSTC7 -X- _ O
- -X- _ O
AVSD -X- _ O
. -X- _ O
DialogVED -X- _ B-MethodName
: -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
latent -X- _ O
variable -X- _ O
encoder -X- _ O
- -X- _ O
decoder -X- _ O
model -X- _ O
for -X- _ O
dialog -X- _ O
response -X- _ O
generation -X- _ O
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
initialize -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
the -X- _ O
large -X- _ O
version -X- _ O
of -X- _ O
DialogVED -X- _ B-MethodName
. -X- _ O

Automatic -X- _ O
& -X- _ O
Human -X- _ B-MetricName
Evaluation -X- _ I-MetricName

Please -X- _ O
refer -X- _ O
to -X- _ O
Appendix -X- _ O
A.3 -X- _ O
and -X- _ O
Appendix -X- _ O
A.4 -X- _ O
for -X- _ O
details -X- _ O
of -X- _ O
automatic -X- _ B-MetricName
evaluation -X- _ I-MetricName
metrics -X- _ O
. -X- _ O
Some -X- _ O
differences -X- _ O
from -X- _ O
previous -X- _ O
works -X- _ O
are -X- _ O
emphasized -X- _ O
here -X- _ O
. -X- _ O
We -X- _ O
employ -X- _ O
improved -X- _ O
versions -X- _ O
of -X- _ O
BLEU -X- _ B-MetricName
and -X- _ O
ROUGE -X- _ B-MetricName
- -X- _ I-MetricName
L -X- _ I-MetricName
, -X- _ O
which -X- _ O
can -X- _ O
better -X- _ O
correlate -X- _ O
n -X- _ O
- -X- _ O
gram -X- _ O
overlap -X- _ O
with -X- _ O
human -X- _ O
judgment -X- _ O
by -X- _ O
weighting -X- _ O
the -X- _ O
relevant -X- _ O
n -X- _ O
- -X- _ O
gram -X- _ O
compared -X- _ O
with -X- _ O
original -X- _ O
BLEU -X- _ B-MetricName
( -X- _ O
Chen -X- _ O
and -X- _ O
Cherry -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O
Although -X- _ O
using -X- _ O
the -X- _ O
improved -X- _ O
versions -X- _ O
of -X- _ O
BLEU -X- _ B-MetricName
and -X- _ O
ROUGE -X- _ B-MetricName
- -X- _ I-MetricName
L -X- _ I-MetricName
will -X- _ O
result -X- _ O
in -X- _ O
lower -X- _ O
literal -X- _ O
values -X- _ O
on -X- _ O
the -X- _ O
corresponding -X- _ O
metrics -X- _ O
, -X- _ O
this -X- _ O
does -X- _ O
not -X- _ O
affect -X- _ O
the -X- _ O
fairness -X- _ O
of -X- _ O
the -X- _ O
comparison -X- _ O
. -X- _ O
We -X- _ O
adopt -X- _ O
the -X- _ O
implementation -X- _ O
of -X- _ O
distinct-1 -X- _ O
/ -X- _ O
2 -X- _ O
metrics -X- _ O
following -X- _ O
previous -X- _ O
study -X- _ O
( -X- _ O
Bahuleyan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
source -X- _ O
code -X- _ O
for -X- _ O
the -X- _ O
evaluation -X- _ O
method -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
on -X- _ O
the -X- _ O
anonymous -X- _ O
GitHub -X- _ O
. -X- _ O

Generality -X- _ O
of -X- _ O
PVGRU -X- _ B-MethodName

Table -X- _ O
1 -X- _ O
reports -X- _ O
the -X- _ O
automatic -X- _ B-MetricName
evaluation -X- _ I-MetricName
performance -X- _ O
comparison -X- _ O
of -X- _ O
the -X- _ O
models -X- _ O
using -X- _ O
GRU -X- _ B-MethodName
and -X- _ O
PVGRU -X- _ B-MethodName
. -X- _ O
We -X- _ O
can -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
models -X- _ O
based -X- _ O
on -X- _ O
PVGRU -X- _ B-MethodName
is -X- _ O
higher -X- _ O
than -X- _ O
that -X- _ O
based -X- _ O
on -X- _ O
GRU -X- _ B-MethodName
. -X- _ O
Specifically -X- _ O
, -X- _ O
on -X- _ O
DailyDialog -X- _ B-DatasetName
dataset -X- _ O
, -X- _ O
the -X- _ O
average -X- _ O
performance -X- _ O
of -X- _ O
models -X- _ O
based -X- _ O
on -X- _ O
PVGRU -X- _ B-MethodName
is -X- _ O
0.63 -X- _ B-MetricValue
% -X- _ I-MetricValue
to -X- _ O
16.35 -X- _ B-MetricValue
% -X- _ I-MetricValue
higher -X- _ O
on -X- _ O
PPL -X- _ B-MetricName
, -X- _ O
1.40 -X- _ B-MetricValue
% -X- _ I-MetricValue
to -X- _ O
1.92 -X- _ B-MetricValue
% -X- _ I-MetricValue
higher -X- _ O
on -X- _ O
BLEU-1 -X- _ B-MetricName
, -X- _ O
1.08 -X- _ B-MetricValue
% -X- _ I-MetricValue
to -X- _ O
2.02 -X- _ B-MetricValue
% -X- _ I-MetricValue
higher -X- _ O
on -X- _ O
Rouge -X- _ B-MetricName
- -X- _ I-MetricName
L -X- _ I-MetricName
, -X- _ O
1.10 -X- _ B-MetricValue
% -X- _ I-MetricValue
to -X- _ O
2.33 -X- _ B-MetricValue
% -X- _ I-MetricValue
higher -X- _ O
on -X- _ O
Dist-1 -X- _ B-MetricName
and -X- _ O
1.36 -X- _ B-MetricValue
% -X- _ I-MetricValue
to -X- _ O
1.62 -X- _ B-MetricValue
% -X- _ I-MetricValue
higher -X- _ O
on -X- _ O
average -X- _ B-MetricName
embedding -X- _ I-MetricName
compared -X- _ O
with -X- _ O
models -X- _ O
based -X- _ O
on -X- _ O
GRU -X- _ B-MethodName
. -X- _ O
On -X- _ O
DSTC7 -X- _ B-DatasetName
- -X- _ I-DatasetName
AVSD -X- _ I-DatasetName
dataset -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
models -X- _ O
based -X- _ O
on -X- _ O
PVGRU -X- _ B-MethodName
is -X- _ O
0.45 -X- _ B-MetricValue
% -X- _ I-MetricValue
to -X- _ O
5.47 -X- _ B-MetricValue
% -X- _ I-MetricValue
higher -X- _ O
on -X- _ O
PPL -X- _ B-MetricName
, -X- _ O
1.14 -X- _ B-MetricValue
% -X- _ I-MetricValue
to -X- _ O
2.57 -X- _ B-MetricValue
% -X- _ I-MetricValue
higher -X- _ O
on -X- _ O
BLEU-1 -X- _ B-MetricName
, -X- _ O
1.38 -X- _ B-MetricValue
% -X- _ I-MetricValue
to -X- _ O
2.7 -X- _ B-MetricValue
% -X- _ I-MetricValue
higher -X- _ O
on -X- _ O
Rouge -X- _ B-MetricName
- -X- _ I-MetricName
L -X- _ I-MetricName
, -X- _ O
0.69 -X- _ B-MetricValue
% -X- _ I-MetricValue
to -X- _ O
2.06 -X- _ B-MetricValue
% -X- _ I-MetricValue
higher -X- _ O
on -X- _ O
Dist-1 -X- _ B-MetricName
and -X- _ O
0.69 -X- _ B-MetricValue
% -X- _ I-MetricValue
to -X- _ O
2.69 -X- _ B-MetricValue
% -X- _ I-MetricValue
higher -X- _ O
on -X- _ O
average -X- _ B-MetricName
embedding -X- _ I-MetricName
compared -X- _ O
with -X- _ O
models -X- _ O
based -X- _ O
on -X- _ O
GRU -X- _ B-MethodName
. -X- _ O
GRU -X- _ B-MethodName
introduces -X- _ O
a -X- _ O
recurrent -X- _ O
summarizing -X- _ O
variable -X- _ O
, -X- _ O
which -X- _ O
records -X- _ O
the -X- _ O
accumulated -X- _ O
distribution -X- _ O
variations -X- _ O
of -X- _ O
sequences -X- _ O
. -X- _ O
The -X- _ O
recurrent -X- _ O
summarizing -X- _ O
variable -X- _ O
brings -X- _ O
randomness -X- _ O
to -X- _ O
the -X- _ O
internal -X- _ O
transition -X- _ O
structure -X- _ O
of -X- _ O
PVGRU -X- _ B-MethodName
, -X- _ O
which -X- _ O
makes -X- _ O
model -X- _ O
perceive -X- _ O
the -X- _ O
subtle -X- _ O
semantic -X- _ O
variability -X- _ O
. -X- _ O

( -X- _ O
a -X- _ O
) -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
( -X- _ O
d -X- _ O
) -X- _ O

Automatic -X- _ B-MetricName
Evaluation -X- _ I-MetricName
Results -X- _ O
& -X- _ O
Analysis -X- _ O

Table -X- _ O
2 -X- _ O
reports -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
automatic -X- _ B-MetricName
evaluation -X- _ I-MetricName
of -X- _ O
PVHD -X- _ B-MethodName
and -X- _ O
other -X- _ O
baselines -X- _ O
on -X- _ O
DailyDialog -X- _ B-DatasetName
and -X- _ O
DSTC7 -X- _ B-DatasetName
- -X- _ I-DatasetName
AVSD -X- _ I-DatasetName
datasets -X- _ O
. -X- _ O
Compared -X- _ O
to -X- _ O
RNNbased -X- _ B-MethodName
baselines -X- _ O
based -X- _ O
on -X- _ O
variational -X- _ O
mechanism -X- _ O
, -X- _ O
PVHD -X- _ B-MethodName
enjoys -X- _ O
an -X- _ O
advantage -X- _ O
in -X- _ O
performance -X- _ O
. -X- _ O
On -X- _ O
DailyDialog -X- _ B-DatasetName
datasets -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
PVHD -X- _ B-MethodName
is -X- _ O
1.16 -X- _ B-MetricValue
% -X- _ I-MetricValue
higher -X- _ O
on -X- _ O
BLEU-1 -X- _ B-MetricName
, -X- _ O
0.45 -X- _ B-MetricValue
% -X- _ I-MetricValue
higher -X- _ O
on -X- _ O
Rouge -X- _ B-MetricName
- -X- _ I-MetricName
L -X- _ I-MetricName
, -X- _ O
1.01 -X- _ B-MetricValue
% -X- _ I-MetricValue
higher -X- _ O
on -X- _ O
Dist-1 -X- _ B-MetricName
and -X- _ O
2.22 -X- _ B-MetricValue
% -X- _ I-MetricValue
higher -X- _ O
on -X- _ O
average -X- _ B-MetricName
embedding -X- _ I-MetricName
compared -X- _ O
to -X- _ O
HVRNN -X- _ B-MethodName
. -X- _ O
As -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
classic -X- _ O
variational -X- _ O
mechanism -X- _ O
models -X- _ O
CVAE -X- _ B-MethodName
, -X- _ O
VAD -X- _ B-MethodName
and -X- _ O
VHCR -X- _ B-MethodName
, -X- _ O
PVHD -X- _ B-MethodName
has -X- _ O
a -X- _ O
advantage -X- _ O
of -X- _ O
0.02 -X- _ B-MetricValue
% -X- _ I-MetricValue
to -X- _ O
22.75 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
PPL -X- _ B-MetricName
, -X- _ O
1.87 -X- _ B-MetricValue
% -X- _ I-MetricValue
to -X- _ O
6.88 -X- _ B-MetricValue
% -X- _ I-MetricValue
higher -X- _ O
on -X- _ O
BLEU-1 -X- _ B-MetricName
, -X- _ O
1.48 -X- _ B-MetricValue
% -X- _ I-MetricValue
to -X- _ O
3.25 -X- _ B-MetricValue
% -X- _ I-MetricValue
higher -X- _ O
on -X- _ O
Dist-1 -X- _ B-MetricName
, -X- _ O
0.43 -X- _ B-MetricValue
% -X- _ I-MetricValue
to -X- _ O
13.37 -X- _ B-MetricValue
% -X- _ I-MetricValue
higher -X- _ O
on -X- _ O
Dist-2 -X- _ B-MetricName
and -X- _ O
0.80 -X- _ B-MetricValue
% -X- _ I-MetricValue
to -X- _ O
2.76 -X- _ O
% -X- _ O
higher -X- _ O
on -X- _ O
average -X- _ B-MetricName
embedding -X- _ I-MetricName
. -X- _ O
We -X- _ O
can -X- _ O
observe -X- _ O
similar -X- _ O
results -X- _ O
on -X- _ O
DSTC7 -X- _ B-DatasetName
- -X- _ I-DatasetName
AVSD -X- _ I-DatasetName
. -X- _ O
PVHD -X- _ B-MethodName
enjoys -X- _ O
the -X- _ O
advantage -X- _ O
of -X- _ O
1.3 -X- _ B-MetricValue
% -X- _ I-MetricValue
to -X- _ O
18.22 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
PPL -X- _ B-MetricName
, -X- _ O
3.00 -X- _ B-MetricValue
% -X- _ I-MetricValue
to -X- _ O
3.40 -X- _ B-MetricValue
% -X- _ I-MetricValue
higher -X- _ O
on -X- _ O
BLEU-1 -X- _ B-MetricName
, -X- _ O
0.54 -X- _ B-MetricValue
% -X- _ I-MetricValue
to -X- _ O
1.19 -X- _ B-MetricValue
% -X- _ I-MetricValue
higher -X- _ O
on -X- _ O
Dist-1 -X- _ B-MetricName
, -X- _ O
1.31 -X- _ B-MetricValue
% -X- _ I-MetricValue
to -X- _ O
5.76 -X- _ B-MetricValue
% -X- _ I-MetricValue
higher -X- _ O
on -X- _ O
Dist-2 -X- _ B-MetricName
and -X- _ O
0.11 -X- _ B-MetricValue
% -X- _ I-MetricValue
to -X- _ O
2.22 -X- _ B-MetricValue
% -X- _ I-MetricValue
higher -X- _ O
on -X- _ O
average -X- _ B-MetricName
embedding -X- _ I-MetricName
compared -X- _ O
with -X- _ O
these -X- _ O
classic -X- _ O
variational -X- _ O
mechanism -X- _ O
models -X- _ O
. -X- _ O
The -X- _ O
main -X- _ O
reason -X- _ O
for -X- _ O
the -X- _ O
unimpressive -X- _ O
performance -X- _ O
of -X- _ O
RNN -X- _ B-MethodName
- -X- _ O
based -X- _ O
baselines -X- _ O
is -X- _ O
that -X- _ O
these -X- _ O
models -X- _ O
suffer -X- _ O
from -X- _ O
latent -X- _ O
variables -X- _ O
vanishing -X- _ O
observed -X- _ O
in -X- _ O
experiments -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
4 -X- _ O
, -X- _ O
the -X- _ O
Kullback -X- _ O
- -X- _ O
Leibler -X- _ O
term -X- _ O
of -X- _ O
these -X- _ O
models -X- _ O
losses -X- _ O
close -X- _ O
to -X- _ O
zero -X- _ O
means -X- _ O
that -X- _ O
variational -X- _ O
posterior -X- _ O
distribution -X- _ O
closely -X- _ O
matches -X- _ O
the -X- _ O
prior -X- _ O
for -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
latent -X- _ O
variables -X- _ O
, -X- _ O
indicating -X- _ O
that -X- _ O
failure -X- _ O
of -X- _ O
the -X- _ O
variational -X- _ O
mechanism -X- _ O
( -X- _ O
Lucas -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
performance -X- _ O
of -X- _ O
SepaCVAE -X- _ B-MethodName
is -X- _ O
unimpressive -X- _ O
. -X- _ O
In -X- _ O
fact -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
SepaCVAE -X- _ B-MethodName
depends -X- _ O
on -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
context -X- _ O
grouping -X- _ O
( -X- _ O
referring -X- _ O
to -X- _ O
dialogue -X- _ O
augmentation -X- _ O
in -X- _ O
original -X- _ O
paper -X- _ O
( -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
) -X- _ O
. -X- _ O
Sepa -X- _ B-MethodName
- -X- _ I-MethodName
CVAE -X- _ I-MethodName
will -X- _ O
degenerate -X- _ O
to -X- _ O
CVAE -X- _ B-MethodName
model -X- _ O
if -X- _ O
context -X- _ O
grouping -X- _ O
fails -X- _ O
to -X- _ O
work -X- _ O
well -X- _ O
, -X- _ O
and -X- _ O
even -X- _ O
which -X- _ O
will -X- _ O
introduce -X- _ O
wrong -X- _ O
grouping -X- _ O
noise -X- _ O
information -X- _ O
result -X- _ O
- -X- _ O
ing -X- _ O
in -X- _ O
degrade -X- _ O
performance -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
4 -X- _ O
, -X- _ O
the -X- _ O
Kullback -X- _ O
- -X- _ O
Leibler -X- _ O
term -X- _ O
of -X- _ O
SepaCVAE -X- _ B-MethodName
losses -X- _ O
is -X- _ O
at -X- _ O
a -X- _ O
high -X- _ O
level -X- _ O
, -X- _ O
which -X- _ O
demonstrates -X- _ O
that -X- _ O
the -X- _ O
prior -X- _ O
for -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
latent -X- _ O
variables -X- _ O
can -X- _ O
not -X- _ O
approximate -X- _ O
variational -X- _ O
posterior -X- _ O
distribution -X- _ O
. -X- _ O

Compared -X- _ O
with -X- _ O
Transformer -X- _ B-MethodName
- -X- _ O
based -X- _ O
baselines -X- _ O
, -X- _ O
PVHD -X- _ B-MethodName
still -X- _ O
enjoys -X- _ O
an -X- _ O
advantage -X- _ O
on -X- _ O
most -X- _ O
metrics -X- _ O
, -X- _ O
especially -X- _ O
the -X- _ O
distinct -X- _ B-MetricName
metric -X- _ O
. -X- _ O
GVT -X- _ B-MethodName
introduces -X- _ O
latent -X- _ O
variables -X- _ O
between -X- _ O
the -X- _ O
whole -X- _ O
dialogue -X- _ O
history -X- _ O
and -X- _ O
response -X- _ O
, -X- _ O
which -X- _ O
faces -X- _ O
the -X- _ O
problem -X- _ O
of -X- _ O
latent -X- _ O
variables -X- _ O
vanishing -X- _ O
. -X- _ O
SVT -X- _ B-MethodName
introduces -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
latent -X- _ O
variables -X- _ O
into -X- _ O
the -X- _ O
decoder -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
diversity -X- _ O
of -X- _ O
responses -X- _ O
. -X- _ O
But -X- _ O
it -X- _ O
is -X- _ O
debatable -X- _ O
whether -X- _ O
latent -X- _ O
variables -X- _ O
will -X- _ O
destroy -X- _ O
the -X- _ O
fragile -X- _ O
sequence -X- _ O
perception -X- _ O
ability -X- _ O
of -X- _ O
the -X- _ O
transformer -X- _ O
, -X- _ O
which -X- _ O
will -X- _ O
greatly -X- _ O
reduce -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
the -X- _ O
responses -X- _ O
. -X- _ O
Training -X- _ O
the -X- _ O
transformer -X- _ B-MethodName
from -X- _ O
scratch -X- _ O
instead -X- _ O
of -X- _ O
using -X- _ O
a -X- _ O
pretrained -X- _ O
model -X- _ O
is -X- _ O
another -X- _ O
reason -X- _ O
for -X- _ O
the -X- _ O
inferior -X- _ O
performance -X- _ O
of -X- _ O
SVT -X- _ B-MethodName
and -X- _ O
GVT -X- _ B-MethodName
. -X- _ O
Compared -X- _ O
to -X- _ O
DialogVED -X- _ B-MethodName
and -X- _ O
PLATO -X- _ B-MethodName
, -X- _ O
PVHD -X- _ B-MethodName
achieves -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
on -X- _ O
most -X- _ O
metrics -X- _ O
. -X- _ O
The -X- _ O
main -X- _ O
reason -X- _ O
is -X- _ O
that -X- _ O
pseudo -X- _ O
- -X- _ O
variational -X- _ O
approaches -X- _ O
do -X- _ O
not -X- _ O
depend -X- _ O
on -X- _ O
posteriors -X- _ O
distribution -X- _ O
avoiding -X- _ O
optimization -X- _ O
problems -X- _ O
and -X- _ O
the -X- _ O
recurrent -X- _ O
summarizing -X- _ O
variable -X- _ O
can -X- _ O
model -X- _ O
the -X- _ O
diversity -X- _ O
of -X- _ O
sequences -X- _ O
. -X- _ O
Overall -X- _ O
, -X- _ O
PVHD -X- _ B-MethodName
has -X- _ O
the -X- _ O
most -X- _ O
obvious -X- _ O
advantages -X- _ O
in -X- _ O
diversity -X- _ O
, -X- _ O
which -X- _ O
demonstrates -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
recurrent -X- _ O
summarizing -X- _ O
variable -X- _ O
. -X- _ O
Another -X- _ O
reason -X- _ O
is -X- _ O
that -X- _ O
Transformer -X- _ B-MethodName
- -X- _ O
based -X- _ O
baselines -X- _ O
including -X- _ O
SVT -X- _ B-MethodName
, -X- _ O
GVT -X- _ B-MethodName
, -X- _ O
PLATO -X- _ B-MethodName
and -X- _ O
DialogVED -X- _ B-MethodName
connect -X- _ O
all -X- _ O
the -X- _ O
dialogue -X- _ O
history -X- _ O
utterances -X- _ O
into -X- _ O
a -X- _ O
consecutive -X- _ O
sequence -X- _ O
. -X- _ O
They -X- _ O
can -X- _ O
only -X- _ O
model -X- _ O
the -X- _ O
diversity -X- _ O
between -X- _ O
entire -X- _ O
dialogue -X- _ O
histories -X- _ O
and -X- _ O
responses -X- _ O
. -X- _ O
Coarse -X- _ O
- -X- _ O
grained -X- _ O
modeling -X- _ O
is -X- _ O
the -X- _ O
reason -X- _ O
for -X- _ O
poor -X- _ O
model -X- _ O
performance -X- _ O
. -X- _ O

Although -X- _ O
transformers -X- _ B-MethodName
are -X- _ O
popular -X- _ O
for -X- _ O
generation -X- _ O
task -X- _ O
, -X- _ O
our -X- _ O
research -X- _ O
is -X- _ O
still -X- _ O
meritorious -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
transformer -X- _ B-MethodName
models -X- _ O
usually -X- _ O
require -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
on -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
corpus -X- _ O
while -X- _ O
RNN -X- _ B-MethodName
- -X- _ O
based -X- _ O
models -X- _ O
usually -X- _ O
do -X- _ O
not -X- _ O
have -X- _ O
such -X- _ O
limitations -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
debatable -X- _ O
whether -X- _ O
transformer -X- _ B-MethodName
models -X- _ O
training -X- _ O
from -X- _ O
scratch -X- _ O
under -X- _ O
conditions -X- _ O
where -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
language -X- _ O
models -X- _ O
are -X- _ O
unavaliable -X- _ O
can -X- _ O
achieve -X- _ O
the -X- _ O
desired -X- _ O
performance -X- _ O
if -X- _ O
downstream -X- _ O
task -X- _ O
does -X- _ O
not -X- _ O
have -X- _ O
enough -X- _ O
corpus -X- _ O
. -X- _ O
Second -X- _ O
, -X- _ O
the -X- _ O
parameter -X- _ O
amount -X- _ O
of -X- _ O
the -X- _ O
RNNbased -X- _ B-MethodName
model -X- _ O
is -X- _ O
usually -X- _ O
smaller -X- _ O
than -X- _ O
that -X- _ O
of -X- _ O
the -X- _ O
transformer -X- _ O
- -X- _ O
based -X- _ O
model -X- _ O
. -X- _ O
The -X- _ O
parameter -X- _ O
sizes -X- _ O
of -X- _ O
PVHD -X- _ B-MethodName
on -X- _ O
the -X- _ O
DailyDialog -X- _ B-DatasetName
and -X- _ O
DSTC7 -X- _ B-DatasetName
- -X- _ I-DatasetName
AVSD -X- _ I-DatasetName
are -X- _ O
29 -X- _ O
M -X- _ O
and -X- _ O
21 -X- _ O
M -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
The -X- _ O
number -X- _ O
of -X- _ O
parameters -X- _ O
for -X- _ O
PLATO -X- _ B-MethodName
and -X- _ O
DialogVED -X- _ B-MethodName
is -X- _ O
132 -X- _ O
M -X- _ O
and -X- _ O
1143 -X- _ O
M -X- _ O
on -X- _ O
two -X- _ O
datasets -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
Compared -X- _ O
to -X- _ O
PLATO -X- _ B-MethodName
and -X- _ O
DialogVED -X- _ B-MethodName
, -X- _ O
the -X- _ O
average -X- _ O
number -X- _ O
of -X- _ O
parameters -X- _ O
of -X- _ O
PVHD -X- _ B-MethodName
is -X- _ O
5.28x -X- _ O
and -X- _ O
45.72x -X- _ O
smaller -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O

Human -X- _ B-MetricName
Evaluation -X- _ I-MetricName
Results -X- _ O
& -X- _ O
Analysis -X- _ O

We -X- _ O
conduct -X- _ O
human -X- _ B-MetricName
evaluation -X- _ I-MetricName
to -X- _ O
further -X- _ O
confirm -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
PVHD -X- _ B-MethodName
. -X- _ O
To -X- _ O
evaluate -X- _ O
the -X- _ O
consistency -X- _ O
of -X- _ O
the -X- _ O
results -X- _ O
assessed -X- _ O
by -X- _ O
annotators -X- _ O
, -X- _ O
we -X- _ O
employ -X- _ O
Pearson -X- _ B-MetricName
's -X- _ I-MetricName
correlation -X- _ I-MetricName
coefficient -X- _ I-MetricName
( -X- _ O
Sedgwick -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
coefficient -X- _ O
is -X- _ O
0.35 -X- _ B-MetricValue
on -X- _ O
diversity -X- _ B-MetricName
, -X- _ O
0.65 -X- _ B-MetricValue
on -X- _ O
relevance -X- _ B-MetricName
, -X- _ O
and -X- _ O
0.75 -X- _ B-MetricValue
on -X- _ O
fluency -X- _ B-MetricName
, -X- _ O
with -X- _ O
p -X- _ O
< -X- _ O
0.0001 -X- _ O
and -X- _ O
below -X- _ O
0.001 -X- _ O
, -X- _ O
which -X- _ O
demonstrates -X- _ O
high -X- _ O
correlation -X- _ O
and -X- _ O
agreement -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
human -X- _ B-MetricName
evaluation -X- _ I-MetricName
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
. -X- _ O
Compared -X- _ O
to -X- _ O
RNN -X- _ B-MethodName
- -X- _ O
based -X- _ O
baselines -X- _ O
, -X- _ O
PVHD -X- _ B-MethodName
has -X- _ O
a -X- _ O
significant -X- _ O
advantage -X- _ O
in -X- _ O
relevance -X- _ B-MetricName
and -X- _ O
diversity -X- _ B-MetricName
. -X- _ O
Specifically -X- _ O
, -X- _ O
PVHD -X- _ B-MethodName
enjoys -X- _ O
the -X- _ O
advantage -X- _ O
of -X- _ O
11.40 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
diversity -X- _ B-MetricName
and -X- _ O
16.00 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
relevance -X- _ B-MetricName
compared -X- _ O
to -X- _ O
SepaCVAE -X- _ B-MethodName
on -X- _ O
DailyDialog -X- _ B-DatasetName
. -X- _ O
On -X- _ O
DSTC7 -X- _ B-DatasetName
- -X- _ I-DatasetName
AVSD -X- _ I-DatasetName
, -X- _ O
PVHD -X- _ B-MethodName
has -X- _ O
a -X- _ O
advantage -X- _ O
of -X- _ O
10.50 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
diversity -X- _ B-MetricName
and -X- _ O
73.00 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
relevance -X- _ B-MetricName
compared -X- _ O
to -X- _ O
SepaCVAE -X- _ B-MethodName
. -X- _ O
Compared -X- _ O
to -X- _ O
transformer -X- _ B-MethodName
- -X- _ O
based -X- _ O
baselines -X- _ O
, -X- _ O
although -X- _ O
PVHD -X- _ B-MethodName
is -X- _ O
sub -X- _ O
- -X- _ O
optimal -X- _ O
in -X- _ O
some -X- _ O
metrics -X- _ O
, -X- _ O
it -X- _ O
enjoys -X- _ O
the -X- _ O
advantage -X- _ O
in -X- _ O
most -X- _ O
metrics -X- _ O
, -X- _ O
especially -X- _ O
diversity -X- _ B-MetricName
. -X- _ O
In -X- _ O
terms -X- _ O
of -X- _ O
fluency -X- _ B-MetricName
, -X- _ O
PVHD -X- _ B-MethodName
is -X- _ O
only -X- _ O
1.00 -X- _ B-MetricValue
% -X- _ I-MetricValue
lower -X- _ O
than -X- _ O
HVRNN -X- _ B-MethodName
and -X- _ O
is -X- _ O
much -X- _ O
better -X- _ O
that -X- _ O
other -X- _ O
baselines -X- _ O
on -X- _ O
DailyDialog -X- _ B-DatasetName
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
fluency -X- _ B-MetricName
of -X- _ O
PVHD -X- _ B-MethodName
is -X- _ O
26.50 -X- _ B-MetricValue
% -X- _ I-MetricValue
lower -X- _ O
compared -X- _ O
with -X- _ O
HVRNN -X- _ B-MethodName
and -X- _ O
8.00 -X- _ B-MetricValue
% -X- _ I-MetricValue
lower -X- _ O
compared -X- _ O
with -X- _ O
VHCR -X- _ B-MethodName
on -X- _ O
DSTC7 -X- _ B-DatasetName
- -X- _ I-DatasetName
AVSD -X- _ I-DatasetName
. -X- _ O
We -X- _ O
argue -X- _ O
that -X- _ O
introducing -X- _ O
a -X- _ O
recurrent -X- _ O
summary -X- _ O
variable -X- _ O
in -X- _ O
the -X- _ O
decoder -X- _ O
increases -X- _ O
the -X- _ O
randomness -X- _ O
of -X- _ O
word -X- _ O
generation -X- _ O
, -X- _ O
which -X- _ O
will -X- _ O
promote -X- _ O
the -X- _ O
diversity -X- _ B-MetricName
of -X- _ O
the -X- _ O
responses -X- _ O
with -X- _ O
a -X- _ O
side -X- _ O
effect -X- _ O
of -X- _ O
fluency -X- _ B-MetricName
reduction -X- _ O
. -X- _ O

Effectiveness -X- _ O
of -X- _ O
Summarizing -X- _ O
Variables -X- _ O

We -X- _ O
further -X- _ O
analyze -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
PVHD -X- _ B-MethodName
on -X- _ O
summarizing -X- _ O
variables -X- _ O
. -X- _ O
Figure -X- _ O
5 -X- _ O
demonstrates -X- _ O
the -X- _ O
visualization -X- _ O
of -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
and -X- _ O
utterance -X- _ O
- -X- _ O
level -X- _ O
summarizing -X- _ O
variables -X- _ O
on -X- _ O
test -X- _ O
set -X- _ O
of -X- _ O
DailyDialog -X- _ B-DatasetName
and -X- _ O
DSTC7 -X- _ B-DatasetName
- -X- _ I-DatasetName
AVSD -X- _ I-DatasetName
datasets -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
observe -X- _ O
that -X- _ O
both -X- _ O
datasets -X- _ O
exhibit -X- _ O
high -X- _ O
variability -X- _ O
characteristic -X- _ O
on -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
and -X- _ O
utterance -X- _ O
- -X- _ O
level -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
the -X- _ O
summarizing -X- _ O
variables -X- _ O
on -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
show -X- _ O
obvious -X- _ O
categorical -X- _ O
features -X- _ O
, -X- _ O
which -X- _ O
indicates -X- _ O
that -X- _ O
a -X- _ O
subsequence -X- _ O
may -X- _ O
have -X- _ O
multiple -X- _ O
suitable -X- _ O
candidate -X- _ O
words -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
the -X- _ O
summarizing -X- _ O
variables -X- _ O
on -X- _ O
utterancelevel -X- _ O
also -X- _ O
exhibit -X- _ O
impressive -X- _ O
categorical -X- _ O
features -X- _ O
, -X- _ O
which -X- _ O
confirms -X- _ O
that -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
one -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
many -X- _ O
issue -X- _ O
in -X- _ O
the -X- _ O
dialogue -X- _ O
. -X- _ O
These -X- _ O
phenomena -X- _ O
make -X- _ O
dialogue -X- _ O
generation -X- _ O
different -X- _ O
from -X- _ O
machine -X- _ O
translation -X- _ O
where -X- _ O
unique -X- _ O
semantic -X- _ O
mapping -X- _ O
exists -X- _ O
between -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
language -X- _ O
. -X- _ O

Conclusion -X- _ O

We -X- _ O
analyze -X- _ O
the -X- _ O
reasons -X- _ O
for -X- _ O
one -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
many -X- _ O
and -X- _ O
manyto -X- _ O
- -X- _ O
one -X- _ O
issues -X- _ O
from -X- _ O
high -X- _ O
variability -X- _ O
of -X- _ O
dialogue -X- _ O
. -X- _ O
We -X- _ O
build -X- _ O
PVHD -X- _ B-MethodName
based -X- _ O
on -X- _ O
proposed -X- _ O
PVGRU -X- _ B-MethodName
component -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
and -X- _ O
utterance -X- _ O
- -X- _ O
level -X- _ O
variation -X- _ O
in -X- _ O
dialogue -X- _ O
for -X- _ O
generating -X- _ O
relevant -X- _ O
and -X- _ O
diverse -X- _ O
responses -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
demonstrate -X- _ O
that -X- _ O
PVHD -X- _ B-MethodName
even -X- _ O
outperforms -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
on -X- _ O
diversity -X- _ O
metrics -X- _ O
. -X- _ O

Limitations -X- _ O

Although -X- _ O
our -X- _ O
work -X- _ O
can -X- _ O
effectively -X- _ O
model -X- _ O
the -X- _ O
variability -X- _ O
issue -X- _ O
in -X- _ O
dialogue -X- _ O
, -X- _ O
we -X- _ O
acknowledge -X- _ O
some -X- _ O
limitations -X- _ O
of -X- _ O
our -X- _ O
study -X- _ O
. -X- _ O
Firstly -X- _ O
, -X- _ O
our -X- _ O
study -X- _ O
can -X- _ O
work -X- _ O
well -X- _ O
on -X- _ O
the -X- _ O
approaches -X- _ O
based -X- _ O
on -X- _ O
RNN -X- _ B-MethodName
, -X- _ O
but -X- _ O
can -X- _ O
not -X- _ O
be -X- _ O
employed -X- _ O
to -X- _ O
sequence -X- _ O
models -X- _ O
based -X- _ O
on -X- _ O
Transformer -X- _ B-MethodName
, -X- _ O
which -X- _ O
limits -X- _ O
the -X- _ O
generality -X- _ O
of -X- _ O
our -X- _ O
approach -X- _ O
. -X- _ O
The -X- _ O
reasons -X- _ O
we -X- _ O
analyze -X- _ O
are -X- _ O
as -X- _ O
follows -X- _ O
. -X- _ O

Transformer -X- _ B-MethodName
is -X- _ O
not -X- _ O
a -X- _ O
good -X- _ O
architecture -X- _ O
for -X- _ O
finegrained -X- _ O
diversity -X- _ B-MetricName
. -X- _ O
The -X- _ O
diversity -X- _ B-MetricName
of -X- _ O
dialogue -X- _ O
includes -X- _ O
three -X- _ O
granularities -X- _ O
of -X- _ O
discourse -X- _ O
level -X- _ O
, -X- _ O
utterance -X- _ O
level -X- _ O
and -X- _ O
word -X- _ O
level -X- _ O
. -X- _ O
To -X- _ O
model -X- _ O
diversity -X- _ B-MetricName
, -X- _ O
models -X- _ O
will -X- _ O
be -X- _ O
required -X- _ O
to -X- _ O
utilize -X- _ O
the -X- _ O
representation -X- _ O
at -X- _ O
time -X- _ O
t -X- _ O
and -X- _ O
the -X- _ O
relationship -X- _ O
between -X- _ O
the -X- _ O
representation -X- _ O
at -X- _ O
time -X- _ O
t -X- _ O
and -X- _ O
time -X- _ O
t+1 -X- _ O
to -X- _ O
determine -X- _ O
the -X- _ O
representation -X- _ O
at -X- _ O
time -X- _ O
t+1 -X- _ O
. -X- _ O
Relationships -X- _ O
are -X- _ O
computed -X- _ O
step -X- _ O
by -X- _ O
step -X- _ O
. -X- _ O
If -X- _ O
we -X- _ O
only -X- _ O
consider -X- _ O
discourse -X- _ O
- -X- _ O
level -X- _ O
diversity -X- _ B-MetricName
, -X- _ O
our -X- _ O
approach -X- _ O
and -X- _ O
variational -X- _ O
mechanisms -X- _ O
are -X- _ O
easily -X- _ O
transferable -X- _ O
to -X- _ O
Transformer -X- _ B-MethodName
architectures -X- _ O
. -X- _ O
Because -X- _ O
we -X- _ O
can -X- _ O
use -X- _ O
the -X- _ O
Transformer -X- _ B-MethodName
model -X- _ O
to -X- _ O
encode -X- _ O
the -X- _ O
entire -X- _ O
historical -X- _ O
dialogue -X- _ O
sequence -X- _ O
. -X- _ O
Latent -X- _ O
variables -X- _ O
or -X- _ O
summarizing -X- _ O
variables -X- _ O
only -X- _ O
exist -X- _ O
between -X- _ O
the -X- _ O
entire -X- _ O
historical -X- _ O
sequence -X- _ O
and -X- _ O
the -X- _ O
responses -X- _ O
. -X- _ O
This -X- _ O
will -X- _ O
not -X- _ O
destroy -X- _ O
the -X- _ O
parallel -X- _ O
structure -X- _ O
of -X- _ O
the -X- _ O
Transformer -X- _ O
. -X- _ O
if -X- _ O
we -X- _ O
employ -X- _ O
a -X- _ O
Transformer -X- _ B-MethodName
to -X- _ O
model -X- _ O
diversity -X- _ B-MetricName
at -X- _ O
the -X- _ O
utterance -X- _ O
and -X- _ O
word -X- _ O
granularity -X- _ O
, -X- _ O
this -X- _ O
will -X- _ O
seriously -X- _ O
damage -X- _ O
the -X- _ O
parallelism -X- _ O
of -X- _ O
the -X- _ O
Transformer -X- _ B-MethodName
. -X- _ O

There -X- _ O
are -X- _ O
great -X- _ O
limitations -X- _ O
in -X- _ O
the -X- _ O
variational -X- _ O
transformer -X- _ B-MethodName
models -X- _ O
. -X- _ O
The -X- _ O
transformer -X- _ B-MethodName
and -X- _ O
variational -X- _ O
thinking -X- _ O
is -X- _ O
not -X- _ O
a -X- _ O
good -X- _ O
match -X- _ O
, -X- _ O
which -X- _ O
leads -X- _ O
to -X- _ O
less -X- _ O
relevant -X- _ O
research -X- _ O
. -X- _ O
The -X- _ O
Transformer -X- _ B-MethodName
baselines -X- _ O
we -X- _ O
compared -X- _ O
in -X- _ O
the -X- _ O
manuscript -X- _ O
( -X- _ O
i.e. -X- _ O
SVT -X- _ B-MethodName
, -X- _ O
GVT -X- _ B-MethodName
, -X- _ O
PLATO -X- _ B-MethodName
and -X- _ O
DialogVED -X- _ B-MethodName
) -X- _ O
cover -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
current -X- _ O
transformer -X- _ B-MethodName
models -X- _ O
that -X- _ O
combine -X- _ O
variations -X- _ O
. -X- _ O
Although -X- _ O
SVT -X- _ B-MethodName
, -X- _ O
GVT -X- _ B-MethodName
, -X- _ O
PLATO -X- _ B-MethodName
and -X- _ O
DialogVED -X- _ B-MethodName
incorporate -X- _ O
variational -X- _ O
ideas -X- _ O
, -X- _ O
these -X- _ O
models -X- _ O
connect -X- _ O
all -X- _ O
the -X- _ O
dialogue -X- _ O
history -X- _ O
utterances -X- _ O
into -X- _ O
a -X- _ O
consecutive -X- _ O
sequence -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
inadvisable -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
finegrained -X- _ O
diversity -X- _ B-MetricName
relationship -X- _ O
in -X- _ O
a -X- _ O
parallel -X- _ O
structure -X- _ O
. -X- _ O

Secondly -X- _ O
, -X- _ O
although -X- _ O
our -X- _ O
methods -X- _ O
can -X- _ O
improve -X- _ O
the -X- _ O
diversity -X- _ B-MetricName
and -X- _ O
relevence -X- _ O
of -X- _ O
responses -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
still -X- _ O
gaps -X- _ O
in -X- _ O
fluency -X- _ B-MetricName
compared -X- _ O
with -X- _ O
other -X- _ O
baselines -X- _ O
. -X- _ O
Gold -X- _ O
: -X- _ O
honey -X- _ O
, -X- _ O
cross -X- _ O
my -X- _ O
heart -X- _ O
, -X- _ O
i'v -X- _ O
never -X- _ O
looked -X- _ O
at -X- _ O
another -X- _ O
woman -X- _ O
since -X- _ O
the -X- _ O
first -X- _ O
day -X- _ O
i -X- _ O
set -X- _ O
my -X- _ O
eyes -X- _ O
on -X- _ O
you -X- _ O
! -X- _ O
believe -X- _ O
me -X- _ O
, -X- _ O
that -X- _ O
's -X- _ O
the -X- _ O
truth -X- _ O
. -X- _ O
SVT -X- _ B-MethodName
: -X- _ O
Honey -X- _ O
, -X- _ O
cross -X- _ O
my -X- _ O
heart -X- _ O
, -X- _ O
I'v -X- _ O
never -X- _ O
looked -X- _ O
at -X- _ O
another -X- _ O
woman -X- _ O
since -X- _ O
the -X- _ O
truth -X- _ O
. -X- _ O
GVT -X- _ B-MethodName
: -X- _ O
I'v -X- _ O
never -X- _ O
looked -X- _ O
at -X- _ O
another -X- _ O
woman -X- _ O
since -X- _ O
the -X- _ O
first -X- _ O
day -X- _ O
UNK -X- _ O
. -X- _ O
SepaCVAE -X- _ B-MethodName
: -X- _ O
i -X- _ O
know -X- _ O
how -X- _ O
you -X- _ O
really -X- _ O
well -X- _ O
. -X- _ O
DialogVED -X- _ B-MethodName
: -X- _ O
i -X- _ O
'm -X- _ O
sorry -X- _ O
, -X- _ O
but -X- _ O
i -X- _ O
ca -X- _ O
n't -X- _ O
let -X- _ O
you -X- _ O
do -X- _ O
that -X- _ O
. -X- _ O
PVHD -X- _ B-MethodName
: -X- _ O
actually -X- _ O
, -X- _ O
i'v -X- _ O
not -X- _ O
looked -X- _ O
at -X- _ O
another -X- _ O
woman -X- _ O
at -X- _ O
all -X- _ O
because -X- _ O
the -X- _ O
first -X- _ O
day -X- _ O
i -X- _ O
set -X- _ O
my -X- _ O
eyes -X- _ O
on -X- _ O
you -X- _ O
! -X- _ O
believe -X- _ O
me -X- _ O
. -X- _ O

Context -X- _ O
: -X- _ O
he -X- _ O
turns -X- _ O
his -X- _ O
cellphone -X- _ O
light -X- _ O
on -X- _ O
to -X- _ O
help -X- _ O
him -X- _ O
see -X- _ O
to -X- _ O
screw -X- _ O
the -X- _ O
knob -X- _ O
back -X- _ O
into -X- _ O
the -X- _ O
dresser -X- _ O
drawer -X- _ O
. -X- _ O

does -X- _ O
he -X- _ O
end -X- _ O
up -X- _ O
fixing -X- _ O
it -X- _ O
correctly -X- _ O
? -X- _ O
yes -X- _ O
, -X- _ O
he -X- _ O
screws -X- _ O
the -X- _ O
knob -X- _ O
back -X- _ O
on -X- _ O
correctly -X- _ O
. -X- _ O
does -X- _ O
he -X- _ O
take -X- _ O
anything -X- _ O
our -X- _ O
of -X- _ O
the -X- _ O
drawer -X- _ O
? -X- _ O
no -X- _ O
he -X- _ O
does -X- _ O
not -X- _ O
open -X- _ O
the -X- _ O
drawer -X- _ O
, -X- _ O
only -X- _ O
fixes -X- _ O
it -X- _ O
. -X- _ O
Gold -X- _ O
: -X- _ O
he -X- _ O
interacts -X- _ O
with -X- _ O
the -X- _ O
computers -X- _ O
after -X- _ O
fixing -X- _ O
the -X- _ O
knob -X- _ O
he -X- _ O
simply -X- _ O
stands -X- _ O
up -X- _ O
and -X- _ O
begins -X- _ O
to -X- _ O
leave -X- _ O
the -X- _ O
room -X- _ O
. -X- _ O
SVT -X- _ B-MethodName
: -X- _ O
he -X- _ O
appears -X- _ O
to -X- _ O
be -X- _ O
carrying -X- _ O
something -X- _ O
. -X- _ O
GVT -X- _ B-MethodName
: -X- _ O
no -X- _ O
, -X- _ O
he -X- _ O
does -X- _ O
not -X- _ O
go -X- _ O
to -X- _ O
the -X- _ O
computer -X- _ O
. -X- _ O
SepaCVAE -X- _ B-MethodName
: -X- _ O
no -X- _ O
, -X- _ O
he -X- _ O
does -X- _ O
not -X- _ O
move -X- _ O
from -X- _ O
his -X- _ O
computer -X- _ O
. -X- _ O
DialogVED -X- _ B-MethodName
: -X- _ O
no -X- _ O
, -X- _ O
he -X- _ O
does -X- _ O
not -X- _ O
touch -X- _ O
the -X- _ O
computer -X- _ O
. -X- _ O
PVHD -X- _ B-MethodName
: -X- _ O
no -X- _ O
, -X- _ O
he -X- _ O
does -X- _ O
not -X- _ O
interact -X- _ O
with -X- _ O
the -X- _ O
computer -X- _ O
at -X- _ O
all -X- _ O
. -X- _ O

A.2 -X- _ O
Implementation -X- _ O
Details -X- _ O

We -X- _ O
implement -X- _ O
our -X- _ O
model -X- _ O
and -X- _ O
baselines -X- _ O
using -X- _ O
Tensorflow -X- _ O
2 -X- _ O
and -X- _ O
train -X- _ O
baselines -X- _ O
on -X- _ O
a -X- _ O
server -X- _ O
with -X- _ O
RTX -X- _ O
8000 -X- _ O
GPU -X- _ O
( -X- _ O
48 -X- _ O
G -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
dimension -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
word -X- _ I-HyperparameterName
embeddings -X- _ I-HyperparameterName
is -X- _ O
set -X- _ O
512 -X- _ B-HyperparameterValue
. -X- _ O
We -X- _ O
consider -X- _ O
at -X- _ O
most -X- _ O
10 -X- _ O
turns -X- _ O
of -X- _ O
dialogue -X- _ O
context -X- _ O
and -X- _ O
50 -X- _ O
words -X- _ O
for -X- _ O
each -X- _ O
utterance -X- _ O
. -X- _ O
The -X- _ O
encoder -X- _ O
adopts -X- _ O
bidirectional -X- _ O
structure -X- _ O
and -X- _ O
the -X- _ O
decoder -X- _ O
uses -X- _ O
unidirectional -X- _ O
structure -X- _ O
. -X- _ O

A.3 -X- _ O
Automatic -X- _ B-MetricName
Evaluation -X- _ I-MetricName
Metrics -X- _ O

We -X- _ O
employ -X- _ O
both -X- _ O
automatic -X- _ O
and -X- _ O
human -X- _ B-MetricName
evaluations -X- _ I-MetricName
to -X- _ O
assess -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
compared -X- _ O
methods -X- _ O
. -X- _ O
The -X- _ O
automatic -X- _ B-MetricName
evaluation -X- _ I-MetricName
mainly -X- _ O
includes -X- _ O
the -X- _ O
following -X- _ O
metrics -X- _ O
: -X- _ O
BLEU -X- _ B-MetricName
( -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
evaluates -X- _ O
the -X- _ O
n -X- _ O
- -X- _ O
gram -X- _ O
co -X- _ O
- -X- _ O
occurrence -X- _ O
between -X- _ O
generated -X- _ O
response -X- _ O
and -X- _ O
target -X- _ O
response -X- _ O
. -X- _ O
ROUGE -X- _ B-MetricName
- -X- _ I-MetricName
L -X- _ I-MetricName
( -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
evaluates -X- _ O
the -X- _ O
overlap -X- _ O
of -X- _ O
the -X- _ O
longest -X- _ O
common -X- _ O
subsequences -X- _ O
between -X- _ O
generated -X- _ O
response -X- _ O
and -X- _ O
the -X- _ O
target -X- _ O
response -X- _ O
. -X- _ O
Distinct-1 -X- _ B-MetricName
/ -X- _ I-MetricName
2 -X- _ I-MetricName
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
measures -X- _ O
the -X- _ O
generated -X- _ O
response -X- _ O
diversity -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
distinct -X- _ O
uni -X- _ O
- -X- _ O
grams -X- _ O
/ -X- _ O
bi -X- _ O
- -X- _ O
grams -X- _ O
divided -X- _ O
by -X- _ O
the -X- _ O
total -X- _ O
amount -X- _ O
of -X- _ O
generated -X- _ O
words -X- _ O
. -X- _ O
PPL -X- _ B-MetricName
( -X- _ O
Perplexity -X- _ O
) -X- _ O
evaluates -X- _ O
the -X- _ O
confidence -X- _ O
of -X- _ O
the -X- _ O
generated -X- _ O
response -X- _ O
. -X- _ O
The -X- _ O
lower -X- _ O
PPL -X- _ B-MetricName
score -X- _ O
, -X- _ O
the -X- _ O
higher -X- _ O
confidence -X- _ O
for -X- _ O
generating -X- _ O
responses -X- _ O
. -X- _ O
Embedding -X- _ B-MetricName
- -X- _ I-MetricName
based -X- _ I-MetricName
metrics -X- _ O
( -X- _ O
Average -X- _ O
, -X- _ O
Exterma -X- _ O
and -X- _ O
Greedy -X- _ O
) -X- _ O
measure -X- _ O
the -X- _ O
semantic -X- _ O
relevance -X- _ O
between -X- _ O
generated -X- _ O
response -X- _ O
and -X- _ O
target -X- _ O
response -X- _ O
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Sedoc -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Xu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018b -X- _ O
) -X- _ O
. -X- _ O

A.4 -X- _ O
Human -X- _ B-MetricName
Evaluation -X- _ I-MetricName

Following -X- _ O
the -X- _ O
work -X- _ O
of -X- _ O
( -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017a -X- _ O
; -X- _ O
Xu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018a -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
divide -X- _ O
six -X- _ O
crowdsourced -X- _ O
graduate -X- _ O
students -X- _ O
into -X- _ O
two -X- _ O
groups -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
generated -X- _ O
responses -X- _ O
for -X- _ O
100 -X- _ O
randomly -X- _ O
sampled -X- _ O
input -X- _ O
contexts -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
We -X- _ O
request -X- _ O
annotators -X- _ O
to -X- _ O
rank -X- _ O
the -X- _ O
generated -X- _ O
responses -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
three -X- _ O
aspects -X- _ O
: -X- _ O
fluency -X- _ B-MetricName
, -X- _ O
diversity -X- _ B-MetricName
, -X- _ O
and -X- _ O
relevance -X- _ B-MetricName
. -X- _ O
Fluency -X- _ B-MetricName
measures -X- _ O
whether -X- _ O
the -X- _ O
generated -X- _ O
responses -X- _ O
are -X- _ O
smooth -X- _ O
or -X- _ O
grammatically -X- _ O
correct -X- _ O
. -X- _ O
Diversity -X- _ B-MetricName
evaluates -X- _ O
whether -X- _ O
the -X- _ O
generated -X- _ O
responses -X- _ O
are -X- _ O
informative -X- _ O
, -X- _ O
rather -X- _ O
than -X- _ O
generic -X- _ O
and -X- _ O
repeated -X- _ O
information -X- _ O
. -X- _ O
Relevance -X- _ B-MetricName
evaluates -X- _ O
whether -X- _ O
the -X- _ O
generated -X- _ O
responses -X- _ O
are -X- _ O
relevant -X- _ O
to -X- _ O
the -X- _ O
dialogue -X- _ O
context -X- _ O
. -X- _ O
The -X- _ O
average -X- _ O
scores -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
groups -X- _ O
is -X- _ O
taken -X- _ O
as -X- _ O
the -X- _ O
final -X- _ O
score -X- _ O
. -X- _ O

A.5 -X- _ O
Ablation -X- _ O
Study -X- _ O

We -X- _ O
conduct -X- _ O
ablation -X- _ O
experiments -X- _ O
on -X- _ O
the -X- _ O
proposed -X- _ O
loss -X- _ O
modules -X- _ O
. -X- _ O
Table -X- _ O
4 -X- _ O
reports -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
ablation -X- _ O
experiments -X- _ O
of -X- _ O
PVHD -X- _ B-MethodName
on -X- _ O
DailyDialog -X- _ B-DatasetName
and -X- _ O
DSTC7 -X- _ B-DatasetName
- -X- _ I-DatasetName
AVSD -X- _ I-DatasetName
. -X- _ O
-RE -X- _ O
removes -X- _ O
the -X- _ O
reconstruction -X- _ O
loss -X- _ O
. -X- _ O
-CO -X- _ O
removes -X- _ O
the -X- _ O
consistency -X- _ O
loss -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
demonstrate -X- _ O
that -X- _ O
our -X- _ O
optimization -X- _ O
objectives -X- _ O
are -X- _ O
effective -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
reconstruction -X- _ O
loss -X- _ O
can -X- _ O
improve -X- _ O
the -X- _ O
BLEU-1 -X- _ B-MetricName
/ -X- _ I-MetricName
2 -X- _ I-MetricName
and -X- _ O
Rouge -X- _ B-MetricName
- -X- _ I-MetricName
L. -X- _ I-MetricName
The -X- _ O
consistency -X- _ O
loss -X- _ O
can -X- _ O
improve -X- _ O
Dist-1 -X- _ B-MetricName
/ -X- _ I-MetricName
2 -X- _ I-MetricName
metrics -X- _ O
at -X- _ O
the -X- _ O
the -X- _ O
expense -X- _ O
of -X- _ O
BLEU-1 -X- _ B-MetricName
/ -X- _ I-MetricName
2 -X- _ I-MetricName
and -X- _ O
Rouge -X- _ B-MetricName
- -X- _ I-MetricName
L -X- _ I-MetricName
metrics -X- _ O
. -X- _ O
We -X- _ O
believe -X- _ O
that -X- _ O
the -X- _ O
consistency -X- _ O
loss -X- _ O
can -X- _ O
ensure -X- _ O
the -X- _ O
consistency -X- _ O
between -X- _ O
the -X- _ O
incremental -X- _ O
information -X- _ O
and -X- _ O
the -X- _ O
input -X- _ O
at -X- _ O
each -X- _ O
time -X- _ O
step -X- _ O
. -X- _ O
There -X- _ O
may -X- _ O
be -X- _ O
multiple -X- _ O
candidate -X- _ O
tokens -X- _ O
following -X- _ O
the -X- _ O
same -X- _ O
distribution -X- _ O
, -X- _ O
which -X- _ O
increases -X- _ O
the -X- _ O
diversity -X- _ B-MetricName
of -X- _ O
generated -X- _ O
responses -X- _ O
. -X- _ O
The -X- _ O
reconstruction -X- _ O
loss -X- _ O
can -X- _ O
make -X- _ O
the -X- _ O
summarizing -X- _ O
variable -X- _ O
recording -X- _ O
the -X- _ O
accumulated -X- _ O
distribution -X- _ O
of -X- _ O
subsequence -X- _ O
reflect -X- _ O
the -X- _ O
semantic -X- _ O
information -X- _ O
of -X- _ O
dialogue -X- _ O
context -X- _ O
correctly -X- _ O
, -X- _ O
which -X- _ O
will -X- _ O
reduce -X- _ O
the -X- _ O
randomness -X- _ O
of -X- _ O
the -X- _ O
generation -X- _ O
process -X- _ O
by -X- _ O
limiting -X- _ O
candidates -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
conform -X- _ O
to -X- _ O
sequence -X- _ O
semantics -X- _ O
. -X- _ O

A.6 -X- _ O
Significance -X- _ O
Testing -X- _ O

To -X- _ O
evaluate -X- _ O
the -X- _ O
reliability -X- _ O
of -X- _ O
the -X- _ O
PVHD -X- _ B-MethodName
results -X- _ O
, -X- _ O
we -X- _ O
performe -X- _ O
multiple -X- _ O
significance -X- _ O
tests -X- _ O
. -X- _ O
Table -X- _ O
6 -X- _ O
( -X- _ O
in -X- _ O
Appendix -X- _ O
A -X- _ O
) -X- _ O
reports -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
significance -X- _ O
test -X- _ O
for -X- _ O
automatic -X- _ B-MetricName
evaluation -X- _ I-MetricName
. -X- _ O
We -X- _ O
can -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
p -X- _ O
- -X- _ O
values -X- _ O
of -X- _ O
PVHD -X- _ B-MethodName
are -X- _ O
less -X- _ O
than -X- _ O
0.05 -X- _ O
compared -X- _ O
with -X- _ O
other -X- _ O
models -X- _ O
. -X- _ O
Although -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
PVHD -X- _ B-MethodName
is -X- _ O
not -X- _ O
optimal -X- _ O
in -X- _ O
some -X- _ O
metrics -X- _ O
, -X- _ O
the -X- _ O
significance -X- _ O
test -X- _ O
demonstrates -X- _ O
that -X- _ O
results -X- _ O
of -X- _ O
PVHD -X- _ B-MethodName
are -X- _ O
statistically -X- _ O
significantly -X- _ O
different -X- _ O
from -X- _ O
other -X- _ O
models -X- _ O
. -X- _ O
In -X- _ O
other -X- _ O
words -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
advantage -X- _ O
of -X- _ O
PVHD -X- _ B-MethodName
is -X- _ O
statistically -X- _ O
reliable -X- _ O
and -X- _ O
not -X- _ O
an -X- _ O
accident -X- _ O
caused -X- _ O
by -X- _ O
random -X- _ O
factors -X- _ O
. -X- _ O

3307 -X- _ O

A.7 -X- _ O
Case -X- _ O
Study -X- _ O

To -X- _ O
further -X- _ O
dissect -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
PVHD -X- _ B-MethodName
, -X- _ O
several -X- _ O
examples -X- _ O
of -X- _ O
generated -X- _ O
responses -X- _ O
are -X- _ O
provided -X- _ O
in -X- _ O
Table -X- _ O
5 -X- _ O
. -X- _ O
Although -X- _ O
DialogVED -X- _ B-MethodName
, -X- _ O
SVT -X- _ B-MethodName
, -X- _ O
GVT -X- _ B-MethodName
can -X- _ O
generate -X- _ O
relevant -X- _ O
responses -X- _ O
, -X- _ O
PVHD -X- _ B-MethodName
can -X- _ O
produce -X- _ O
higher -X- _ O
quality -X- _ O
responses -X- _ O
in -X- _ O
comparison -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
for -X- _ O
the -X- _ O
first -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
responses -X- _ O
generated -X- _ O
by -X- _ O
other -X- _ O
models -X- _ O
are -X- _ O
contextual -X- _ O
except -X- _ O
for -X- _ O
Sepa -X- _ B-MethodName
- -X- _ I-MethodName
CVAE -X- _ I-MethodName
. -X- _ O
The -X- _ O
response -X- _ O
generated -X- _ O
by -X- _ O
DialogVED -X- _ B-MethodName
is -X- _ O
more -X- _ O
diffuse -X- _ O
than -X- _ O
gold -X- _ O
response -X- _ O
, -X- _ O
but -X- _ O
response -X- _ O
generated -X- _ O
by -X- _ O
PVHD -X- _ B-MethodName
is -X- _ O
more -X- _ O
informative -X- _ O
and -X- _ O
possesses -X- _ O
a -X- _ O
different -X- _ O
sentence -X- _ O
pattern -X- _ O
and -X- _ O
different -X- _ O
wording -X- _ O
than -X- _ O
gold -X- _ O
response -X- _ O
to -X- _ O
some -X- _ O
extent -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
observe -X- _ O
the -X- _ O
similar -X- _ O
case -X- _ O
for -X- _ O
the -X- _ O
second -X- _ O
example -X- _ O
. -X- _ O
We -X- _ O
believe -X- _ O
that -X- _ O
this -X- _ O
is -X- _ O
mainly -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
capture -X- _ O
of -X- _ O
variability -X- _ O
of -X- _ O
corpus -X- _ O
by -X- _ O
summarizing -X- _ O
variable -X- _ O
, -X- _ O
which -X- _ O
enables -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
identify -X- _ O
similar -X- _ O
sentence -X- _ O
patterns -X- _ O
and -X- _ O
words -X- _ O
, -X- _ O
and -X- _ O
generate -X- _ O
diverse -X- _ O
responses -X- _ O
. -X- _ O

Acknowledgement -X- _ O

We -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
thank -X- _ O
the -X- _ O
reviewers -X- _ O
for -X- _ O
their -X- _ O
constructive -X- _ O
comments -X- _ O
. -X- _ O
The -X- _ O
project -X- _ O
is -X- _ O
supported -X- _ O
by -X- _ O
the -X- _ O
National -X- _ O
Natural -X- _ O
Science -X- _ O
Foundation -X- _ O
of -X- _ O
China -X- _ O
( -X- _ O
62272092,62172086 -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
European -X- _ O
Research -X- _ O
Council -X- _ O
( -X- _ O
grant -X- _ O
# -X- _ O
740516 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
project -X- _ O
is -X- _ O
also -X- _ O
supported -X- _ O
by -X- _ O
the -X- _ O
Fundamental -X- _ O
Research -X- _ O
Funds -X- _ O
for -X- _ O
the -X- _ O
Central -X- _ O
Universities -X- _ O
of -X- _ O
China -X- _ O
under -X- _ O
Grant -X- _ O
No -X- _ O
. -X- _ O
N2116008 -X- _ O
and -X- _ O
China -X- _ O
Scholarship -X- _ O
Council -X- _ O
. -X- _ O

