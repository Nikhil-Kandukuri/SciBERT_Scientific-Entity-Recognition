-DOCSTART- -X- O
Seeking -X- _ O
Common -X- _ O
but -X- _ O
Distinguishing -X- _ O
Difference -X- _ O
, -X- _ O
A -X- _ O
Joint -X- _ O
Aspect -X- _ O
- -X- _ O
based -X- _ O
Sentiment -X- _ B-TaskName
Analysis -X- _ I-TaskName
Model -X- _ B-TaskName

Aspect -X- _ B-TaskName
- -X- _ I-TaskName
based -X- _ I-TaskName
sentiment -X- _ I-TaskName
analysis -X- _ I-TaskName
( -X- _ O
ABSA -X- _ B-TaskName
) -X- _ O
task -X- _ O
consists -X- _ O
of -X- _ O
three -X- _ O
typical -X- _ O
subtasks -X- _ O
: -X- _ O
aspect -X- _ O
term -X- _ O
extraction -X- _ O
, -X- _ O
opinion -X- _ O
term -X- _ O
extraction -X- _ O
, -X- _ O
and -X- _ O
sentiment -X- _ O
polarity -X- _ O
classification -X- _ O
. -X- _ O
These -X- _ O
three -X- _ O
subtasks -X- _ O
are -X- _ O
usually -X- _ O
performed -X- _ O
jointly -X- _ O
to -X- _ O
save -X- _ O
resources -X- _ O
and -X- _ O
reduce -X- _ O
the -X- _ O
error -X- _ O
propagation -X- _ O
in -X- _ O
the -X- _ O
pipeline -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
existing -X- _ O
joint -X- _ O
models -X- _ O
only -X- _ O
focus -X- _ O
on -X- _ O
the -X- _ O
benefits -X- _ O
of -X- _ O
encoder -X- _ O
sharing -X- _ O
between -X- _ O
subtasks -X- _ O
but -X- _ O
ignore -X- _ O
the -X- _ O
difference -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
joint -X- _ O
ABSA -X- _ B-TaskName
model -X- _ O
, -X- _ O
which -X- _ O
not -X- _ O
only -X- _ O
enjoys -X- _ O
the -X- _ O
benefits -X- _ O
of -X- _ O
encoder -X- _ O
sharing -X- _ O
but -X- _ O
also -X- _ O
focuses -X- _ O
on -X- _ O
the -X- _ O
difference -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O
In -X- _ O
detail -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
a -X- _ O
dual -X- _ O
- -X- _ O
encoder -X- _ O
design -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
a -X- _ O
pair -X- _ O
encoder -X- _ O
especially -X- _ O
focuses -X- _ O
on -X- _ O
candidate -X- _ O
aspect -X- _ O
- -X- _ O
opinion -X- _ O
pair -X- _ O
classification -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
original -X- _ O
encoder -X- _ O
keeps -X- _ O
attention -X- _ O
on -X- _ O
sequence -X- _ O
labeling -X- _ O
. -X- _ O
Empirical -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
proposed -X- _ O
model -X- _ O
shows -X- _ O
robustness -X- _ O
and -X- _ O
significantly -X- _ O
outperforms -X- _ O
the -X- _ O
previous -X- _ O
state -X- _ O
- -X- _ O
ofthe -X- _ O
- -X- _ O
art -X- _ O
on -X- _ O
four -X- _ O
benchmark -X- _ O
datasets -X- _ O
. -X- _ O

Introduction -X- _ O

Sentiment -X- _ B-TaskName
analysis -X- _ I-TaskName
is -X- _ O
a -X- _ O
task -X- _ O
that -X- _ O
aims -X- _ O
to -X- _ O
retrieve -X- _ O
the -X- _ O
sentiment -X- _ O
polarity -X- _ O
based -X- _ O
on -X- _ O
three -X- _ O
levels -X- _ O
of -X- _ O
granularities -X- _ O
: -X- _ O
document -X- _ O
level -X- _ O
, -X- _ O
sentence -X- _ O
level -X- _ O
, -X- _ O
and -X- _ O
entity -X- _ O
and -X- _ O
aspect -X- _ O
level -X- _ O
( -X- _ O
Liu -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
under -X- _ O
the -X- _ O
urgent -X- _ O
demands -X- _ O
of -X- _ O
several -X- _ O
society -X- _ O
scenarios -X- _ O
( -X- _ O
Preethi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Cobos -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Islam -X- _ O
and -X- _ O
Zibran -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Novielli -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
Recently -X- _ O
, -X- _ O
the -X- _ O
aspect -X- _ O
- -X- _ O
based -X- _ O
sentiment -X- _ B-TaskName
analysis -X- _ I-TaskName
( -X- _ O
ABSA -X- _ B-TaskName
) -X- _ O
task -X- _ O
( -X- _ O
Pontiki -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
, -X- _ O
focusing -X- _ O
on -X- _ O
excavating -X- _ O
the -X- _ O
specific -X- _ O
aspect -X- _ O
from -X- _ O
an -X- _ O
annotated -X- _ O
review -X- _ O
, -X- _ O
has -X- _ O
aroused -X- _ O
much -X- _ O
attention -X- _ O
from -X- _ O
researchers -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
this -X- _ O
paper -X- _ O
mainly -X- _ O
concerns -X- _ O
the -X- _ O
aspect -X- _ O
/ -X- _ O
opinion -X- _ O
term -X- _ O
extraction -X- _ O
and -X- _ O
sentiment -X- _ O
classification -X- _ O
task -X- _ O
. -X- _ O
The -X- _ O
latest -X- _ O
benchmark -X- _ O
proposed -X- _ O
by -X- _ O
Peng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
formulates -X- _ O
the -X- _ O
relevant -X- _ O
information -X- _ O
into -X- _ O
a -X- _ O
triplet -X- _ O
: -X- _ O
target -X- _ O
aspect -X- _ O
object -X- _ O
, -X- _ O
opinion -X- _ O
clue -X- _ O
, -X- _ O
and -X- _ O
sentiment -X- _ O
polarity -X- _ O

The -X- _ O
view -X- _ O
is -X- _ O
spectacular -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
food -X- _ O
is -X- _ O
great -X- _ O
. -X- _ O
orientation -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
the -X- _ O
concerned -X- _ O
aspect -X- _ O
term -X- _ O
extraction -X- _ O
becomes -X- _ O
a -X- _ O
task -X- _ O
of -X- _ O
Aspect -X- _ B-TaskName
Sentiment -X- _ I-TaskName
Triplet -X- _ I-TaskName
Extraction -X- _ I-TaskName
( -X- _ O
ASTE -X- _ B-TaskName
) -X- _ O
. -X- _ O
Similarly -X- _ O
, -X- _ O
the -X- _ O
relevant -X- _ O
information -X- _ O
is -X- _ O
formulated -X- _ O
into -X- _ O
a -X- _ O
pair -X- _ O
with -X- _ O
aspect -X- _ O
term -X- _ O
and -X- _ O
sentiment -X- _ O
polarity -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
task -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O
Aspect -X- _ B-TaskName
Term -X- _ I-TaskName
Extraction -X- _ I-TaskName
and -X- _ I-TaskName
Sentiment -X- _ I-TaskName
Classification -X- _ I-TaskName
( -X- _ O
AESC -X- _ B-TaskName
) -X- _ O
. -X- _ O
Figure -X- _ O
1 -X- _ O
shows -X- _ O
an -X- _ O
example -X- _ O
of -X- _ O
ASTE -X- _ B-TaskName
and -X- _ O
AESC -X- _ B-TaskName
. -X- _ O
Two -X- _ O
early -X- _ O
methods -X- _ O
handle -X- _ O
the -X- _ O
triplet -X- _ O
extraction -X- _ O
task -X- _ O
efficiently -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
; -X- _ O
Huang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Both -X- _ O
are -X- _ O
typically -X- _ O
composed -X- _ O
of -X- _ O
a -X- _ O
sequence -X- _ O
representation -X- _ O
layer -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
aspect -X- _ O
/ -X- _ O
opinion -X- _ O
term -X- _ O
mentions -X- _ O
and -X- _ O
a -X- _ O
classification -X- _ O
layer -X- _ O
to -X- _ O
infer -X- _ O
the -X- _ O
sentiment -X- _ O
polarity -X- _ O
of -X- _ O
the -X- _ O
predicted -X- _ O
mention -X- _ O
pair -X- _ O
of -X- _ O
the -X- _ O
last -X- _ O
layer -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
as -X- _ O
is -X- _ O
often -X- _ O
the -X- _ O
case -X- _ O
, -X- _ O
such -X- _ O
model -X- _ O
design -X- _ O
may -X- _ O
easily -X- _ O
result -X- _ O
in -X- _ O
that -X- _ O
the -X- _ O
errors -X- _ O
of -X- _ O
the -X- _ O
upper -X- _ O
prediction -X- _ O
layer -X- _ O
would -X- _ O
hurt -X- _ O
the -X- _ O
accuracy -X- _ O
of -X- _ O
the -X- _ O
lower -X- _ O
layer -X- _ O
during -X- _ O
the -X- _ O
training -X- _ O
procedure -X- _ O
. -X- _ O

To -X- _ O
tackle -X- _ O
the -X- _ O
error -X- _ O
cascading -X- _ O
phenomenon -X- _ O
on -X- _ O
the -X- _ O
pipeline -X- _ O
model -X- _ O
, -X- _ O
a -X- _ O
growing -X- _ O
trend -X- _ O
of -X- _ O
jointly -X- _ O
modeling -X- _ O
these -X- _ O
subtasks -X- _ O
in -X- _ O
one -X- _ O
shot -X- _ O
appears -X- _ O
. -X- _ O
proposed -X- _ O
a -X- _ O
joint -X- _ O
model -X- _ O
using -X- _ O
a -X- _ O
sequence -X- _ O
tagging -X- _ O
method -X- _ O
, -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
bidirectional -X- _ B-MethodName
Long -X- _ I-MethodName
Short -X- _ I-MethodName
- -X- _ I-MethodName
Term -X- _ I-MethodName
Memory -X- _ I-MethodName
( -X- _ O
LSTM -X- _ B-MethodName
) -X- _ O
and -X- _ O
Conditional -X- _ B-MethodName
Random -X- _ I-MethodName
Fields -X- _ I-MethodName
( -X- _ O
CRF -X- _ B-MethodName
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
they -X- _ O
found -X- _ O
that -X- _ O
if -X- _ O
a -X- _ O
tagged -X- _ O
mention -X- _ O
belongs -X- _ O
to -X- _ O
more -X- _ O
than -X- _ O
one -X- _ O
triplet -X- _ O
, -X- _ O
this -X- _ O
method -X- _ O
will -X- _ O
be -X- _ O
ineffective -X- _ O
. -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020a -X- _ O
) -X- _ O
proposed -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
learning -X- _ O
approach -X- _ O
with -X- _ O
the -X- _ O
aid -X- _ O
of -X- _ O
dependency -X- _ O
parsing -X- _ O
on -X- _ O
tail -X- _ O
word -X- _ O
pair -X- _ O
of -X- _ O
corresponding -X- _ O
aspect -X- _ O
- -X- _ O
opinion -X- _ O
pair -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
this -X- _ O
non -X- _ O
- -X- _ O
strict -X- _ O
dependency -X- _ O
parsing -X- _ O
may -X- _ O
miss -X- _ O
capturing -X- _ O
structural -X- _ O
information -X- _ O
of -X- _ O
term -X- _ O
span -X- _ O
. -X- _ O
Meanwhile -X- _ O
, -X- _ O
the -X- _ O
many -X- _ O
- -X- _ O
target -X- _ O
to -X- _ O
one -X- _ O
- -X- _ O
opinion -X- _ O
issue -X- _ O
is -X- _ O
not -X- _ O
effectively -X- _ O
handled -X- _ O
. -X- _ O

The -X- _ O
promising -X- _ O
results -X- _ O
achieved -X- _ O
by -X- _ O
machine -X- _ O
reading -X- _ O
comprehension -X- _ O
( -X- _ O
MRC -X- _ O
) -X- _ O
frameworks -X- _ O
on -X- _ O
solving -X- _ O
many -X- _ O
other -X- _ O
NLP -X- _ O
tasks -X- _ O
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
, -X- _ O
2019a -X- _ O
) -X- _ O
also -X- _ O
inspires -X- _ O
the -X- _ O
ASTE -X- _ B-TaskName
task -X- _ O
. -X- _ O
Mao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
and -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
attempted -X- _ O
to -X- _ O
design -X- _ O
question -X- _ O
- -X- _ O
answer -X- _ O
pair -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
MRC -X- _ O
to -X- _ O
formulate -X- _ O
the -X- _ O
triplet -X- _ O
extraction -X- _ O
. -X- _ O
Nevertheless -X- _ O
, -X- _ O
both -X- _ O
need -X- _ O
to -X- _ O
make -X- _ O
the -X- _ O
converted -X- _ O
question -X- _ O
correspond -X- _ O
one -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
one -X- _ O
to -X- _ O
the -X- _ O
designed -X- _ O
question -X- _ O
manually -X- _ O
, -X- _ O
hence -X- _ O
increasing -X- _ O
computation -X- _ O
complexity -X- _ O
. -X- _ O

Among -X- _ O
these -X- _ O
joint -X- _ O
models -X- _ O
, -X- _ O
transformed -X- _ O
the -X- _ O
sequence -X- _ O
representation -X- _ O
into -X- _ O
the -X- _ O
two -X- _ O
- -X- _ O
dimension -X- _ O
space -X- _ O
and -X- _ O
argued -X- _ O
that -X- _ O
the -X- _ O
word -X- _ O
- -X- _ O
pair -X- _ O
under -X- _ O
at -X- _ O
least -X- _ O
one -X- _ O
assumption -X- _ O
could -X- _ O
represent -X- _ O
the -X- _ O
aspect -X- _ O
- -X- _ O
opinion -X- _ O
pair -X- _ O
as -X- _ O
input -X- _ O
of -X- _ O
different -X- _ O
encoders -X- _ O
. -X- _ O
Although -X- _ O
this -X- _ O
model -X- _ O
indicated -X- _ O
significant -X- _ O
improvement -X- _ O
, -X- _ O
it -X- _ O
treated -X- _ O
the -X- _ O
word -X- _ O
- -X- _ O
pair -X- _ O
without -X- _ O
taking -X- _ O
span -X- _ O
boundary -X- _ O
of -X- _ O
aspect -X- _ O
term -X- _ O
and -X- _ O
opinion -X- _ O
term -X- _ O
into -X- _ O
consideration -X- _ O
and -X- _ O
incorporated -X- _ O
nonexistent -X- _ O
pre -X- _ O
- -X- _ O
defined -X- _ O
aspect -X- _ O
- -X- _ O
opinion -X- _ O
pairs -X- _ O
. -X- _ O

Considering -X- _ O
the -X- _ O
problems -X- _ O
mentioned -X- _ O
above -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
dual -X- _ O
- -X- _ O
encoder -X- _ O
model -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
pretrained -X- _ O
language -X- _ O
model -X- _ O
by -X- _ O
jointly -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
multiple -X- _ O
encoders -X- _ O
on -X- _ O
the -X- _ O
ABSA -X- _ B-TaskName
task -X- _ O
. -X- _ O
Similar -X- _ O
to -X- _ O
prior -X- _ O
work -X- _ O
, -X- _ O
our -X- _ O
framework -X- _ O
uses -X- _ O
a -X- _ O
shared -X- _ O
sequence -X- _ O
encoder -X- _ O
to -X- _ O
represent -X- _ O
the -X- _ O
aspect -X- _ O
terms -X- _ O
and -X- _ O
opinion -X- _ O
terms -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
embedding -X- _ O
space -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
a -X- _ O
pair -X- _ O
encoder -X- _ O
to -X- _ O
represent -X- _ O
the -X- _ O
aspectopinion -X- _ O
pair -X- _ O
on -X- _ O
the -X- _ O
span -X- _ O
level -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
our -X- _ O
dualencoder -X- _ O
model -X- _ O
could -X- _ O
learn -X- _ O
from -X- _ O
the -X- _ O
ABSA -X- _ B-TaskName
subtasks -X- _ O
individually -X- _ O
and -X- _ O
benefit -X- _ O
from -X- _ O
each -X- _ O
other -X- _ O
in -X- _ O
an -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
manner -X- _ O
. -X- _ O

Experiments -X- _ O
on -X- _ O
benchmark -X- _ O
datasets -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
significantly -X- _ O
outperforms -X- _ O
previous -X- _ O
approaches -X- _ O
at -X- _ O
the -X- _ O
aspect -X- _ O
level -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
conduct -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
experiments -X- _ O
to -X- _ O
analyze -X- _ O
the -X- _ O
gain -X- _ O
of -X- _ O
additional -X- _ O
representation -X- _ O
from -X- _ O
the -X- _ O
proposed -X- _ O
dualencoder -X- _ O
structure -X- _ O
. -X- _ O

The -X- _ O
contributions -X- _ O
of -X- _ O
our -X- _ O
work -X- _ O
are -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

• -X- _ O
We -X- _ O
propose -X- _ O
a -X- _ O
jointly -X- _ O
optimized -X- _ O
dual -X- _ O
- -X- _ O
encoder -X- _ O
model -X- _ O
for -X- _ O
ABSA -X- _ B-TaskName
to -X- _ O
boost -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
ABSA -X- _ B-TaskName
tasks -X- _ O
. -X- _ O

• -X- _ O
We -X- _ O
apply -X- _ O
an -X- _ O
attention -X- _ O
mechanism -X- _ O
to -X- _ O
allow -X- _ O
information -X- _ O
transfer -X- _ O
between -X- _ O
words -X- _ O
to -X- _ O
promote -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
know -X- _ O
the -X- _ O
word -X- _ O
pairs -X- _ O
before -X- _ O
inference -X- _ O
. -X- _ O

• -X- _ O
We -X- _ O
achieve -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performance -X- _ O
on -X- _ O
benchmark -X- _ O
datasets -X- _ O
at -X- _ O
the -X- _ O
time -X- _ O
of -X- _ O
submission -X- _ O
. -X- _ O

Our -X- _ O
Approach -X- _ O

Problem -X- _ O
Formulation -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
split -X- _ O
the -X- _ O
ABSA -X- _ B-TaskName
task -X- _ O
into -X- _ O
two -X- _ O
periods -X- _ O
: -X- _ O
aspect -X- _ B-TaskName
/ -X- _ I-TaskName
opinion -X- _ I-TaskName
term -X- _ I-TaskName
extraction -X- _ I-TaskName
and -X- _ O
sentiment -X- _ B-TaskName
classification -X- _ I-TaskName
( -X- _ O
SC -X- _ B-TaskName
) -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
. -X- _ O
The -X- _ O
aspect -X- _ B-TaskName
/ -X- _ I-TaskName
opinion -X- _ I-TaskName
term -X- _ I-TaskName
extraction -X- _ I-TaskName
subtask -X- _ O
extracts -X- _ O
the -X- _ O
aspect -X- _ O
terms -X- _ O
( -X- _ O
AT -X- _ O
) -X- _ O
and -X- _ O
opinion -X- _ O
terms -X- _ O
( -X- _ O
OT -X- _ O
) -X- _ O
in -X- _ O
the -X- _ O
sentences -X- _ O
without -X- _ O
considering -X- _ O
the -X- _ O
sentiment -X- _ O
polarities -X- _ O
( -X- _ O
SP -X- _ O
) -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
sentiment -X- _ O
polarity -X- _ O
tagging -X- _ O
style -X- _ O
of -X- _ O
the -X- _ O
dataset -X- _ O
, -X- _ O
the -X- _ O
SC -X- _ B-TaskName
subtask -X- _ O
is -X- _ O
divided -X- _ O
into -X- _ O
two -X- _ O
categories -X- _ O
: -X- _ O
ASTE -X- _ B-TaskName
, -X- _ O
tagging -X- _ O
SP -X- _ O
on -X- _ O
AT -X- _ O
and -X- _ O
OT -X- _ O
, -X- _ O
and -X- _ O
AESC -X- _ B-TaskName
, -X- _ O
which -X- _ O
tags -X- _ O
SP -X- _ O
only -X- _ O
on -X- _ O
AT -X- _ O
. -X- _ O

In -X- _ O
particular -X- _ O
, -X- _ O
we -X- _ O
denote -X- _ O
AT -X- _ O
, -X- _ O
OT -X- _ O
and -X- _ O
SP -X- _ O
as -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
predefined -X- _ O
aspect -X- _ O
terms -X- _ O
, -X- _ O
opinion -X- _ O
terms -X- _ O
and -X- _ O
sentiment -X- _ O
polarities -X- _ O
, -X- _ O
respectively -X- _ O
, -X- _ O
where -X- _ O
AT -X- _ O
∈ -X- _ O
AT -X- _ O
, -X- _ O
OT -X- _ O
∈ -X- _ O
OT -X- _ O
, -X- _ O
and -X- _ O
SP -X- _ O
∈ -X- _ O
SP -X- _ O
= -X- _ O
{ -X- _ O
POS -X- _ O
, -X- _ O
NEU -X- _ O
, -X- _ O
NEG -X- _ O
} -X- _ O
. -X- _ O
Given -X- _ O
a -X- _ O
sentence -X- _ O
s -X- _ O
consisting -X- _ O
of -X- _ O
n -X- _ O
tokens -X- _ O
ω -X- _ O
1 -X- _ O
, -X- _ O
ω -X- _ O
2 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
ω -X- _ O
n -X- _ O
, -X- _ O
we -X- _ O
denote -X- _ O
T -X- _ O
as -X- _ O
the -X- _ O
sentence -X- _ O
output -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
for -X- _ O
the -X- _ O
ASTE -X- _ B-TaskName
task -X- _ O
, -X- _ O
T -X- _ O
= -X- _ O
{ -X- _ O
( -X- _ O
AT -X- _ O
, -X- _ O
OT -X- _ O
, -X- _ O
SP -X- _ O
) -X- _ O
} -X- _ O
, -X- _ O
and -X- _ O
for -X- _ O
the -X- _ O
AESC -X- _ B-TaskName
task -X- _ O
, -X- _ O
T -X- _ O
= -X- _ O
{ -X- _ O
( -X- _ O
AT -X- _ O
, -X- _ O
SP -X- _ O
) -X- _ O
} -X- _ O
. -X- _ O

Model -X- _ O
Overview -X- _ O

Our -X- _ O
approach -X- _ O
for -X- _ O
the -X- _ O
ABSA -X- _ B-TaskName
task -X- _ O
is -X- _ O
designed -X- _ O
to -X- _ O
subtly -X- _ O
model -X- _ O
high -X- _ O
affinity -X- _ O
between -X- _ O
aspect -X- _ O
/ -X- _ O
opinion -X- _ O
pair -X- _ O
and -X- _ O
ground -X- _ O
truth -X- _ O
by -X- _ O
effectively -X- _ O
leveraging -X- _ O
the -X- _ O
pair -X- _ O
representation -X- _ O
, -X- _ O
which -X- _ O
adapts -X- _ O
the -X- _ O
same -X- _ O
encoder -X- _ O
design -X- _ O
proposed -X- _ O
by -X- _ O
Wang -X- _ O
and -X- _ O
Lu -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
to -X- _ O
the -X- _ O
aspectbased -X- _ O
sentiment -X- _ O
analysis -X- _ O
problem -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
, -X- _ O
our -X- _ O
dual -X- _ O
- -X- _ O
encoder -X- _ O
comprises -X- _ O
two -X- _ O
modules -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
a -X- _ O
sequence -X- _ O
encoder -X- _ O
, -X- _ O
with -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
model -X- _ O
to -X- _ O
represent -X- _ O
AT -X- _ O
and -X- _ O
OT -X- _ O
with -X- _ O
the -X- _ O
corresponding -X- _ O
context -X- _ O
; -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
a -X- _ O
pair -X- _ O
encoder -X- _ O
, -X- _ O
encoding -X- _ O
the -X- _ O
aspect -X- _ O
- -X- _ O
opinion -X- _ O
pair -X- _ O
for -X- _ O
each -X- _ O
sentiment -X- _ O
polarity -X- _ O
. -X- _ O

Differences -X- _ O
from -X- _ O
Table -X- _ O
- -X- _ O
sequence -X- _ O
Model -X- _ O
of -X- _ O
Relation -X- _ O
Extraction -X- _ O

Our -X- _ O
approach -X- _ O
differs -X- _ O
from -X- _ O
Wang -X- _ O
and -X- _ O
Lu -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
in -X- _ O
the -X- _ O
AT -X- _ O
/ -X- _ O
OT -X- _ O
extraction -X- _ O
subtask -X- _ O
modeling -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
sentiment -X- _ O
classification -X- _ O
module -X- _ O
in -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
still -X- _ O
follow -X- _ O
the -X- _ O
efficient -X- _ O
relation -X- _ O
extraction -X- _ O
module -X- _ O
design -X- _ O
of -X- _ O
Wang -X- _ O
and -X- _ O
Lu -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
for -X- _ O
tackling -X- _ O
pair -X- _ O
classifications -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
reason -X- _ O
that -X- _ O
we -X- _ O
found -X- _ O
there -X- _ O
are -X- _ O
many -X- _ O
commonalities -X- _ O
in -X- _ O
modeling -X- _ O
including -X- _ O
the -X- _ O
Our -X- _ O
proposed -X- _ O
strategy -X- _ O
is -X- _ O
more -X- _ O
adapted -X- _ O
to -X- _ O
the -X- _ O
characteristics -X- _ O
of -X- _ O
the -X- _ O
ABSA -X- _ B-TaskName
task -X- _ O
. -X- _ O
With -X- _ O
this -X- _ O
modified -X- _ O
model -X- _ O
structure -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
could -X- _ O
efficiently -X- _ O
infer -X- _ O
the -X- _ O
AT -X- _ O
, -X- _ O
OT -X- _ O
, -X- _ O
and -X- _ O
their -X- _ O
corresponding -X- _ O
relationship -X- _ O
. -X- _ O

Token -X- _ O
Representation -X- _ O

For -X- _ O
a -X- _ O
length -X- _ O
- -X- _ O
n -X- _ O
input -X- _ O
sentence -X- _ O
s -X- _ O
= -X- _ O
ω -X- _ O
1 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
ω -X- _ O
n -X- _ O
, -X- _ O
besides -X- _ O
the -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
representation -X- _ O
x -X- _ O
word -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
feed -X- _ O
the -X- _ O
characters -X- _ O
of -X- _ O
the -X- _ O
word -X- _ O
into -X- _ O
the -X- _ O
LSTM -X- _ B-MethodName
to -X- _ O
generate -X- _ O
the -X- _ O
character -X- _ O
- -X- _ O
level -X- _ O
representation -X- _ O
x -X- _ O
char -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
model -X- _ O
provides -X- _ O
the -X- _ O
contextualized -X- _ O
representation -X- _ O
x -X- _ O
plm -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
concatenate -X- _ O
these -X- _ O
three -X- _ O
representations -X- _ O
of -X- _ O
each -X- _ O
word -X- _ O
to -X- _ O
feed -X- _ O
into -X- _ O
the -X- _ O
dual -X- _ O
- -X- _ O
encoder -X- _ O
: -X- _ O

x -X- _ O
i -X- _ O
= -X- _ O
[ -X- _ O
x -X- _ O
char -X- _ O
; -X- _ O
x -X- _ O
word -X- _ O
; -X- _ O
x -X- _ O
plm -X- _ O
] -X- _ O
. -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O

In -X- _ O
our -X- _ O
proposed -X- _ O
dual -X- _ O
- -X- _ O
encoder -X- _ O
architecture -X- _ O
, -X- _ O
we -X- _ O
still -X- _ O
treat -X- _ O
the -X- _ O
ASTE -X- _ B-TaskName
/ -X- _ O
AESC -X- _ B-TaskName
task -X- _ O
as -X- _ O
a -X- _ O
unified -X- _ O
sequence -X- _ O
tagging -X- _ O
task -X- _ O
in -X- _ O
previous -X- _ O
work -X- _ O
: -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
sentence -X- _ O
s -X- _ O
, -X- _ O
where -X- _ O
AT -X- _ O
and -X- _ O
OT -X- _ O
on -X- _ O
the -X- _ O
main -X- _ O
diagonal -X- _ O
are -X- _ O
annotated -X- _ O
with -X- _ O
B -X- _ O
/ -X- _ O
I -X- _ O
/ -X- _ O
O -X- _ O
( -X- _ O
Begin -X- _ O
, -X- _ O
Inside -X- _ O
, -X- _ O
Outside -X- _ O
) -X- _ O
, -X- _ O
each -X- _ O
entry -X- _ O
E -X- _ O
i -X- _ O
, -X- _ O
j -X- _ O
of -X- _ O
the -X- _ O
upper -X- _ O
triangular -X- _ O
matrix -X- _ O
denotes -X- _ O
the -X- _ O
pair -X- _ O
( -X- _ O
ω -X- _ O
i -X- _ O
, -X- _ O
ω -X- _ O
j -X- _ O
) -X- _ O
from -X- _ O
the -X- _ O
input -X- _ O
sentence -X- _ O
. -X- _ O
Our -X- _ O
work -X- _ O
is -X- _ O
partially -X- _ O
motivated -X- _ O
by -X- _ O
but -X- _ O
significantly -X- _ O
different -X- _ O
. -X- _ O

First -X- _ O
, -X- _ O
we -X- _ O
improve -X- _ O
the -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
pair -X- _ O
representation -X- _ O
to -X- _ O
span -X- _ O
- -X- _ O
level -X- _ O
pair -X- _ O
representation -X- _ O
with -X- _ O
more -X- _ O
accurate -X- _ O
boundary -X- _ O
information -X- _ O
fed -X- _ O
into -X- _ O
our -X- _ O
model -X- _ O
. -X- _ O
The -X- _ O
tagging -X- _ O
scheme -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
is -X- _ O
illustrated -X- _ O
in -X- _ O
Figure -X- _ O
3 -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
main -X- _ O
diagonal -X- _ O
are -X- _ O
filled -X- _ O
with -X- _ O
AT -X- _ O
and -X- _ O
OT -X- _ O
accompanying -X- _ O
entries -X- _ O
to -X- _ O
the -X- _ O
right -X- _ O
of -X- _ O
the -X- _ O
main -X- _ O
diagonal -X- _ O
with -X- _ O
span -X- _ O
pairs -X- _ O
. -X- _ O
Compared -X- _ O
to -X- _ O
, -X- _ O
our -X- _ O
method -X- _ O
may -X- _ O
heavily -X- _ O
reduce -X- _ O
the -X- _ O
redundancy -X- _ O
aroused -X- _ O
by -X- _ O
AT -X- _ O
and -X- _ O
OT -X- _ O
tags -X- _ O
at -X- _ O
the -X- _ O
right -X- _ O
of -X- _ O
the -X- _ O
main -X- _ O
diagonal -X- _ O
. -X- _ O

Second -X- _ O
, -X- _ O
we -X- _ O
consider -X- _ O
the -X- _ O
context -X- _ O
information -X- _ O
on -X- _ O
both -X- _ O
two -X- _ O
- -X- _ O
dimension -X- _ O
spaces -X- _ O
and -X- _ O
the -X- _ O
historical -X- _ O
information -X- _ O
with -X- _ O
the -X- _ O
utilization -X- _ O
of -X- _ O
the -X- _ O
recurrent -X- _ B-MethodName
neural -X- _ I-MethodName
network -X- _ I-MethodName
( -X- _ O
RNN -X- _ B-MethodName
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
merely -X- _ O
adopted -X- _ O
a -X- _ O
single -X- _ O
encoder -X- _ O
which -X- _ O
based -X- _ O
on -X- _ O
DE -X- _ B-MethodName
- -X- _ I-MethodName
CNN -X- _ I-MethodName
( -X- _ O
Xu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
/ -X- _ O
BiLSTM -X- _ B-MethodName
/ -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
to -X- _ O
establish -X- _ O
token -X- _ O
representation -X- _ O
, -X- _ O
and -X- _ O
they -X- _ O
Thus -X- _ O
, -X- _ O
our -X- _ O
dual -X- _ O
- -X- _ O
encoder -X- _ O
could -X- _ O
jointly -X- _ O
encode -X- _ O
AT -X- _ O
, -X- _ O
OT -X- _ O
( -X- _ O
with -X- _ O
the -X- _ O
corresponding -X- _ O
context -X- _ O
on -X- _ O
both -X- _ O
dimensions -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
AT -X- _ O
- -X- _ O
OT -X- _ O
pairs -X- _ O
with -X- _ O
representation -X- _ O
information -X- _ O
sharing -X- _ O
. -X- _ O

Sequence -X- _ O
Encoder -X- _ O

Following -X- _ O
the -X- _ O
previous -X- _ O
work -X- _ O
of -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
construct -X- _ O
the -X- _ O
sequence -X- _ O
encoder -X- _ O
as -X- _ O
a -X- _ O
Transformer -X- _ B-MethodName
network -X- _ O
. -X- _ O

Here -X- _ O
we -X- _ O
apply -X- _ O
a -X- _ O
stack -X- _ O
of -X- _ O
m -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
layers -X- _ O
, -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
. -X- _ O
Each -X- _ O
layer -X- _ O
consists -X- _ O
of -X- _ O
two -X- _ O
sublayers -X- _ O
: -X- _ O
namely -X- _ O
multi -X- _ O
- -X- _ O
head -X- _ O
attention -X- _ O
sublayer -X- _ O
, -X- _ O
feed -X- _ O
- -X- _ O
forward -X- _ O
sublayer -X- _ O
, -X- _ O
at -X- _ O
the -X- _ O
top -X- _ O
of -X- _ O
each -X- _ O
sublayer -X- _ O
followed -X- _ O
with -X- _ O
both -X- _ O
residual -X- _ O
connection -X- _ O
and -X- _ O
layer -X- _ O
normalization -X- _ O
. -X- _ O

Multi -X- _ O
- -X- _ O
head -X- _ O
Attention -X- _ O
Sublayer -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
the -X- _ O
token -X- _ O
representation -X- _ O
x -X- _ O
i -X- _ O
is -X- _ O
fed -X- _ O
into -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
head -X- _ O
attention -X- _ O
sublayer -X- _ O
. -X- _ O

At -X- _ O
first -X- _ O
of -X- _ O
our -X- _ O
sequence -X- _ O
encoder -X- _ O
, -X- _ O
the -X- _ O
token -X- _ O
representation -X- _ O
x -X- _ O
i -X- _ O
will -X- _ O
be -X- _ O
mapped -X- _ O
into -X- _ O
vector -X- _ O
space -X- _ O
as -X- _ O
query -X- _ O
Q -X- _ O
i -X- _ O
, -X- _ O
key -X- _ O
K -X- _ O
i -X- _ O
, -X- _ O
value -X- _ O
V -X- _ O
i -X- _ O
: -X- _ O

Q -X- _ O
i -X- _ O
= -X- _ O
x -X- _ O
i -X- _ O
W -X- _ O
Q -X- _ O
K -X- _ O
i -X- _ O
= -X- _ O
x -X- _ O
i -X- _ O
W -X- _ O
K -X- _ O
V -X- _ O
i -X- _ O
= -X- _ O
x -X- _ O
i -X- _ O
W -X- _ O
V -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O

then -X- _ O
the -X- _ O
value -X- _ O
vectors -X- _ O
of -X- _ O
all -X- _ O
positions -X- _ O
will -X- _ O
be -X- _ O
aggregated -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
normalized -X- _ O
attention -X- _ O
weight -X- _ O
to -X- _ O
get -X- _ O
the -X- _ O
single -X- _ O
- -X- _ O
head -X- _ O
representation -X- _ O
: -X- _ O

SingleHead -X- _ O
( -X- _ O
Q -X- _ O
i -X- _ O
, -X- _ O
K -X- _ O
i -X- _ O
, -X- _ O
V -X- _ O
i -X- _ O
) -X- _ O
= -X- _ O
softmax -X- _ O
( -X- _ O
Q -X- _ O
i -X- _ O
K -X- _ O
T -X- _ O
i -X- _ O
d -X- _ O
/ -X- _ O
m -X- _ O
) -X- _ O
V -X- _ O

( -X- _ O
3 -X- _ O
) -X- _ O
where -X- _ O
m -X- _ B-HyperparameterName
is -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
heads -X- _ I-HyperparameterName
, -X- _ O
d -X- _ B-HyperparameterName
is -X- _ O
the -X- _ O
dimension -X- _ O
of -X- _ O
x -X- _ O
i -X- _ O
, -X- _ O
and -X- _ O
in -X- _ O
our -X- _ O
sequence -X- _ O
encoder -X- _ O
, -X- _ O

Q -X- _ O
= -X- _ O
K -X- _ O
= -X- _ O
V -X- _ O
= -X- _ O
x -X- _ O
i -X- _ O
. -X- _ O

Then -X- _ O
with -X- _ O
multi -X- _ O
- -X- _ O
heads -X- _ O
attention -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
builds -X- _ O
up -X- _ O
representations -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
sequence -X- _ O
: -X- _ O

r -X- _ O
i -X- _ O
= -X- _ O
MultiHead -X- _ O
( -X- _ O
Q -X- _ O
i -X- _ O
, -X- _ O
K -X- _ O
i -X- _ O
, -X- _ O
V -X- _ O
i -X- _ O
) -X- _ O
= -X- _ O
Concat -X- _ O
( -X- _ O
SingleHead -X- _ O
1 -X- _ O
, -X- _ O
.. -X- _ O
, -X- _ O
m -X- _ O
( -X- _ O
Q -X- _ O
i -X- _ O
, -X- _ O
K -X- _ O
i -X- _ O
, -X- _ O
V -X- _ O
i -X- _ O
) -X- _ O
) -X- _ O
W -X- _ O
O -X- _ O

( -X- _ O
4 -X- _ O
) -X- _ O
where -X- _ O
W -X- _ O
O -X- _ O
∈ -X- _ O
R -X- _ O
d -X- _ O
. -X- _ O
We -X- _ O
adopt -X- _ O
the -X- _ O
residual -X- _ O
connection -X- _ O
and -X- _ O
layer -X- _ O
normalization -X- _ O
( -X- _ O
Ba -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
on -X- _ O
r -X- _ O
i -X- _ O
and -X- _ O
x -X- _ O
i -X- _ O
: -X- _ O

a -X- _ O
i -X- _ O
= -X- _ O
LayerNorm -X- _ O
( -X- _ O
r -X- _ O
i -X- _ O
+ -X- _ O
x -X- _ O
i -X- _ O
) -X- _ O

( -X- _ O
5 -X- _ O
) -X- _ O

Feed -X- _ O
- -X- _ O
Forward -X- _ O
Sublayer -X- _ O

The -X- _ O
outputs -X- _ O
of -X- _ O
the -X- _ O
multi -X- _ O
- -X- _ O
head -X- _ O
attention -X- _ O
are -X- _ O
fed -X- _ O
into -X- _ O
a -X- _ O
feed -X- _ O
- -X- _ O
forward -X- _ O
network -X- _ O
: -X- _ O

e -X- _ O
i -X- _ O
= -X- _ O
FFNN -X- _ O
( -X- _ O
r -X- _ O
i -X- _ O
) -X- _ O
= -X- _ O
( -X- _ O
a -X- _ O
i -X- _ O
W -X- _ O
1 -X- _ O
+ -X- _ O
b -X- _ O
1 -X- _ O
) -X- _ O
W -X- _ O
2 -X- _ O
+ -X- _ O
b -X- _ O
2 -X- _ O
( -X- _ O
6 -X- _ O
) -X- _ O

where -X- _ O

W -X- _ O
1 -X- _ O
, -X- _ O
W -X- _ O
2 -X- _ O
, -X- _ O
∈ -X- _ O
R -X- _ O
d×d -X- _ O
/ -X- _ O
m -X- _ O
and -X- _ O
b -X- _ O
1 -X- _ O
, -X- _ O
b -X- _ O
2 -X- _ O
∈ -X- _ O
R -X- _ O
d -X- _ O
. -X- _ O

At -X- _ O
last -X- _ O
, -X- _ O
the -X- _ O
sequence -X- _ O
representation -X- _ O
will -X- _ O
be -X- _ O
performed -X- _ O
by -X- _ O
layer -X- _ O
normalization -X- _ O
with -X- _ O
residual -X- _ O
connection -X- _ O
: -X- _ O

S -X- _ O
i -X- _ O
= -X- _ O
LayerNorm -X- _ O
( -X- _ O
e -X- _ O
i -X- _ O
+ -X- _ O
a -X- _ O
i -X- _ O
) -X- _ O
( -X- _ O
7 -X- _ O
) -X- _ O

Pair -X- _ O
Encoder -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
, -X- _ O
our -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
pair -X- _ O
representation -X- _ O
is -X- _ O
an -X- _ O
n -X- _ O
× -X- _ O
n -X- _ O
matrix -X- _ O
of -X- _ O
vectors -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
vector -X- _ O
at -X- _ O
row -X- _ O
i -X- _ O
and -X- _ O
column -X- _ O
j -X- _ O
represents -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
and -X- _ O
j -X- _ O
- -X- _ O
th -X- _ O
word -X- _ O
pair -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
sentence -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
l -X- _ O
- -X- _ O
th -X- _ O
layer -X- _ O
of -X- _ O
our -X- _ O
network -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
add -X- _ O
a -X- _ O
Multi -X- _ O
- -X- _ O
Layer -X- _ O
Perception -X- _ O
( -X- _ O
MLP -X- _ O
) -X- _ O
layer -X- _ O
with -X- _ O
ReLU -X- _ O
( -X- _ O
Nair -X- _ O
and -X- _ O
Hinton -X- _ O
, -X- _ O
2010 -X- _ O
) -X- _ O
to -X- _ O
contextualize -X- _ O
the -X- _ O
concatenation -X- _ O
of -X- _ O
representations -X- _ O
from -X- _ O
the -X- _ O
sequence -X- _ O
encoder -X- _ O
: -X- _ O

S -X- _ O
l -X- _ O
, -X- _ O
i -X- _ O
, -X- _ O
j -X- _ O
= -X- _ O
ReLU -X- _ O
( -X- _ O
MLP -X- _ O
( -X- _ O
[ -X- _ O
S -X- _ O
l−1 -X- _ O
, -X- _ O
i -X- _ O
; -X- _ O
S -X- _ O
l−1 -X- _ O
, -X- _ O
j -X- _ O
] -X- _ O
) -X- _ O
) -X- _ O
( -X- _ O
8 -X- _ O
) -X- _ O

Then -X- _ O
we -X- _ O
utilize -X- _ O
the -X- _ O
multi -X- _ B-MethodName
- -X- _ I-MethodName
dimensional -X- _ I-MethodName
recurrent -X- _ I-MethodName
neural -X- _ I-MethodName
network -X- _ I-MethodName
( -X- _ O
MDRNN -X- _ B-MethodName
) -X- _ O
( -X- _ O
Graves -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2007 -X- _ O
) -X- _ O
and -X- _ O
gated -X- _ O
recurrent -X- _ O
unit -X- _ O
( -X- _ O
GRU -X- _ O
) -X- _ O
( -X- _ O
Cho -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
to -X- _ O
contextualize -X- _ O
S -X- _ O
l -X- _ O
, -X- _ O
i -X- _ O
, -X- _ O
j -X- _ O
. -X- _ O
The -X- _ O
contextualized -X- _ O
pair -X- _ O
representation -X- _ O
P -X- _ O
i -X- _ O
is -X- _ O
computed -X- _ O
iteratively -X- _ O
from -X- _ O
the -X- _ O
hidden -X- _ O
states -X- _ O
of -X- _ O
each -X- _ O
cell -X- _ O
: -X- _ O
P -X- _ O
l -X- _ O
, -X- _ O
i -X- _ O
, -X- _ O
j -X- _ O
= -X- _ O
GRU -X- _ O
( -X- _ O
S -X- _ O
l -X- _ O
, -X- _ O
i -X- _ O
, -X- _ O
j -X- _ O
, -X- _ O
P -X- _ O
l−1 -X- _ O
, -X- _ O
i -X- _ O
, -X- _ O
j -X- _ O
, -X- _ O
P -X- _ O
l -X- _ O
, -X- _ O
i−1 -X- _ O
, -X- _ O
j -X- _ O
, -X- _ O
P -X- _ O
l -X- _ O
, -X- _ O
i -X- _ O
, -X- _ O
j−1 -X- _ O
) -X- _ O
( -X- _ O
9 -X- _ O
) -X- _ O
The -X- _ O
pair -X- _ O
encoder -X- _ O
does -X- _ O
not -X- _ O
consider -X- _ O
only -X- _ O
the -X- _ O
word -X- _ O
pair -X- _ O
at -X- _ O
neighboring -X- _ O
rows -X- _ O
and -X- _ O
columns -X- _ O
but -X- _ O
also -X- _ O
those -X- _ O
of -X- _ O
the -X- _ O
previous -X- _ O
layer -X- _ O
. -X- _ O

Training -X- _ O

Given -X- _ O
a -X- _ O
sentence -X- _ O
s -X- _ O
with -X- _ O
pre -X- _ O
- -X- _ O
defined -X- _ O
tags -X- _ O
AT -X- _ O
, -X- _ O
OT -X- _ O
, -X- _ O
and -X- _ O
SP -X- _ O
∈ -X- _ O
{ -X- _ O
POS -X- _ O
, -X- _ O
NEU -X- _ O
, -X- _ O
NEG -X- _ O
} -X- _ O
, -X- _ O
we -X- _ O
denote -X- _ O
the -X- _ O
AT -X- _ O
or -X- _ O
OT -X- _ O
tag -X- _ O
of -X- _ O
token -X- _ O
ω -X- _ O
i -X- _ O
as -X- _ O
a -X- _ O
i -X- _ O
and -X- _ O
the -X- _ O
SP -X- _ O
tag -X- _ O
between -X- _ O
the -X- _ O
tokens -X- _ O
ω -X- _ O
i -X- _ O
and -X- _ O
ω -X- _ O
j -X- _ O
as -X- _ O
t -X- _ O
ij -X- _ O
. -X- _ O
To -X- _ O
predict -X- _ O
the -X- _ O
label -X- _ O
of -X- _ O
the -X- _ O
posterior -X- _ O
of -X- _ O
the -X- _ O
aspect -X- _ O
/ -X- _ O
opinion -X- _ O
termsŷ -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
a -X- _ O
softmax -X- _ O
layer -X- _ O
on -X- _ O
the -X- _ O
sequence -X- _ O
embedding -X- _ O
of -X- _ O
aspect -X- _ O
/ -X- _ O
opinion -X- _ O
terms -X- _ O
S -X- _ O
l -X- _ O
. -X- _ O
Similarly -X- _ O
, -X- _ O
to -X- _ O
obtain -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
sentiment -X- _ O
polarity -X- _ O
type -X- _ O
labelv -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
softmax -X- _ O
on -X- _ O
the -X- _ O
pair -X- _ O
representation -X- _ O
of -X- _ O
P -X- _ O
l -X- _ O
: -X- _ O

P -X- _ O
( -X- _ O
ŷ|a -X- _ O
i -X- _ O
, -X- _ O
s -X- _ O
) -X- _ O
= -X- _ O
softmax -X- _ O
( -X- _ O
W -X- _ O
term -X- _ O
S -X- _ O
l -X- _ O
) -X- _ O
( -X- _ O
10 -X- _ O
) -X- _ O

P -X- _ O
( -X- _ O
v|t -X- _ O
ij -X- _ O
, -X- _ O
s -X- _ O
) -X- _ O
= -X- _ O
softmax -X- _ O
( -X- _ O
W -X- _ O
pola -X- _ O
P -X- _ O
l -X- _ O
) -X- _ O
( -X- _ O
11 -X- _ O
) -X- _ O

where -X- _ O
W -X- _ O
term -X- _ O
and -X- _ O
W -X- _ O
pola -X- _ O
are -X- _ O
learnable -X- _ O
parameters -X- _ O
. -X- _ O

At -X- _ O
the -X- _ O
training -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
the -X- _ O
Cross -X- _ B-MetricName
- -X- _ I-MetricName
Entropy -X- _ I-MetricName
as -X- _ O
our -X- _ O
loss -X- _ O
function -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
gold -X- _ O
aspect -X- _ O
and -X- _ O
opinion -X- _ O
term -X- _ O
a -X- _ O
i -X- _ O
∈ -X- _ O
AT -X- _ O
OT -X- _ O
and -X- _ O
gold -X- _ O
polarity -X- _ O
t -X- _ O
ij -X- _ O
∈ -X- _ O
SP -X- _ O
, -X- _ O
the -X- _ O
training -X- _ O
losses -X- _ O
are -X- _ O
respectively -X- _ O
: -X- _ O

L -X- _ B-MetricName
term -X- _ I-MetricName
= -X- _ O
− -X- _ O
a -X- _ O
i -X- _ O
∈AT∪OT -X- _ O
log -X- _ O
( -X- _ O
P -X- _ O
( -X- _ O
ŷ -X- _ O
= -X- _ O
y|a -X- _ O
i -X- _ O
, -X- _ O
s -X- _ O
) -X- _ O
) -X- _ O
( -X- _ O
12 -X- _ O
) -X- _ O
L -X- _ O
pola -X- _ O
= -X- _ O
− -X- _ O
t -X- _ O
ij -X- _ O
∈SP -X- _ O
, -X- _ O
i -X- _ O
= -X- _ O
j -X- _ O
log -X- _ O
( -X- _ O
P -X- _ O
( -X- _ O
v -X- _ O
= -X- _ O
v|t -X- _ O
ij -X- _ O
, -X- _ O
s -X- _ O
) -X- _ O
) -X- _ O
( -X- _ O
13 -X- _ O
) -X- _ O

where -X- _ O
the -X- _ O
y -X- _ O
and -X- _ O
v -X- _ O
are -X- _ O
the -X- _ O
gold -X- _ O
annotations -X- _ O
of -X- _ O
corresponding -X- _ O
terms -X- _ O
. -X- _ O

To -X- _ O
jointly -X- _ O
train -X- _ O
the -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
utilize -X- _ O
the -X- _ O
summation -X- _ O
of -X- _ O
these -X- _ O
two -X- _ O
loss -X- _ O
functions -X- _ O
as -X- _ O
our -X- _ O
training -X- _ O
objective -X- _ O
: -X- _ O

L -X- _ B-MetricName
= -X- _ O
L -X- _ B-MetricName
term -X- _ I-MetricName
+ -X- _ O
L -X- _ B-MetricName
pola -X- _ I-MetricName
( -X- _ O
14 -X- _ O
) -X- _ O

3 -X- _ O
Experiments -X- _ O

Data -X- _ O

To -X- _ O
make -X- _ O
a -X- _ O
fair -X- _ O
comparison -X- _ O
with -X- _ O
previous -X- _ O
methods -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
two -X- _ O
versions -X- _ O
of -X- _ O
datasets -X- _ O
for -X- _ O
the -X- _ O
ASTE -X- _ B-TaskName
task -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
ASTE -X- _ B-DatasetName
- -X- _ I-DatasetName
Data -X- _ I-DatasetName
- -X- _ I-DatasetName
V1 -X- _ I-DatasetName
, -X- _ O
originally -X- _ O
provided -X- _ O
by -X- _ O
Peng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
from -X- _ O
the -X- _ O
SemEval -X- _ O
2014 -X- _ O
Task -X- _ O
4 -X- _ O
( -X- _ O
Pontiki -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
, -X- _ O
SemEval -X- _ O
2015Task -X- _ O
12 -X- _ O
( -X- _ O
Pontiki -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
and -X- _ O
SemEval -X- _ O
2016 -X- _ O
Task -X- _ O
5 -X- _ O
( -X- _ O
Pontiki -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
ASTE -X- _ B-DatasetName
- -X- _ I-DatasetName
Data -X- _ I-DatasetName
- -X- _ I-DatasetName
V2 -X- _ I-DatasetName
, -X- _ O
the -X- _ O
refined -X- _ O
version -X- _ O
annotated -X- _ O
by -X- _ O
, -X- _ O
with -X- _ O
additional -X- _ O
annotation -X- _ O
of -X- _ O
implicitly -X- _ O
overlapping -X- _ O
triplets -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
the -X- _ O
name -X- _ O
of -X- _ O
each -X- _ O
dataset -X- _ O
is -X- _ O
composed -X- _ O
of -X- _ O
two -X- _ O
parts -X- _ O
. -X- _ O
The -X- _ O
former -X- _ O
part -X- _ O
denotes -X- _ O
the -X- _ O
year -X- _ O
when -X- _ O
the -X- _ O
corresponding -X- _ O
SemEval -X- _ O
data -X- _ O
was -X- _ O
proposed -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
latter -X- _ O
part -X- _ O
is -X- _ O
the -X- _ O
domain -X- _ O
name -X- _ O
of -X- _ O
the -X- _ O
reviews -X- _ O
on -X- _ O
restaurant -X- _ O
service -X- _ O
or -X- _ O
laptop -X- _ O
sales -X- _ O
. -X- _ O
Data -X- _ O
statistics -X- _ O
of -X- _ O
them -X- _ O
is -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
9 -X- _ O
. -X- _ O

Then -X- _ O
, -X- _ O
for -X- _ O
the -X- _ O
AESC -X- _ B-TaskName
task -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
the -X- _ O
dataset -X- _ O
annotated -X- _ O
by -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
composed -X- _ O
of -X- _ O
three -X- _ O
datasets -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
statistics -X- _ O
is -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
10 -X- _ O
. -X- _ O
The -X- _ O
implementation -X- _ O
details -X- _ O
of -X- _ O
our -X- _ O
dual -X- _ O
- -X- _ O
encoder -X- _ O
model -X- _ O
are -X- _ O
unfolded -X- _ O
in -X- _ O
Appendix -X- _ O
A.2 -X- _ O
for -X- _ O
the -X- _ O
sake -X- _ O
of -X- _ O
putting -X- _ O
main -X- _ O
concentration -X- _ O
on -X- _ O
our -X- _ O
argument -X- _ O
. -X- _ O
Our -X- _ O
model -X- _ O
implementation -X- _ O
generally -X- _ O
follows -X- _ O
the -X- _ O
released -X- _ O
code -X- _ O
by -X- _ O
Wang -X- _ O
and -X- _ O
Lu -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
1 -X- _ O
, -X- _ O
and -X- _ O
our -X- _ O
code -X- _ O
will -X- _ O
be -X- _ O
available -X- _ O
at -X- _ O
https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
github.com -X- _ O
/ -X- _ O
Betahj -X- _ O
/ -X- _ O
PairABSA -X- _ O
. -X- _ O

Results -X- _ O
on -X- _ O
the -X- _ O
ASTE -X- _ B-TaskName
Task -X- _ O

Our -X- _ O
model -X- _ O
will -X- _ O
compare -X- _ O
to -X- _ O
the -X- _ O
following -X- _ O
baselines -X- _ O
on -X- _ O
the -X- _ O
ASTE -X- _ B-TaskName
task -X- _ O
, -X- _ O
and -X- _ O
more -X- _ O
details -X- _ O
about -X- _ O
these -X- _ O
baseline -X- _ O
models -X- _ O
are -X- _ O
listed -X- _ O
in -X- _ O
Appendix -X- _ O
A.3 -X- _ O
. -X- _ O

1 -X- _ O
) -X- _ O
RINANTE+ -X- _ B-MethodName
( -X- _ O
Peng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

2 -X- _ O
) -X- _ O
CMLA+ -X- _ B-MethodName
( -X- _ O
Peng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

3 -X- _ O
) -X- _ O
Li -X- _ B-MethodName
- -X- _ I-MethodName
unified -X- _ I-MethodName
- -X- _ I-MethodName
R -X- _ I-MethodName
( -X- _ O
Peng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
4 -X- _ O
) -X- _ O
Peng -X- _ B-MethodName
et -X- _ I-MethodName
al -X- _ I-MethodName
. -X- _ I-MethodName
( -X- _ O
Peng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
5 -X- _ O
) -X- _ O
OTE -X- _ B-MethodName
- -X- _ I-MethodName
MTL -X- _ I-MethodName
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
. -X- _ O
6 -X- _ O
) -X- _ O
JET -X- _ B-MethodName
. -X- _ O
7 -X- _ O
) -X- _ O
GTS -X- _ B-MethodName
. -X- _ O
8 -X- _ O
) -X- _ O
Huang -X- _ B-MethodName
et -X- _ I-MethodName
al -X- _ I-MethodName
. -X- _ I-MethodName
( -X- _ O
Huang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
main -X- _ O
results -X- _ O
of -X- _ O
all -X- _ O
the -X- _ O
models -X- _ O
on -X- _ O
the -X- _ O
ASTE -X- _ B-TaskName
task -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O
Compared -X- _ O
with -X- _ O
the -X- _ O
best -X- _ O
baseline -X- _ O
model -X- _ O
( -X- _ O
Huang -X- _ B-MethodName
et -X- _ I-MethodName
al -X- _ I-MethodName
. -X- _ I-MethodName
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
our -X- _ O
BERTbased -X- _ O
dual -X- _ O
- -X- _ O
encoder -X- _ O
model -X- _ O
achieves -X- _ O
an -X- _ O
improvement -X- _ O
by -X- _ O
1.39 -X- _ B-MetricValue
, -X- _ O
0.53 -X- _ B-MetricValue
, -X- _ O
0.68 -X- _ B-MetricValue
, -X- _ O
and -X- _ O
2.92 -X- _ B-MetricValue
absolute -X- _ O
F -X- _ B-MetricName
1 -X- _ I-MetricName
score -X- _ O
on -X- _ O
benchmark -X- _ O
datasets -X- _ O
. -X- _ O
This -X- _ O
result -X- _ O
signifies -X- _ O
that -X- _ O
our -X- _ O
dual -X- _ O
- -X- _ O
encoder -X- _ O
model -X- _ O
is -X- _ O
capable -X- _ O
of -X- _ O
capturing -X- _ O
the -X- _ O
difference -X- _ O
between -X- _ O
AT -X- _ O
/ -X- _ O
OT -X- _ O
extraction -X- _ O
subtask -X- _ O
and -X- _ O
SC -X- _ O
subtask -X- _ O
with -X- _ O
the -X- _ O
help -X- _ O
of -X- _ O
the -X- _ O
additional -X- _ O
pair -X- _ O
encoder -X- _ O
. -X- _ O
Besides -X- _ O
, -X- _ O
our -X- _ O
ALBERT -X- _ O
- -X- _ O
based -X- _ O
model -X- _ O
significantly -X- _ O
outperforms -X- _ O
all -X- _ O
the -X- _ O
other -X- _ O
competitive -X- _ O
methods -X- _ O
on -X- _ O
most -X- _ O
metrics -X- _ O
of -X- _ O
4 -X- _ O
datasets -X- _ O
14Rest -X- _ B-DatasetName
, -X- _ O
14Lap -X- _ B-DatasetName
, -X- _ O
15Rest -X- _ B-DatasetName
and -X- _ O
16Rest -X- _ B-DatasetName
except -X- _ O
for -X- _ O
precision -X- _ O
score -X- _ O
of -X- _ O
15Rest -X- _ B-DatasetName
. -X- _ O
Most -X- _ O
notably -X- _ O
, -X- _ O
our -X- _ O
ALBERT -X- _ O
- -X- _ O
based -X- _ O
model -X- _ O
achieves -X- _ O
an -X- _ O
improvement -X- _ O
of -X- _ O
6.66 -X- _ B-MetricValue
, -X- _ O
4.72 -X- _ B-MetricValue
, -X- _ O
9.08 -X- _ B-MetricValue
, -X- _ O
and -X- _ O
4.49 -X- _ B-MetricValue
absolute -X- _ O
F -X- _ B-MetricName
1 -X- _ I-MetricName
score -X- _ O
over -X- _ O
all -X- _ O
the -X- _ O
baseline -X- _ O
models -X- _ O
on -X- _ O
four -X- _ O
benchmark -X- _ O
datasets -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
This -X- _ O
result -X- _ O
demonstrates -X- _ O
the -X- _ O
superiority -X- _ O
of -X- _ O
our -X- _ O
dualencoder -X- _ O
model -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
we -X- _ O
notice -X- _ O
that -X- _ O
our -X- _ O
precision -X- _ O
score -X- _ O
of -X- _ O
15Rest -X- _ B-DatasetName
is -X- _ O
comparable -X- _ O
to -X- _ O
, -X- _ O
which -X- _ O
might -X- _ O
be -X- _ O
due -X- _ O
to -X- _ O
our -X- _ O
model -X- _ O
is -X- _ O
more -X- _ O
biased -X- _ O
towards -X- _ O
positive -X- _ O
predictions -X- _ O
but -X- _ O
that -X- _ O
the -X- _ O
F1 -X- _ B-MetricName
score -X- _ O
still -X- _ O
suggests -X- _ O
it -X- _ O
is -X- _ O
an -X- _ O
overall -X- _ O
improvement -X- _ O
. -X- _ O

The -X- _ O
similar -X- _ O
phenomenon -X- _ O
that -X- _ O
our -X- _ O
BERT -X- _ O
- -X- _ O
based -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
Baseline -X- _ O
results -X- _ O
are -X- _ O
directly -X- _ O
retrieved -X- _ O
from -X- _ O
( -X- _ O
Mao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
best -X- _ O
result -X- _ O
of -X- _ O
each -X- _ O
evaluation -X- _ O
metric -X- _ O
is -X- _ O
bolded -X- _ O
. -X- _ O

dual -X- _ O
- -X- _ O
encoder -X- _ O
model -X- _ O
shows -X- _ O
larger -X- _ O
improvements -X- _ O
in -X- _ O
F1 -X- _ B-MetricName
scores -X- _ O
on -X- _ O
14Rest -X- _ B-DatasetName
( -X- _ O
1.39 -X- _ B-MetricValue
) -X- _ O
and -X- _ O
16Rest -X- _ B-DatasetName
( -X- _ O
2.92 -X- _ B-MetricValue
) -X- _ O
than -X- _ O
on -X- _ O
14Lap -X- _ B-DatasetName
( -X- _ O
0.53 -X- _ B-MetricValue
) -X- _ O
and -X- _ O
15Rest -X- _ B-DatasetName
( -X- _ O
0.68 -X- _ B-MetricValue
) -X- _ O
verifies -X- _ O
the -X- _ O
explanation -X- _ O
of -X- _ O
on -X- _ O
large -X- _ O
distribution -X- _ O
differences -X- _ O
of -X- _ O
14Rest -X- _ B-DatasetName
and -X- _ O
15Rest -X- _ B-DatasetName
. -X- _ O
Nevertheless -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
observe -X- _ O
a -X- _ O
different -X- _ O
phenomenon -X- _ O
that -X- _ O
our -X- _ O
ALBERT -X- _ O
- -X- _ O
based -X- _ O
dual -X- _ O
- -X- _ O
encoder -X- _ O
model -X- _ O
achieves -X- _ O
significant -X- _ O
F -X- _ B-MetricName
1 -X- _ I-MetricName
score -X- _ O
improvements -X- _ O
on -X- _ O
14Rest -X- _ B-DatasetName
( -X- _ O
6.66 -X- _ B-MetricValue
) -X- _ O
and -X- _ O
15Rest -X- _ B-DatasetName
( -X- _ O
9.08 -X- _ B-MetricValue
) -X- _ O
, -X- _ O
better -X- _ O
than -X- _ O
14Lap -X- _ B-DatasetName
( -X- _ O
4.72 -X- _ B-MetricValue
) -X- _ O
and -X- _ O
16Rest -X- _ B-DatasetName
( -X- _ O
4.49 -X- _ B-MetricValue
) -X- _ O
, -X- _ O
makes -X- _ O
a -X- _ O
challenge -X- _ O
to -X- _ O
the -X- _ O
explanation -X- _ O
developed -X- _ O
by -X- _ O
. -X- _ O
From -X- _ O
our -X- _ O
perspective -X- _ O
, -X- _ O
it -X- _ O
might -X- _ O
be -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
different -X- _ O
fitting -X- _ O
degree -X- _ O
between -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
ASTE -X- _ B-DatasetName
- -X- _ I-DatasetName
Data -X- _ I-DatasetName
- -X- _ I-DatasetName
V2 -X- _ I-DatasetName
datasets -X- _ O
and -X- _ O
corresponding -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
our -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
ASTE -X- _ B-DatasetName
- -X- _ I-DatasetName
Data -X- _ I-DatasetName
- -X- _ I-DatasetName
V1 -X- _ I-DatasetName
datasets -X- _ O
and -X- _ O
then -X- _ O
experimental -X- _ O
results -X- _ O
further -X- _ O
demonstrate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
dual -X- _ O
- -X- _ O
encoder -X- _ O
model -X- _ O
. -X- _ O
These -X- _ O
results -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
8 -X- _ O
of -X- _ O
the -X- _ O
Appendix -X- _ O
. -X- _ O

Results -X- _ O
on -X- _ O
the -X- _ O
AESC -X- _ B-TaskName
Task -X- _ O

For -X- _ O
the -X- _ O
AESC -X- _ B-TaskName
task -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
will -X- _ O
compare -X- _ O
to -X- _ O
the -X- _ O
following -X- _ O
baselines -X- _ O
: -X- _ O

1 -X- _ O
) -X- _ O
SPAN -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
. -X- _ O

2 -X- _ O
) -X- _ O
IMN -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
. -X- _ O

3 -X- _ O
) -X- _ O
RACL -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
( -X- _ O
Chen -X- _ O
and -X- _ O
Qian -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
4 -X- _ O
) -X- _ O
Mao -X- _ B-MethodName
et -X- _ I-MethodName
al -X- _ I-MethodName
. -X- _ I-MethodName
( -X- _ O
Mao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

To -X- _ O
investigate -X- _ O
whether -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
AESC -X- _ B-TaskName
task -X- _ O
maintains -X- _ O
the -X- _ O
same -X- _ O
efficiency -X- _ O
as -X- _ O
the -X- _ O
ASTE -X- _ B-TaskName
task -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
experiments -X- _ O
on -X- _ O
AESC -X- _ B-TaskName
datasets -X- _ O
. -X- _ O
Results -X- _ O
of -X- _ O
all -X- _ O
the -X- _ O
models -X- _ O
on -X- _ O
the -X- _ O
AESC -X- _ B-TaskName
task -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O
Compared -X- _ O
with -X- _ O
the -X- _ O
best -X- _ O
baseline -X- _ O
model -X- _ O
of -X- _ O
Mao -X- _ B-MethodName
et -X- _ I-MethodName
al -X- _ I-MethodName
. -X- _ I-MethodName
( -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
is -X- _ O
not -X- _ O
comparable -X- _ O
except -X- _ O
for -X- _ O
the -X- _ O
absolute -X- _ O
F -X- _ B-MetricName
1 -X- _ I-MetricName
score -X- _ O
on -X- _ O
AE -X- _ O
and -X- _ O
OE -X- _ O
of -X- _ O
15Rest -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
to -X- _ O
excavate -X- _ O
the -X- _ O
contribution -X- _ O
of -X- _ O
our -X- _ O
dual -X- _ O
- -X- _ O
encoder -X- _ O
structure -X- _ O
on -X- _ O
the -X- _ O
AESC -X- _ B-TaskName
task -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
our -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
baseline -X- _ O
without -X- _ O
the -X- _ O
pair -X- _ O
encoder -X- _ O
. -X- _ O
From -X- _ O
Table -X- _ O
2 -X- _ O
we -X- _ O
can -X- _ O
see -X- _ O
that -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
dual -X- _ O
- -X- _ O
encoder -X- _ O
model -X- _ O
is -X- _ O
comparable -X- _ O
on -X- _ O
the -X- _ O
AESC -X- _ B-TaskName
task -X- _ O
than -X- _ O
single -X- _ O
- -X- _ O
encoder -X- _ O
structure -X- _ O
. -X- _ O
The -X- _ O
AESC -X- _ B-TaskName
task -X- _ O
is -X- _ O
only -X- _ O
a -X- _ O
simplified -X- _ O
version -X- _ O
of -X- _ O
the -X- _ O
ASTE -X- _ B-TaskName
task -X- _ O
without -X- _ O
taking -X- _ O
AT -X- _ O
/ -X- _ O
OT -X- _ O
paring -X- _ O
and -X- _ O
sentiment -X- _ O
polarity -X- _ O
classification -X- _ O
into -X- _ O
consideration -X- _ O
reversely -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
training -X- _ O
objective -X- _ O
of -X- _ O
our -X- _ O
joint -X- _ O
model -X- _ O
with -X- _ O
the -X- _ O
help -X- _ O
of -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
structure -X- _ O
design -X- _ O
. -X- _ O
Consequently -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
is -X- _ O
incapable -X- _ O
of -X- _ O
functioning -X- _ O
well -X- _ O
in -X- _ O
the -X- _ O
AESC -X- _ B-TaskName
task -X- _ O
. -X- _ O

Ablation -X- _ O
Studies -X- _ O

Different -X- _ O
Pre -X- _ O
- -X- _ O
trained -X- _ O
Language -X- _ O
Models -X- _ O

We -X- _ O
conduct -X- _ O
the -X- _ O
experiment -X- _ O
on -X- _ O
the -X- _ O
14Lap -X- _ B-DatasetName
of -X- _ O
ASTE -X- _ B-DatasetName
- -X- _ I-DatasetName
Data -X- _ I-DatasetName
- -X- _ I-DatasetName
V2 -X- _ I-DatasetName
datasets -X- _ O
to -X- _ O
excavate -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
three -X- _ O
frequently -X- _ O
utilized -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
( -X- _ O
PLMs -X- _ O
) -X- _ O
: -X- _ O
XLNet -X- _ B-MethodName
, -X- _ O
RoBERTa -X- _ B-MethodName
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
ALBERT -X- _ B-MethodName
( -X- _ O
Lan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

Table -X- _ O
3 -X- _ O
shows -X- _ O
that -X- _ O
ALBERT -X- _ B-MethodName
helps -X- _ O
achieve -X- _ O
the -X- _ O
best -X- _ O
result -X- _ O
among -X- _ O
these -X- _ O
four -X- _ O
PLMs -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
even -X- _ O
with -X- _ O
BERT -X- _ B-MethodName
as -X- _ O
the -X- _ O
baseline -X- _ O
model -X- _ O
Huang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
also -X- _ O
performs -X- _ O
better -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
notice -X- _ O
that -X- _ O
, -X- _ O
different -X- _ O
from -X- _ O
most -X- _ O
models -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
is -X- _ O
sensitive -X- _ O
to -X- _ O
different -X- _ O
PLMs -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
the -X- _ O
absolute -X- _ O
F -X- _ B-MetricName
1 -X- _ I-MetricName
score -X- _ O
between -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
RoBERTa -X- _ B-MethodName
, -X- _ O
ALBERT -X- _ B-MethodName
is -X- _ O
1.04 -X- _ B-MetricValue
and -X- _ O
4.19 -X- _ B-MetricValue
, -X- _ O
respectively -X- _ O
. -X- _ O
It -X- _ O
demonstrates -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
performance -X- _ O
could -X- _ O
effectively -X- _ O
be -X- _ O
boosted -X- _ O
by -X- _ O
our -X- _ O
choice -X- _ O
of -X- _ O
PLM -X- _ O
, -X- _ O
and -X- _ O
thus -X- _ O
we -X- _ O
choose -X- _ O
ALBERT -X- _ B-MethodName
as -X- _ O
our -X- _ O
base -X- _ O
encoder -X- _ O
. -X- _ O

Dual -X- _ O
- -X- _ O
encoder -X- _ O
Structure -X- _ O

Therefore -X- _ O
, -X- _ O
the -X- _ O
joint -X- _ O
modeling -X- _ O
method -X- _ O
must -X- _ O
take -X- _ O
not -X- _ O
only -X- _ O
the -X- _ O
fitting -X- _ O
degree -X- _ O
between -X- _ O
individual -X- _ O
modules -X- _ O
and -X- _ O
subtasks -X- _ O
but -X- _ O
also -X- _ O
the -X- _ O
difference -X- _ O
of -X- _ O
each -X- _ O
module -X- _ O
into -X- _ O
consideration -X- _ O
. -X- _ O

Number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
Encoder -X- _ I-HyperparameterName
Layers -X- _ I-HyperparameterName

The -X- _ O
results -X- _ O
with -X- _ O
different -X- _ O
numbers -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
encoder -X- _ I-HyperparameterName
layers -X- _ I-HyperparameterName
are -X- _ O
in -X- _ O
Figure -X- _ O
4 -X- _ O
. -X- _ O
Generally -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
triplet -X- _ O
extraction -X- _ O
synchronously -X- _ O
increases -X- _ O
with -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
encoder -X- _ I-HyperparameterName
layers -X- _ I-HyperparameterName
of -X- _ O
both -X- _ O
dataset -X- _ O
distributions -X- _ O
. -X- _ O
Nevertheless -X- _ O
, -X- _ O
when -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
encoder -X- _ I-HyperparameterName
layers -X- _ I-HyperparameterName
exceeds -X- _ O
3 -X- _ B-HyperparameterValue
, -X- _ O
the -X- _ O
performance -X- _ O
shows -X- _ O
a -X- _ O
continuous -X- _ O
decreasing -X- _ O
trend -X- _ O
, -X- _ O
except -X- _ O
that -X- _ O
on -X- _ O
16Rest -X- _ B-DatasetName
when -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
encoder -X- _ I-HyperparameterName
layers -X- _ I-HyperparameterName
is -X- _ O
increased -X- _ O
to -X- _ O
7 -X- _ B-HyperparameterValue
, -X- _ O
the -X- _ O
performance -X- _ O
increases -X- _ O
by -X- _ O
nearly -X- _ O
2.5 -X- _ B-MetricValue
absolute -X- _ O
F -X- _ B-MetricName
1 -X- _ I-MetricName
score -X- _ O
. -X- _ O
Despite -X- _ O
this -X- _ O
inconsistent -X- _ O
phenomenon -X- _ O
, -X- _ O
to -X- _ O
mainly -X- _ O
consider -X- _ O
computational -X- _ O
/ -X- _ O
time -X- _ O
complexities -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
3 -X- _ B-HyperparameterValue
as -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
encoders -X- _ I-HyperparameterName
. -X- _ O

The -X- _ O
Impact -X- _ O
of -X- _ O
The -X- _ O
Number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
GRU -X- _ I-HyperparameterName

Table -X- _ O
5 -X- _ O
shows -X- _ O
the -X- _ O
results -X- _ O
with -X- _ O
different -X- _ O
settings -X- _ O
of -X- _ O
multi -X- _ O
- -X- _ O
dimensional -X- _ O
recurrent -X- _ O
neural -X- _ O
networks -X- _ O
. -X- _ O
The -X- _ O
Uni -X- _ O
- -X- _ O
directional -X- _ O
denotes -X- _ O
the -X- _ O
hidden -X- _ O
state -X- _ O
from -X- _ O
forward -X- _ O
GRU -X- _ O
results -X- _ O
in -X- _ O
one -X- _ O
quadrant -X- _ O
of -X- _ O
same -X- _ O
dimension -X- _ O
space -X- _ O
, -X- _ O
the -X- _ O
Bi -X- _ O
- -X- _ O
directional -X- _ O
denotes -X- _ O
the -X- _ O
hidden -X- _ O
state -X- _ O
from -X- _ O
forward -X- _ O
and -X- _ O
backward -X- _ O
GRU -X- _ O
results -X- _ O
in -X- _ O
two -X- _ O
quadrants -X- _ O
of -X- _ O
same -X- _ O
dimension -X- _ O
space -X- _ O
, -X- _ O
and -X- _ O
Quaddirectional -X- _ O
denotes -X- _ O
the -X- _ O
hidden -X- _ O
state -X- _ O
from -X- _ O
forward -X- _ O
and -X- _ O
backward -X- _ O
GRU -X- _ O
results -X- _ O
in -X- _ O
four -X- _ O
quadrants -X- _ O
of -X- _ O
same -X- _ O
dimension -X- _ O
space -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
Quaddirectional -X- _ O
setting -X- _ O
significantly -X- _ O
outperforms -X- _ O
the -X- _ O
other -X- _ O
two -X- _ O
settings -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
also -X- _ O
noteworthy -X- _ O
that -X- _ O
the -X- _ O
performance -X- _ O
gap -X- _ O
between -X- _ O
Bi -X- _ O
- -X- _ O
directional -X- _ O
and -X- _ O
Unidirectional -X- _ O
dimensions -X- _ O
is -X- _ O
much -X- _ O
lower -X- _ O
than -X- _ O
the -X- _ O
gap -X- _ O
between -X- _ O
Quad -X- _ O
- -X- _ O
directional -X- _ O
and -X- _ O
Bi -X- _ O
- -X- _ O
directional -X- _ O
dimensions -X- _ O
, -X- _ O
which -X- _ O
might -X- _ O
be -X- _ O
the -X- _ O
reason -X- _ O
why -X- _ O
most -X- _ O
previous -X- _ O
work -X- _ O
using -X- _ O
bidirectional -X- _ O
modelings -X- _ O
can -X- _ O
not -X- _ O
perform -X- _ O
well -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
we -X- _ O
choose -X- _ O
Quad -X- _ O
- -X- _ O
directional -X- _ O
as -X- _ O
the -X- _ O
dimensional -X- _ O
setting -X- _ O
of -X- _ O
our -X- _ O
multi -X- _ O
- -X- _ O
dimensional -X- _ O
RNNs -X- _ O
. -X- _ O

The -X- _ O
Effect -X- _ O
of -X- _ O
Character -X- _ O
- -X- _ O
level -X- _ O
Representation -X- _ O

To -X- _ O
investigate -X- _ O
the -X- _ O
contribution -X- _ O
of -X- _ O
character -X- _ O
- -X- _ O
level -X- _ O
representation -X- _ O
to -X- _ O
our -X- _ O
input -X- _ O
sequence -X- _ O
, -X- _ O
we -X- _ O
remove -X- _ O
the -X- _ O
character -X- _ O
- -X- _ O
level -X- _ O
representation -X- _ O
generated -X- _ O
by -X- _ O
LSTM -X- _ O
. -X- _ O
Experimental -X- _ O
result -X- _ O
shows -X- _ O
that -X- _ O
the -X- _ O
performance -X- _ O
decreases -X- _ O
by -X- _ O
0.44 -X- _ B-MetricValue
absolute -X- _ O
F -X- _ B-MetricName
1 -X- _ I-MetricName
score -X- _ O
. -X- _ O

Case -X- _ O
Study -X- _ O

To -X- _ O
investigate -X- _ O
why -X- _ O
our -X- _ O
model -X- _ O
far -X- _ O
exceeds -X- _ O
the -X- _ O
baseline -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
a -X- _ O
case -X- _ O
study -X- _ O
of -X- _ O
three -X- _ O
typical -X- _ O
cases -X- _ O
from -X- _ O
14Lap -X- _ B-DatasetName
test -X- _ O
dataset -X- _ O
of -X- _ O
ASTE -X- _ B-DatasetName
- -X- _ I-DatasetName
Data -X- _ I-DatasetName
- -X- _ I-DatasetName
V2 -X- _ I-DatasetName
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
6 -X- _ O
. -X- _ O

From -X- _ O
Example-1 -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
handle -X- _ O
the -X- _ O
one -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
one -X- _ O
case -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
our -X- _ O
dual -X- _ O
- -X- _ O
encoder -X- _ O
structure -X- _ O
is -X- _ O
more -X- _ O
biased -X- _ O
towards -X- _ O
coordinative -X- _ O
relation -X- _ O
between -X- _ O
colors -X- _ O
and -X- _ O
speedy -X- _ O
. -X- _ O
More -X- _ O
cases -X- _ O
we -X- _ O
investigated -X- _ O
further -X- _ O
demonstrating -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
performs -X- _ O
slightly -X- _ O
worse -X- _ O
on -X- _ O
one -X- _ O
- -X- _ O
toone -X- _ O
than -X- _ O
one -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
many -X- _ O
and -X- _ O
many -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
many -X- _ O
relation -X- _ O
types -X- _ O
. -X- _ O
From -X- _ O
Example-2 -X- _ O
, -X- _ O
we -X- _ O
see -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
can -X- _ O
tackle -X- _ O
the -X- _ O
one -X- _ O
- -X- _ O
opinion -X- _ O
to -X- _ O
many -X- _ O
- -X- _ O
target -X- _ O
problem -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
most -X- _ O
previous -X- _ O
works -X- _ O
are -X- _ O
even -X- _ O
unable -X- _ O
to -X- _ O
tackle -X- _ O
one -X- _ O
- -X- _ O
opinion -X- _ O
to -X- _ O
two -X- _ O
- -X- _ O
target -X- _ O
. -X- _ O
From -X- _ O
Example-3 -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
is -X- _ O
capable -X- _ O
of -X- _ O
well -X- _ O
handling -X- _ O
the -X- _ O
one -X- _ O
- -X- _ O
target -X- _ O
to -X- _ O
many -X- _ O
- -X- _ O
opinion -X- _ O
problem -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
neglected -X- _ O
by -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
existing -X- _ O
work -X- _ O
but -X- _ O
important -X- _ O
for -X- _ O
triplet -X- _ O
extraction -X- _ O
. -X- _ O
Because -X- _ O
many -X- _ O
sentences -X- _ O
compose -X- _ O
conflicting -X- _ O
sentiments -X- _ O
on -X- _ O
target -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
will -X- _ O
fail -X- _ O
to -X- _ O
recognize -X- _ O
the -X- _ O
opposite -X- _ O
polarity -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
AT -X- _ O
when -X- _ O
the -X- _ O
incorrect -X- _ O
AT -X- _ O
extraction -X- _ O
happens -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
observe -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
accurately -X- _ O
inferences -X- _ O
the -X- _ O
boundary -X- _ O
of -X- _ O
OSX -X- _ O
Lion -X- _ O
span -X- _ O
, -X- _ O
which -X- _ O
demonstrates -X- _ O
the -X- _ O
usefulness -X- _ O
of -X- _ O
our -X- _ O
transformation -X- _ O
that -X- _ O
utilizes -X- _ O
span -X- _ O
to -X- _ O
replace -X- _ O
the -X- _ O
word -X- _ O
. -X- _ O
From -X- _ O
Example-4 -X- _ O
, -X- _ O
we -X- _ O
notice -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
could -X- _ O
efficiently -X- _ O
handle -X- _ O
the -X- _ O
complex -X- _ O
situation -X- _ O
of -X- _ O
many -X- _ O
- -X- _ O
opinion -X- _ O
to -X- _ O
many -X- _ O
- -X- _ O
target -X- _ O
with -X- _ O
long -X- _ O
- -X- _ O
range -X- _ O
dependency -X- _ O
, -X- _ O
which -X- _ O
was -X- _ O
particularly -X- _ O
paid -X- _ O
attention -X- _ O
to -X- _ O
but -X- _ O
not -X- _ O
solved -X- _ O
well -X- _ O
by -X- _ O
Zhang -X- _ B-MethodName
et -X- _ I-MethodName
al -X- _ I-MethodName
. -X- _ I-MethodName
( -X- _ O
2020a -X- _ O
) -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
due -X- _ O
to -X- _ O
incorporating -X- _ O
the -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
mechanism -X- _ O
and -X- _ O
GRU -X- _ O
in -X- _ O
two -X- _ O
dimensions -X- _ O
, -X- _ O
and -X- _ O
our -X- _ O
model -X- _ O
is -X- _ O
sensitive -X- _ O
to -X- _ O
the -X- _ O
difference -X- _ O
between -X- _ O
the -X- _ O
proposed -X- _ O
dual -X- _ O
- -X- _ O
encoder -X- _ O
architecture -X- _ O
. -X- _ O
Collectively -X- _ O
, -X- _ O
these -X- _ O
aforementioned -X- _ O
cases -X- _ O
demonstrate -X- _ O
the -X- _ O
robustness -X- _ O
of -X- _ O
our -X- _ O
dual -X- _ O
- -X- _ O
encoder -X- _ O
model -X- _ O
. -X- _ O

Related -X- _ O
Work -X- _ O

Recently -X- _ O
, -X- _ O
NLP -X- _ O
has -X- _ O
been -X- _ O
developed -X- _ O
rapidly -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019b -X- _ O
; -X- _ O
Jiang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
process -X- _ O
is -X- _ O
further -X- _ O
by -X- _ O
deep -X- _ O
neural -X- _ O
networks -X- _ O
( -X- _ O
Parnow -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021a -X- _ O
) -X- _ O
and -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021b -X- _ O
; -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
. -X- _ O
Aspect -X- _ O
- -X- _ O
based -X- _ O
sentiment -X- _ O
analysis -X- _ O
was -X- _ O
proposed -X- _ O
by -X- _ O
Pontiki -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2014 -X- _ O
) -X- _ O
and -X- _ O
also -X- _ O
received -X- _ O
lots -X- _ O
of -X- _ O
attention -X- _ O
in -X- _ O
recent -X- _ O
years -X- _ O
. -X- _ O

ASTE -X- _ B-TaskName
Task -X- _ O

The -X- _ O
ASTE -X- _ B-TaskName
task -X- _ O
aims -X- _ O
to -X- _ O
make -X- _ O
triplet -X- _ O
extraction -X- _ O
of -X- _ O
aspect -X- _ O
terms -X- _ O
, -X- _ O
opinion -X- _ O
terms -X- _ O
, -X- _ O
and -X- _ O
sentiment -X- _ O
polarity -X- _ O
, -X- _ O
which -X- _ O
was -X- _ O
introduced -X- _ O
by -X- _ O
Peng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
their -X- _ O
work -X- _ O
, -X- _ O
they -X- _ O
leveraged -X- _ O
the -X- _ O
sequence -X- _ O
labeling -X- _ O
method -X- _ O
to -X- _ O
extract -X- _ O
aspect -X- _ O
terms -X- _ O
and -X- _ O
target -X- _ O
sentiment -X- _ O
and -X- _ O
utilized -X- _ O
graph -X- _ O
neural -X- _ O
networks -X- _ O
to -X- _ O
detect -X- _ O
candidate -X- _ O
opinion -X- _ O
terms -X- _ O
. -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020a -X- _ O
) -X- _ O
proposed -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
framework -X- _ O
that -X- _ O
decomposes -X- _ O
the -X- _ O
original -X- _ O
ASTE -X- _ B-TaskName
task -X- _ O
into -X- _ O
two -X- _ O
subtasks -X- _ O
, -X- _ O
sequence -X- _ O
tagging -X- _ O
of -X- _ O
AT -X- _ O
/ -X- _ O
OT -X- _ O
, -X- _ O
and -X- _ O
word -X- _ O
pair -X- _ O
dependency -X- _ O
parsing -X- _ O
. -X- _ O
For -X- _ O
joint -X- _ O
learning -X- _ O
, -X- _ O
proposed -X- _ O
a -X- _ O
sequence -X- _ O
tagging -X- _ O
framework -X- _ O
based -X- _ O
on -X- _ O
LSTM -X- _ O
- -X- _ O
CRF -X- _ O
. -X- _ O
constructed -X- _ O
an -X- _ O
encoder -X- _ O
- -X- _ O
decoder -X- _ O
model -X- _ O
to -X- _ O
handle -X- _ O
this -X- _ O
task -X- _ O
with -X- _ O
grid -X- _ O
representation -X- _ O
of -X- _ O
aspectopinion -X- _ O
pairs -X- _ O
. -X- _ O
Then -X- _ O
with -X- _ O
the -X- _ O
incorporation -X- _ O
of -X- _ O
a -X- _ O
more -X- _ O
specific -X- _ O
semantic -X- _ O
information -X- _ O
guide -X- _ O
for -X- _ O
the -X- _ O
proposed -X- _ O
model -X- _ O
, -X- _ O
the -X- _ O
ASTE -X- _ B-TaskName
is -X- _ O
transformed -X- _ O
as -X- _ O
MRC -X- _ O
task -X- _ O
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Mao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Recently -X- _ O
, -X- _ O
Huang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
proposed -X- _ O
a -X- _ O
sequence -X- _ O
taggingbased -X- _ O
model -X- _ O
to -X- _ O
perform -X- _ O
representation -X- _ O
learning -X- _ O
on -X- _ O
the -X- _ O
ASTE -X- _ B-TaskName
task -X- _ O
. -X- _ O

AESC -X- _ B-TaskName
Task -X- _ O

The -X- _ O
AESC -X- _ B-TaskName
task -X- _ O
is -X- _ O
to -X- _ O
perform -X- _ O
aspect -X- _ O
terms -X- _ O
extraction -X- _ O
and -X- _ O
sentiment -X- _ O
classification -X- _ O
simultaneously -X- _ O
. -X- _ O
and -X- _ O
used -X- _ O
a -X- _ O
span -X- _ O
- -X- _ O
level -X- _ O
sequence -X- _ O
tagging -X- _ O
method -X- _ O
to -X- _ O
tackle -X- _ O
huge -X- _ O
search -X- _ O
space -X- _ O
and -X- _ O
sentiment -X- _ O
inconsistency -X- _ O
problems -X- _ O
. -X- _ O
Although -X- _ O
the -X- _ O
huge -X- _ O
search -X- _ O
space -X- _ O
issue -X- _ O
has -X- _ O
been -X- _ O
solved -X- _ O
by -X- _ O
, -X- _ O
there -X- _ O
still -X- _ O
exists -X- _ O
a -X- _ O
lowperformance -X- _ O
problem -X- _ O
. -X- _ O
Addressing -X- _ O
this -X- _ O
issue -X- _ O
, -X- _ O
Lin -X- _ O
and -X- _ O
Yang -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
utilized -X- _ O
a -X- _ O
BERT -X- _ B-MethodName
encoder -X- _ O
to -X- _ O
contextualize -X- _ O
shared -X- _ O
information -X- _ O
of -X- _ O
target -X- _ O
extraction -X- _ O
and -X- _ O
target -X- _ O
classification -X- _ O
subtasks -X- _ O
. -X- _ O
Meanwhile -X- _ O
, -X- _ O
they -X- _ O
used -X- _ O
two -X- _ O
BiLSTM -X- _ O
networks -X- _ O
to -X- _ O
encode -X- _ O
the -X- _ O
private -X- _ O
information -X- _ O
of -X- _ O
each -X- _ O
subtask -X- _ O
, -X- _ O
which -X- _ O
greatly -X- _ O
boosted -X- _ O
the -X- _ O
model -X- _ O
performance -X- _ O
. -X- _ O

Dual -X- _ O
- -X- _ O
encoder -X- _ O
Structure -X- _ O

Productive -X- _ O
efforts -X- _ O
were -X- _ O
put -X- _ O
into -X- _ O
the -X- _ O
research -X- _ O
of -X- _ O
dual -X- _ O
- -X- _ O
encoder -X- _ O
structure -X- _ O
for -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
tasks -X- _ O
in -X- _ O
the -X- _ O
last -X- _ O
few -X- _ O
years -X- _ O
because -X- _ O
of -X- _ O
the -X- _ O
Example-1 -X- _ O
Also -X- _ O
stunning -X- _ O
colors -X- _ O
and -X- _ O
speedy -X- _ O
. -X- _ O
Table -X- _ O
6 -X- _ O
: -X- _ O
Case -X- _ O
study -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
model -X- _ O
, -X- _ O
where -X- _ O
AT -X- _ O
/ -X- _ O
OT -X- _ O
denote -X- _ O
aspect -X- _ O
term -X- _ O
/ -X- _ O
opinion -X- _ O
term -X- _ O
, -X- _ O
POS -X- _ O
denotes -X- _ O
sensitive -X- _ O
polarity -X- _ O
of -X- _ O
positive -X- _ O
, -X- _ O
the -X- _ O
subscript -X- _ O
of -X- _ O
sensitive -X- _ O
polarity -X- _ O
h -X- _ O
1 -X- _ O
/ -X- _ O
t -X- _ O
1 -X- _ O
denotes -X- _ O
the -X- _ O
head -X- _ O
/ -X- _ O
tail -X- _ O
term -X- _ O
of -X- _ O
the -X- _ O
1st -X- _ O
pair -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
corresponding -X- _ O
sentiment -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O

natural -X- _ O
ability -X- _ O
to -X- _ O
model -X- _ O
representational -X- _ O
similarity -X- _ O
maximization -X- _ O
associated -X- _ O
tasks -X- _ O
( -X- _ O
Chidambaram -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Yu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Bhowmik -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Generally -X- _ O
, -X- _ O
these -X- _ O
approaches -X- _ O
encoded -X- _ O
a -X- _ O
single -X- _ O
component -X- _ O
of -X- _ O
the -X- _ O
corresponding -X- _ O
task -X- _ O
separately -X- _ O
for -X- _ O
the -X- _ O
processing -X- _ O
in -X- _ O
the -X- _ O
next -X- _ O
phase -X- _ O
. -X- _ O
Recently -X- _ O
, -X- _ O
Wang -X- _ O
and -X- _ O
Lu -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
proposed -X- _ O
a -X- _ O
sequence -X- _ O
- -X- _ O
table -X- _ O
representation -X- _ O
learning -X- _ O
architecture -X- _ O
for -X- _ O
a -X- _ O
typical -X- _ O
triplet -X- _ O
extraction -X- _ O
task -X- _ O
: -X- _ O
relation -X- _ O
extraction -X- _ O
, -X- _ O
and -X- _ O
this -X- _ O
work -X- _ O
established -X- _ O
an -X- _ O
example -X- _ O
of -X- _ O
tackling -X- _ O
the -X- _ O
triplet -X- _ O
extraction -X- _ O
task -X- _ O
with -X- _ O
the -X- _ O
dual -X- _ O
- -X- _ O
encoder -X- _ O
based -X- _ O
architecture -X- _ O
. -X- _ O

Conclusion -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
the -X- _ O
significant -X- _ O
differences -X- _ O
between -X- _ O
the -X- _ O
AT -X- _ O
/ -X- _ O
OT -X- _ O
extraction -X- _ O
subtask -X- _ O
and -X- _ O
the -X- _ O
SC -X- _ O
subtask -X- _ O
of -X- _ O
ABSA -X- _ B-TaskName
for -X- _ O
the -X- _ O
joint -X- _ O
model -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
the -X- _ O
results -X- _ O
on -X- _ O
8 -X- _ O
benchmark -X- _ O
datasets -X- _ O
with -X- _ O
significant -X- _ O
improvement -X- _ O
over -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
baselines -X- _ O
verify -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
model -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
to -X- _ O
distinguish -X- _ O
such -X- _ O
differences -X- _ O
and -X- _ O
keep -X- _ O
the -X- _ O
shared -X- _ O
part -X- _ O
between -X- _ O
different -X- _ O
modules -X- _ O
simultaneously -X- _ O
, -X- _ O
we -X- _ O
construct -X- _ O
a -X- _ O
dual -X- _ O
- -X- _ O
encoder -X- _ O
framework -X- _ O
with -X- _ O
representation -X- _ O
learning -X- _ O
and -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
mechanism -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
to -X- _ O
the -X- _ O
encoder -X- _ O
- -X- _ O
sharing -X- _ O
approach -X- _ O
, -X- _ O
our -X- _ O
dual -X- _ O
- -X- _ O
encoder -X- _ O
framework -X- _ O
can -X- _ O
capture -X- _ O
the -X- _ O
difference -X- _ O
between -X- _ O
the -X- _ O
subtasks -X- _ O
by -X- _ O
interconnecting -X- _ O
encoders -X- _ O
at -X- _ O
each -X- _ O
layer -X- _ O
to -X- _ O
share -X- _ O
the -X- _ O
critical -X- _ O
information -X- _ O
. -X- _ O

Acknowledgement -X- _ O

We -X- _ O
appreciate -X- _ O
Wang -X- _ O
and -X- _ O
Lu -X- _ O
for -X- _ O
their -X- _ O
provided -X- _ O
open -X- _ O
resource -X- _ O
. -X- _ O
Based -X- _ O
on -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
conducted -X- _ O
our -X- _ O
work -X- _ O
on -X- _ O
ABSA -X- _ B-TaskName
. -X- _ O
We -X- _ O
also -X- _ O
appreciate -X- _ O
the -X- _ O
help -X- _ O
from -X- _ O
the -X- _ O
reviewers -X- _ O
and -X- _ O
program -X- _ O
chairs -X- _ O
. -X- _ O

A -X- _ O
Additional -X- _ O
Results -X- _ O

A.1 -X- _ O
Evaluation -X- _ O
Metric -X- _ O

We -X- _ O
adopt -X- _ O
F -X- _ B-MetricName
1 -X- _ I-MetricName
score -X- _ O
as -X- _ O
our -X- _ O
evaluation -X- _ O
metric -X- _ O
as -X- _ O
other -X- _ O
baseline -X- _ O
models -X- _ O
. -X- _ O
In -X- _ O
precise -X- _ O
, -X- _ O
we -X- _ O
measure -X- _ O
the -X- _ O
F1 -X- _ O
score -X- _ O
calculated -X- _ O
between -X- _ O
the -X- _ O
final -X- _ O
exact -X- _ O
match -X- _ O
of -X- _ O
AT -X- _ O
/ -X- _ O
OT -X- _ O
span -X- _ O
, -X- _ O
AT -X- _ O
/ -X- _ O
OT -X- _ O
types -X- _ O
and -X- _ O
corresponding -X- _ O
polarity -X- _ O
predictions -X- _ O
and -X- _ O
gold -X- _ O
triplets -X- _ O
. -X- _ O

A.2 -X- _ O
Implementation -X- _ O
Details -X- _ O

For -X- _ O
the -X- _ O
token -X- _ O
representation -X- _ O
, -X- _ O
we -X- _ O
utilize -X- _ O
100dimensional -X- _ O
GloVe -X- _ O
( -X- _ O
Pennington -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O

A.3 -X- _ O
Baselines -X- _ O

Our -X- _ O
model -X- _ O
will -X- _ O
compare -X- _ O
to -X- _ O
the -X- _ O
following -X- _ O
baselines -X- _ O
on -X- _ O
the -X- _ O
ASTE -X- _ B-TaskName
task -X- _ O
. -X- _ O
1 -X- _ O
) -X- _ O
RINANTE+ -X- _ B-MethodName
( -X- _ O
Peng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
RINANTE -X- _ B-MethodName
is -X- _ O
modified -X- _ O
from -X- _ O
that -X- _ O
by -X- _ O
Ma -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
RINANTE+ -X- _ B-MethodName
is -X- _ O
an -X- _ O
LSTM -X- _ O
- -X- _ O
CRF -X- _ O
model -X- _ O
which -X- _ O
first -X- _ O
uses -X- _ O
dependency -X- _ O
relations -X- _ O
of -X- _ O
words -X- _ O
to -X- _ O
extract -X- _ O
opinion -X- _ O
and -X- _ O
aspects -X- _ O
with -X- _ O
the -X- _ O
sentiment -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
all -X- _ O
the -X- _ O
candidate -X- _ O
aspect -X- _ O
- -X- _ O
opinion -X- _ O
pairs -X- _ O
with -X- _ O
position -X- _ O
embedding -X- _ O
are -X- _ O
fed -X- _ O
into -X- _ O
the -X- _ O
Bi -X- _ O
- -X- _ O
LSTM -X- _ O
encoder -X- _ O
to -X- _ O
make -X- _ O
a -X- _ O
final -X- _ O
classification -X- _ O
. -X- _ O

2 -X- _ O
) -X- _ O
CMLA+ -X- _ B-MethodName
( -X- _ O
Peng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
is -X- _ O
adjusted -X- _ O
from -X- _ O
the -X- _ O
one -X- _ O
by -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
an -X- _ O
attention -X- _ O
- -X- _ O
based -X- _ O
model -X- _ O
, -X- _ O
following -X- _ O
the -X- _ O
same -X- _ O
two -X- _ O
- -X- _ O
stage -X- _ O
processing -X- _ O
with -X- _ O
dependency -X- _ O
relations -X- _ O
as -X- _ O
RINANTE+ -X- _ B-MethodName
. -X- _ O

3 -X- _ O
) -X- _ O
Li -X- _ B-MethodName
- -X- _ I-MethodName
unified -X- _ I-MethodName
- -X- _ I-MethodName
R -X- _ I-MethodName
( -X- _ O
Peng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Li -X- _ B-MethodName
- -X- _ I-MethodName
unified -X- _ I-MethodName
- -X- _ I-MethodName
R -X- _ I-MethodName
utilizes -X- _ O
a -X- _ O
modulated -X- _ O
multi -X- _ O
- -X- _ O
layer -X- _ O
LSTM -X- _ O
encoder -X- _ O
by -X- _ O
Li -X- _ O
and -X- _ O
Lu -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
adopts -X- _ O
the -X- _ O
same -X- _ O
aspectopinion -X- _ O
pair -X- _ O
classification -X- _ O
as -X- _ O
RINANTE+ -X- _ B-MethodName
. -X- _ O

4 -X- _ O
) -X- _ O
Peng -X- _ B-MethodName
et -X- _ I-MethodName
al -X- _ I-MethodName
. -X- _ I-MethodName
( -X- _ O
Peng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
model -X- _ O
adopts -X- _ O
GCN -X- _ O
to -X- _ O
capture -X- _ O
dependency -X- _ O
information -X- _ O
, -X- _ O
and -X- _ O
at -X- _ O
the -X- _ O
second -X- _ O
stage -X- _ O
, -X- _ O
uses -X- _ O
the -X- _ O
same -X- _ O
strategy -X- _ O
of -X- _ O
RINANTE+ -X- _ B-MethodName
to -X- _ O
fulfill -X- _ O
triplet -X- _ O
extraction -X- _ O
. -X- _ O

5 -X- _ O
) -X- _ O
OTE -X- _ B-MethodName
- -X- _ I-MethodName
MTL -X- _ I-MethodName
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
. -X- _ O
A -X- _ O
multitask -X- _ O
learning -X- _ O
approach -X- _ O
that -X- _ O
incorporates -X- _ O
word -X- _ O
dependency -X- _ O
parsing -X- _ O
boosts -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
triplet -X- _ O
extraction -X- _ O
. -X- _ O

6 -X- _ O
) -X- _ O
JET -X- _ B-MethodName
. -X- _ O
This -X- _ O
model -X- _ O
jointly -X- _ O
extracts -X- _ O
all -X- _ O
the -X- _ O
subtasks -X- _ O
through -X- _ O
a -X- _ O
unified -X- _ O
sequence -X- _ O
labeling -X- _ O
method -X- _ O
. -X- _ O
JET -X- _ B-MethodName
t -X- _ I-MethodName
and -X- _ O
JET -X- _ B-MethodName
o -X- _ O
denote -X- _ O
two -X- _ O
different -X- _ O
tagging -X- _ O
forms -X- _ O
. -X- _ O
7 -X- _ O
) -X- _ O
GTS -X- _ B-MethodName
. -X- _ O
A -X- _ O
sequence -X- _ O
tagging -X- _ O
model -X- _ O
leverages -X- _ O
the -X- _ O
property -X- _ O
element -X- _ O
upper -X- _ O
triangular -X- _ O
matrix -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
extraction -X- _ O
of -X- _ O
aspect -X- _ O
and -X- _ O
opinion -X- _ O
terms -X- _ O
. -X- _ O

8 -X- _ O
) -X- _ O
Huang -X- _ B-MethodName
et -X- _ I-MethodName
al -X- _ I-MethodName
. -X- _ I-MethodName
( -X- _ O
Huang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
latest -X- _ O
sequence -X- _ O
labeling -X- _ O
model -X- _ O
which -X- _ O
utilizes -X- _ O
the -X- _ O
restricted -X- _ O
attention -X- _ O
field -X- _ O
mechanism -X- _ O
and -X- _ O
represents -X- _ O
word -X- _ O
- -X- _ O
word -X- _ O
perceivable -X- _ O
pairs -X- _ O
for -X- _ O
the -X- _ O
final -X- _ O
classification -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
AESC -X- _ B-TaskName
task -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
will -X- _ O
compare -X- _ O
to -X- _ O
the -X- _ O
following -X- _ O
baselines -X- _ O
: -X- _ O

1 -X- _ O
) -X- _ O
SPAN -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
. -X- _ O
It -X- _ O
is -X- _ O
a -X- _ O
BERTbased -X- _ O
model -X- _ O
which -X- _ O
utilizes -X- _ O
span -X- _ O
representation -X- _ O
to -X- _ O
perform -X- _ O
the -X- _ O
AESC -X- _ B-TaskName
task -X- _ O
. -X- _ O

2 -X- _ O
) -X- _ O
IMN -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
. -X- _ O
It -X- _ O
is -X- _ O
a -X- _ O
multi -X- _ O
task -X- _ O
learning -X- _ O
model -X- _ O
modified -X- _ O
by -X- _ O
and -X- _ O
utilizes -X- _ O
BERT -X- _ O
as -X- _ O
encoder -X- _ O
to -X- _ O
perform -X- _ O
aspect -X- _ O
term -X- _ O
extraction -X- _ O
and -X- _ O
sentiment -X- _ O
classification -X- _ O
. -X- _ O

3 -X- _ O
) -X- _ O
RACL -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
( -X- _ O
Chen -X- _ O
and -X- _ O
Qian -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
layer -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
learning -X- _ O
model -X- _ O
with -X- _ O
mutual -X- _ O
information -X- _ O
propagation -X- _ O
to -X- _ O
boost -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
AESC -X- _ B-TaskName
task -X- _ O
. -X- _ O

4 -X- _ O
) -X- _ O
Mao -X- _ B-MethodName
et -X- _ I-MethodName
al -X- _ I-MethodName
. -X- _ I-MethodName
( -X- _ O
Mao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
a -X- _ O
dual -X- _ O
- -X- _ O
MRC -X- _ O
architecture -X- _ O
model -X- _ O
to -X- _ O
detect -X- _ O
the -X- _ O
AT -X- _ O
/ -X- _ O
OT -X- _ O
and -X- _ O
corresponding -X- _ O
sentiment -X- _ O
polarity -X- _ O
by -X- _ O
means -X- _ O
of -X- _ O
a -X- _ O
two -X- _ O
- -X- _ O
round -X- _ O
query -X- _ O
answering -X- _ O
approach -X- _ O
. -X- _ O

A.4 -X- _ O
Results -X- _ O
on -X- _ O
ASTE -X- _ B-DatasetName
- -X- _ I-DatasetName
Data -X- _ I-DatasetName
- -X- _ I-DatasetName
V1 -X- _ I-DatasetName
for -X- _ O
ASTE -X- _ B-TaskName

Results -X- _ O
on -X- _ O
the -X- _ O
ASTE -X- _ B-DatasetName
- -X- _ I-DatasetName
Data -X- _ I-DatasetName
- -X- _ I-DatasetName
V1 -X- _ I-DatasetName
datasets -X- _ O
also -X- _ O
show -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
. -X- _ O
But -X- _ O
there -X- _ O
is -X- _ O
an -X- _ O
interesting -X- _ O
phenomenon -X- _ O
that -X- _ O
on -X- _ O
the -X- _ O
16Rest -X- _ B-DatasetName
test -X- _ O
set -X- _ O
, -X- _ O
the -X- _ O
result -X- _ O
of -X- _ O
ALBERT -X- _ B-MethodName
- -X- _ O
based -X- _ O
model -X- _ O
is -X- _ O
lower -X- _ O
than -X- _ O
that -X- _ O
of -X- _ O
BERT -X- _ O
- -X- _ O
based -X- _ O
model -X- _ O
. -X- _ O
It -X- _ O
may -X- _ O
be -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
inconsistent -X- _ O
domain -X- _ O
between -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
and -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
model -X- _ O
. -X- _ O

A.5 -X- _ O
Data -X- _ O
Statistics -X- _ O

Table -X- _ O
9 -X- _ O
and -X- _ O
Table -X- _ O
10 -X- _ O
show -X- _ O
the -X- _ O
statistics -X- _ O
of -X- _ O
the -X- _ O
datasets -X- _ O
we -X- _ O
used -X- _ O
. -X- _ O

