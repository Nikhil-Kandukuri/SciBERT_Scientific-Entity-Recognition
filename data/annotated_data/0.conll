-DOCSTART- -X- O
Rethinking -X- _ O
the -X- _ O
Role -X- _ O
of -X- _ O
Scale -X- _ O
for -X- _ O
In -X- _ O
- -X- _ O
Context -X- _ O
Learning -X- _ O
: -X- _ O
An -X- _ O
Interpretability -X- _ O
- -X- _ O
based -X- _ O
Case -X- _ O
Study -X- _ O
at -X- _ O
66 -X- _ O
Billion -X- _ O
Scale -X- _ O

Language -X- _ O
models -X- _ O
have -X- _ O
been -X- _ O
shown -X- _ O
to -X- _ O
perform -X- _ O
better -X- _ O
with -X- _ O
an -X- _ O
increase -X- _ O
in -X- _ O
scale -X- _ O
on -X- _ O
a -X- _ O
wide -X- _ O
variety -X- _ O
of -X- _ O
tasks -X- _ O
via -X- _ O
the -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
paradigm -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
investigate -X- _ O
the -X- _ O
hypothesis -X- _ O
that -X- _ O
the -X- _ O
ability -X- _ O
of -X- _ O
a -X- _ O
large -X- _ O
language -X- _ O
model -X- _ O
to -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learn -X- _ O
- -X- _ O
perform -X- _ O
a -X- _ O
task -X- _ O
is -X- _ O
not -X- _ O
uniformly -X- _ O
spread -X- _ O
across -X- _ O
all -X- _ O
of -X- _ O
its -X- _ O
underlying -X- _ O
components -X- _ O
. -X- _ O
Using -X- _ O
a -X- _ O
66 -X- _ B-MethodName
billion -X- _ I-MethodName
parameter -X- _ I-MethodName
language -X- _ I-MethodName
model -X- _ I-MethodName
( -X- _ O
OPT-66B -X- _ B-MethodName
) -X- _ O
across -X- _ O
a -X- _ O
diverse -X- _ O
set -X- _ O
of -X- _ O
14 -X- _ O
downstream -X- _ O
tasks -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
this -X- _ O
is -X- _ O
indeed -X- _ O
the -X- _ O
case -X- _ O
: -X- _ O
∼70 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
attention -X- _ O
heads -X- _ O
and -X- _ O
∼20 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
feed -X- _ O
forward -X- _ O
networks -X- _ O
can -X- _ O
be -X- _ O
removed -X- _ O
with -X- _ O
minimal -X- _ O
decline -X- _ O
in -X- _ O
task -X- _ O
performance -X- _ O
. -X- _ O
We -X- _ O
find -X- _ O
substantial -X- _ O
overlap -X- _ O
in -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
attention -X- _ O
heads -X- _ O
( -X- _ O
un -X- _ O
) -X- _ O
important -X- _ O
for -X- _ O
incontext -X- _ O
learning -X- _ O
across -X- _ O
tasks -X- _ O
and -X- _ O
number -X- _ O
of -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
examples -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
address -X- _ O
our -X- _ O
hypothesis -X- _ O
through -X- _ O
a -X- _ O
task -X- _ O
- -X- _ O
agnostic -X- _ O
lens -X- _ O
, -X- _ O
finding -X- _ O
that -X- _ O
a -X- _ O
small -X- _ O
set -X- _ O
of -X- _ O
attention -X- _ O
heads -X- _ O
in -X- _ O
OPT-66B -X- _ B-MethodName
score -X- _ O
highly -X- _ O
on -X- _ O
their -X- _ O
ability -X- _ O
to -X- _ O
perform -X- _ O
primitive -X- _ O
induction -X- _ O
operations -X- _ O
associated -X- _ O
with -X- _ O
incontext -X- _ O
learning -X- _ O
, -X- _ O
namely -X- _ O
, -X- _ O
prefix -X- _ O
matching -X- _ O
and -X- _ O
copying -X- _ O
. -X- _ O
These -X- _ O
induction -X- _ O
heads -X- _ O
overlap -X- _ O
with -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
important -X- _ O
heads -X- _ O
, -X- _ O
reinforcing -X- _ O
arguments -X- _ O
by -X- _ O
Olsson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
regarding -X- _ O
induction -X- _ O
head -X- _ O
generality -X- _ O
to -X- _ O
more -X- _ O
sophisticated -X- _ O
behaviors -X- _ O
associated -X- _ O
with -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
. -X- _ O
Overall -X- _ O
, -X- _ O
our -X- _ O
study -X- _ O
provides -X- _ O
several -X- _ O
insights -X- _ O
that -X- _ O
indicate -X- _ O
large -X- _ O
language -X- _ O
models -X- _ O
may -X- _ O
be -X- _ O
undertrained -X- _ O
for -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
and -X- _ O
opens -X- _ O
up -X- _ O
questions -X- _ O
on -X- _ O
how -X- _ O
to -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
language -X- _ O
models -X- _ O
to -X- _ O
more -X- _ O
effectively -X- _ O
perform -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
. -X- _ O

Introduction -X- _ O

In -X- _ O
recent -X- _ O
years -X- _ O
, -X- _ O
large -X- _ O
language -X- _ O
models -X- _ O
( -X- _ O
LLMs -X- _ O
) -X- _ O
Rae -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Lieber -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Black -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
; -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
; -X- _ O
Chowdhery -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
; -X- _ O
Hoffmann -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
; -X- _ O
Smith -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
Transformer -X- _ O
architecture -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
using -X- _ O
self -X- _ O
- -X- _ O
supervision -X- _ O
on -X- _ O
web -X- _ O
- -X- _ O
scale -X- _ O
textual -X- _ O
corpora -X- _ O
have -X- _ O
revolutionized -X- _ O
the -X- _ O
field -X- _ O
of -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
( -X- _ O
NLP -X- _ O
) -X- _ O
. -X- _ O
At -X- _ O
larger -X- _ O
scales -X- _ O
, -X- _ O
these -X- _ O
models -X- _ O
demonstrate -X- _ O
remarkable -X- _ O
emergent -X- _ O
( -X- _ O
Wei -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
prowess -X- _ O
in -X- _ O
performing -X- _ O
a -X- _ O
wide -X- _ O
variety -X- _ O
of -X- _ O
tasks -X- _ O
without -X- _ O
any -X- _ O
form -X- _ O
of -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
, -X- _ O
via -X- _ O
the -X- _ O
zero -X- _ O
/ -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
incontext -X- _ O
learning -X- _ O
paradigm -X- _ O
. -X- _ O
How -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
works -X- _ O
has -X- _ O
been -X- _ O
an -X- _ O
open -X- _ O
question -X- _ O
since -X- _ O
its -X- _ O
advent -X- _ O
and -X- _ O
recent -X- _ O
studies -X- _ O
( -X- _ O
Xie -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Garg -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
; -X- _ O
Olsson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
; -X- _ O
Min -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022b -X- _ O
) -X- _ O
have -X- _ O
begun -X- _ O
scratching -X- _ O
the -X- _ O
surface -X- _ O
toward -X- _ O
better -X- _ O
understanding -X- _ O
the -X- _ O
paradigm -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
empirically -X- _ O
address -X- _ O
the -X- _ O
following -X- _ O
key -X- _ O
question -X- _ O
: -X- _ O
Are -X- _ O
all -X- _ O
LLM -X- _ O
components -X- _ O
really -X- _ O
needed -X- _ O
to -X- _ O
perform -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
? -X- _ O

The -X- _ O
first -X- _ O
way -X- _ O
we -X- _ O
address -X- _ O
the -X- _ O
aforementioned -X- _ O
question -X- _ O
is -X- _ O
through -X- _ O
the -X- _ O
lens -X- _ O
of -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
importance -X- _ B-MetricName
scores -X- _ O
and -X- _ O
structured -X- _ O
pruning -X- _ O
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Molchanov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Anwar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
of -X- _ O
components -X- _ O
underlying -X- _ O
modern -X- _ O
LLMs -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
primarily -X- _ O
stacks -X- _ O
composed -X- _ O
of -X- _ O
multiple -X- _ O
highdimensional -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
blocks -X- _ O
that -X- _ O
form -X- _ O
multiheaded -X- _ O
attention -X- _ O
and -X- _ O
densely -X- _ O
activated -X- _ O
feed -X- _ O
forward -X- _ O
networks -X- _ O
( -X- _ O
FFNs -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
pick -X- _ O
the -X- _ O
Open -X- _ B-MethodName
Pretrained -X- _ I-MethodName
Transformer -X- _ I-MethodName
( -X- _ O
OPT -X- _ B-MethodName
) -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
model -X- _ O
with -X- _ O
66B -X- _ O
parameters -X- _ O
for -X- _ O
our -X- _ O
analyses -X- _ O
, -X- _ O
which -X- _ O
yield -X- _ O
several -X- _ O
surprising -X- _ O
observations -X- _ O
. -X- _ O
We -X- _ O
find -X- _ O
that -X- _ O
important -X- _ O
attention -X- _ O
heads -X- _ O
are -X- _ O
primarily -X- _ O
clustered -X- _ O
in -X- _ O
the -X- _ O
intermediate -X- _ O
layers -X- _ O
and -X- _ O
important -X- _ O
FFNs -X- _ O
are -X- _ O
primarily -X- _ O
in -X- _ O
later -X- _ O
layers -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
( -X- _ O
§ -X- _ O
4 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
ability -X- _ O
to -X- _ O
perform -X- _ O
zero -X- _ O
/ -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
on -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
14 -X- _ O
NLP -X- _ O
datasets -X- _ O
/ -X- _ O
tasks -X- _ O
stays -X- _ O
nearly -X- _ O
intact -X- _ O
when -X- _ O
up -X- _ O
to -X- _ O
70 -X- _ O
% -X- _ O
( -X- _ O
∼15.7B -X- _ O
parameters -X- _ O
in -X- _ O
OPT-66B -X- _ B-MethodName
) -X- _ O
of -X- _ O
the -X- _ O
attention -X- _ O
heads -X- _ O
are -X- _ O
removed -X- _ O
( -X- _ O
§ -X- _ O
5.1 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
attention -X- _ O
heads -X- _ O
that -X- _ O
are -X- _ O
( -X- _ O
un -X- _ O
) -X- _ O
important -X- _ O
for -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
also -X- _ O
seem -X- _ O
to -X- _ O
overlap -X- _ O
across -X- _ O
tasks -X- _ O
( -X- _ O
§ -X- _ O
6.1 -X- _ O
) -X- _ O
and -X- _ O
shots -X- _ O
( -X- _ O
§ -X- _ O
6.2 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
pruning -X- _ O
attention -X- _ O
heads -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
" -X- _ O
universal -X- _ O
" -X- _ O
importance -X- _ O
order -X- _ O
computed -X- _ O
using -X- _ O
all -X- _ O
14 -X- _ O
datasets -X- _ O
generalizes -X- _ O
to -X- _ O
varying -X- _ O
degrees -X- _ O
on -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
distribution -X- _ O
datasets -X- _ O
( -X- _ O
§ -X- _ O
6.1.2 -X- _ O
) -X- _ O
. -X- _ O
These -X- _ O
observations -X- _ O
indicate -X- _ O
that -X- _ O
a -X- _ O
common -X- _ O
taskagnostic -X- _ O
subset -X- _ O
of -X- _ O
the -X- _ O
attention -X- _ O
heads -X- _ O
are -X- _ O
responsible -X- _ O
for -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
find -X- _ O
that -X- _ O
only -X- _ O
up -X- _ O
to -X- _ O
20 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
FFNs -X- _ O
( -X- _ O
∼8.5B -X- _ O
parameters -X- _ O
) -X- _ O
can -X- _ O
be -X- _ O
removed -X- _ O
with -X- _ O
minimal -X- _ O
decline -X- _ O
in -X- _ O
zero -X- _ O
/ -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
performance -X- _ O
( -X- _ O
§ -X- _ O
5.2 -X- _ O
) -X- _ O
, -X- _ O
indicating -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
FFNs -X- _ O
toward -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
. -X- _ O

The -X- _ O
second -X- _ O
way -X- _ O
we -X- _ O
address -X- _ O
the -X- _ O
aforementioned -X- _ O
question -X- _ O
is -X- _ O
by -X- _ O
quantifying -X- _ O
the -X- _ O
capacity -X- _ O
of -X- _ O
all -X- _ O
attention -X- _ O
heads -X- _ O
in -X- _ O
OPT-66B -X- _ B-MethodName
to -X- _ O
perform -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
task -X- _ O
- -X- _ O
agnostic -X- _ O
primitive -X- _ O
operations -X- _ O
associated -X- _ O
with -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
, -X- _ O
namely -X- _ O
, -X- _ O
prefix -X- _ B-TaskName
matching -X- _ I-TaskName
and -X- _ O
copying -X- _ B-TaskName
: -X- _ O
explicitly -X- _ O
searching -X- _ O
for -X- _ O
a -X- _ O
prior -X- _ O
occurrence -X- _ O
of -X- _ O
the -X- _ O
current -X- _ O
token -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
and -X- _ O
copying -X- _ O
over -X- _ O
its -X- _ O
suffix -X- _ O
. -X- _ O
Elhage -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
and -X- _ O
Olsson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
developed -X- _ O
a -X- _ O
mathematical -X- _ O
framework -X- _ O
to -X- _ O
reverse -X- _ O
- -X- _ O
engineer -X- _ O
a -X- _ O
Transformer -X- _ O
and -X- _ O
also -X- _ O
find -X- _ O
such -X- _ O
heads -X- _ O
, -X- _ O
termed -X- _ O
induction -X- _ O
heads -X- _ O
, -X- _ O
and -X- _ O
explored -X- _ O
the -X- _ O
hypothesis -X- _ O
that -X- _ O
such -X- _ O
heads -X- _ O
drive -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
with -X- _ O
model -X- _ O
sizes -X- _ O
up -X- _ O
to -X- _ O
13B -X- _ O
parameters -X- _ O
in -X- _ O
a -X- _ O
mostly -X- _ O
task -X- _ O
- -X- _ O
agnostic -X- _ O
fashion -X- _ O
. -X- _ O
Using -X- _ O
this -X- _ O
framework -X- _ O
, -X- _ O
we -X- _ O
compute -X- _ O
task -X- _ O
- -X- _ O
agnostic -X- _ O
scores -X- _ O
for -X- _ O
prefix -X- _ B-TaskName
matching -X- _ I-TaskName
and -X- _ O
copying -X- _ B-TaskName
for -X- _ O
each -X- _ O
attention -X- _ O
head -X- _ O
and -X- _ O
find -X- _ O
that -X- _ O
a -X- _ O
small -X- _ O
set -X- _ O
of -X- _ O
heads -X- _ O
in -X- _ O
OPT-66B -X- _ B-MethodName
have -X- _ O
nontrivial -X- _ O
scores -X- _ O
for -X- _ O
both -X- _ O
primitives -X- _ O
( -X- _ O
§ -X- _ O
6.3 -X- _ O
) -X- _ O
. -X- _ O
Qualitative -X- _ O
inspection -X- _ O
and -X- _ O
quantitative -X- _ O
analyses -X- _ O
show -X- _ O
that -X- _ O
these -X- _ O
heads -X- _ O
overlap -X- _ O
( -X- _ O
to -X- _ O
varying -X- _ O
degrees -X- _ O
) -X- _ O
with -X- _ O
the -X- _ O
ones -X- _ O
identified -X- _ O
earlier -X- _ O
to -X- _ O
be -X- _ O
important -X- _ O
for -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
via -X- _ O
our -X- _ O
set -X- _ O
of -X- _ O
14 -X- _ O
NLP -X- _ O
datasets -X- _ O
/ -X- _ O
tasks -X- _ O
, -X- _ O
indicating -X- _ O
that -X- _ O
induction -X- _ O
heads -X- _ O
are -X- _ O
capable -X- _ O
of -X- _ O
more -X- _ O
sophisticated -X- _ O
behaviors -X- _ O
associated -X- _ O
with -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
such -X- _ O
as -X- _ O
latent -X- _ O
concept -X- _ O
matching -X- _ O
but -X- _ O
are -X- _ O
not -X- _ O
the -X- _ O
only -X- _ O
heads -X- _ O
with -X- _ O
such -X- _ O
capabilities -X- _ O
( -X- _ O
§ -X- _ O
6.3.1 -X- _ O
) -X- _ O
. -X- _ O

Overall -X- _ O
, -X- _ O
our -X- _ O
study -X- _ O
provides -X- _ O
several -X- _ O
insights -X- _ O
about -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
at -X- _ O
massive -X- _ O
scale -X- _ O
using -X- _ O
both -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
and -X- _ O
task -X- _ O
- -X- _ O
agnostic -X- _ O
settings -X- _ O
. -X- _ O
In -X- _ O
a -X- _ O
world -X- _ O
of -X- _ O
ever -X- _ O
increasing -X- _ O
language -X- _ O
model -X- _ O
sizes -X- _ O
, -X- _ O
we -X- _ O
believe -X- _ O
these -X- _ O
insights -X- _ O
serve -X- _ O
as -X- _ O
a -X- _ O
strong -X- _ O
foundation -X- _ O
for -X- _ O
researchers -X- _ O
and -X- _ O
practitioners -X- _ O
in -X- _ O
language -X- _ O
modeling -X- _ O
to -X- _ O
build -X- _ O
and -X- _ O
leverage -X- _ O
compact -X- _ O
language -X- _ O
models -X- _ O
that -X- _ O
can -X- _ O
also -X- _ O
demonstrate -X- _ O
emergent -X- _ O
abilities -X- _ O
. -X- _ O

Background -X- _ O
& -X- _ O
Methods -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
establish -X- _ O
notation -X- _ O
and -X- _ O
methods -X- _ O
with -X- _ O
the -X- _ O
Open -X- _ B-MethodName
Pre -X- _ I-MethodName
- -X- _ I-MethodName
trained -X- _ I-MethodName
Transformer -X- _ I-MethodName
( -X- _ O
OPT -X- _ B-MethodName
) -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
model -X- _ O
used -X- _ O
for -X- _ O
our -X- _ O
study -X- _ O
, -X- _ O
provide -X- _ O
background -X- _ O
on -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
and -X- _ O
the -X- _ O
mathematical -X- _ O
formulation -X- _ O
of -X- _ O
induction -X- _ O
heads -X- _ O
by -X- _ O
Olsson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
that -X- _ O
we -X- _ O
build -X- _ O
on -X- _ O
, -X- _ O
and -X- _ O
describe -X- _ O
our -X- _ O
adaptation -X- _ O
of -X- _ O
oracle -X- _ O
and -X- _ O
gradient -X- _ O
- -X- _ O
based -X- _ O
importance -X- _ B-MetricName
score -X- _ O
formulations -X- _ O
for -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
. -X- _ O

Open -X- _ B-MethodName
Pre -X- _ I-MethodName
- -X- _ I-MethodName
trained -X- _ I-MethodName
Transformer -X- _ I-MethodName
( -X- _ O
OPT -X- _ B-MethodName
) -X- _ O

OPT -X- _ B-MethodName
is -X- _ O
a -X- _ O
suite -X- _ O
of -X- _ O
language -X- _ O
models -X- _ O
of -X- _ O
varying -X- _ O
sizes -X- _ O
aimed -X- _ O
at -X- _ O
serving -X- _ O
as -X- _ O
open -X- _ O
replicas -X- _ O
of -X- _ O
GPT-3 -X- _ O
. -X- _ O
The -X- _ O
largest -X- _ O
openly -X- _ O
accessible -X- _ O
model -X- _ O
from -X- _ O
this -X- _ O
suite -X- _ O
is -X- _ O
OPT-66B -X- _ B-MethodName
with -X- _ O
66 -X- _ O
billion -X- _ O
parameters -X- _ O
. -X- _ O

Architecture -X- _ O
: -X- _ O
Consider -X- _ O
a -X- _ O
tokenized -X- _ O
input -X- _ O
sentence -X- _ O
to -X- _ O
OPT -X- _ B-MethodName
, -X- _ O
X -X- _ O
∈ -X- _ O
R -X- _ O
N -X- _ O
×de -X- _ B-HyperparameterName
, -X- _ O
where -X- _ O
N -X- _ O
is -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
sentence -X- _ O
and -X- _ O
d -X- _ B-HyperparameterName
e -X- _ I-HyperparameterName
is -X- _ O
the -X- _ O
embedding -X- _ B-HyperparameterName
dimension -X- _ I-HyperparameterName
. -X- _ O
The -X- _ O
input -X- _ O
is -X- _ O
processed -X- _ O
by -X- _ O
multiple -X- _ O
decoder -X- _ O
layers -X- _ O
consisting -X- _ O
of -X- _ O
multi -X- _ O
- -X- _ O
headed -X- _ O
attention -X- _ O
( -X- _ O
MHA -X- _ O
) -X- _ O
blocks -X- _ O
, -X- _ O
layer -X- _ O
norm -X- _ O
( -X- _ O
LN -X- _ O
) -X- _ O
and -X- _ O
feed -X- _ O
forward -X- _ O
networks -X- _ O
( -X- _ O
FFN -X- _ O
) -X- _ O
, -X- _ O
followed -X- _ O
by -X- _ O
a -X- _ O
linear -X- _ O
layer -X- _ O
to -X- _ O
produce -X- _ O
logits -X- _ O
over -X- _ O
the -X- _ O
vocabulary -X- _ O
. -X- _ O
The -X- _ O
decoder -X- _ O
layers -X- _ O
can -X- _ O
be -X- _ O
formally -X- _ O
expressed -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

t -X- _ O
( -X- _ O
ℓ+1 -X- _ O
) -X- _ O
= -X- _ O
z -X- _ O
ℓ -X- _ O
+ -X- _ O
MHA -X- _ O
ℓ -X- _ O
( -X- _ O
LN -X- _ O
ℓ -X- _ O
( -X- _ O
z -X- _ O
ℓ -X- _ O
) -X- _ O
) -X- _ O

( -X- _ O
1 -X- _ O
) -X- _ O

z -X- _ O
( -X- _ O
ℓ+1 -X- _ O
) -X- _ O
= -X- _ O
t -X- _ O
( -X- _ O
ℓ+1 -X- _ O
) -X- _ O
+ -X- _ O
FFN -X- _ O
ℓ -X- _ O
( -X- _ O
t -X- _ O
( -X- _ O
ℓ+1 -X- _ O
) -X- _ O
) -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O

where -X- _ O
z -X- _ O
1 -X- _ O
= -X- _ O
X -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
& -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
are -X- _ O
the -X- _ O
residual -X- _ O
connections -X- _ O
corresponding -X- _ O
to -X- _ O
the -X- _ O
MHA -X- _ O
and -X- _ O
FFN -X- _ O
in -X- _ O
layer -X- _ O
ℓ -X- _ O
> -X- _ O
= -X- _ O
1 -X- _ O
respectively -X- _ O
. -X- _ O
OPT-66B -X- _ B-MethodName
was -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
with -X- _ O
a -X- _ O
maximum -X- _ B-HyperparameterValue
sequence -X- _ I-HyperparameterValue
length -X- _ I-HyperparameterValue
of -X- _ O
2048 -X- _ B-HyperparameterValue
and -X- _ O
embedding -X- _ B-HyperparameterName
dimension -X- _ I-HyperparameterName
d -X- _ B-HyperparameterName
e -X- _ I-HyperparameterName
= -X- _ O
9216 -X- _ B-HyperparameterValue
. -X- _ O

MHA -X- _ O
: -X- _ O

In -X- _ O
an -X- _ O
MHA -X- _ O
block -X- _ O
, -X- _ O
H -X- _ B-HyperparameterName
attention -X- _ B-HyperparameterName
heads -X- _ I-HyperparameterName
are -X- _ O
applied -X- _ O
in -X- _ O
parallel -X- _ O
to -X- _ O
the -X- _ O
input -X- _ O
and -X- _ O
their -X- _ O
outputs -X- _ O
are -X- _ O
concatenated -X- _ O
. -X- _ O
In -X- _ O
OPT-66B -X- _ B-MethodName
, -X- _ O
there -X- _ O
are -X- _ O
H -X- _ B-HyperparameterName
= -X- _ O
72 -X- _ B-HyperparameterValue
attention -X- _ B-HyperparameterName
heads -X- _ I-HyperparameterName
of -X- _ O
dimension -X- _ B-HyperparameterName
d -X- _ B-HyperparameterName
h -X- _ I-HyperparameterName
= -X- _ O
128 -X- _ B-HyperparameterValue
in -X- _ O
every -X- _ O
layer -X- _ O
ℓ. -X- _ O
An -X- _ O
individual -X- _ O
attention -X- _ O
head -X- _ O
h -X- _ O
in -X- _ O
layer -X- _ O
ℓ -X- _ O
consists -X- _ O
of -X- _ O
three -X- _ O
learnable -X- _ O
matrices -X- _ O
, -X- _ O
W -X- _ O
h -X- _ O
k -X- _ O
, -X- _ O
W -X- _ O
h -X- _ O
q -X- _ O
, -X- _ O
W -X- _ O
h -X- _ O
v -X- _ O
∈ -X- _ O
R -X- _ O
de×d -X- _ O
h -X- _ O
, -X- _ O
all -X- _ O
unique -X- _ O
to -X- _ O
the -X- _ O
head -X- _ O
, -X- _ O
such -X- _ O
that -X- _ O
it -X- _ O
applies -X- _ O
selfattention -X- _ O
A -X- _ O
h -X- _ O
( -X- _ O
. -X- _ O
) -X- _ O
on -X- _ O
the -X- _ O
input -X- _ O
, -X- _ O
where -X- _ O
d -X- _ B-HyperparameterName
h -X- _ I-HyperparameterName
= -X- _ O
d -X- _ B-HyperparameterName
e -X- _ I-HyperparameterName
/ -X- _ O
H. -X- _ B-HyperparameterName
Formally -X- _ O
, -X- _ O
for -X- _ O
input -X- _ O
M -X- _ O
in -X- _ O
layer -X- _ O
ℓ -X- _ O
: -X- _ O

MHA -X- _ O
ℓ -X- _ O
( -X- _ O
M -X- _ O
) -X- _ O
= -X- _ O
[ -X- _ O
A -X- _ O
1 -X- _ O
( -X- _ O
M -X- _ O
) -X- _ O
; -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
; -X- _ O
A -X- _ O
H -X- _ O
( -X- _ O
M -X- _ O
) -X- _ O
] -X- _ O
W -X- _ O
ℓ -X- _ O
o -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
A -X- _ O
h -X- _ O
( -X- _ O
M -X- _ O
) -X- _ O
= -X- _ O
s -X- _ O
h -X- _ O
( -X- _ O
M -X- _ O
) -X- _ O
MW -X- _ O
h -X- _ O
v -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
s -X- _ O
h -X- _ O
( -X- _ O
M -X- _ O
) -X- _ O
= -X- _ O
σ -X- _ O
MW -X- _ O
h -X- _ O
q -X- _ O
( -X- _ O
W -X- _ O
h -X- _ O
k -X- _ O
) -X- _ O
T -X- _ O
M -X- _ O
T -X- _ O
√ -X- _ O
d -X- _ O
h -X- _ O
( -X- _ O
5 -X- _ O

) -X- _ O

where -X- _ O
σ -X- _ O
is -X- _ O
the -X- _ O
softmax -X- _ O
function -X- _ O
and -X- _ O
W -X- _ O
ℓ -X- _ O
o -X- _ O
∈ -X- _ O
R -X- _ O
de×de -X- _ O
is -X- _ O
a -X- _ O
learnable -X- _ O
output -X- _ O
matrix -X- _ O
unique -X- _ O
to -X- _ O
the -X- _ O
MHA -X- _ O
block -X- _ O
in -X- _ O
layer -X- _ O
ℓ. -X- _ O
To -X- _ O
ensure -X- _ O
OPT -X- _ B-MethodName
is -X- _ O
auto -X- _ O
- -X- _ O
regressive -X- _ O
, -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
s -X- _ O
h -X- _ O
( -X- _ O
. -X- _ O
) -X- _ O
is -X- _ O
masked -X- _ O
to -X- _ O
prevent -X- _ O
the -X- _ O
dependence -X- _ O
of -X- _ O
the -X- _ O
hidden -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
token -X- _ O
i -X- _ O
, -X- _ O
z -X- _ O
ℓ -X- _ O
i -X- _ O
∈ -X- _ O
R -X- _ O
de -X- _ O
, -X- _ O
on -X- _ O
future -X- _ O
tokens -X- _ O
in -X- _ O
indices -X- _ O
{ -X- _ O
i -X- _ O
+ -X- _ O
1 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
N -X- _ O
} -X- _ O
. -X- _ O

To -X- _ O
remove -X- _ O
a -X- _ O
head -X- _ O
h -X- _ O
in -X- _ O
layer -X- _ O
ℓ -X- _ O
in -X- _ O
practice -X- _ O
, -X- _ O
we -X- _ O
set -X- _ O
A -X- _ O
h -X- _ O
( -X- _ O
M -X- _ O
) -X- _ O
to -X- _ O
be -X- _ O
the -X- _ O
zero -X- _ O
matrix -X- _ O
in -X- _ O
Equation -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
implies -X- _ O
that -X- _ O
W -X- _ O
h -X- _ O
k -X- _ O
, -X- _ O
W -X- _ O
h -X- _ O
q -X- _ O
, -X- _ O
W -X- _ O
h -X- _ O
v -X- _ O
can -X- _ O
be -X- _ O
entirely -X- _ O
removed -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
corresponding -X- _ O
d -X- _ O
h -X- _ O
rows -X- _ O
in -X- _ O
W -X- _ O
ℓ -X- _ O
o -X- _ O
can -X- _ O
also -X- _ O
be -X- _ O
removed -X- _ O
. -X- _ O
In -X- _ O
total -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
4608 -X- _ B-HyperparameterValue
attention -X- _ B-HyperparameterName
heads -X- _ I-HyperparameterName
across -X- _ O
64 -X- _ B-HyperparameterValue
layers -X- _ B-HyperparameterName
in -X- _ O
OPT-66B -X- _ B-MethodName
that -X- _ O
constitute -X- _ O
21.7B -X- _ O
of -X- _ O
the -X- _ O
total -X- _ O
66B -X- _ O
parameters -X- _ O
. -X- _ O

FFN -X- _ O
: -X- _ O
Each -X- _ O
layer -X- _ O
ℓ -X- _ O
consists -X- _ O
of -X- _ O
a -X- _ O
feed -X- _ O
forward -X- _ O
network -X- _ O
( -X- _ O
FFN -X- _ O
) -X- _ O
parameterized -X- _ O
by -X- _ O
a -X- _ O
high -X- _ O
- -X- _ O
dimensional -X- _ O
projection -X- _ O
matrix -X- _ O
, -X- _ O
W -X- _ O
ℓ -X- _ O
1 -X- _ O
∈ -X- _ O
R -X- _ O
de×d -X- _ O
followed -X- _ O
by -X- _ O
a -X- _ O
low -X- _ O
- -X- _ O
dimensional -X- _ O
projection -X- _ O
matrix -X- _ O
, -X- _ O
W -X- _ O
ℓ -X- _ O
2 -X- _ O
∈ -X- _ O
R -X- _ O
d×de -X- _ B-HyperparameterName
where -X- _ O
d -X- _ B-HyperparameterName
= -X- _ O
36864 -X- _ B-HyperparameterValue
for -X- _ O
OPT-66B. -X- _ B-MethodName
Formally -X- _ O
, -X- _ O
for -X- _ O
input -X- _ O
M -X- _ O
in -X- _ O
layer -X- _ O
ℓ -X- _ O
: -X- _ O

FFN -X- _ O
ℓ -X- _ O
( -X- _ O
M -X- _ O
) -X- _ O
= -X- _ O
ReLU -X- _ O
( -X- _ O
LN -X- _ O
ℓ -X- _ O
( -X- _ O
M -X- _ O
) -X- _ O
W -X- _ O
ℓ -X- _ O
1 -X- _ O
) -X- _ O
W -X- _ O
ℓ -X- _ O
2 -X- _ O
( -X- _ O
6 -X- _ O
) -X- _ O

where -X- _ O
ReLU -X- _ O
is -X- _ O
the -X- _ O
rectified -X- _ O
linear -X- _ O
unit -X- _ O
activation -X- _ O
function -X- _ O
and -X- _ O
LN -X- _ O
is -X- _ O
the -X- _ O
layer -X- _ O
norm -X- _ O
. -X- _ O

To -X- _ O
remove -X- _ O
an -X- _ O
FFN -X- _ O
in -X- _ O
layer -X- _ O
ℓ -X- _ O
in -X- _ O
practice -X- _ O
, -X- _ O
we -X- _ O
set -X- _ O
FFN -X- _ O
ℓ -X- _ O
( -X- _ O
M -X- _ O
) -X- _ O
to -X- _ O
be -X- _ O
the -X- _ O
zero -X- _ O
matrix -X- _ O
in -X- _ O
Equation -X- _ O
( -X- _ O
6 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
implies -X- _ O
W -X- _ O
ℓ -X- _ O
1 -X- _ O
, -X- _ O
W -X- _ O
ℓ -X- _ O
2 -X- _ O
and -X- _ O
the -X- _ O
layer -X- _ O
norm -X- _ O
LN -X- _ O
ℓ -X- _ O
( -X- _ O
. -X- _ O
) -X- _ O
for -X- _ O
the -X- _ O
FFN -X- _ O
can -X- _ O
be -X- _ O
entirely -X- _ O
removed -X- _ O
. -X- _ O
In -X- _ O
total -X- _ O
, -X- _ O
FFNs -X- _ O
constitute -X- _ O
43.4B -X- _ O
parameters -X- _ O
in -X- _ O
OPT-66B -X- _ B-MethodName
. -X- _ O

In -X- _ O
- -X- _ O
Context -X- _ O
Learning -X- _ O
& -X- _ O
Induction -X- _ O
Heads -X- _ O

With -X- _ O
increasingly -X- _ O
larger -X- _ O
language -X- _ O
models -X- _ O
being -X- _ O
trained -X- _ O
in -X- _ O
recent -X- _ O
years -X- _ O
, -X- _ O
a -X- _ O
new -X- _ O
paradigm -X- _ O
of -X- _ O
learning -X- _ O
termed -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
has -X- _ O
become -X- _ O
popular -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paradigm -X- _ O
, -X- _ O
language -X- _ O
models -X- _ O
perform -X- _ O
tasks -X- _ O
by -X- _ O
being -X- _ O
prompted -X- _ O
to -X- _ O
generate -X- _ O
output -X- _ O
text -X- _ O
conditioned -X- _ O
on -X- _ O
a -X- _ O
few -X- _ O
( -X- _ O
or -X- _ O
zero -X- _ O
) -X- _ O
incontext -X- _ O
training -X- _ O
examples -X- _ O
that -X- _ O
form -X- _ O
solved -X- _ O
" -X- _ O
inputoutput -X- _ O
" -X- _ O
pairs -X- _ O
for -X- _ O
the -X- _ O
task -X- _ O
along -X- _ O
with -X- _ O
a -X- _ O
query -X- _ O
input -X- _ O
. -X- _ O
Figure -X- _ O
1 -X- _ O
illustrates -X- _ O
the -X- _ O
paradigm -X- _ O
for -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
identifying -X- _ O
the -X- _ O
sound -X- _ O
that -X- _ O
an -X- _ O
animal -X- _ O
makes -X- _ O
. -X- _ O
In -X- _ O
some -X- _ O
cases -X- _ O
, -X- _ O
tasks -X- _ O
can -X- _ O
also -X- _ O
be -X- _ O
accompanied -X- _ O
by -X- _ O
task -X- _ O
descriptions -X- _ O
/ -X- _ O
templates -X- _ O
to -X- _ O
help -X- _ O
prime -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
better -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
translating -X- _ O
from -X- _ O
English -X- _ O
to -X- _ O
German -X- _ O
using -X- _ O
the -X- _ O
prompt -X- _ O
: -X- _ O
While -X- _ O
these -X- _ O
examples -X- _ O
involve -X- _ O
learning -X- _ O
and -X- _ O
relying -X- _ O
on -X- _ O
latent -X- _ O
concepts -X- _ O
during -X- _ O
inference -X- _ O
, -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
can -X- _ O
additionally -X- _ O
involve -X- _ O
explicit -X- _ O
primitive -X- _ O
interactions -X- _ O
between -X- _ O
the -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
examples -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
prompt -X- _ O
: -X- _ O
the -X- _ O
model -X- _ O
may -X- _ O
rely -X- _ O
on -X- _ O
prior -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
translations -X- _ O
of -X- _ O
the -X- _ O
tokens -X- _ O
I -X- _ O
and -X- _ O
like -X- _ O
when -X- _ O
performing -X- _ O
the -X- _ O
task -X- _ O
for -X- _ O
the -X- _ O
query -X- _ O
input -X- _ O
. -X- _ O
Olsson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
developed -X- _ O
a -X- _ O
mathematical -X- _ O
framework -X- _ O
toward -X- _ O
better -X- _ O
understanding -X- _ O
such -X- _ O
mechanics -X- _ O
, -X- _ O
starting -X- _ O
off -X- _ O
with -X- _ O
a -X- _ O
task -X- _ O
- -X- _ O
agnostic -X- _ O
formulation -X- _ O
of -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
as -X- _ O
the -X- _ O
ability -X- _ O
of -X- _ O
a -X- _ O
model -X- _ O
to -X- _ O
better -X- _ O
predict -X- _ O
tokens -X- _ O
later -X- _ O
in -X- _ O
the -X- _ O
context -X- _ O
than -X- _ O
the -X- _ O
tokens -X- _ O
earlier -X- _ O
. -X- _ O
They -X- _ O
define -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
task -X- _ O
- -X- _ O
agnostic -X- _ O
primitive -X- _ O
operations -X- _ O
that -X- _ O
reflect -X- _ O
the -X- _ O
kind -X- _ O
of -X- _ O
interactions -X- _ O
we -X- _ O
refer -X- _ O
to -X- _ O
in -X- _ O
the -X- _ O
above -X- _ O
example -X- _ O
, -X- _ O
namely -X- _ O
, -X- _ O
prefix -X- _ B-TaskName
matching -X- _ I-TaskName
and -X- _ O
copying -X- _ B-TaskName
. -X- _ O
These -X- _ O
operations -X- _ O
are -X- _ O
defined -X- _ O
in -X- _ O
a -X- _ O
simplistic -X- _ O
fashion -X- _ O
on -X- _ O
a -X- _ O
repeated -X- _ O
sequence -X- _ O
of -X- _ O
randomly -X- _ O
generated -X- _ O
tokens -X- _ O
: -X- _ O
explicitly -X- _ O
searching -X- _ O
for -X- _ O
a -X- _ O
prior -X- _ O
occurrence -X- _ O
of -X- _ O
the -X- _ O
current -X- _ O
token -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
and -X- _ O
copying -X- _ O
over -X- _ O
its -X- _ O
suffix -X- _ O
. -X- _ O
The -X- _ O
heads -X- _ O
that -X- _ O
are -X- _ O
capable -X- _ O
of -X- _ O
performing -X- _ O
these -X- _ O
operations -X- _ O
are -X- _ O
termed -X- _ O
induction -X- _ O
heads -X- _ O
. -X- _ O
Figure -X- _ O
2 -X- _ O
depicts -X- _ O
these -X- _ O
operations -X- _ O
for -X- _ O
a -X- _ O
repeated -X- _ O
sequence -X- _ O
of -X- _ O
tokens -X- _ O
. -X- _ O
While -X- _ O
these -X- _ O
operations -X- _ O
are -X- _ O
intertwined -X- _ O
in -X- _ O
practice -X- _ O
, -X- _ O
the -X- _ O
capacity -X- _ O
of -X- _ O
attention -X- _ O
heads -X- _ O
to -X- _ O
independently -X- _ O
perform -X- _ O
them -X- _ O
is -X- _ O
computed -X- _ O
with -X- _ O
the -X- _ O
scoring -X- _ O
algorithms -X- _ O
described -X- _ O
in -X- _ O
detail -X- _ O
in -X- _ O
Appendix -X- _ O
A.8 -X- _ O
. -X- _ O

Importance -X- _ B-MetricName
Scores -X- _ O

Consider -X- _ O
a -X- _ O
model -X- _ O
M -X- _ O
and -X- _ O
a -X- _ O
dataset -X- _ O
D -X- _ O
= -X- _ O
{ -X- _ O
X -X- _ O
, -X- _ O
Y -X- _ O
} -X- _ O
, -X- _ O
where -X- _ O

X -X- _ O
= -X- _ O
{ -X- _ O
x -X- _ O
1 -X- _ O
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
x -X- _ O
L -X- _ O
} -X- _ O
and -X- _ O
Y -X- _ O
= -X- _ O
{ -X- _ O
y -X- _ O
1 -X- _ O
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
y -X- _ O
L -X- _ O
} -X- _ O
such -X- _ O
that -X- _ O
x -X- _ O
i -X- _ O
represents -X- _ O
a -X- _ O
prompt -X- _ O
with -X- _ O
few -X- _ O
( -X- _ O
or -X- _ O
zero -X- _ O
) -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O

training -X- _ O
examples -X- _ O
along -X- _ O
with -X- _ O
a -X- _ O
query -X- _ O
input -X- _ O
and -X- _ O
y -X- _ O
i -X- _ O
represents -X- _ O
the -X- _ O
corresponding -X- _ O
target -X- _ O
output -X- _ O
sequence -X- _ O
. -X- _ O
We -X- _ O
define -X- _ O
and -X- _ O
compute -X- _ O
importance -X- _ B-MetricName
scores -X- _ O
for -X- _ O
model -X- _ O
components -X- _ O
using -X- _ O
such -X- _ O
datasets -X- _ O
to -X- _ O
quantify -X- _ O
their -X- _ O
relative -X- _ O
contributions -X- _ O
to -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
ability -X- _ O
to -X- _ O
perform -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
. -X- _ O

Oracle -X- _ O

Let -X- _ O
P -X- _ O
M -X- _ O
( -X- _ O
D -X- _ O
) -X- _ O
denote -X- _ O
a -X- _ O
dataset -X- _ O
/ -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
performance -X- _ O
metric -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
accuracy -X- _ B-MetricName
. -X- _ O
Given -X- _ O
dataset -X- _ O
D -X- _ O
, -X- _ O
the -X- _ O
oracle -X- _ O
importance -X- _ B-MetricName
score -X- _ O
of -X- _ O
a -X- _ O
component -X- _ O
C -X- _ O
in -X- _ O
M -X- _ O
is -X- _ O
computed -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

IS -X- _ O
C -X- _ O
( -X- _ O
D -X- _ O
) -X- _ O
= -X- _ O
P -X- _ O
M -X- _ O
( -X- _ O
D -X- _ O
) -X- _ O
− -X- _ O
P -X- _ O
M -X- _ O
\C -X- _ O
( -X- _ O
D -X- _ O
) -X- _ O
( -X- _ O
7 -X- _ O
) -X- _ O

where -X- _ O
M -X- _ O
\C -X- _ O
denotes -X- _ O
the -X- _ O
resultant -X- _ O
model -X- _ O
when -X- _ O
C -X- _ O
is -X- _ O
pruned -X- _ O
from -X- _ O
M. -X- _ O
Clearly -X- _ O
, -X- _ O
if -X- _ O
pruning -X- _ O
a -X- _ O
component -X- _ O
leads -X- _ O
to -X- _ O
poor -X- _ O
model -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
task -X- _ O
, -X- _ O
it -X- _ O
must -X- _ O
be -X- _ O
important -X- _ O
for -X- _ O
the -X- _ O
task -X- _ O
. -X- _ O
Similarly -X- _ O
, -X- _ O
if -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
difference -X- _ O
or -X- _ O
an -X- _ O
improvement -X- _ O
in -X- _ O
performance -X- _ O
upon -X- _ O
pruning -X- _ O
a -X- _ O
component -X- _ O
, -X- _ O
it -X- _ O
must -X- _ O
be -X- _ O
unimportant -X- _ O
. -X- _ O
Computing -X- _ O
oracle -X- _ O
importance -X- _ B-MetricName
scores -X- _ O
for -X- _ O
K -X- _ O
model -X- _ O
components -X- _ O
requires -X- _ O
us -X- _ O
to -X- _ O
perform -X- _ O
O -X- _ O
( -X- _ O
K -X- _ O
) -X- _ O
evaluations -X- _ O
for -X- _ O
each -X- _ O
dataset -X- _ O
D -X- _ O
. -X- _ O

Gradient -X- _ O
- -X- _ O
based -X- _ O

Given -X- _ O
dataset -X- _ O
D -X- _ O
, -X- _ O
the -X- _ O
gradient -X- _ O
- -X- _ O
based -X- _ O
importance -X- _ B-MetricName
score -X- _ O
( -X- _ O
Molchanov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Michel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
of -X- _ O
an -X- _ O
attention -X- _ O
head -X- _ O
h -X- _ O
captures -X- _ O
the -X- _ O
expected -X- _ O
sensitivity -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
h -X- _ O
and -X- _ O
is -X- _ O
computed -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

IS -X- _ O
h -X- _ O
( -X- _ O
D -X- _ O
) -X- _ O
= -X- _ O
E -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
A -X- _ O
h -X- _ O
( -X- _ O
[ -X- _ O
x -X- _ O
; -X- _ O
y -X- _ O
] -X- _ O
) -X- _ O
T -X- _ O
∂L -X- _ O
( -X- _ O
y|x -X- _ O
) -X- _ O
∂A -X- _ O
h -X- _ O
( -X- _ O
[ -X- _ O
x -X- _ O
; -X- _ O
y -X- _ O
] -X- _ O
) -X- _ O
( -X- _ O
8 -X- _ O
) -X- _ O

where -X- _ O
; -X- _ O
is -X- _ O
the -X- _ O
concatenation -X- _ O
operator -X- _ O
, -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
∼ -X- _ O
D -X- _ O
such -X- _ O
that -X- _ O
x -X- _ O
is -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
T -X- _ O
x -X- _ O
tokens -X- _ O
x -X- _ O
1 -X- _ O
: -X- _ O
Tx -X- _ O
, -X- _ O
y -X- _ O
is -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
T -X- _ O
y -X- _ O
tokens -X- _ O
y -X- _ O
1 -X- _ O
: -X- _ O
Ty -X- _ O
, -X- _ O
A -X- _ O
h -X- _ O
is -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
head -X- _ O
h -X- _ O
defined -X- _ O
in -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
loss -X- _ O
term -X- _ O
in -X- _ O
( -X- _ O
8 -X- _ O
) -X- _ O
is -X- _ O
computed -X- _ O
using -X- _ O
the -X- _ O
auto -X- _ O
- -X- _ O
regressive -X- _ O
decomposition -X- _ O
of -X- _ O
the -X- _ O
log -X- _ O
- -X- _ O
likelihood -X- _ O
: -X- _ O

L -X- _ O
( -X- _ O
y|x -X- _ O
) -X- _ O
= -X- _ O
− -X- _ O
1 -X- _ O
T -X- _ O
y -X- _ O
j -X- _ O
= -X- _ O
Ty -X- _ O
j=1 -X- _ O

log -X- _ O
( -X- _ O
p -X- _ O
( -X- _ O
y -X- _ O
j -X- _ O
|x -X- _ O
, -X- _ O
y -X- _ O
1 -X- _ O
: -X- _ O
j−1 -X- _ O
) -X- _ O
) -X- _ O
( -X- _ O
9 -X- _ O
) -X- _ O

These -X- _ O
importance -X- _ B-MetricName
scores -X- _ O
can -X- _ O
be -X- _ O
efficiently -X- _ O
computed -X- _ O
for -X- _ O
all -X- _ O
heads -X- _ O
by -X- _ O
simply -X- _ O
performing -X- _ O
a -X- _ O
single -X- _ O
forward -X- _ O
and -X- _ O
backward -X- _ O
pass -X- _ O
over -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
D -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
define -X- _ O
the -X- _ O
aggregated -X- _ O
importance -X- _ B-MetricName
score -X- _ O
of -X- _ O
an -X- _ O
attention -X- _ O
head -X- _ O
on -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
datasets -X- _ O
S -X- _ O
= -X- _ O
{ -X- _ O
D -X- _ O
1 -X- _ O
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
D -X- _ O
K -X- _ O
} -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

IS -X- _ O
h -X- _ O
( -X- _ O
S -X- _ O
) -X- _ O
= -X- _ O
E -X- _ O
D∼S -X- _ O
[ -X- _ O
IS -X- _ O
h -X- _ O
( -X- _ O
D -X- _ O
) -X- _ O
] -X- _ O
( -X- _ O
10 -X- _ O
) -X- _ O

3 -X- _ O
Experimental -X- _ O
Setup -X- _ O

We -X- _ O
conducted -X- _ O
our -X- _ O
experiments -X- _ O
on -X- _ O
OPT-66B -X- _ B-MethodName
, -X- _ O
which -X- _ O
was -X- _ O
the -X- _ O
largest -X- _ O
publicly -X- _ O
available -X- _ O
dense -X- _ O
decoderonly -X- _ O
language -X- _ O
model -X- _ O
at -X- _ O
the -X- _ O
time -X- _ O
of -X- _ O
our -X- _ O
experiments -X- _ O
. -X- _ O
We -X- _ O
efficiently -X- _ O
compute -X- _ O
gradient -X- _ O
- -X- _ O
based -X- _ O
importance -X- _ B-MetricName
scores -X- _ O
for -X- _ O
the -X- _ O
4608 -X- _ B-HyperparameterValue
attention -X- _ B-HyperparameterName
heads -X- _ I-HyperparameterName
and -X- _ O
oracle -X- _ O
importance -X- _ B-MetricName
scores -X- _ O
for -X- _ O
the -X- _ O
64 -X- _ B-HyperparameterValue
feed -X- _ B-HyperparameterName
forward -X- _ I-HyperparameterName
networks -X- _ I-HyperparameterName
( -X- _ O
FFNs -X- _ B-HyperparameterName
) -X- _ O
in -X- _ O
OPT-66B. -X- _ B-MethodName
We -X- _ O
experiment -X- _ O
with -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
14 -X- _ O
NLP -X- _ O
datasets -X- _ O
/ -X- _ O
tasks -X- _ O
. -X- _ O
For -X- _ O
consistency -X- _ O
in -X- _ O
the -X- _ O
evaluation -X- _ O
metric -X- _ O
, -X- _ O
we -X- _ O
report -X- _ O
accuracy -X- _ B-MetricName
on -X- _ O
all -X- _ O
tasks -X- _ O
. -X- _ O
Our -X- _ O
choice -X- _ O
of -X- _ O
datasets -X- _ O
and -X- _ O
metric -X- _ O
is -X- _ O
in -X- _ O
line -X- _ O
with -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
datasets -X- _ O
include -X- _ O
ARC -X- _ B-DatasetName
Easy -X- _ O
and -X- _ O
Challenge -X- _ O
and -X- _ O
OpenBookQA -X- _ B-DatasetName
( -X- _ O
Mihaylov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
for -X- _ O
advanced -X- _ O
question -X- _ B-TaskName
- -X- _ I-TaskName
answering -X- _ I-TaskName
, -X- _ O
Hel -X- _ B-DatasetName
- -X- _ I-DatasetName
laSwag -X- _ I-DatasetName
( -X- _ O
Zellers -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
PIQA -X- _ B-DatasetName
( -X- _ O
Bisk -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
Winogrande -X- _ B-DatasetName
( -X- _ O
Sakaguchi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
for -X- _ O
various -X- _ O
forms -X- _ O
of -X- _ O
commonsense -X- _ B-TaskName
reasoning -X- _ I-TaskName
, -X- _ O
and -X- _ O
the -X- _ O
following -X- _ O
datasets -X- _ O
from -X- _ O
the -X- _ O
standard -X- _ O
SuperGLUE -X- _ B-DatasetName
benchmark -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
: -X- _ O
BoolQ -X- _ B-DatasetName
, -X- _ O
CB -X- _ B-DatasetName
, -X- _ O
COPA -X- _ B-DatasetName
, -X- _ O
MultiRC -X- _ B-DatasetName
, -X- _ O
ReCoRD -X- _ B-DatasetName
, -X- _ O
RTE -X- _ B-DatasetName
, -X- _ O
WiC -X- _ B-DatasetName
, -X- _ O
and -X- _ O
WSC -X- _ B-DatasetName
. -X- _ O
For -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
experiments -X- _ O
involving -X- _ O
evaluation -X- _ O
of -X- _ O
outof -X- _ O
- -X- _ O
distribution -X- _ O
generalization -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
use -X- _ O
2 -X- _ O
additional -X- _ O
datasets -X- _ O
: -X- _ O
MathQA -X- _ B-DatasetName
( -X- _ O
Amini -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
LAMBADA -X- _ B-DatasetName
( -X- _ O
Paperno -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
a -X- _ O
modified -X- _ O
version -X- _ O
of -X- _ O
the -X- _ O
lm -X- _ O
- -X- _ O
evaluation -X- _ O
- -X- _ O
harness -X- _ O
framework -X- _ O
( -X- _ O
Gao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
for -X- _ O
our -X- _ O
experiments -X- _ O
. -X- _ O
The -X- _ O
default -X- _ O
framework -X- _ O
samples -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
examples -X- _ O
at -X- _ O
random -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
use -X- _ O
without -X- _ O
modification -X- _ O
. -X- _ O

4 -X- _ O
Importance -X- _ B-MetricName
Scores -X- _ O
for -X- _ O
OPT-66B -X- _ B-MethodName
Figure -X- _ O
3 -X- _ O
depicts -X- _ O
a -X- _ O
heatmap -X- _ O
of -X- _ O
the -X- _ O
head -X- _ O
importance -X- _ B-MetricName
scores -X- _ O
averaged -X- _ O
across -X- _ O
all -X- _ O
tasks -X- _ O
( -X- _ O
as -X- _ O
described -X- _ O
in -X- _ O
§ -X- _ O
2.3.2 -X- _ O
) -X- _ O
in -X- _ O
the -X- _ O
5 -X- _ O
- -X- _ O
shot -X- _ O
setting -X- _ O
. -X- _ O
Task -X- _ O
- -X- _ O
averaged -X- _ O
heatmaps -X- _ O
for -X- _ O
the -X- _ O
0 -X- _ O
- -X- _ O
shot -X- _ O
and -X- _ O
1 -X- _ O
- -X- _ O
shot -X- _ O
settings -X- _ O
and -X- _ O
all -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
heatmaps -X- _ O
are -X- _ O
provided -X- _ O
in -X- _ O
Appendix -X- _ O
A.1 -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
important -X- _ O
attention -X- _ O
heads -X- _ O
are -X- _ O
primarily -X- _ O
clustered -X- _ O
in -X- _ O
the -X- _ O
intermediate -X- _ O
layers -X- _ O
of -X- _ O
OPT-66B -X- _ B-MethodName
in -X- _ O
both -X- _ O
the -X- _ O
task -X- _ O
- -X- _ O
averaged -X- _ O
and -X- _ O
taskspecific -X- _ O
cases -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
observe -X- _ O
overlap -X- _ O
in -X- _ O
the -X- _ O
important -X- _ O
heads -X- _ O
across -X- _ O
the -X- _ O
different -X- _ O
zero -X- _ O
/ -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
settings -X- _ O
, -X- _ O
confirmed -X- _ O
in -X- _ O
follow -X- _ O
- -X- _ O
up -X- _ O
analysis -X- _ O
in -X- _ O
§ -X- _ O
6.2 -X- _ O
. -X- _ O

Attention -X- _ O
Heads -X- _ O

Feed -X- _ O
Forward -X- _ O
Networks -X- _ O

We -X- _ O
compute -X- _ O
oracle -X- _ O
importance -X- _ B-MetricName
scores -X- _ O
( -X- _ O
both -X- _ O
taskspecific -X- _ O
and -X- _ O
averaged -X- _ O
across -X- _ O
tasks -X- _ O
) -X- _ O
for -X- _ O
each -X- _ O
FFN -X- _ O
as -X- _ O
described -X- _ O
in -X- _ O
§ -X- _ O
2.3.1 -X- _ O
in -X- _ O
the -X- _ O
zero -X- _ O
/ -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
settings -X- _ O
. -X- _ O
1 -X- _ O
4 -X- _ O
7 -X- _ O
10 -X- _ O
13 -X- _ O
16 -X- _ O
19 -X- _ O
22 -X- _ O
25 -X- _ O
28 -X- _ O
31 -X- _ O
34 -X- _ O
37 -X- _ O
40 -X- _ O
43 -X- _ O
46 -X- _ O
49 -X- _ O
52 -X- _ O
55 -X- _ O
58 -X- _ O
61 -X- _ O
We -X- _ O
observe -X- _ O
in -X- _ O
the -X- _ O
0 -X- _ O
/ -X- _ O
1 -X- _ O
- -X- _ O
shot -X- _ O
settings -X- _ O
that -X- _ O
the -X- _ O
removal -X- _ O
of -X- _ O
any -X- _ O
FFN -X- _ O
in -X- _ O
the -X- _ O
early -X- _ O
( -X- _ O
1 -X- _ O
- -X- _ O
30 -X- _ O
) -X- _ O
layers -X- _ O
of -X- _ O
OPT-66B -X- _ B-MethodName
either -X- _ O
gives -X- _ O
comparable -X- _ O
or -X- _ O
better -X- _ O
performance -X- _ O
for -X- _ O
a -X- _ O
vast -X- _ O
majority -X- _ O
of -X- _ O
tasks -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
5 -X- _ O
- -X- _ O
shot -X- _ O
setting -X- _ O
however -X- _ O
, -X- _ O
both -X- _ O
the -X- _ O
early -X- _ O
and -X- _ O
later -X- _ O
layers -X- _ O
seem -X- _ O
to -X- _ O
have -X- _ O
important -X- _ O
FFNs -X- _ O
for -X- _ O
most -X- _ O
tasks -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
generally -X- _ O
observe -X- _ O
high -X- _ O
variance -X- _ O
in -X- _ O
FFN -X- _ O
importance -X- _ B-MetricName
scores -X- _ O
in -X- _ O
later -X- _ O
layers -X- _ O
. -X- _ O
We -X- _ O
particularly -X- _ O
note -X- _ O
high -X- _ O
variance -X- _ O
for -X- _ O
WSC -X- _ B-DatasetName
and -X- _ O
MultiRC -X- _ B-DatasetName
, -X- _ O
observing -X- _ O
that -X- _ O
removal -X- _ O
of -X- _ O
some -X- _ O
individual -X- _ O
FFNs -X- _ O
can -X- _ O
lead -X- _ O
to -X- _ O
absolute -X- _ O
accuracy -X- _ B-MetricName
improvements -X- _ O
/ -X- _ O
degradation -X- _ O
of -X- _ O
up -X- _ O
to -X- _ O
20 -X- _ B-MetricValue
% -X- _ I-MetricValue
! -X- _ O
We -X- _ O
leave -X- _ O
further -X- _ O
investigation -X- _ O
into -X- _ O
the -X- _ O
cause -X- _ O
for -X- _ O
this -X- _ O
variance -X- _ O
for -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O

Iterative -X- _ O
Pruning -X- _ O

We -X- _ O
now -X- _ O
assess -X- _ O
to -X- _ O
what -X- _ O
extent -X- _ O
we -X- _ O
can -X- _ O
remove -X- _ O
multiple -X- _ O
attention -X- _ O
heads -X- _ O
and -X- _ O
/ -X- _ O
or -X- _ O
FFNs -X- _ O
with -X- _ O
minimal -X- _ O
decline -X- _ O
in -X- _ O
task -X- _ O
performance -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
task -X- _ O
in -X- _ O
each -X- _ O
( -X- _ O
0 -X- _ O
/ -X- _ O
1 -X- _ O
/ -X- _ O
5 -X- _ O
- -X- _ O
shot -X- _ O
) -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
setting -X- _ O
, -X- _ O
we -X- _ O
create -X- _ O
separate -X- _ O
rankings -X- _ O
of -X- _ O
attention -X- _ O
heads -X- _ O
and -X- _ O
FFNs -X- _ O
in -X- _ O
OPT-66B -X- _ B-MethodName
by -X- _ O
separately -X- _ O
sorting -X- _ O
them -X- _ O
in -X- _ O
ascending -X- _ O
order -X- _ O
by -X- _ O
their -X- _ O
importance -X- _ B-MetricName
scores -X- _ O
( -X- _ O
§ -X- _ O
4.1 -X- _ O
and -X- _ O
§ -X- _ O
4.2 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
remove -X- _ O
unimportant -X- _ O
attention -X- _ O
heads -X- _ O
or -X- _ O
FFNs -X- _ O
in -X- _ O
an -X- _ O
iterative -X- _ O
fashion -X- _ O
using -X- _ O
these -X- _ O
rankings -X- _ O
, -X- _ O
10 -X- _ O
% -X- _ O
at -X- _ O
a -X- _ O
time -X- _ O
, -X- _ O
and -X- _ O
re -X- _ O
- -X- _ O
evaluate -X- _ O
task -X- _ O
performance -X- _ O
after -X- _ O
each -X- _ O
removal -X- _ O
. -X- _ O
1 -X- _ O

Removing -X- _ O
Attention -X- _ O
Heads -X- _ O

Figure -X- _ O
5 -X- _ O
depicts -X- _ O
the -X- _ O
resulting -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
and -X- _ O
task -X- _ O
- -X- _ O
averaged -X- _ O
accuracy -X- _ B-MetricName
trends -X- _ O
in -X- _ O
the -X- _ O
5 -X- _ O
- -X- _ O
shot -X- _ O
setting -X- _ O
. -X- _ O
Corresponding -X- _ O
0 -X- _ O
/ -X- _ O
1 -X- _ O
- -X- _ O
shot -X- _ O
trends -X- _ O
are -X- _ O
depicted -X- _ O
in -X- _ O
Appendix -X- _ O
A.3 -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
average -X- _ O
accuracy -X- _ B-MetricName
across -X- _ O
tasks -X- _ O
does -X- _ O
not -X- _ O
change -X- _ O
much -X- _ O
up -X- _ O
until -X- _ O
1 -X- _ O
We -X- _ O
do -X- _ O
not -X- _ O
remove -X- _ O
attention -X- _ O
heads -X- _ O
one -X- _ O
at -X- _ O
a -X- _ O
time -X- _ O
and -X- _ O
reevaluate -X- _ O
given -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
heads -X- _ O
and -X- _ O
evaluation -X- _ O
cost -X- _ O
. -X- _ O
∼70 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
attention -X- _ O
heads -X- _ O
are -X- _ O
removed -X- _ O
. -X- _ O
A -X- _ O
finegrained -X- _ O
look -X- _ O
at -X- _ O
the -X- _ O
individual -X- _ O
tasks -X- _ O
also -X- _ O
mostly -X- _ O
shows -X- _ O
similar -X- _ O
trends -X- _ O
, -X- _ O
with -X- _ O
accuracy -X- _ B-MetricName
staying -X- _ O
fairly -X- _ O
intact -X- _ O
until -X- _ O
a -X- _ O
large -X- _ O
proportion -X- _ O
of -X- _ O
the -X- _ O
heads -X- _ O
are -X- _ O
removed -X- _ O
. -X- _ O
Some -X- _ O
oddities -X- _ O
include -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
WSC -X- _ B-DatasetName
and -X- _ O
CB -X- _ B-DatasetName
, -X- _ O
wherein -X- _ O
we -X- _ O
see -X- _ O
that -X- _ O
the -X- _ O
0 -X- _ O
- -X- _ O
shot -X- _ O
accuracy -X- _ B-MetricName
actually -X- _ O
increases -X- _ O
after -X- _ O
removal -X- _ O
of -X- _ O
70 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
heads -X- _ O
. -X- _ O
Figure -X- _ O
6 -X- _ O
depicts -X- _ O
the -X- _ O
resulting -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
and -X- _ O
task -X- _ O
- -X- _ O
averaged -X- _ O
accuracy -X- _ B-MetricName
trends -X- _ O
in -X- _ O
the -X- _ O
0 -X- _ O
- -X- _ O
shot -X- _ O
setting -X- _ O
. -X- _ O
Corresponding -X- _ O
1 -X- _ O
/ -X- _ O
5 -X- _ O
- -X- _ O
shot -X- _ O
trends -X- _ O
are -X- _ O
depicted -X- _ O
in -X- _ O
Appendix -X- _ O
A.4 -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
in -X- _ O
the -X- _ O
0 -X- _ O
- -X- _ O
shot -X- _ O
setting -X- _ O
, -X- _ O
the -X- _ O
average -X- _ O
accuracy -X- _ B-MetricName
across -X- _ O
tasks -X- _ O
does -X- _ O
not -X- _ O
change -X- _ O
up -X- _ O
until -X- _ O
∼20 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
FFNs -X- _ O
are -X- _ O
removed -X- _ O
. -X- _ O
For -X- _ O
some -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
PIQA -X- _ B-DatasetName
, -X- _ O
Winogrande -X- _ B-DatasetName
and -X- _ O
RTE -X- _ B-DatasetName
, -X- _ O
the -X- _ O
accuracy -X- _ B-MetricName
does -X- _ O
not -X- _ O
change -X- _ O
even -X- _ O
if -X- _ O
30 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
FFNs -X- _ O
( -X- _ O
∼13B -X- _ O
of -X- _ O
the -X- _ O
66B -X- _ O
parameters -X- _ O
) -X- _ O
are -X- _ O
removed -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
inflection -X- _ O
point -X- _ O
after -X- _ O
which -X- _ O
we -X- _ O
observe -X- _ O
a -X- _ O
sharp -X- _ O
decline -X- _ O
in -X- _ O
accuracy -X- _ B-MetricName
changes -X- _ O
to -X- _ O
10 -X- _ B-MetricValue
% -X- _ I-MetricValue
for -X- _ O
the -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
settings -X- _ O
. -X- _ O
Overall -X- _ O
, -X- _ O
these -X- _ O
observations -X- _ O
indicate -X- _ O
that -X- _ O
FFNs -X- _ O
play -X- _ O
a -X- _ O
critical -X- _ O
role -X- _ O
toward -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
. -X- _ O
We -X- _ O
now -X- _ O
investigate -X- _ O
whether -X- _ O
the -X- _ O
inflection -X- _ O
points -X- _ O
to -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
performance -X- _ O
when -X- _ O
removing -X- _ O
either -X- _ O
attention -X- _ O
heads -X- _ O
or -X- _ O
FFNs -X- _ O
in -X- _ O
an -X- _ O
iterative -X- _ O
fashion -X- _ O
still -X- _ O
hold -X- _ O
when -X- _ O
removing -X- _ O
them -X- _ O
in -X- _ O
tandem -X- _ O
. -X- _ O
Figure -X- _ O
7 -X- _ O
depicts -X- _ O
the -X- _ O
average -X- _ O
5 -X- _ O
- -X- _ O
shot -X- _ O
accuracy -X- _ B-MetricName
of -X- _ O
all -X- _ O
tasks -X- _ O
on -X- _ O
joint -X- _ O
iterative -X- _ O
removal -X- _ O
of -X- _ O
attention -X- _ O
heads -X- _ O
and -X- _ O
FFNs -X- _ O
. -X- _ O
Corresponding -X- _ O
0 -X- _ O
/ -X- _ O
1 -X- _ O
- -X- _ O
shot -X- _ O
trends -X- _ O
are -X- _ O
depicted -X- _ O
in -X- _ O
Appendix -X- _ O
A.5 -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
removal -X- _ O
of -X- _ O
70 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
attention -X- _ O
heads -X- _ O
( -X- _ O
∼15.7B -X- _ O
parameters -X- _ O
) -X- _ O
and -X- _ O
20 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
FFNs -X- _ O
( -X- _ O
∼8.5B -X- _ O
parameters -X- _ O
) -X- _ O
leads -X- _ O
to -X- _ O
a -X- _ O
mere -X- _ O
5 -X- _ B-MetricValue
% -X- _ I-MetricValue
absolute -X- _ O
drop -X- _ O
in -X- _ O
the -X- _ O
average -X- _ O
0 -X- _ O
- -X- _ O
shot -X- _ O
accuracy -X- _ B-MetricName
. -X- _ O
In -X- _ O
the -X- _ O
1 -X- _ O
- -X- _ O
shot -X- _ O
setting -X- _ O
, -X- _ O
the -X- _ O
drop -X- _ O
in -X- _ O
accuracy -X- _ B-MetricName
is -X- _ O
6 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
removing -X- _ O
70 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
attention -X- _ O
heads -X- _ O
and -X- _ O
10 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
FFNs -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
5 -X- _ O
- -X- _ O
shot -X- _ O
setting -X- _ O
, -X- _ O
the -X- _ O
drop -X- _ O
in -X- _ O
accuracy -X- _ B-MetricName
is -X- _ O
4 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
removing -X- _ O
60 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
attention -X- _ O
heads -X- _ O
and -X- _ O
20 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
FFNs -X- _ O
. -X- _ O
Overall -X- _ O
, -X- _ O
these -X- _ O
new -X- _ O
inflection -X- _ O
points -X- _ O
have -X- _ O
deviated -X- _ O
by -X- _ O
at -X- _ O
most -X- _ O
10 -X- _ B-MetricValue
% -X- _ I-MetricValue
absolute -X- _ O
, -X- _ O
which -X- _ O
may -X- _ O
be -X- _ O
attributed -X- _ O
to -X- _ O
the -X- _ O
interplay -X- _ O
between -X- _ O
heads -X- _ O
and -X- _ O
FFNs -X- _ O
. -X- _ O

Removing -X- _ O
FFNs -X- _ O

Combined -X- _ O
Removal -X- _ O
of -X- _ O
Heads -X- _ O
& -X- _ O
FFNs -X- _ O

Detailed -X- _ O
Analysis -X- _ O
of -X- _ O
Attention -X- _ O
Heads -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
a -X- _ O
detailed -X- _ O
analysis -X- _ O
of -X- _ O
the -X- _ O
attention -X- _ O
heads -X- _ O
in -X- _ O
OPT-66B -X- _ B-MethodName
, -X- _ O
given -X- _ O
that -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
is -X- _ O
auto -X- _ O
- -X- _ O
regressive -X- _ O
in -X- _ O
nature -X- _ O
and -X- _ O
attention -X- _ O
heads -X- _ O
explicitly -X- _ O
encode -X- _ O
cross -X- _ O
- -X- _ O
token -X- _ O
interactions -X- _ O
. -X- _ O
Michel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
found -X- _ O
preliminary -X- _ O
empirical -X- _ O
evidence -X- _ O
of -X- _ O
the -X- _ O
existence -X- _ O
of -X- _ O
" -X- _ O
universally -X- _ O
" -X- _ O
important -X- _ O
attention -X- _ O
heads -X- _ O
in -X- _ O
trained -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
Transformer -X- _ O
and -X- _ O
BERT -X- _ O
models -X- _ O
via -X- _ O
evaluating -X- _ O
on -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
domain -X- _ O
test -X- _ O
sets -X- _ O
for -X- _ O
machine -X- _ O
translation -X- _ O
and -X- _ O
natural -X- _ O
language -X- _ O
inference -X- _ O
respectively -X- _ O
. -X- _ O
With -X- _ O
similar -X- _ O
motivation -X- _ O
, -X- _ O
we -X- _ O
study -X- _ O
if -X- _ O
the -X- _ O
( -X- _ O
un -X- _ O
) -X- _ O
important -X- _ O
attention -X- _ O
heads -X- _ O
identified -X- _ O
in -X- _ O
various -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
settings -X- _ O
for -X- _ O
OPT-66B -X- _ B-MethodName
are -X- _ O
shared -X- _ O
across -X- _ O
tasks -X- _ O
. -X- _ O

Cross -X- _ O
- -X- _ O
Task -X- _ O
Analysis -X- _ O

Spearman -X- _ B-MetricName
's -X- _ I-MetricName
Rank -X- _ I-MetricName
Correlation -X- _ I-MetricName

We -X- _ O
assess -X- _ O
overlap -X- _ O
in -X- _ O
( -X- _ O
un -X- _ O
) -X- _ O
important -X- _ O
attention -X- _ O
heads -X- _ O
across -X- _ O
tasks -X- _ O
by -X- _ O
sorting -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
head -X- _ O
importance -X- _ B-MetricName
scores -X- _ O
to -X- _ O
get -X- _ O
head -X- _ O
importance -X- _ B-MetricName
rankings -X- _ I-MetricName
and -X- _ O
computing -X- _ O
the -X- _ O
Spearman -X- _ B-MetricName
's -X- _ I-MetricName
rank -X- _ I-MetricName
correlation -X- _ I-MetricName
coefficient -X- _ I-MetricName
( -X- _ O
SRCC -X- _ B-MetricName
) -X- _ O
between -X- _ O
the -X- _ O
rankings -X- _ O
for -X- _ O
every -X- _ O
pair -X- _ O
of -X- _ O
tasks -X- _ O
in -X- _ O
the -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
and -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
settings -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
sort -X- _ O
the -X- _ O
task -X- _ O
- -X- _ O
aggregate -X- _ O
head -X- _ O
importance -X- _ B-MetricName
scores -X- _ O
to -X- _ O
get -X- _ O
the -X- _ O
aggregate -X- _ O
ranking -X- _ O
and -X- _ O
compute -X- _ O
the -X- _ O
SRCC -X- _ B-MetricName
against -X- _ O
the -X- _ O
ranking -X- _ O
for -X- _ O
every -X- _ O
constituent -X- _ O
task -X- _ O
. -X- _ O
All -X- _ O
correlations -X- _ O
are -X- _ O
depicted -X- _ O
in -X- _ O
Figure -X- _ O
8 -X- _ O
for -X- _ O
the -X- _ O
5 -X- _ O
- -X- _ O
shot -X- _ O
setting -X- _ O
and -X- _ O
Appendix -X- _ O
A.6 -X- _ O
for -X- _ O
the -X- _ O
0 -X- _ O
/ -X- _ O
1 -X- _ O
- -X- _ O
shot -X- _ O
settings -X- _ O
. -X- _ O

In -X- _ O
both -X- _ O
zero -X- _ O
and -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
settings -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
statistically -X- _ O
significant -X- _ O
( -X- _ O
p -X- _ O
< -X- _ O
0.01 -X- _ O
) -X- _ O
positive -X- _ O
correlations -X- _ O
in -X- _ O
the -X- _ O
head -X- _ O
importance -X- _ B-MetricName
rankings -X- _ I-MetricName
for -X- _ O
every -X- _ O
pair -X- _ O
of -X- _ O
tasks -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
between -X- _ O
every -X- _ O
task -X- _ O
's -X- _ O
ranking -X- _ O
and -X- _ O
the -X- _ O
aggregate -X- _ O
ranking -X- _ O
. -X- _ O
This -X- _ O
indicates -X- _ O
that -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
( -X- _ O
un -X- _ O
) -X- _ O
important -X- _ O
attention -X- _ O
heads -X- _ O
are -X- _ O
clustered -X- _ O
together -X- _ O
across -X- _ O
tasks -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
observe -X- _ O
seemingly -X- _ O
lower -X- _ O
magnitude -X- _ O
SRCC -X- _ B-MetricName
values -X- _ O
between -X- _ O
every -X- _ O
task -X- _ O
and -X- _ O
ReCoRD -X- _ B-DatasetName
, -X- _ O
a -X- _ O
long -X- _ O
reading -X- _ B-TaskName
comprehension -X- _ I-TaskName
task -X- _ O
which -X- _ O
requires -X- _ O
commonsense -X- _ B-TaskName
reasoning -X- _ I-TaskName
, -X- _ O
indicating -X- _ O
the -X- _ O
amount -X- _ O
of -X- _ O
head -X- _ O
overlap -X- _ O
is -X- _ O
proportionally -X- _ O
lower -X- _ O
. -X- _ O

Generalization -X- _ O
Trends -X- _ O

To -X- _ O
understand -X- _ O
how -X- _ O
well -X- _ O
head -X- _ O
importance -X- _ B-MetricName
rankings -X- _ I-MetricName
generalize -X- _ O
across -X- _ O
tasks -X- _ O
, -X- _ O
we -X- _ O
study -X- _ O
accuracy -X- _ B-MetricName
trends -X- _ O
for -X- _ O
tasks -X- _ O
when -X- _ O
pruning -X- _ O
using -X- _ O
various -X- _ O
head -X- _ O
importance -X- _ B-MetricName
rankings -X- _ I-MetricName
. -X- _ O
We -X- _ O
study -X- _ O
two -X- _ O
sets -X- _ O
of -X- _ O
tasks -X- _ O
. -X- _ O

The -X- _ O
first -X- _ O
set -X- _ O
of -X- _ O
tasks -X- _ O
we -X- _ O
study -X- _ O
were -X- _ O
used -X- _ O
to -X- _ O
compute -X- _ O
the -X- _ O
aggregate -X- _ O
ranking -X- _ O
: -X- _ O
COPA -X- _ B-DatasetName
, -X- _ O
Winogrande -X- _ B-DatasetName
and -X- _ O
ReCoRD -X- _ B-DatasetName
. -X- _ O
For -X- _ O
each -X- _ O
of -X- _ O
these -X- _ O
3 -X- _ O
tasks -X- _ O
, -X- _ O
we -X- _ O
consider -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
pruning -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
self -X- _ O
- -X- _ O
ranking -X- _ O
, -X- _ O
aggregate -X- _ O
ranking -X- _ O
and -X- _ O
the -X- _ O
rankings -X- _ O
from -X- _ O
the -X- _ O
tasks -X- _ O
which -X- _ O
share -X- _ O
the -X- _ O
highest -X- _ O
and -X- _ O
lowest -X- _ O
SRCC -X- _ B-MetricName
with -X- _ O
them -X- _ O
. -X- _ O
Figures -X- _ O
9a -X- _ O
, -X- _ O
9b -X- _ O
and -X- _ O
9c -X- _ O
de -X- _ O
- -X- _ O
pict -X- _ O
the -X- _ O
accuracy -X- _ B-MetricName
trends -X- _ O
for -X- _ O
these -X- _ O
3 -X- _ O
tasks -X- _ O
in -X- _ O
the -X- _ O
5 -X- _ O
- -X- _ O
shot -X- _ O
setting -X- _ O
. -X- _ O
Corresponding -X- _ O
trends -X- _ O
in -X- _ O
the -X- _ O
0 -X- _ O
/ -X- _ O
1shot -X- _ O
settings -X- _ O
are -X- _ O
in -X- _ O
Appendix -X- _ O
A.7 -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
0 -X- _ O
- -X- _ O
shot -X- _ O
setting -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
accuracy -X- _ B-MetricName
on -X- _ O
all -X- _ O
3 -X- _ O
tasks -X- _ O
when -X- _ O
pruning -X- _ O
using -X- _ O
the -X- _ O
rankings -X- _ O
described -X- _ O
is -X- _ O
almost -X- _ O
unaffected -X- _ O
up -X- _ O
to -X- _ O
the -X- _ O
50 -X- _ O
% -X- _ O
mark -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
observe -X- _ O
a -X- _ O
sharp -X- _ O
decline -X- _ O
in -X- _ O
accuracy -X- _ B-MetricName
on -X- _ O
COPA -X- _ B-DatasetName
and -X- _ O
Winogrande -X- _ B-DatasetName
when -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
pruned -X- _ O
to -X- _ O
the -X- _ O
70 -X- _ O
% -X- _ O
mark -X- _ O
using -X- _ O
the -X- _ O
ranking -X- _ O
identified -X- _ O
via -X- _ O
ReCoRD -X- _ B-DatasetName
, -X- _ O
the -X- _ O
task -X- _ O
with -X- _ O
the -X- _ O
lowest -X- _ O
SRCC -X- _ B-MetricName
( -X- _ O
0.13 -X- _ B-MetricValue
) -X- _ O
with -X- _ O
both -X- _ O
COPA -X- _ B-DatasetName
and -X- _ O
Winogrande -X- _ B-DatasetName
. -X- _ O
This -X- _ O
indicates -X- _ O
that -X- _ O
even -X- _ O
if -X- _ O
the -X- _ O
rankings -X- _ O
vary -X- _ O
between -X- _ O
ReCoRD -X- _ B-DatasetName
and -X- _ O
COPA -X- _ B-DatasetName
/ -X- _ O
Winogrande -X- _ B-DatasetName
( -X- _ O
as -X- _ O
reflected -X- _ O
in -X- _ O
the -X- _ O
low -X- _ O
magnitude -X- _ O
of -X- _ O
the -X- _ O
SRCC -X- _ B-MetricName
score -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
attention -X- _ O
heads -X- _ O
important -X- _ O
for -X- _ O
0 -X- _ O
- -X- _ O
shot -X- _ O
learning -X- _ O
with -X- _ O
ReCoRD -X- _ B-DatasetName
are -X- _ O
important -X- _ O
for -X- _ O
COPA -X- _ B-DatasetName
/ -X- _ O
Winogrande -X- _ B-DatasetName
too -X- _ O
. -X- _ O
To -X- _ O
further -X- _ O
verify -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
calculated -X- _ O
and -X- _ O
found -X- _ O
71 -X- _ O
% -X- _ O
and -X- _ O
76 -X- _ O
% -X- _ O
overlap -X- _ O
between -X- _ O
the -X- _ O
top -X- _ O
30 -X- _ O
% -X- _ O
important -X- _ O
attention -X- _ O
heads -X- _ O
for -X- _ O
ReCoRD -X- _ B-DatasetName
- -X- _ O
COPA -X- _ B-DatasetName
and -X- _ O
ReCoRD -X- _ B-DatasetName
- -X- _ O
Winogrande -X- _ B-DatasetName
respectively -X- _ O
. -X- _ O
Comparing -X- _ O
the -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
setting -X- _ O
against -X- _ O
the -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
settings -X- _ O
, -X- _ O
we -X- _ O
note -X- _ O
that -X- _ O
the -X- _ O
decline -X- _ O
/ -X- _ O
divergence -X- _ O
in -X- _ O
accuracy -X- _ B-MetricName
beyond -X- _ O
the -X- _ O
50 -X- _ O
% -X- _ O
pruning -X- _ O
mark -X- _ O
using -X- _ O
the -X- _ O
ReCoRD -X- _ B-DatasetName
ranking -X- _ O
is -X- _ O
less -X- _ O
sharp -X- _ O
for -X- _ O
COPA -X- _ B-DatasetName
and -X- _ O
Winogrande -X- _ B-DatasetName
in -X- _ O
the -X- _ O
1 -X- _ O
- -X- _ O
shot -X- _ O
setting -X- _ O
and -X- _ O
fades -X- _ O
away -X- _ O
in -X- _ O
the -X- _ O
5 -X- _ O
- -X- _ O
shot -X- _ O
setting -X- _ O
, -X- _ O
indicating -X- _ O
a -X- _ O
convergence -X- _ O
of -X- _ O
important -X- _ O
heads -X- _ O
across -X- _ O
tasks -X- _ O
. -X- _ O

The -X- _ O
second -X- _ O
set -X- _ O
of -X- _ O
tasks -X- _ O
we -X- _ O
study -X- _ O
are -X- _ O
unseen -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
not -X- _ O
used -X- _ O
to -X- _ O
compute -X- _ O
the -X- _ O
aggregate -X- _ O
ranking -X- _ O
: -X- _ O
MathQA -X- _ B-DatasetName
and -X- _ O
LAMBADA -X- _ B-DatasetName
. -X- _ O
For -X- _ O
these -X- _ O
tasks -X- _ O
, -X- _ O
we -X- _ O
analyze -X- _ O
accuracy -X- _ B-MetricName
trends -X- _ O
when -X- _ O
pruning -X- _ O
using -X- _ O
the -X- _ O
selfranking -X- _ O
and -X- _ O
aggregate -X- _ O
ranking -X- _ O
. -X- _ O
Figures -X- _ O
9d -X- _ O
and -X- _ O
9e -X- _ O
depict -X- _ O
their -X- _ O
accuracy -X- _ B-MetricName
trends -X- _ O
in -X- _ O
the -X- _ O
5 -X- _ O
- -X- _ O
shot -X- _ O
setting -X- _ O
. -X- _ O
Corresponding -X- _ O
trends -X- _ O
in -X- _ O
the -X- _ O
0 -X- _ O
/ -X- _ O
1 -X- _ O
- -X- _ O
shot -X- _ O
settings -X- _ O
are -X- _ O
in -X- _ O
Appendix -X- _ O
A.7 -X- _ O
. -X- _ O
As -X- _ O
expected -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
self -X- _ O
- -X- _ O
ranking -X- _ O
accuracy -X- _ O
curves -X- _ O
are -X- _ O
somewhat -X- _ O
higher -X- _ O
than -X- _ O
the -X- _ O
aggregate -X- _ O
ranking -X- _ O
accuracy -X- _ O
curves -X- _ O
in -X- _ O
general -X- _ O
across -X- _ O
both -X- _ O
tasks -X- _ O
. -X- _ O
For -X- _ O
MathQA -X- _ B-DatasetName
, -X- _ O
we -X- _ O
also -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
absolute -X- _ O
difference -X- _ O
in -X- _ O
accuracy -X- _ B-MetricName
for -X- _ O
both -X- _ O
cases -X- _ O
is -X- _ O
within -X- _ O
1 -X- _ B-MetricValue
- -X- _ I-MetricValue
2 -X- _ I-MetricValue
% -X- _ I-MetricValue
. -X- _ O
These -X- _ O
indicate -X- _ O
that -X- _ O
the -X- _ O
aggregate -X- _ O
rankings -X- _ O
generalize -X- _ O
well -X- _ O
to -X- _ O
MathQA -X- _ B-DatasetName
but -X- _ O
not -X- _ O
as -X- _ O
much -X- _ O
to -X- _ O
LAMBADA -X- _ B-DatasetName
. -X- _ O

Cross -X- _ O
- -X- _ O
Shot -X- _ O
Analysis -X- _ O

To -X- _ O
see -X- _ O
if -X- _ O
the -X- _ O
attention -X- _ O
heads -X- _ O
identified -X- _ O
to -X- _ O
be -X- _ O
( -X- _ O
un -X- _ O
) -X- _ O
important -X- _ O
for -X- _ O
a -X- _ O
task -X- _ O
are -X- _ O
shared -X- _ O
across -X- _ O
the -X- _ O
different -X- _ O
zero -X- _ O
and -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
settings -X- _ O
, -X- _ O
we -X- _ O
compute -X- _ O
Spearman -X- _ B-MetricName
's -X- _ I-MetricName
rank -X- _ I-MetricName
correlation -X- _ I-MetricName
coefficient -X- _ I-MetricName
( -X- _ O
SRCC -X- _ B-MetricName
) -X- _ O
between -X- _ O
the -X- _ O
cross -X- _ O
- -X- _ O
shot -X- _ O
head -X- _ O
importance -X- _ O
rankings -X- _ O
for -X- _ O
each -X- _ O
task -X- _ O
and -X- _ O
compute -X- _ O
the -X- _ O
mean -X- _ O
and -X- _ O
variance -X- _ O
across -X- _ O
all -X- _ O
14 -X- _ O
tasks -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
mean -X- _ O
SRCC -X- _ B-MetricName
is -X- _ O
higher -X- _ O
for -X- _ O
rankings -X- _ O
within -X- _ O
the -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
setting -X- _ O
( -X- _ O
0.41 -X- _ B-MetricValue
for -X- _ O
1 -X- _ O
- -X- _ O
shot -X- _ O
vs. -X- _ O
5 -X- _ O
- -X- _ O
shot -X- _ O
) -X- _ O
than -X- _ O
for -X- _ O
rankings -X- _ O
across -X- _ O
the -X- _ O
zero -X- _ O
and -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
settings -X- _ O
( -X- _ O
0.39 -X- _ B-MetricValue
for -X- _ O
0 -X- _ O
- -X- _ O
shot -X- _ O
vs. -X- _ O
1 -X- _ O
- -X- _ O
shot -X- _ O
and -X- _ O
0.37 -X- _ B-MetricValue
for -X- _ O
0 -X- _ O
- -X- _ O
shot -X- _ O
vs. -X- _ O
5 -X- _ O
- -X- _ O
shot -X- _ O
) -X- _ O
, -X- _ O
with -X- _ O
low -X- _ O
variance -X- _ O
( -X- _ O
0.001 -X- _ O
) -X- _ O
and -X- _ O
p -X- _ O
- -X- _ O
value -X- _ O
< -X- _ O
0.01 -X- _ O
. -X- _ O
This -X- _ O
matches -X- _ O
the -X- _ O
intuition -X- _ O
that -X- _ O
a -X- _ O
similar -X- _ O
set -X- _ O
of -X- _ O
heads -X- _ O
must -X- _ O
be -X- _ O
important -X- _ O
within -X- _ O
the -X- _ O
different -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
settings -X- _ O
than -X- _ O
across -X- _ O
the -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
and -X- _ O
any -X- _ O
of -X- _ O
the -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
settings -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
see -X- _ O
that -X- _ O
the -X- _ O
SRCC -X- _ B-MetricName
magnitudes -X- _ O
for -X- _ O
the -X- _ O
latter -X- _ O
are -X- _ O
not -X- _ O
very -X- _ O
far -X- _ O
off -X- _ O
. -X- _ O
In -X- _ O
totality -X- _ O
, -X- _ O
these -X- _ O
indicate -X- _ O
non -X- _ O
- -X- _ O
trivial -X- _ O
overlap -X- _ O
in -X- _ O
the -X- _ O
( -X- _ O
un -X- _ O
) -X- _ O
important -X- _ O
attention -X- _ O
heads -X- _ O
for -X- _ O
tasks -X- _ O
across -X- _ O
shots -X- _ O
. -X- _ O

Induction -X- _ O
Heads -X- _ O
in -X- _ O
OPT-66B -X- _ B-MethodName

We -X- _ O
look -X- _ O
for -X- _ O
induction -X- _ O
heads -X- _ O
in -X- _ O
OPT-66B -X- _ B-MethodName
by -X- _ O
quantifying -X- _ O
the -X- _ O
capacity -X- _ O
of -X- _ O
all -X- _ O
attention -X- _ O
heads -X- _ O
to -X- _ O
perform -X- _ O
prefix -X- _ B-TaskName
matching -X- _ I-TaskName
and -X- _ O
copying -X- _ B-TaskName
using -X- _ O
random -X- _ O
input -X- _ O
sequences -X- _ O
in -X- _ O
a -X- _ O
task -X- _ O
- -X- _ O
agnostic -X- _ O
fashion -X- _ O
, -X- _ O
following -X- _ O
the -X- _ O
definition -X- _ O
and -X- _ O
algorithms -X- _ O
by -X- _ O
Olsson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
discussed -X- _ O
in -X- _ O
§ -X- _ O
2.2 -X- _ O
and -X- _ O
Appendix -X- _ O
A.8 -X- _ O
. -X- _ O

Figures -X- _ O
10a -X- _ O
and -X- _ O
10b -X- _ O
depict -X- _ O
the -X- _ O
prefix -X- _ B-MetricName
matching -X- _ I-MetricName
and -X- _ O
copying -X- _ B-MetricName
score -X- _ O
heatmaps -X- _ O
respectively -X- _ O
for -X- _ O
OPT-66B. -X- _ B-MethodName
We -X- _ O
observe -X- _ O
that -X- _ O
a -X- _ O
small -X- _ O
subset -X- _ O
of -X- _ O
attention -X- _ O
heads -X- _ O
in -X- _ O
OPT-66B -X- _ B-MethodName
have -X- _ O
high -X- _ O
prefix -X- _ B-MetricName
matching -X- _ I-MetricName
scores -X- _ O
, -X- _ O
located -X- _ O
in -X- _ O
the -X- _ O
upper -X- _ O
layers -X- _ O
( -X- _ O
31 -X- _ O
+ -X- _ O
) -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
a -X- _ O
relatively -X- _ O
larger -X- _ O
number -X- _ O
of -X- _ O
attention -X- _ O
heads -X- _ O
with -X- _ O
high -X- _ O
copying -X- _ B-MetricName
scores -X- _ O
, -X- _ O
although -X- _ O
the -X- _ O
vast -X- _ O
majority -X- _ O
of -X- _ O
these -X- _ O
are -X- _ O
also -X- _ O
located -X- _ O
in -X- _ O
the -X- _ O
upper -X- _ O
layers -X- _ O
( -X- _ O
41 -X- _ O
+ -X- _ O
) -X- _ O
. -X- _ O
When -X- _ O
seen -X- _ O
in -X- _ O
conjunction -X- _ O
, -X- _ O
these -X- _ O
observations -X- _ O
indicate -X- _ O
that -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
sparse -X- _ O
set -X- _ O
of -X- _ O
attention -X- _ O
heads -X- _ O
that -X- _ O
are -X- _ O
capable -X- _ O
of -X- _ O
performing -X- _ O
both -X- _ O
primitive -X- _ O
operations -X- _ O
and -X- _ O
thus -X- _ O
can -X- _ O
be -X- _ O
deemed -X- _ O
plausible -X- _ O
induction -X- _ O
heads -X- _ O
. -X- _ O

Are -X- _ O
Induction -X- _ O
Heads -X- _ O
Important -X- _ O
? -X- _ O

We -X- _ O
now -X- _ O
study -X- _ O
whether -X- _ O
induction -X- _ O
heads -X- _ O
( -X- _ O
which -X- _ O
encode -X- _ O
the -X- _ O
basic -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
primitives -X- _ O
of -X- _ O
explicit -X- _ O
prefix -X- _ B-TaskName
matching -X- _ I-TaskName
and -X- _ O
copying -X- _ B-TaskName
) -X- _ O
overlap -X- _ O
with -X- _ O
attention -X- _ O
heads -X- _ O
identified -X- _ O
to -X- _ O
be -X- _ O
important -X- _ O
( -X- _ O
and -X- _ O
consequently -X- _ O
capable -X- _ O
of -X- _ O
sophisticated -X- _ O
and -X- _ O
latent -X- _ O
behaviors -X- _ O
associated -X- _ O
with -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
) -X- _ O
for -X- _ O
our -X- _ O
chosen -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O

A -X- _ O
qualitative -X- _ O
comparison -X- _ O
of -X- _ O
the -X- _ O
heatmaps -X- _ O
in -X- _ O
Figure -X- _ O
10 -X- _ O
against -X- _ O
the -X- _ O
heatmaps -X- _ O
referenced -X- _ O
in -X- _ O
§ -X- _ O
4.1 -X- _ O
indicates -X- _ O
that -X- _ O
induction -X- _ O
heads -X- _ O
do -X- _ O
overlap -X- _ O
with -X- _ O
taskaggregated -X- _ O
important -X- _ O
attention -X- _ O
heads -X- _ O
. -X- _ O
To -X- _ O
better -X- _ O
facilitate -X- _ O
this -X- _ O
comparison -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
formalize -X- _ O
the -X- _ O
total -X- _ O
capacity -X- _ O
of -X- _ O
a -X- _ O
model -X- _ O
to -X- _ O
perform -X- _ O
prefix -X- _ B-TaskName
matching -X- _ I-TaskName
( -X- _ O
or -X- _ O
copying -X- _ B-TaskName
) -X- _ O
to -X- _ O
be -X- _ O
the -X- _ O
sum -X- _ O
of -X- _ O
the -X- _ O
respective -X- _ O
scores -X- _ O
for -X- _ O
individual -X- _ O
attention -X- _ O
heads -X- _ O
in -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
investigate -X- _ O
how -X- _ O
much -X- _ O
of -X- _ O
this -X- _ O
capacity -X- _ O
is -X- _ O
retained -X- _ O
when -X- _ O
attention -X- _ O
heads -X- _ O
are -X- _ O
pruned -X- _ O
in -X- _ O
the -X- _ O
order -X- _ O
of -X- _ O
least -X- _ O
important -X- _ O
heads -X- _ O
first -X- _ O
. -X- _ O
Figure -X- _ O
11 -X- _ O
picts -X- _ O
this -X- _ O
comparison -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
much -X- _ O
of -X- _ O
the -X- _ O
total -X- _ O
prefix -X- _ B-MetricName
matching -X- _ I-MetricName
score -X- _ O
is -X- _ O
retained -X- _ O
when -X- _ O
20 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
least -X- _ O
important -X- _ O
heads -X- _ O
are -X- _ O
removed -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
slope -X- _ O
of -X- _ O
decline -X- _ O
becoming -X- _ O
sharp -X- _ O
only -X- _ O
after -X- _ O
the -X- _ O
40 -X- _ O
% -X- _ O
pruning -X- _ O
mark -X- _ O
. -X- _ O
This -X- _ O
indicates -X- _ O
that -X- _ O
unimportant -X- _ O
heads -X- _ O
also -X- _ O
have -X- _ O
low -X- _ O
prefix -X- _ B-MetricName
matching -X- _ I-MetricName
scores -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
prefix -X- _ B-MetricName
matching -X- _ I-MetricName
scores -X- _ O
are -X- _ O
generally -X- _ O
higher -X- _ O
for -X- _ O
heads -X- _ O
important -X- _ O
for -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
than -X- _ O
for -X- _ O
heads -X- _ O
important -X- _ O
for -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
learning -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
across -X- _ O
the -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
and -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
settings -X- _ O
that -X- _ O
the -X- _ O
total -X- _ O
copying -X- _ B-MetricName
score -X- _ O
retained -X- _ O
on -X- _ O
pruning -X- _ O
attention -X- _ O
heads -X- _ O
rapidly -X- _ O
and -X- _ O
consistently -X- _ O
declines -X- _ O
, -X- _ O
indicating -X- _ O
that -X- _ O
even -X- _ O
unimportant -X- _ O
heads -X- _ O
have -X- _ O
a -X- _ O
non -X- _ O
- -X- _ O
trivial -X- _ O
capacity -X- _ O
to -X- _ O
perform -X- _ O
copying -X- _ B-TaskName
. -X- _ O
When -X- _ O
seen -X- _ O
in -X- _ O
conjunction -X- _ O
, -X- _ O
these -X- _ O
observations -X- _ O
indicate -X- _ O
that -X- _ O
induction -X- _ O
heads -X- _ O
in -X- _ O
OPT-66B -X- _ B-MethodName
are -X- _ O
capable -X- _ O
of -X- _ O
sophisticated -X- _ O
behaviors -X- _ O
associated -X- _ O
with -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
popular -X- _ O
downstream -X- _ O
NLP -X- _ O
tasks -X- _ O
and -X- _ O
reinforce -X- _ O
the -X- _ O
induction -X- _ O
head -X- _ O
generality -X- _ O
arguments -X- _ O
Olsson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
make -X- _ O
in -X- _ O
the -X- _ O
context -X- _ O
of -X- _ O
smaller -X- _ O
models -X- _ O
with -X- _ O
stylized -X- _ O
and -X- _ O
synthetic -X- _ O
tasks -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
provide -X- _ O
per -X- _ O
- -X- _ O
task -X- _ O
plots -X- _ O
in -X- _ O
Appendix -X- _ O
A.9 -X- _ O
which -X- _ O
showcase -X- _ O
that -X- _ O
some -X- _ O
tasks -X- _ O
rely -X- _ O
on -X- _ O
induction -X- _ O
heads -X- _ O
more -X- _ O
than -X- _ O
other -X- _ O
tasks -X- _ O
. -X- _ O

Related -X- _ O
Work -X- _ O

There -X- _ O
has -X- _ O
been -X- _ O
an -X- _ O
interest -X- _ O
in -X- _ O
effectively -X- _ O
leveraging -X- _ O
the -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
paradigm -X- _ O
( -X- _ O
Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Holtzman -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Min -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022a -X- _ O
; -X- _ O
Lu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
; -X- _ O
Rubin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
; -X- _ O
ever -X- _ O
since -X- _ O
its -X- _ O
introduction -X- _ O
by -X- _ O
, -X- _ O
but -X- _ O
there -X- _ O
have -X- _ O
been -X- _ O
relatively -X- _ O
fewer -X- _ O
studies -X- _ O
toward -X- _ O
better -X- _ O
understanding -X- _ O
the -X- _ O
paradigm -X- _ O
itself -X- _ O
. -X- _ O
Xie -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
cast -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
as -X- _ O
implicit -X- _ O
Bayesian -X- _ O
inference -X- _ O
where -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
implicitly -X- _ O
infers -X- _ O
a -X- _ O
shared -X- _ O
concept -X- _ O
among -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
examples -X- _ O
when -X- _ O
making -X- _ O
a -X- _ O
prediction -X- _ O
. -X- _ O
Min -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022b -X- _ O
) -X- _ O
study -X- _ O
the -X- _ O
role -X- _ O
of -X- _ O
the -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
examples -X- _ O
themselves -X- _ O
, -X- _ O
finding -X- _ O
that -X- _ O
the -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
labels -X- _ O
are -X- _ O
not -X- _ O
needed -X- _ O
in -X- _ O
the -X- _ O
examples -X- _ O
and -X- _ O
that -X- _ O
the -X- _ O
more -X- _ O
important -X- _ O
drivers -X- _ O
are -X- _ O
provision -X- _ O
of -X- _ O
the -X- _ O
label -X- _ O
space -X- _ O
, -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
text -X- _ O
and -X- _ O
the -X- _ O
overall -X- _ O
format -X- _ O
of -X- _ O
the -X- _ O
sequence -X- _ O
. -X- _ O
Garg -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
showcase -X- _ O
that -X- _ O
Transformer -X- _ O
models -X- _ O
trained -X- _ O
from -X- _ O
scratch -X- _ O
can -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learn -X- _ O
the -X- _ O
class -X- _ O
of -X- _ O
linear -X- _ O
functions -X- _ O
with -X- _ O
performance -X- _ O
comparable -X- _ O
to -X- _ O
the -X- _ O
optimal -X- _ O
least -X- _ O
squares -X- _ O
estimator -X- _ O
even -X- _ O
under -X- _ O
distribution -X- _ O
shifts -X- _ O
. -X- _ O
Razeghi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
showcase -X- _ O
that -X- _ O
incontext -X- _ O
learning -X- _ O
performance -X- _ O
is -X- _ O
correlated -X- _ O
strongly -X- _ O
with -X- _ O
term -X- _ O
frequencies -X- _ O
in -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
corpora -X- _ O
used -X- _ O
. -X- _ O
Olsson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
consider -X- _ O
an -X- _ O
alternate -X- _ O
framing -X- _ O
of -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
as -X- _ O
the -X- _ O
ability -X- _ O
of -X- _ O
a -X- _ O
language -X- _ O
model -X- _ O
to -X- _ O
better -X- _ O
predict -X- _ O
tokens -X- _ O
later -X- _ O
in -X- _ O
the -X- _ O
context -X- _ O
than -X- _ O
tokens -X- _ O
earlier -X- _ O
and -X- _ O
hypothesize -X- _ O
the -X- _ O
existence -X- _ O
of -X- _ O
induction -X- _ O
heads -X- _ O
that -X- _ O
are -X- _ O
responsible -X- _ O
for -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
. -X- _ O
Chan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
show -X- _ O
that -X- _ O
Transformers -X- _ O
exhibit -X- _ O
striking -X- _ O
differences -X- _ O
in -X- _ O
generalizing -X- _ O
from -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
vs. -X- _ O
in -X- _ O
- -X- _ O
weights -X- _ O
information -X- _ O
. -X- _ O

Several -X- _ O
works -X- _ O
have -X- _ O
also -X- _ O
focused -X- _ O
on -X- _ O
analyzing -X- _ O
and -X- _ O
interpreting -X- _ O
how -X- _ O
attention -X- _ O
works -X- _ O
. -X- _ O
Vig -X- _ O
and -X- _ O
Belinkov -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
performed -X- _ O
a -X- _ O
study -X- _ O
on -X- _ O
GPT-2 -X- _ O
, -X- _ O
finding -X- _ O
that -X- _ O
attention -X- _ O
targets -X- _ O
different -X- _ O
parts -X- _ O
of -X- _ O
speech -X- _ O
at -X- _ O
different -X- _ O
layer -X- _ O
depths -X- _ O
and -X- _ O
aligns -X- _ O
with -X- _ O
dependency -X- _ O
relations -X- _ O
most -X- _ O
strongly -X- _ O
in -X- _ O
the -X- _ O
middle -X- _ O
layers -X- _ O
. -X- _ O
Tenney -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
showcase -X- _ O
that -X- _ O
BERT -X- _ O
encodes -X- _ O
the -X- _ O
classical -X- _ O
NLP -X- _ O
pipeline -X- _ O
in -X- _ O
an -X- _ O
interpretable -X- _ O
way -X- _ O
across -X- _ O
layers -X- _ O
. -X- _ O
There -X- _ O
are -X- _ O
works -X- _ O
relying -X- _ O
on -X- _ O
different -X- _ O
formulations -X- _ O
for -X- _ O
head -X- _ O
importance -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
layerwise -X- _ O
relevance -X- _ O
propagation -X- _ O
( -X- _ O
Voita -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
gradient -X- _ O
- -X- _ O
based -X- _ O
importance -X- _ O
and -X- _ O
oracle -X- _ O
knock -X- _ O
- -X- _ O
off -X- _ O
importance -X- _ O
( -X- _ O
Michel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
with -X- _ O
small -X- _ O
taskspecific -X- _ O
trained -X- _ O
models -X- _ O
and -X- _ O
report -X- _ O
the -X- _ O
existence -X- _ O
of -X- _ O
specialized -X- _ O
heads -X- _ O
. -X- _ O
Given -X- _ O
the -X- _ O
recent -X- _ O
trend -X- _ O
of -X- _ O
increasing -X- _ O
model -X- _ O
scale -X- _ O
( -X- _ O
Lieber -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Chowdhery -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
; -X- _ O
Smith -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
; -X- _ O
Rae -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
toward -X- _ O
tuning -X- _ O
- -X- _ O
free -X- _ O
general -X- _ O
- -X- _ O
purpose -X- _ O
language -X- _ O
models -X- _ O
that -X- _ O
exhibit -X- _ O
emergent -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
abilities -X- _ O
, -X- _ O
we -X- _ O
draw -X- _ O
and -X- _ O
build -X- _ O
on -X- _ O
prior -X- _ O
work -X- _ O
to -X- _ O
understand -X- _ O
just -X- _ O
how -X- _ O
much -X- _ O
scale -X- _ O
is -X- _ O
really -X- _ O
needed -X- _ O
and -X- _ O
/ -X- _ O
or -X- _ O
used -X- _ O
for -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
downstream -X- _ O
, -X- _ O
an -X- _ O
aspect -X- _ O
somewhat -X- _ O
eclipsed -X- _ O
by -X- _ O
the -X- _ O
focus -X- _ O
on -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
loss -X- _ O
curve -X- _ O
in -X- _ O
scaling -X- _ O
laws -X- _ O
( -X- _ O
Hoffmann -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
also -X- _ O
worth -X- _ O
noting -X- _ O
that -X- _ O
some -X- _ O
of -X- _ O
our -X- _ O
empirical -X- _ O
observations -X- _ O
rely -X- _ O
on -X- _ O
a -X- _ O
simple -X- _ O
greedy -X- _ O
approach -X- _ O
to -X- _ O
training -X- _ O
- -X- _ O
free -X- _ O
pruning -X- _ O
since -X- _ O
our -X- _ O
focus -X- _ O
was -X- _ O
not -X- _ O
to -X- _ O
optimally -X- _ O
prune -X- _ O
a -X- _ O
language -X- _ O
model -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
performing -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
. -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
show -X- _ O
the -X- _ O
greedy -X- _ O
approach -X- _ O
is -X- _ O
sub -X- _ O
- -X- _ O
optimal -X- _ O
and -X- _ O
produces -X- _ O
under -X- _ O
- -X- _ O
estimates -X- _ O
and -X- _ O
Halabi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
account -X- _ O
for -X- _ O
the -X- _ O
need -X- _ O
to -X- _ O
re -X- _ O
- -X- _ O
compute -X- _ O
importance -X- _ O
scores -X- _ O
after -X- _ O
removal -X- _ O
of -X- _ O
each -X- _ O
attention -X- _ O
head -X- _ O
or -X- _ O
FFN -X- _ O
by -X- _ O
formulating -X- _ O
pruning -X- _ O
as -X- _ O
weakly -X- _ O
sub -X- _ O
- -X- _ O
modular -X- _ O
maximization -X- _ O
. -X- _ O

Conclusion -X- _ O
& -X- _ O
Future -X- _ O
Work -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
studied -X- _ O
the -X- _ O
efficacy -X- _ O
of -X- _ O
attention -X- _ O
heads -X- _ O
and -X- _ O
feed -X- _ O
forward -X- _ O
networks -X- _ O
( -X- _ O
FFNs -X- _ O
) -X- _ O
in -X- _ O
a -X- _ O
large -X- _ O
language -X- _ O
model -X- _ O
( -X- _ O
OPT-66B -X- _ B-MethodName
) -X- _ O
in -X- _ O
performing -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
in -X- _ O
both -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
and -X- _ O
task -X- _ O
- -X- _ O
agnostic -X- _ O
settings -X- _ O
. -X- _ O
We -X- _ O
observed -X- _ O
that -X- _ O
while -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
may -X- _ O
have -X- _ O
emerged -X- _ O
via -X- _ O
selfsupervised -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
at -X- _ O
scale -X- _ O
, -X- _ O
only -X- _ O
a -X- _ O
core -X- _ O
nucleus -X- _ O
of -X- _ O
attention -X- _ O
heads -X- _ O
and -X- _ O
FFNs -X- _ O
seem -X- _ O
to -X- _ O
be -X- _ O
important -X- _ O
for -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
across -X- _ O
a -X- _ O
wide -X- _ O
variety -X- _ O
of -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O
We -X- _ O
observed -X- _ O
that -X- _ O
a -X- _ O
small -X- _ O
set -X- _ O
of -X- _ O
attention -X- _ O
heads -X- _ O
have -X- _ O
the -X- _ O
capacity -X- _ O
to -X- _ O
perform -X- _ O
task -X- _ O
- -X- _ O
agnostic -X- _ O
primitive -X- _ O
induction -X- _ O
operations -X- _ O
associated -X- _ O
with -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
, -X- _ O
namely -X- _ O
, -X- _ O
prefix -X- _ B-TaskName
matching -X- _ I-TaskName
and -X- _ O
copying -X- _ B-TaskName
. -X- _ O
We -X- _ O
also -X- _ O
saw -X- _ O
that -X- _ O
these -X- _ O
induction -X- _ O
heads -X- _ O
overlap -X- _ O
with -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
important -X- _ O
attention -X- _ O
heads -X- _ O
, -X- _ O
indicating -X- _ O
that -X- _ O
induction -X- _ O
heads -X- _ O
are -X- _ O
capable -X- _ O
of -X- _ O
more -X- _ O
sophisticated -X- _ O
forms -X- _ O
of -X- _ O
incontext -X- _ O
learning -X- _ O
and -X- _ O
reinforcing -X- _ O
arguments -X- _ O
( -X- _ O
Olsson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
about -X- _ O
their -X- _ O
generality -X- _ O
. -X- _ O
Overall -X- _ O
, -X- _ O
our -X- _ O
incontext -X- _ O
learning -X- _ O
- -X- _ O
centric -X- _ O
observations -X- _ O
complement -X- _ O
recent -X- _ O
work -X- _ O
( -X- _ O
Hoffmann -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
in -X- _ O
indicating -X- _ O
that -X- _ O
large -X- _ O
language -X- _ O
models -X- _ O
may -X- _ O
be -X- _ O
under -X- _ O
- -X- _ O
trained -X- _ O
and -X- _ O
motivate -X- _ O
several -X- _ O
interesting -X- _ O
directions -X- _ O
for -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O
While -X- _ O
induction -X- _ O
heads -X- _ O
are -X- _ O
formed -X- _ O
naturally -X- _ O
during -X- _ O
self -X- _ O
- -X- _ O
supervised -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
in -X- _ O
its -X- _ O
current -X- _ O
form -X- _ O
, -X- _ O
we -X- _ O
believe -X- _ O
it -X- _ O
may -X- _ O
be -X- _ O
possible -X- _ O
to -X- _ O
increase -X- _ O
the -X- _ O
number -X- _ O
and -X- _ O
strength -X- _ O
of -X- _ O
induction -X- _ O
heads -X- _ O
formed -X- _ O
by -X- _ O
defining -X- _ O
auxiliary -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
objectives -X- _ O
for -X- _ O
primitives -X- _ O
like -X- _ O
prefix -X- _ B-TaskName
matching -X- _ I-TaskName
and -X- _ O
copying -X- _ B-TaskName
. -X- _ O
More -X- _ O
generally -X- _ O
, -X- _ O
it -X- _ O
may -X- _ O
also -X- _ O
be -X- _ O
prudent -X- _ O
to -X- _ O
investigate -X- _ O
and -X- _ O
improve -X- _ O
( -X- _ O
pre- -X- _ O
) -X- _ O
training -X- _ O
regimes -X- _ O
to -X- _ O
increase -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
important -X- _ O
model -X- _ O
components -X- _ O
to -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learn -X- _ O
- -X- _ O
perform -X- _ O
a -X- _ O
wide -X- _ O
variety -X- _ O
of -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O
Multi -X- _ O
- -X- _ O
task -X- _ O
instruction -X- _ O
- -X- _ O
tuning -X- _ O
likely -X- _ O
belongs -X- _ O
to -X- _ O
this -X- _ O
category -X- _ O
and -X- _ O
it -X- _ O
would -X- _ O
be -X- _ O
interesting -X- _ O
to -X- _ O
replicate -X- _ O
our -X- _ O
study -X- _ O
with -X- _ O
now -X- _ O
increasingly -X- _ O
accessible -X- _ O
instructiontuned -X- _ O
model -X- _ O
variants -X- _ O
( -X- _ O
such -X- _ O
as -X- _ O
OPT -X- _ B-MethodName
's -X- _ O
instruction -X- _ O
meta -X- _ O
- -X- _ O
learned -X- _ O
variant -X- _ O
OPT -X- _ O
- -X- _ O
IML -X- _ O
) -X- _ O
. -X- _ O

Limitations -X- _ O

Our -X- _ O
work -X- _ O
is -X- _ O
a -X- _ O
comprehensive -X- _ O
empirical -X- _ O
study -X- _ O
of -X- _ O
a -X- _ O
popular -X- _ O
large -X- _ O
language -X- _ O
model -X- _ O
's -X- _ O
capacity -X- _ O
to -X- _ O
perform -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
, -X- _ O
relying -X- _ O
on -X- _ O
both -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
( -X- _ O
via -X- _ O
a -X- _ O
wide -X- _ O
variety -X- _ O
of -X- _ O
challenging -X- _ O
and -X- _ O
practically -X- _ O
relevant -X- _ O
downstream -X- _ O
tasks -X- _ O
) -X- _ O
and -X- _ O
task -X- _ O
- -X- _ O
agnostic -X- _ O
( -X- _ O
via -X- _ O
looking -X- _ O
for -X- _ O
induction -X- _ O
heads -X- _ O
) -X- _ O
analyses -X- _ O
and -X- _ O
connecting -X- _ O
the -X- _ O
two -X- _ O
via -X- _ O
correlation -X- _ O
/ -X- _ O
overlap -X- _ O
investigations -X- _ O
. -X- _ O
We -X- _ O
do -X- _ O
not -X- _ O
claim -X- _ O
a -X- _ O
causal -X- _ O
link -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
claim -X- _ O
that -X- _ O
an -X- _ O
attention -X- _ O
head -X- _ O
that -X- _ O
acquires -X- _ O
the -X- _ O
capacity -X- _ O
to -X- _ O
be -X- _ O
an -X- _ O
induction -X- _ O
head -X- _ O
will -X- _ O
become -X- _ O
capable -X- _ O
of -X- _ O
more -X- _ O
sophisticated -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
associated -X- _ O
with -X- _ O
our -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O
Making -X- _ O
this -X- _ O
claim -X- _ O
will -X- _ O
require -X- _ O
a -X- _ O
more -X- _ O
deeper -X- _ O
investigation -X- _ O
that -X- _ O
is -X- _ O
outside -X- _ O
the -X- _ O
scope -X- _ O
of -X- _ O
this -X- _ O
paper -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
do -X- _ O
not -X- _ O
fully -X- _ O
understand -X- _ O
why -X- _ O
most -X- _ O
attention -X- _ O
heads -X- _ O
seem -X- _ O
to -X- _ O
be -X- _ O
unimportant -X- _ O
for -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
and -X- _ O
why -X- _ O
there -X- _ O
is -X- _ O
an -X- _ O
overlap -X- _ O
in -X- _ O
( -X- _ O
un -X- _ O
) -X- _ O
important -X- _ O
attention -X- _ O
heads -X- _ O
across -X- _ O
tasks -X- _ O
and -X- _ O
shots -X- _ O
, -X- _ O
which -X- _ O
warrant -X- _ O
further -X- _ O
investigation -X- _ O
. -X- _ O
Other -X- _ O
more -X- _ O
obvious -X- _ O
limitations -X- _ O
to -X- _ O
our -X- _ O
work -X- _ O
include -X- _ O
our -X- _ O
use -X- _ O
of -X- _ O
only -X- _ O
up -X- _ O
to -X- _ O
5 -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
examples -X- _ O
, -X- _ O
random -X- _ O
selection -X- _ O
of -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
examples -X- _ O
for -X- _ O
a -X- _ O
query -X- _ O
input -X- _ O
and -X- _ O
our -X- _ O
choice -X- _ O
of -X- _ O
all -X- _ O
monolingual -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O

Impact -X- _ O
Statement -X- _ O

The -X- _ O
findings -X- _ O
in -X- _ O
our -X- _ O
work -X- _ O
have -X- _ O
significant -X- _ O
implications -X- _ O
for -X- _ O
the -X- _ O
design -X- _ O
, -X- _ O
development -X- _ O
and -X- _ O
deployment -X- _ O
of -X- _ O
large -X- _ O
language -X- _ O
models -X- _ O
, -X- _ O
known -X- _ O
to -X- _ O
have -X- _ O
a -X- _ O
very -X- _ O
high -X- _ O
carbon -X- _ O
footprint -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
training -X- _ O
and -X- _ O
inference -X- _ O
costs -X- _ O
. -X- _ O
Having -X- _ O
identified -X- _ O
that -X- _ O
a -X- _ O
core -X- _ O
nucleus -X- _ O
of -X- _ O
model -X- _ O
parameters -X- _ O
seem -X- _ O
to -X- _ O
be -X- _ O
important -X- _ O
for -X- _ O
incontext -X- _ O
learning -X- _ O
, -X- _ O
it -X- _ O
may -X- _ O
be -X- _ O
possible -X- _ O
to -X- _ O
reduce -X- _ O
these -X- _ O
models -X- _ O
' -X- _ O
carbon -X- _ O
footprint -X- _ O
and -X- _ O
mitigate -X- _ O
these -X- _ O
costs -X- _ O
. -X- _ O
Our -X- _ O
findings -X- _ O
provide -X- _ O
architectural -X- _ O
transparency -X- _ O
and -X- _ O
may -X- _ O
also -X- _ O
be -X- _ O
helpful -X- _ O
in -X- _ O
identifying -X- _ O
targeted -X- _ O
improvements -X- _ O
for -X- _ O
downstream -X- _ O
tasks -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
for -X- _ O
more -X- _ O
broader -X- _ O
facets -X- _ O
such -X- _ O
as -X- _ O
bias -X- _ O
and -X- _ O
fairness -X- _ O
. -X- _ O

A -X- _ O
Appendix -X- _ O

A.1 -X- _ O
Head -X- _ O
Importance -X- _ B-MetricName
Scores -X- _ O
Figure -X- _ O
12 -X- _ O
depicts -X- _ O
the -X- _ O
attention -X- _ O
head -X- _ O
aggregate -X- _ O
importance -X- _ B-MetricName
score -X- _ O
heatmaps -X- _ O
in -X- _ O
the -X- _ O
0 -X- _ O
- -X- _ O
shot -X- _ O
and -X- _ O
1 -X- _ O
- -X- _ O
shot -X- _ O
settings -X- _ O
. -X- _ O
Figures -X- _ O
14 -X- _ O
, -X- _ O
15 -X- _ O
and -X- _ O
16 -X- _ O
depict -X- _ O
the -X- _ O
attention -X- _ O
head -X- _ O
importance -X- _ B-MetricName
scores -X- _ O
for -X- _ O
each -X- _ O
task -X- _ O
in -X- _ O
the -X- _ O
0 -X- _ O
- -X- _ O
shot -X- _ O
, -X- _ O
1 -X- _ O
- -X- _ O
shot -X- _ O
and -X- _ O
5 -X- _ O
- -X- _ O
shot -X- _ O
settings -X- _ O
respectively -X- _ O
. -X- _ O

A.2 -X- _ O
FFN -X- _ O
Importance -X- _ B-MetricName
Scores -X- _ O

Figure -X- _ O
13 -X- _ O
depicts -X- _ O
the -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
and -X- _ O
taskaveraged -X- _ O
importance -X- _ B-MetricName
scores -X- _ O
for -X- _ O
feed -X- _ O
forward -X- _ O
networks -X- _ O
in -X- _ O
the -X- _ O
0 -X- _ O
- -X- _ O
shot -X- _ O
and -X- _ O
1 -X- _ O
- -X- _ O
shot -X- _ O
settings -X- _ O
. -X- _ O

A.3 -X- _ O
Removing -X- _ O
Attention -X- _ O
Heads -X- _ O

Figure -X- _ O
17 -X- _ O
depicts -X- _ O
the -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
and -X- _ O
taskaveraged -X- _ O
accuracy -X- _ B-MetricName
trends -X- _ O
on -X- _ O
iterative -X- _ O
removal -X- _ O
of -X- _ O
attention -X- _ O
heads -X- _ O
in -X- _ O
the -X- _ O
order -X- _ O
of -X- _ O
least -X- _ O
important -X- _ O
first -X- _ O
in -X- _ O
the -X- _ O
0 -X- _ O
- -X- _ O
shot -X- _ O
and -X- _ O
1 -X- _ O
- -X- _ O
shot -X- _ O
settings -X- _ O
. -X- _ O

A.4 -X- _ O
Removing -X- _ O
FFNs -X- _ O

Figure -X- _ O
18 -X- _ O
depicts -X- _ O
the -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
and -X- _ O
taskaveraged -X- _ O
accuracy -X- _ B-MetricName
trends -X- _ O
on -X- _ O
iterative -X- _ O
removal -X- _ O
of -X- _ O
feed -X- _ O
forward -X- _ O
networks -X- _ O
in -X- _ O
the -X- _ O
order -X- _ O
of -X- _ O
least -X- _ O
important -X- _ O
first -X- _ O
in -X- _ O
the -X- _ O
1 -X- _ O
- -X- _ O
shot -X- _ O
and -X- _ O
5 -X- _ O
- -X- _ O
shot -X- _ O
settings -X- _ O
. -X- _ O

A.5 -X- _ O
Combined -X- _ O
Removal -X- _ O
of -X- _ O
Heads -X- _ O
& -X- _ O
FFNs -X- _ O

Figure -X- _ O
19 -X- _ O
depicts -X- _ O
the -X- _ O
average -X- _ O
accuracy -X- _ B-MetricName
of -X- _ O
all -X- _ O
tasks -X- _ O
on -X- _ O
joint -X- _ O
iterative -X- _ O
removal -X- _ O
of -X- _ O
attention -X- _ O
heads -X- _ O
and -X- _ O
feed -X- _ O
forward -X- _ O
networks -X- _ O
in -X- _ O
the -X- _ O
order -X- _ O
of -X- _ O
least -X- _ O
important -X- _ O
first -X- _ O
in -X- _ O
the -X- _ O
0 -X- _ O
- -X- _ O
shot -X- _ O
and -X- _ O
1 -X- _ O
- -X- _ O
shot -X- _ O
settings -X- _ O
. -X- _ O

A.6 -X- _ O
Cross -X- _ O
- -X- _ O
Task -X- _ O
Analysis -X- _ O
: -X- _ O
Spearman -X- _ B-MetricName
's -X- _ I-MetricName
Rank -X- _ I-MetricName
Correlation -X- _ I-MetricName

Figure -X- _ O
20 -X- _ O
depicts -X- _ O
the -X- _ O
Spearman -X- _ B-MetricName
's -X- _ I-MetricName
rank -X- _ I-MetricName
correlation -X- _ I-MetricName
coefficients -X- _ I-MetricName
( -X- _ O
SRCC -X- _ B-MetricName
) -X- _ O
between -X- _ O
the -X- _ O
attention -X- _ O
head -X- _ O
importance -X- _ O
rankings -X- _ O
for -X- _ O
every -X- _ O
pair -X- _ O
of -X- _ O
tasks -X- _ O
in -X- _ O
the -X- _ O
0 -X- _ O
- -X- _ O
shot -X- _ O
and -X- _ O
1 -X- _ O
- -X- _ O
shot -X- _ O
settings -X- _ O
. -X- _ O
It -X- _ O
also -X- _ O
depicts -X- _ O
the -X- _ O
SRCC -X- _ B-MetricName
between -X- _ O
the -X- _ O
aggregate -X- _ O
ranking -X- _ O
and -X- _ O
the -X- _ O
ranking -X- _ O
for -X- _ O
each -X- _ O
constituent -X- _ O
task -X- _ O
. -X- _ O

A.7 -X- _ O
Cross -X- _ O
- -X- _ O
Task -X- _ O
Analysis -X- _ O
: -X- _ O
Generalization -X- _ O
Trends -X- _ O

Figures -X- _ O
21 -X- _ O
and -X- _ O
22 -X- _ O
depict -X- _ O
the -X- _ O
cross -X- _ O
- -X- _ O
task -X- _ O
head -X- _ O
importance -X- _ B-MetricName
ranking -X- _ I-MetricName
generalization -X- _ O
plots -X- _ O
in -X- _ O
the -X- _ O
0 -X- _ O
- -X- _ O
shot -X- _ O
and -X- _ O
1 -X- _ O
- -X- _ O
shot -X- _ O
settings -X- _ O
. -X- _ O

A.8 -X- _ O
Details -X- _ O
of -X- _ O
Prefix -X- _ B-MetricName
Matching -X- _ I-MetricName
and -X- _ O
Copying -X- _ B-MetricName
Scores -X- _ O

Algorithms -X- _ O
1 -X- _ O
and -X- _ O
2 -X- _ O
contain -X- _ O
pseudo -X- _ O
- -X- _ O
code -X- _ O
to -X- _ O
compute -X- _ O
prefix -X- _ B-MetricName
matching -X- _ I-MetricName
and -X- _ O
copying -X- _ B-MetricName
scores -X- _ O
respectively -X- _ O
for -X- _ O
each -X- _ O
attention -X- _ O
head -X- _ O
in -X- _ O
OPT-66B. -X- _ B-MethodName
We -X- _ O
follow -X- _ O
the -X- _ O
approach -X- _ O
described -X- _ O
by -X- _ O
Olsson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
instead -X- _ O
of -X- _ O
computing -X- _ O
scores -X- _ O
using -X- _ O
10 -X- _ O
sequences -X- _ O
with -X- _ O
fixed -X- _ O
length -X- _ O
of -X- _ O
25 -X- _ O
, -X- _ O
we -X- _ O
compute -X- _ O
these -X- _ O
scores -X- _ O
using -X- _ O
100 -X- _ B-HyperparameterValue
sequences -X- _ B-HyperparameterName
with -X- _ O
varying -X- _ O
lengths -X- _ O
to -X- _ O
account -X- _ O
for -X- _ O
OPT-66B -X- _ B-MethodName
's -X- _ O
large -X- _ O
maximum -X- _ O
sequence -X- _ O
length -X- _ O
. -X- _ O
Each -X- _ O
FFN -X- _ O
is -X- _ O
knocked -X- _ O
off -X- _ O
independently -X- _ O
to -X- _ O
compute -X- _ O
these -X- _ O
scores -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
the -X- _ O
curves -X- _ O
are -X- _ O
discrete -X- _ O
and -X- _ O
not -X- _ O
cumulative -X- _ O
. -X- _ O

As -X- _ O
in -X- _ O
Olsson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
exclude -X- _ O
a -X- _ O
small -X- _ O
fraction -X- _ O
of -X- _ O
the -X- _ O
most -X- _ O
and -X- _ O
least -X- _ O
common -X- _ O
tokens -X- _ O
from -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
vocabulary -X- _ O
and -X- _ O
randomly -X- _ O
sample -X- _ O
tokens -X- _ O
for -X- _ O
these -X- _ O
sequences -X- _ O
to -X- _ O
strip -X- _ O
out -X- _ O
the -X- _ O
effects -X- _ O
of -X- _ O
pretraining -X- _ O
corpora -X- _ O
memorization -X- _ O
from -X- _ O
our -X- _ O
scores -X- _ O
and -X- _ O
inductive -X- _ O
behavior -X- _ O
analyses -X- _ O
. -X- _ O

For -X- _ O
prefix -X- _ B-MetricName
matching -X- _ I-MetricName
, -X- _ O
the -X- _ O
high -X- _ O
- -X- _ O
level -X- _ O
approach -X- _ O
is -X- _ O
the -X- _ O
following -X- _ O
: -X- _ O
take -X- _ O
a -X- _ O
random -X- _ O
sequence -X- _ O
, -X- _ O
repeat -X- _ O
it -X- _ O
4 -X- _ O
times -X- _ O
, -X- _ O
perform -X- _ O
a -X- _ O
forward -X- _ O
pass -X- _ O
and -X- _ O
then -X- _ O
for -X- _ O
each -X- _ O
head -X- _ O
, -X- _ O
compute -X- _ O
the -X- _ O
attention -X- _ O
pattern -X- _ O
and -X- _ O
take -X- _ O
the -X- _ O
average -X- _ O
of -X- _ O
all -X- _ O
attention -X- _ O
pattern -X- _ O
entries -X- _ O
attending -X- _ O
from -X- _ O
a -X- _ O
given -X- _ O
token -X- _ O
back -X- _ O
to -X- _ O
tokens -X- _ O
that -X- _ O
succeeded -X- _ O
the -X- _ O
same -X- _ O
token -X- _ O
in -X- _ O
earlier -X- _ O
repeats -X- _ O
. -X- _ O

For -X- _ O
copying -X- _ B-MetricName
, -X- _ O
the -X- _ O
high -X- _ O
- -X- _ O
level -X- _ O
approach -X- _ O
is -X- _ O
the -X- _ O
following -X- _ O
: -X- _ O
take -X- _ O
a -X- _ O
random -X- _ O
sequence -X- _ O
, -X- _ O
directly -X- _ O
feed -X- _ O
the -X- _ O
sequence -X- _ O
through -X- _ O
each -X- _ O
head -X- _ O
and -X- _ O
compute -X- _ O
the -X- _ O
contribution -X- _ O
of -X- _ O
the -X- _ O
head -X- _ O
to -X- _ O
the -X- _ O
output -X- _ O
logits -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
measure -X- _ O
how -X- _ O
much -X- _ O
the -X- _ O
head -X- _ O
increased -X- _ O
the -X- _ O
logit -X- _ O
of -X- _ O
the -X- _ O
maximally -X- _ O
attended -X- _ O
to -X- _ O
token -X- _ O
over -X- _ O
increasing -X- _ O
the -X- _ O
logits -X- _ O
of -X- _ O
other -X- _ O
attendable -X- _ O
tokens -X- _ O
at -X- _ O
each -X- _ O
timestep -X- _ O
. -X- _ O
Unlike -X- _ O
Olsson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
scale -X- _ O
the -X- _ O
raw -X- _ O
scores -X- _ O
to -X- _ O
be -X- _ O
in -X- _ O
the -X- _ O
range -X- _ O
of -X- _ O
-1 -X- _ O
to -X- _ O
1 -X- _ O
. -X- _ O

A.9 -X- _ O
Importance -X- _ O
of -X- _ O
Induction -X- _ O
Heads -X- _ O
to -X- _ O
Each -X- _ O
Task -X- _ O

Figures -X- _ O
23 -X- _ O
and -X- _ O
24 -X- _ O
showcase -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
induction -X- _ O
heads -X- _ O
to -X- _ O
each -X- _ O
task -X- _ O
via -X- _ O
measuring -X- _ O
the -X- _ O
percentage -X- _ O
of -X- _ O
the -X- _ O
total -X- _ O
prefix -X- _ B-MetricName
matching -X- _ I-MetricName
and -X- _ O
copying -X- _ B-MetricName
capacities -X- _ O
retained -X- _ O
as -X- _ O
a -X- _ O
function -X- _ O
of -X- _ O
percentage -X- _ O
of -X- _ O
attention -X- _ O
heads -X- _ O
pruned -X- _ O
, -X- _ O
where -X- _ O
heads -X- _ O
are -X- _ O
pruned -X- _ O
based -X- _ O
on -X- _ O
each -X- _ O
task -X- _ O
's -X- _ O
head -X- _ O
importance -X- _ B-MetricName
ranking -X- _ I-MetricName
for -X- _ O
each -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
setting -X- _ O
( -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
, -X- _ O
oneshot -X- _ O
and -X- _ O
five -X- _ O
- -X- _ O
shot -X- _ O
) -X- _ O
in -X- _ O
the -X- _ O
order -X- _ O
of -X- _ O
least -X- _ O
important -X- _ O
first -X- _ O
. -X- _ O
A -X- _ O
small -X- _ O
initial -X- _ O
slope -X- _ O
of -X- _ O
decline -X- _ O
implies -X- _ O
that -X- _ O
unimportant -X- _ O
heads -X- _ O
also -X- _ O
have -X- _ O
low -X- _ O
prefix -X- _ B-MetricName
matching -X- _ I-MetricName
or -X- _ O
copying -X- _ B-MetricName
scores -X- _ O
while -X- _ O
a -X- _ O
steep -X- _ O
initial -X- _ O
slope -X- _ O
of -X- _ O
decline -X- _ O
implies -X- _ O
unimportant -X- _ O
heads -X- _ O
also -X- _ O
have -X- _ O
high -X- _ O
prefix -X- _ B-MetricName
matching -X- _ I-MetricName
or -X- _ O
copying -X- _ B-MetricName
scores -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
differ -X- _ O
- -X- _ O
ences -X- _ O
in -X- _ O
the -X- _ O
slopes -X- _ O
of -X- _ O
decline -X- _ O
across -X- _ O
different -X- _ O
tasks -X- _ O
, -X- _ O
with -X- _ O
tasks -X- _ O
like -X- _ O
HellaSwag -X- _ B-DatasetName
and -X- _ O
ReCoRD -X- _ B-DatasetName
( -X- _ O
which -X- _ O
have -X- _ O
high -X- _ O
accuracies -X- _ B-MetricName
in -X- _ O
Figure -X- _ O
5 -X- _ O
) -X- _ O
having -X- _ O
smaller -X- _ O
initial -X- _ O
slopes -X- _ O
than -X- _ O
a -X- _ O
task -X- _ O
like -X- _ O
OpenBookQA -X- _ B-DatasetName
( -X- _ O
which -X- _ O
has -X- _ O
relatively -X- _ O
lower -X- _ O
accuracy -X- _ B-MetricName
in -X- _ O
Figure -X- _ O
5 -X- _ O
) -X- _ O
. -X- _ O
When -X- _ O
seen -X- _ O
in -X- _ O
conjunction -X- _ O
, -X- _ O
these -X- _ O
plots -X- _ O
not -X- _ O
only -X- _ O
point -X- _ O
to -X- _ O
the -X- _ O
generality -X- _ O
of -X- _ O
induction -X- _ O
heads -X- _ O
to -X- _ O
more -X- _ O
sophisticated -X- _ O
behaviors -X- _ O
associated -X- _ O
with -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
but -X- _ O
also -X- _ O
indicate -X- _ O
that -X- _ O
some -X- _ O
tasks -X- _ O
rely -X- _ O
on -X- _ O
induction -X- _ O
heads -X- _ O
more -X- _ O
than -X- _ O
others -X- _ O
. -X- _ O


The -X- _ O
OPT-66B -X- _ B-MethodName
model -X- _ O
is -X- _ O
open -X- _ O
- -X- _ O
sourced -X- _ O
by -X- _ O
Meta -X- _ O
under -X- _ O
an -X- _ O
unrestricted -X- _ O
license -X- _ O
for -X- _ O
academic -X- _ O
research -X- _ O
. -X- _ O