-DOCSTART- -X- O
DaMSTF -X- _ B-MethodName
: -X- _ O
Domain -X- _ B-MethodName
Adversarial -X- _ I-MethodName
Learning -X- _ I-MethodName
Enhanced -X- _ I-MethodName
Meta -X- _ I-MethodName
Self -X- _ I-MethodName
- -X- _ I-MethodName
Training -X- _ I-MethodName
for -X- _ O
Domain -X- _ B-TaskName
Adaptation -X- _ I-TaskName

Self -X- _ O
- -X- _ O
training -X- _ O
emerges -X- _ O
as -X- _ O
an -X- _ O
important -X- _ O
research -X- _ O
line -X- _ O
on -X- _ O
domain -X- _ B-TaskName
adaptation -X- _ I-TaskName
. -X- _ O
By -X- _ O
taking -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
prediction -X- _ O
as -X- _ O
the -X- _ O
pseudo -X- _ O
labels -X- _ O
of -X- _ O
the -X- _ O
unlabeled -X- _ O
data -X- _ O
, -X- _ O
self -X- _ O
- -X- _ O
training -X- _ O
bootstraps -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
pseudo -X- _ O
instances -X- _ O
in -X- _ O
the -X- _ O
target -X- _ O
domain -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
prediction -X- _ O
errors -X- _ O
of -X- _ O
pseudo -X- _ O
labels -X- _ O
( -X- _ O
label -X- _ O
noise -X- _ O
) -X- _ O
challenge -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
self -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O
To -X- _ O
address -X- _ O
this -X- _ O
problem -X- _ O
, -X- _ O
previous -X- _ O
approaches -X- _ O
only -X- _ O
use -X- _ O
reliable -X- _ O
pseudo -X- _ O
instances -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
pseudo -X- _ O
instances -X- _ O
with -X- _ O
high -X- _ O
prediction -X- _ O
confidence -X- _ O
, -X- _ O
to -X- _ O
retrain -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O
Although -X- _ O
these -X- _ O
strategies -X- _ O
effectively -X- _ O
reduce -X- _ O
the -X- _ O
label -X- _ O
noise -X- _ O
, -X- _ O
they -X- _ O
are -X- _ O
prone -X- _ O
to -X- _ O
miss -X- _ O
the -X- _ O
hard -X- _ O
examples -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
new -X- _ O
self -X- _ O
- -X- _ O
training -X- _ O
framework -X- _ O
for -X- _ O
domain -X- _ B-TaskName
adaptation -X- _ I-TaskName
, -X- _ O
namely -X- _ O
Domain -X- _ B-MethodName
adversarial -X- _ I-MethodName
learning -X- _ I-MethodName
enhanced -X- _ I-MethodName
Self -X- _ I-MethodName
- -X- _ I-MethodName
Training -X- _ I-MethodName
Framework -X- _ I-MethodName
( -X- _ O
DaMSTF -X- _ B-MethodName
) -X- _ O
. -X- _ O
Firstly -X- _ O
, -X- _ O
DaMSTF -X- _ O
involves -X- _ O
meta -X- _ O
- -X- _ O
learning -X- _ O
to -X- _ O
estimate -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
each -X- _ O
pseudo -X- _ O
instance -X- _ O
, -X- _ O
so -X- _ O
as -X- _ O
to -X- _ O
simultaneously -X- _ O
reduce -X- _ O
the -X- _ O
label -X- _ O
noise -X- _ O
and -X- _ O
preserve -X- _ O
hard -X- _ O
examples -X- _ O
. -X- _ O
Secondly -X- _ O
, -X- _ O
we -X- _ O
design -X- _ O
a -X- _ O
meta -X- _ O
constructor -X- _ O
for -X- _ O
constructing -X- _ O
the -X- _ O
meta -X- _ O
validation -X- _ O
set -X- _ O
, -X- _ O
which -X- _ O
guarantees -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
meta -X- _ O
- -X- _ O
learning -X- _ O
module -X- _ O
by -X- _ O
improving -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
the -X- _ O
meta -X- _ O
validation -X- _ O
set -X- _ O
. -X- _ O
Thirdly -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
meta -X- _ O
- -X- _ O
learning -X- _ O
module -X- _ O
suffers -X- _ O
from -X- _ O
the -X- _ O
training -X- _ O
guidance -X- _ O
vanishment -X- _ O
and -X- _ O
tends -X- _ O
to -X- _ O
converge -X- _ O
to -X- _ O
an -X- _ O
inferior -X- _ O
optimal -X- _ O
. -X- _ O
To -X- _ O
this -X- _ O
end -X- _ O
, -X- _ O
we -X- _ O
employ -X- _ O
domain -X- _ O
adversarial -X- _ O
learning -X- _ O
as -X- _ O
a -X- _ O
heuristic -X- _ O
neural -X- _ O
network -X- _ O
initialization -X- _ O
method -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
help -X- _ O
the -X- _ O
meta -X- _ O
- -X- _ O
learning -X- _ O
module -X- _ O
converge -X- _ O
to -X- _ O
a -X- _ O
better -X- _ O
optimal -X- _ O
. -X- _ O
Theoretically -X- _ O
and -X- _ O
experimentally -X- _ O
, -X- _ O
we -X- _ O
demonstrate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
DaMSTF -X- _ B-MethodName
. -X- _ O
On -X- _ O
the -X- _ O
cross -X- _ O
- -X- _ O
domain -X- _ O
sentiment -X- _ B-TaskName
classification -X- _ I-TaskName
task -X- _ O
, -X- _ O
DaMSTF -X- _ B-MethodName
improves -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
with -X- _ O
an -X- _ O
average -X- _ O
of -X- _ O
nearly -X- _ O
4 -X- _ B-MetricValue
% -X- _ I-MetricValue
. -X- _ O

Introduction -X- _ O

Domain -X- _ B-TaskName
adaptation -X- _ I-TaskName
, -X- _ O
which -X- _ O
aims -X- _ O
to -X- _ O
adapt -X- _ O
the -X- _ O
model -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
source -X- _ O
domain -X- _ O
to -X- _ O
the -X- _ O
target -X- _ O
domain -X- _ O
, -X- _ O
† -X- _ O
contributed -X- _ O
equally -X- _ O
to -X- _ O
this -X- _ O
work -X- _ O
* -X- _ O
corresponding -X- _ O
author -X- _ O
attracts -X- _ O
much -X- _ O
attention -X- _ O
in -X- _ O
Natural -X- _ O
Language -X- _ O
Processing -X- _ O
( -X- _ O
NLP -X- _ O
) -X- _ O
applications -X- _ O
( -X- _ O
Du -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Lu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
Since -X- _ O
domain -X- _ B-TaskName
adaptation -X- _ I-TaskName
involves -X- _ O
labeled -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
source -X- _ O
domain -X- _ O
and -X- _ O
unlabeled -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
target -X- _ O
domain -X- _ O
, -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
regarded -X- _ O
as -X- _ O
a -X- _ O
semi -X- _ O
- -X- _ O
supervised -X- _ O
learning -X- _ O
problem -X- _ O
. -X- _ O
From -X- _ O
this -X- _ O
perspective -X- _ O
, -X- _ O
self -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
a -X- _ O
classical -X- _ O
semi -X- _ O
- -X- _ O
supervised -X- _ O
learning -X- _ O
approach -X- _ O
, -X- _ O
emerges -X- _ O
a -X- _ O
prospective -X- _ O
research -X- _ O
direction -X- _ O
on -X- _ O
domain -X- _ B-TaskName
adaptation -X- _ I-TaskName
( -X- _ O
Zou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

Self -X- _ O
- -X- _ O
training -X- _ O
consists -X- _ O
of -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
loops -X- _ O
over -X- _ O
the -X- _ O
pseudo -X- _ O
labeling -X- _ O
phase -X- _ O
and -X- _ O
model -X- _ O
retraining -X- _ O
phase -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
pseudo -X- _ O
labeling -X- _ O
phase -X- _ O
, -X- _ O
self -X- _ O
- -X- _ O
training -X- _ O
takes -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
prediction -X- _ O
as -X- _ O
the -X- _ O
pseudo -X- _ O
labels -X- _ O
for -X- _ O
the -X- _ O
unlabeled -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
target -X- _ O
domain -X- _ O
. -X- _ O
Based -X- _ O
on -X- _ O
these -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
instances -X- _ O
, -X- _ O
self -X- _ O
- -X- _ O
training -X- _ O
retrains -X- _ O
the -X- _ O
current -X- _ O
model -X- _ O
in -X- _ O
the -X- _ O
model -X- _ O
retraining -X- _ O
phase -X- _ O
. -X- _ O
The -X- _ O
trained -X- _ O
model -X- _ O
can -X- _ O
be -X- _ O
adapted -X- _ O
to -X- _ O
the -X- _ O
target -X- _ O
domain -X- _ O
by -X- _ O
repeating -X- _ O
these -X- _ O
two -X- _ O
phases -X- _ O
. -X- _ O
Due -X- _ O
to -X- _ O
the -X- _ O
prediction -X- _ O
errors -X- _ O
, -X- _ O
there -X- _ O
exists -X- _ O
label -X- _ O
noise -X- _ O
in -X- _ O
pseudo -X- _ O
instances -X- _ O
, -X- _ O
which -X- _ O
challenges -X- _ O
self -X- _ O
- -X- _ O
training -X- _ O
approaches -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

Previous -X- _ O
self -X- _ O
- -X- _ O
training -X- _ O
approaches -X- _ O
usually -X- _ O
involve -X- _ O
a -X- _ O
data -X- _ O
selection -X- _ O
process -X- _ O
to -X- _ O
reduce -X- _ O
the -X- _ O
label -X- _ O
noise -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
preserving -X- _ O
the -X- _ O
reliable -X- _ O
pseudo -X- _ O
instances -X- _ O
and -X- _ O
discarding -X- _ O
the -X- _ O
remaining -X- _ O
ones -X- _ O
. -X- _ O
In -X- _ O
general -X- _ O
, -X- _ O
higher -X- _ O
prediction -X- _ O
confidence -X- _ O
implies -X- _ O
higher -X- _ O
prediction -X- _ O
correctness -X- _ O
, -X- _ O
so -X- _ O
existing -X- _ O
self -X- _ O
- -X- _ O
training -X- _ O
approaches -X- _ O
prefer -X- _ O
the -X- _ O
pseudo -X- _ O
instances -X- _ O
with -X- _ O
high -X- _ O
prediction -X- _ O
confidence -X- _ O
( -X- _ O
Zou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Shin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
fitting -X- _ O
the -X- _ O
model -X- _ O
on -X- _ O
these -X- _ O
easy -X- _ O
pseudo -X- _ O
instances -X- _ O
can -X- _ O
not -X- _ O
effectively -X- _ O
improve -X- _ O
the -X- _ O
model -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
already -X- _ O
confident -X- _ O
about -X- _ O
its -X- _ O
prediction -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
contrary -X- _ O
, -X- _ O
pseudo -X- _ O
instances -X- _ O
with -X- _ O
low -X- _ O
prediction -X- _ O
confidence -X- _ O
can -X- _ O
provide -X- _ O
more -X- _ O
information -X- _ O
for -X- _ O
improving -X- _ O
the -X- _ O
model -X- _ O
, -X- _ O
but -X- _ O
contain -X- _ O
more -X- _ O
label -X- _ O
noise -X- _ O
at -X- _ O
the -X- _ O
same -X- _ O
time -X- _ O
. -X- _ O

To -X- _ O
simultaneously -X- _ O
reduce -X- _ O
the -X- _ O
label -X- _ O
noise -X- _ O
and -X- _ O
preserve -X- _ O
hard -X- _ O
examples -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
involve -X- _ O
in -X- _ O
meta -X- _ O
- -X- _ O
learning -X- _ O
to -X- _ O
reweight -X- _ O
pseudo -X- _ O
instances -X- _ O
. -X- _ O
Within -X- _ O
a -X- _ O
learning -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
learn -X- _ O
schema -X- _ O
, -X- _ O
the -X- _ O
meta -X- _ O
- -X- _ O
learning -X- _ O
mod -X- _ O
- -X- _ O
ule -X- _ O
learns -X- _ O
to -X- _ O
estimate -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
every -X- _ O
pseudo -X- _ O
instance -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
, -X- _ O
allocates -X- _ O
different -X- _ O
instance -X- _ O
weights -X- _ O
to -X- _ O
different -X- _ O
pseudo -X- _ O
instances -X- _ O
. -X- _ O
Ideally -X- _ O
, -X- _ O
hard -X- _ O
and -X- _ O
correct -X- _ O
pseudo -X- _ O
instances -X- _ O
will -X- _ O
be -X- _ O
assigned -X- _ O
larger -X- _ O
weights -X- _ O
, -X- _ O
while -X- _ O
easy -X- _ O
or -X- _ O
error -X- _ O
pseudo -X- _ O
instances -X- _ O
will -X- _ O
be -X- _ O
assigned -X- _ O
smaller -X- _ O
weights -X- _ O
. -X- _ O
To -X- _ O
achieve -X- _ O
this -X- _ O
, -X- _ O
the -X- _ O
process -X- _ O
in -X- _ O
the -X- _ O
meta -X- _ O
- -X- _ O
learning -X- _ O
module -X- _ O
is -X- _ O
formulated -X- _ O
as -X- _ O
a -X- _ O
bi -X- _ O
- -X- _ O
level -X- _ O
hyperparameters -X- _ O
optimization -X- _ O
problem -X- _ O
( -X- _ O
Franceschi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
instance -X- _ O
weights -X- _ O
are -X- _ O
taken -X- _ O
as -X- _ O
the -X- _ O
hyperparameters -X- _ O
and -X- _ O
determined -X- _ O
by -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
meta -X- _ O
- -X- _ O
training -X- _ O
steps -X- _ O
and -X- _ O
meta -X- _ O
- -X- _ O
validation -X- _ O
steps -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
meta -X- _ O
- -X- _ O
training -X- _ O
step -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
virtually -X- _ O
updated -X- _ O
on -X- _ O
the -X- _ O
metatraining -X- _ O
set -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
current -X- _ O
instance -X- _ O
weights -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
meta -X- _ O
validation -X- _ O
step -X- _ O
, -X- _ O
we -X- _ O
validate -X- _ O
the -X- _ O
virtually -X- _ O
updated -X- _ O
model -X- _ O
with -X- _ O
an -X- _ O
unbiased -X- _ O
meta -X- _ O
validation -X- _ O
set -X- _ O
, -X- _ O
and -X- _ O
optimize -X- _ O
the -X- _ O
instance -X- _ O
weights -X- _ O
with -X- _ O
the -X- _ O
training -X- _ O
guidance -X- _ O
back -X- _ O
- -X- _ O
propagated -X- _ O
from -X- _ O
the -X- _ O
validation -X- _ O
performance -X- _ O
. -X- _ O

According -X- _ O
to -X- _ O
the -X- _ O
analysis -X- _ O
in -X- _ O
( -X- _ O
Ren -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
high -X- _ O
- -X- _ O
quality -X- _ O
meta -X- _ O
validation -X- _ O
set -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
clean -X- _ O
and -X- _ O
unbiased -X- _ O
to -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
, -X- _ O
is -X- _ O
important -X- _ O
for -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
meta -X- _ O
- -X- _ O
learning -X- _ O
algorithm -X- _ O
. -X- _ O
To -X- _ O
this -X- _ O
end -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
meta -X- _ O
constructor -X- _ O
oriented -X- _ O
to -X- _ O
the -X- _ O
domain -X- _ O
adaptation -X- _ O
scenario -X- _ O
. -X- _ O
At -X- _ O
each -X- _ O
self -X- _ O
- -X- _ O
training -X- _ O
iteration -X- _ O
, -X- _ O
the -X- _ O
meta -X- _ O
constructor -X- _ O
selects -X- _ O
out -X- _ O
the -X- _ O
most -X- _ O
reliable -X- _ O
pseudo -X- _ O
instances -X- _ O
and -X- _ O
inserts -X- _ O
them -X- _ O
into -X- _ O
the -X- _ O
meta -X- _ O
validation -X- _ O
set -X- _ O
. -X- _ O
Since -X- _ O
the -X- _ O
instances -X- _ O
in -X- _ O
the -X- _ O
meta -X- _ O
validation -X- _ O
set -X- _ O
are -X- _ O
all -X- _ O
from -X- _ O
the -X- _ O
target -X- _ O
domain -X- _ O
and -X- _ O
vary -X- _ O
along -X- _ O
with -X- _ O
the -X- _ O
self -X- _ O
- -X- _ O
training -X- _ O
iterations -X- _ O
, -X- _ O
the -X- _ O
data -X- _ O
distribution -X- _ O
in -X- _ O
the -X- _ O
constructed -X- _ O
meta -X- _ O
validation -X- _ O
set -X- _ O
approximates -X- _ O
the -X- _ O
one -X- _ O
in -X- _ O
the -X- _ O
target -X- _ O
domain -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
the -X- _ O
meta -X- _ O
constructor -X- _ O
reduces -X- _ O
the -X- _ O
bias -X- _ O
of -X- _ O
the -X- _ O
meta -X- _ O
validation -X- _ O
set -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
selecting -X- _ O
the -X- _ O
most -X- _ O
reliable -X- _ O
pseudo -X- _ O
instances -X- _ O
can -X- _ O
reduce -X- _ O
the -X- _ O
label -X- _ O
noise -X- _ O
, -X- _ O
making -X- _ O
the -X- _ O
meta -X- _ O
validation -X- _ O
set -X- _ O
cleaner -X- _ O
. -X- _ O

Another -X- _ O
challenge -X- _ O
for -X- _ O
the -X- _ O
meta -X- _ O
- -X- _ O
learning -X- _ O
module -X- _ O
is -X- _ O
the -X- _ O
training -X- _ O
guidance -X- _ O
vanishment -X- _ O
, -X- _ O
referring -X- _ O
to -X- _ O
the -X- _ O
gradient -X- _ O
vanishment -X- _ O
on -X- _ O
hyperparameters -X- _ O
. -X- _ O
With -X- _ O
a -X- _ O
theoretical -X- _ O
analysis -X- _ O
, -X- _ O
we -X- _ O
attribute -X- _ O
this -X- _ O
problem -X- _ O
to -X- _ O
the -X- _ O
gradient -X- _ O
vanishment -X- _ O
on -X- _ O
the -X- _ O
meta -X- _ O
validation -X- _ O
set -X- _ O
. -X- _ O
To -X- _ O
this -X- _ O
end -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
a -X- _ O
domain -X- _ B-MethodName
adversarial -X- _ I-MethodName
learning -X- _ I-MethodName
module -X- _ O
to -X- _ O
perturb -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
parameters -X- _ O
, -X- _ O
thereby -X- _ O
increasing -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
gradients -X- _ O
on -X- _ O
the -X- _ O
meta -X- _ O
validation -X- _ O
set -X- _ O
. -X- _ O
In -X- _ O
DaMSTF -X- _ B-MethodName
, -X- _ O
we -X- _ O
also -X- _ O
interpret -X- _ O
the -X- _ O
domain -X- _ B-MethodName
adversarial -X- _ I-MethodName
learning -X- _ I-MethodName
module -X- _ O
as -X- _ O
a -X- _ O
heuristic -X- _ O
neural -X- _ O
network -X- _ O
initialization -X- _ O
method -X- _ O
. -X- _ O
Before -X- _ O
the -X- _ O
model -X- _ O
retraining -X- _ O
phase -X- _ O
, -X- _ O
the -X- _ O
domain -X- _ B-MethodName
adversarial -X- _ I-MethodName
learning -X- _ I-MethodName
module -X- _ O
first -X- _ O
initializes -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
parameters -X- _ O
by -X- _ O
aligning -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
feature -X- _ O
space -X- _ O
. -X- _ O
For -X- _ O
domain -X- _ B-TaskName
adaptation -X- _ I-TaskName
, -X- _ O
the -X- _ O
global -X- _ O
optimal -X- _ O
refers -X- _ O
to -X- _ O
the -X- _ O
state -X- _ O
where -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
parameters -X- _ O
are -X- _ O
agnostic -X- _ O
to -X- _ O
the -X- _ O
domain -X- _ O
information -X- _ O
but -X- _ O
discriminative -X- _ O
to -X- _ O
the -X- _ O
task -X- _ O
information -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
the -X- _ O
training -X- _ O
process -X- _ O
in -X- _ O
the -X- _ O
domain -X- _ B-MethodName
adversarial -X- _ I-MethodName
learning -X- _ I-MethodName
module -X- _ O
makes -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
parameters -X- _ O
closer -X- _ O
to -X- _ O
the -X- _ O
global -X- _ O
optimal -X- _ O
, -X- _ O
serving -X- _ O
as -X- _ O
a -X- _ O
heuristic -X- _ O
neural -X- _ O
network -X- _ O
initialization -X- _ O
. -X- _ O

Our -X- _ O
contributions -X- _ O
can -X- _ O
be -X- _ O
summarized -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

• -X- _ O
• -X- _ O
We -X- _ O
propose -X- _ O
a -X- _ O
meta -X- _ O
constructor -X- _ O
to -X- _ O
construct -X- _ O
the -X- _ O
meta -X- _ O
validation -X- _ O
set -X- _ O
, -X- _ O
which -X- _ O
guarantees -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
meta -X- _ O
- -X- _ O
learning -X- _ O
module -X- _ O
. -X- _ O

• -X- _ O
We -X- _ O
theoretically -X- _ O
point -X- _ O
out -X- _ O
the -X- _ O
training -X- _ O
guidance -X- _ O
vanishment -X- _ O
problem -X- _ O
in -X- _ O
the -X- _ O
meta -X- _ O
- -X- _ O
learning -X- _ O
module -X- _ O
and -X- _ O
propose -X- _ O
to -X- _ O
address -X- _ O
this -X- _ O
problem -X- _ O
with -X- _ O
a -X- _ O
domain -X- _ B-MethodName
adversarial -X- _ I-MethodName
learning -X- _ I-MethodName
module -X- _ O
. -X- _ O

• -X- _ O
Theoretically -X- _ O
, -X- _ O
We -X- _ O
analyze -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
DaMSTF -X- _ B-MethodName
in -X- _ O
achieving -X- _ O
domain -X- _ B-TaskName
adaptation -X- _ I-TaskName
. -X- _ O
Experimentally -X- _ O
, -X- _ O
we -X- _ O
validate -X- _ O
the -X- _ O
DaMSTF -X- _ B-MethodName
on -X- _ O
two -X- _ O
popular -X- _ O
models -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
for -X- _ O
the -X- _ O
sentiment -X- _ B-TaskName
analysis -X- _ I-TaskName
task -X- _ O
and -X- _ O
BiGCN -X- _ B-MethodName
for -X- _ O
the -X- _ O
rumor -X- _ B-TaskName
detection -X- _ I-TaskName
task -X- _ O
, -X- _ O
with -X- _ O
four -X- _ O
benchmark -X- _ O
datasets -X- _ O
. -X- _ O

Problem -X- _ O
Formulation -X- _ O

We -X- _ O
denote -X- _ O
the -X- _ O
set -X- _ O
that -X- _ O
involves -X- _ O
all -X- _ O
instances -X- _ O
in -X- _ O
the -X- _ O
source -X- _ O
domain -X- _ O
as -X- _ O
D -X- _ O
S -X- _ O
, -X- _ O
and -X- _ O
denote -X- _ O
the -X- _ O
set -X- _ O
that -X- _ O
contains -X- _ O
all -X- _ O
instances -X- _ O
in -X- _ O
the -X- _ O
target -X- _ O
domain -X- _ O
as -X- _ O
D -X- _ O
T -X- _ O
. -X- _ O

From -X- _ O
D -X- _ O
S -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
obtain -X- _ O
a -X- _ O
labeled -X- _ O
dataset -X- _ O
for -X- _ O
training -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
D -X- _ O
S -X- _ O
= -X- _ O
{ -X- _ O
( -X- _ O
x -X- _ O
i -X- _ O
, -X- _ O
y -X- _ O
i -X- _ O
) -X- _ O
} -X- _ O
N -X- _ O
i=1 -X- _ O
. -X- _ O
In -X- _ O
text -X- _ O
classification -X- _ O
tasks -X- _ O
, -X- _ O
the -X- _ O
input -X- _ O
x -X- _ O
i -X- _ O
is -X- _ O
a -X- _ O
text -X- _ O
from -X- _ O
the -X- _ O
input -X- _ O
space -X- _ O
X -X- _ O
, -X- _ O
the -X- _ O
corresponding -X- _ O
label -X- _ O
y -X- _ O
i -X- _ O
is -X- _ O
a -X- _ O
C -X- _ O
- -X- _ O
dimensional -X- _ O
one -X- _ O
- -X- _ O
hot -X- _ O
label -X- _ O
vector -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
y -X- _ O
i -X- _ O
∈ -X- _ O
{ -X- _ O
0 -X- _ O
, -X- _ O
1 -X- _ O
} -X- _ O
C -X- _ O
, -X- _ O
where -X- _ O
C -X- _ O
is -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
classes -X- _ O
. -X- _ O
Based -X- _ O
on -X- _ O
D -X- _ O
S -X- _ O
, -X- _ O
we -X- _ O
learn -X- _ O
a -X- _ O
hypothesis -X- _ O
, -X- _ O
h -X- _ O
: -X- _ O
X -X- _ O
→ -X- _ O
{ -X- _ O
0 -X- _ O
, -X- _ O
1 -X- _ O
} -X- _ O
C -X- _ O
. -X- _ O
Since -X- _ O
D -X- _ O
S -X- _ O
comes -X- _ O
from -X- _ O
D -X- _ O
S -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
D -X- _ O
S -X- _ O
⊆ -X- _ O
D -X- _ O
S -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
learned -X- _ O
hypothesis -X- _ O
h -X- _ O
usually -X- _ O
performs -X- _ O
well -X- _ O
on -X- _ O
D -X- _ O
S -X- _ O
. -X- _ O
When -X- _ O
we -X- _ O
transfer -X- _ O
the -X- _ O
hypothesis -X- _ O
h -X- _ O
from -X- _ O
D -X- _ O
S -X- _ O
to -X- _ O
D -X- _ O
T -X- _ O
, -X- _ O
h -X- _ O
may -X- _ O
perform -X- _ O
poorly -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
domain -X- _ O
shift -X- _ O
. -X- _ O
The -X- _ O
goal -X- _ O
of -X- _ O
domain -X- _ O
adaptation -X- _ O
is -X- _ O
to -X- _ O
adapt -X- _ O
the -X- _ O
hypothesis -X- _ O
h -X- _ O
to -X- _ O
D -X- _ O
T -X- _ O
. -X- _ O

In -X- _ O
general -X- _ O
, -X- _ O
unlabeled -X- _ O
text -X- _ O
in -X- _ O
the -X- _ O
target -X- _ O
domain -X- _ O
is -X- _ O
available -X- _ O
( -X- _ O
Gururangan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
denote -X- _ O
the -X- _ O
unlabeled -X- _ O
target -X- _ O
domain -X- _ O
dataset -X- _ O
as -X- _ O

D -X- _ O
u -X- _ O
T -X- _ O
= -X- _ O
{ -X- _ O
( -X- _ O
x -X- _ O
m -X- _ O
) -X- _ O
} -X- _ O
U -X- _ O
m=1 -X- _ O

, -X- _ O
where -X- _ O
x -X- _ O
m -X- _ O
∈ -X- _ O
X -X- _ O
is -X- _ O
a -X- _ O
text -X- _ O
input -X- _ O
. -X- _ O
In -X- _ O
some -X- _ O
cases -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
even -X- _ O
access -X- _ O
an -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
dataset -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
a -X- _ O
small -X- _ O
set -X- _ O
of -X- _ O
labeled -X- _ O
data -X- _ O
in -X- _ O
the -X- _ O
target -X- _ O
Sort -X- _ O
the -X- _ O
D -X- _ O
p -X- _ O
T -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
H -X- _ O
in -X- _ O
ascending -X- _ O
order -X- _ O
, -X- _ O
and -X- _ O
denote -X- _ O
the -X- _ O
first -X- _ O
K -X- _ O
data -X- _ O
as -X- _ O
DE -X- _ O
, -X- _ O
the -X- _ O
remaining -X- _ O
data -X- _ O
as -X- _ O
D -X- _ O
tr -X- _ O
T -X- _ O
6 -X- _ O
: -X- _ O

DM -X- _ O
= -X- _ O
D -X- _ O
l -X- _ O
T -X- _ O
∪ -X- _ O
DE -X- _ O
7 -X- _ O
: -X- _ O
DOMAINADVERSARIAL -X- _ O
( -X- _ O
DS -X- _ O
∪ -X- _ O
D -X- _ O
u -X- _ O
T -X- _ O
, -X- _ O
θF -X- _ O
, -X- _ O
ϑ -X- _ O
) -X- _ O
8 -X- _ O
: -X- _ O

METALEARNING -X- _ O
( -X- _ O
DS -X- _ O
∪ -X- _ O
D -X- _ O
tr -X- _ O
T -X- _ O
, -X- _ O
θ -X- _ O
, -X- _ O
w -X- _ O
) -X- _ O
9 -X- _ O
: -X- _ O
end -X- _ O
while -X- _ O
10 -X- _ O
: -X- _ O
function -X- _ O
METALEARNING -X- _ O
( -X- _ O
D -X- _ O
, -X- _ O
θ -X- _ O
, -X- _ O
w -X- _ O
) -X- _ O
11 -X- _ O
: -X- _ O

for -X- _ O
training -X- _ O
batch -X- _ O
B -X- _ O
in -X- _ O
D -X- _ O
do -X- _ O
12 -X- _ O
: -X- _ O

for -X- _ O
t=1 -X- _ O
→ -X- _ O
TM -X- _ O
do -X- _ O
13 -X- _ O
: -X- _ O

Computeθ -X- _ O
( -X- _ O
w -X- _ O
t -X- _ O
) -X- _ O
via -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
14 -X- _ O
: -X- _ O

Compute -X- _ O
weight -X- _ O
w -X- _ O
t+1 -X- _ O
via -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
6 -X- _ O
) -X- _ O
15 -X- _ O
: -X- _ O

end -X- _ O
for -X- _ O
16 -X- _ O
: -X- _ O

w -X- _ O
* -X- _ O
← -X- _ O
w -X- _ O
T -X- _ O
M -X- _ O
, -X- _ O
update -X- _ O
θ -X- _ O
with -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
7 -X- _ O
) -X- _ O
17 -X- _ O
: -X- _ O

end -X- _ O
for -X- _ O
18 -X- _ O
: -X- _ O

return -X- _ O
θ -X- _ O
, -X- _ O
w -X- _ O
19 -X- _ O
: -X- _ O
end -X- _ O
function -X- _ O
20 -X- _ O
: -X- _ O
function -X- _ O
DOMAINADVERSARIAL -X- _ O
( -X- _ O
D -X- _ O
, -X- _ O
θF -X- _ O
, -X- _ O
ϑ -X- _ O
) -X- _ O
21 -X- _ O
: -X- _ O

for -X- _ O
training -X- _ O
batch -X- _ O
B -X- _ O
in -X- _ O
D -X- _ O
do -X- _ O
22 -X- _ O
: -X- _ O

for -X- _ O
t=1 -X- _ O
→ -X- _ O
TD -X- _ O
do -X- _ O
23 -X- _ O
: -X- _ O

ϑ -X- _ O
= -X- _ O
ϑ -X- _ O
− -X- _ O
η1 -X- _ O
ϑ -X- _ O
LDA -X- _ O
( -X- _ O
θF -X- _ O
, -X- _ O
ϑ -X- _ O
, -X- _ O
B -X- _ O
) -X- _ O
24 -X- _ O
: -X- _ O

end -X- _ O
for -X- _ O
25 -X- _ O
: -X- _ O

for -X- _ O
t=1 -X- _ O
→ -X- _ O
TG -X- _ O
do -X- _ O
26 -X- _ O
: -X- _ O

θF -X- _ O
= -X- _ O
θF -X- _ O
+ -X- _ O
η2 -X- _ O
θ -X- _ O
LDA -X- _ O
( -X- _ O
θF -X- _ O
, -X- _ O
ϑ -X- _ O
, -X- _ O
B -X- _ O
) -X- _ O
27 -X- _ O
: -X- _ O
end -X- _ O
for -X- _ O
28 -X- _ O
: -X- _ O

end -X- _ O
for -X- _ O
29 -X- _ O
: -X- _ O

return -X- _ O
θ -X- _ O
, -X- _ O
ϑ -X- _ O
30 -X- _ O
: -X- _ O
end -X- _ O
function -X- _ O
domain -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
denoted -X- _ O
as -X- _ O
D -X- _ O
l -X- _ O
T -X- _ O
= -X- _ O
{ -X- _ O
( -X- _ O
x -X- _ O
j -X- _ O
, -X- _ O
y -X- _ O
j -X- _ O
) -X- _ O
} -X- _ O
L -X- _ O
j=1 -X- _ O
( -X- _ O
x -X- _ O
i -X- _ O
∈ -X- _ O
X -X- _ O
and -X- _ O
y -X- _ O
i -X- _ O
∈ -X- _ O
{ -X- _ O
0 -X- _ O
, -X- _ O
1 -X- _ O
} -X- _ O
C -X- _ O
) -X- _ O
. -X- _ O
When -X- _ O
D -X- _ O
l -X- _ O
T -X- _ O
= -X- _ O
∅ -X- _ O
, -X- _ O
the -X- _ O
task -X- _ O
is -X- _ O
a -X- _ O
case -X- _ O
of -X- _ O
unsupervised -X- _ O
domain -X- _ B-TaskName
adaptation -X- _ I-TaskName
( -X- _ O
Wilson -X- _ O
and -X- _ O
Cook -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Otherwise -X- _ O
, -X- _ O
the -X- _ O
task -X- _ O
is -X- _ O
a -X- _ O
case -X- _ O
of -X- _ O
semi -X- _ O
- -X- _ O
supervised -X- _ O
domain -X- _ B-TaskName
adaptation -X- _ I-TaskName
( -X- _ O
Saito -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

Methodology -X- _ O

Model -X- _ O
Overview -X- _ O

DaMSTF -X- _ B-MethodName
inherits -X- _ O
the -X- _ O
basic -X- _ O
framework -X- _ O
of -X- _ O
selftraining -X- _ O
, -X- _ O
which -X- _ O
consists -X- _ O
of -X- _ O
iterations -X- _ O
over -X- _ O
the -X- _ O
" -X- _ O
Pseudo -X- _ O
Labeling -X- _ O
" -X- _ O
phase -X- _ O
and -X- _ O
the -X- _ O
" -X- _ O
Model -X- _ O
Retraining -X- _ O
" -X- _ O
phase -X- _ O
. -X- _ O
To -X- _ O
achieve -X- _ O
domain -X- _ B-TaskName
adaptation -X- _ I-TaskName
, -X- _ O
selftraining -X- _ O
simultaneously -X- _ O
optimizes -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
parameters -X- _ O
and -X- _ O
the -X- _ O
pseudo -X- _ O
labels -X- _ O
with -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O

min -X- _ O
θ -X- _ O
, -X- _ O
Ŷ -X- _ O
T -X- _ O
Lst -X- _ O
( -X- _ O
θ -X- _ O
, -X- _ O
ŶT -X- _ O
) -X- _ O
= -X- _ O
( -X- _ O
x -X- _ O
k -X- _ O
, -X- _ O
y -X- _ O
k -X- _ O
) -X- _ O
∈D -X- _ O
S -X- _ O
E -X- _ O
( -X- _ O
Φ -X- _ O
( -X- _ O
x -X- _ O
k -X- _ O
; -X- _ O
θ -X- _ O
) -X- _ O
, -X- _ O
y -X- _ O
k -X- _ O
) -X- _ O
+ -X- _ O
x -X- _ O
i -X- _ O
∈D -X- _ O
u -X- _ O
T -X- _ O
E -X- _ O
( -X- _ O
Φ -X- _ O
( -X- _ O
xi -X- _ O
; -X- _ O
θ -X- _ O
) -X- _ O
, -X- _ O
ŷ -X- _ O
( -X- _ O
xi -X- _ O
) -X- _ O
) -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O

whereŶ -X- _ O
T -X- _ O
= -X- _ O
[ -X- _ O
ŷ -X- _ O
1 -X- _ O
, -X- _ O
ŷ -X- _ O
2 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
ŷ -X- _ O
|D -X- _ O
u -X- _ O
T -X- _ O
| -X- _ O
] -X- _ O
T -X- _ O
denotes -X- _ O
the -X- _ O
pseudo -X- _ O
label -X- _ O
set -X- _ O
of -X- _ O
the -X- _ O
unlabeled -X- _ O
target -X- _ O
domain -X- _ O
data -X- _ O
, -X- _ O
Φ -X- _ O
θ -X- _ O
denotes -X- _ O
the -X- _ O
model -X- _ O
under -X- _ O
the -X- _ O
hypothesis -X- _ O
( -X- _ O
h -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
θ -X- _ O
denotes -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
parameters -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
pseudo -X- _ O
labeling -X- _ O
phase -X- _ O
, -X- _ O
DaMSTF -X- _ B-MethodName
predicts -X- _ O
the -X- _ O
unlabeled -X- _ O
data -X- _ O
in -X- _ O
the -X- _ O
target -X- _ O
domain -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
predictions -X- _ O
are -X- _ O
taken -X- _ O
as -X- _ O
pseudo -X- _ O
labels -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
these -X- _ O
pseudo -X- _ O
instances -X- _ O
are -X- _ O
sent -X- _ O
to -X- _ O
the -X- _ O
meta -X- _ O
constructor -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
instances -X- _ O
with -X- _ O
high -X- _ O
prediction -X- _ O
confidence -X- _ O
, -X- _ O
the -X- _ O
meta -X- _ O
constructor -X- _ O
uses -X- _ O
them -X- _ O
to -X- _ O
expand -X- _ O
the -X- _ O
meta -X- _ O
validation -X- _ O
set -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
remaining -X- _ O
ones -X- _ O
, -X- _ O
the -X- _ O
meta -X- _ O
constructor -X- _ O
uses -X- _ O
them -X- _ O
to -X- _ O
construct -X- _ O
the -X- _ O
meta -X- _ O
- -X- _ O
training -X- _ O
set -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
model -X- _ O
retraining -X- _ O
phase -X- _ O
, -X- _ O
DaMSTF -X- _ B-MethodName
first -X- _ O
trains -X- _ O
the -X- _ O
model -X- _ O
in -X- _ O
the -X- _ O
domain -X- _ O
adversarial -X- _ O
training -X- _ O
module -X- _ O
to -X- _ O
align -X- _ O
the -X- _ O
feature -X- _ O
space -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
in -X- _ O
the -X- _ O
meta -X- _ O
- -X- _ O
learning -X- _ O
module -X- _ O
. -X- _ O
Afterward -X- _ O
, -X- _ O
DaMSTF -X- _ B-MethodName
backs -X- _ O
to -X- _ O
the -X- _ O
pseudo -X- _ O
labeling -X- _ O
phase -X- _ O
to -X- _ O
start -X- _ O
another -X- _ O
self -X- _ O
- -X- _ O
training -X- _ O
iteration -X- _ O
. -X- _ O

Fig -X- _ O
. -X- _ O
1 -X- _ O
shows -X- _ O
the -X- _ O
structure -X- _ O
of -X- _ O
DaMSTF -X- _ B-MethodName
, -X- _ O
and -X- _ O
Algorithm -X- _ O
1 -X- _ O
presents -X- _ O
the -X- _ O
corresponding -X- _ O
pseudo -X- _ O
- -X- _ O
code -X- _ O
. -X- _ O

Meta -X- _ O
- -X- _ O
Learning -X- _ O
Module -X- _ O

As -X- _ O
described -X- _ O
in -X- _ O
Fig -X- _ O
. -X- _ O
1 -X- _ O
, -X- _ O
the -X- _ O
meta -X- _ O
- -X- _ O
learning -X- _ O
module -X- _ O
involves -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
loops -X- _ O
over -X- _ O
the -X- _ O
" -X- _ O
Meta -X- _ O
Training -X- _ O
" -X- _ O
step -X- _ O
and -X- _ O
" -X- _ O
Meta -X- _ O
Validation -X- _ O
" -X- _ O
step -X- _ O
to -X- _ O
optimize -X- _ O
the -X- _ O
hyper -X- _ O
- -X- _ O
parameters -X- _ O
and -X- _ O
the -X- _ O
model -X- _ O
parameters -X- _ O
. -X- _ O

Meta -X- _ O
Training -X- _ O
. -X- _ O
The -X- _ O
training -X- _ O
batch -X- _ O
in -X- _ O
the -X- _ O
meta -X- _ O
training -X- _ O
phase -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
B -X- _ O
= -X- _ O
{ -X- _ O
( -X- _ O
x -X- _ O
1 -X- _ O
, -X- _ O
y -X- _ O
1 -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
x -X- _ O
2 -X- _ O
, -X- _ O
y -X- _ O
2 -X- _ O
) -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
} -X- _ O
, -X- _ O
merges -X- _ O
the -X- _ O
labeled -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
source -X- _ O
domain -X- _ O
with -X- _ O
the -X- _ O
pseudo -X- _ O
labeled -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
target -X- _ O
domain -X- _ O
. -X- _ O
The -X- _ O
supervision -X- _ O
on -X- _ O
the -X- _ O
pseudo -X- _ O
instances -X- _ O
is -X- _ O
the -X- _ O
pseudo -X- _ O
- -X- _ O
label -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
supervision -X- _ O
on -X- _ O
the -X- _ O
labeled -X- _ O
instances -X- _ O
is -X- _ O
the -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
label -X- _ O
. -X- _ O
We -X- _ O
compute -X- _ O
the -X- _ O
risk -X- _ O
loss -X- _ O
on -X- _ O
the -X- _ O
training -X- _ O
batch -X- _ O
with -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
: -X- _ O

LT -X- _ O
( -X- _ O
θ -X- _ O
, -X- _ O
w -X- _ O
t -X- _ O
, -X- _ O
B -X- _ O
) -X- _ O
= -X- _ O
1 -X- _ O
|B| -X- _ O
x -X- _ O
i -X- _ O
, -X- _ O
y -X- _ O
i -X- _ O
∈B -X- _ O
σ -X- _ O
( -X- _ O
w -X- _ O
t -X- _ O
i -X- _ O
) -X- _ O
E -X- _ O
( -X- _ O
Φ -X- _ O
( -X- _ O
xi -X- _ O
; -X- _ O
θ -X- _ O
) -X- _ O
, -X- _ O
yi -X- _ O
) -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O

where -X- _ O
|B| -X- _ O
is -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
B -X- _ O
, -X- _ O
E -X- _ O
is -X- _ O
the -X- _ O
loss -X- _ O
function -X- _ O
. -X- _ O
Φ -X- _ O
θ -X- _ O
denotes -X- _ O
the -X- _ O
model -X- _ O
under -X- _ O
the -X- _ O
hypothesis -X- _ O
( -X- _ O
h -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
θ -X- _ O
denotes -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
parameters -X- _ O
. -X- _ O

θ -X- _ O
( -X- _ O
w -X- _ O
t -X- _ O
) -X- _ O
= -X- _ O
θ -X- _ O
− -X- _ O
η -X- _ O
θ -X- _ O
LT -X- _ O
( -X- _ O
θ -X- _ O
, -X- _ O
w -X- _ O
t -X- _ O
, -X- _ O
B -X- _ O
) -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O

where -X- _ O
η -X- _ O
is -X- _ O
the -X- _ O
learning -X- _ O
rate -X- _ O
. -X- _ O
Meta -X- _ O
Validation -X- _ O
After -X- _ O
being -X- _ O
virtually -X- _ O
updated -X- _ O
in -X- _ O
the -X- _ O
meta -X- _ O
training -X- _ O
phase -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
validated -X- _ O
on -X- _ O
the -X- _ O
meta -X- _ O
validation -X- _ O
set -X- _ O
D -X- _ O
M -X- _ O
with -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
: -X- _ O

LM -X- _ O
( -X- _ O
θ -X- _ O
( -X- _ O
w -X- _ O
t -X- _ O
) -X- _ O
) -X- _ O
= -X- _ O
1 -X- _ O
|DM -X- _ O
| -X- _ O
• -X- _ O
x -X- _ O
j -X- _ O
, -X- _ O
y -X- _ O
j -X- _ O
∈D -X- _ O
M -X- _ O
E -X- _ O
( -X- _ O
Φ -X- _ O
( -X- _ O
xj -X- _ O
; -X- _ O
θ -X- _ O
( -X- _ O
w -X- _ O
t -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
yj -X- _ O
) -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O

where -X- _ O
E -X- _ O
is -X- _ O
the -X- _ O
loss -X- _ O
function -X- _ O
, -X- _ O
|D -X- _ O
M -X- _ O
| -X- _ O
is -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
meta -X- _ O
validation -X- _ O
set -X- _ O
. -X- _ O
By -X- _ O
backpropagating -X- _ O
the -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
meta -X- _ O
validation -X- _ O
set -X- _ O
, -X- _ O
we -X- _ O
derive -X- _ O
the -X- _ O
training -X- _ O
guidance -X- _ O
for -X- _ O
updating -X- _ O
the -X- _ O
instance -X- _ O
weights -X- _ O
on -X- _ O
the -X- _ O
training -X- _ O
batch -X- _ O
as -X- _ O
below -X- _ O
: -X- _ O

∂LM -X- _ O
( -X- _ O
θ -X- _ O
( -X- _ O
w -X- _ O
) -X- _ O
) -X- _ O
∂w -X- _ O
= -X- _ O
∂LM -X- _ O
( -X- _ O
θ -X- _ O
( -X- _ O
w -X- _ O
) -X- _ O
) -X- _ O
∂θ -X- _ O
( -X- _ O
w -X- _ O
) -X- _ O
• -X- _ O
∂θ -X- _ O
( -X- _ O
w -X- _ O
) -X- _ O
∂w -X- _ O
( -X- _ O
5 -X- _ O
) -X- _ O

To -X- _ O
reduce -X- _ O
the -X- _ O
computation -X- _ O
cost -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
approximation -X- _ O
technique -X- _ O
in -X- _ O
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
to -X- _ O
compute -X- _ O
the -X- _ O
training -X- _ O
guidance -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
∂L -X- _ O
M -X- _ O
( -X- _ O
θ -X- _ O
( -X- _ O
w -X- _ O
) -X- _ O
) -X- _ O

∂w -X- _ O

) -X- _ O
. -X- _ O
Based -X- _ O
on -X- _ O
the -X- _ O
computed -X- _ O
training -X- _ O
guidance -X- _ O
, -X- _ O
we -X- _ O
obtain -X- _ O
the -X- _ O
optimal -X- _ O
instance -X- _ O
weights -X- _ O
( -X- _ O
marked -X- _ O
as -X- _ O
w -X- _ O
* -X- _ O
) -X- _ O
with -X- _ O
gradient -X- _ O
descent -X- _ O
algorithm -X- _ O
, -X- _ O
as -X- _ O
described -X- _ O
in -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
6 -X- _ O
) -X- _ O
. -X- _ O
Further -X- _ O
, -X- _ O
we -X- _ O
update -X- _ O
θ -X- _ O
with -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
7 -X- _ O
) -X- _ O
: -X- _ O

w -X- _ O
t+1 -X- _ O
= -X- _ O
w -X- _ O
t -X- _ O
− -X- _ O
γ -X- _ O
• -X- _ O
∂L -X- _ O
M -X- _ O
( -X- _ O
θ -X- _ O
( -X- _ O
w -X- _ O
) -X- _ O
) -X- _ O
∂w -X- _ O
( -X- _ O
6 -X- _ O
) -X- _ O
θ -X- _ O
t+1 -X- _ O
= -X- _ O
θ -X- _ O
t -X- _ O
− -X- _ O
η -X- _ O
θ -X- _ O
LT -X- _ O
( -X- _ O
θ -X- _ O
, -X- _ O
w -X- _ O
* -X- _ O
, -X- _ O
B -X- _ O
) -X- _ O
( -X- _ O
7 -X- _ O
) -X- _ O

After -X- _ O
the -X- _ O
above -X- _ O
process -X- _ O
is -X- _ O
completed -X- _ O
on -X- _ O
the -X- _ O
training -X- _ O
batch -X- _ O
B -X- _ O
, -X- _ O
another -X- _ O
training -X- _ O
batch -X- _ O
will -X- _ O
be -X- _ O
selected -X- _ O
to -X- _ O
start -X- _ O
the -X- _ O
meta -X- _ O
- -X- _ O
learning -X- _ O
phase -X- _ O
again -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
lines -X- _ O
15 -X- _ O
- -X- _ O
21 -X- _ O
in -X- _ O
Algorithm -X- _ O
1 -X- _ O
. -X- _ O

Meta -X- _ O
Constructor -X- _ O

In -X- _ O
previous -X- _ O
studies -X- _ O
, -X- _ O
the -X- _ O
meta -X- _ O
validation -X- _ O
set -X- _ O
is -X- _ O
constructed -X- _ O
by -X- _ O
collecting -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
labeled -X- _ O
data -X- _ O
that -X- _ O
have -X- _ O
the -X- _ O
same -X- _ O
distribution -X- _ O
as -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
( -X- _ O
Ren -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Shu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
such -X- _ O
practice -X- _ O
is -X- _ O
not -X- _ O
acceptable -X- _ O
in -X- _ O
domain -X- _ O
adaptation -X- _ O
, -X- _ O
as -X- _ O
we -X- _ O
are -X- _ O
not -X- _ O
aware -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
distribution -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
domain -X- _ O
during -X- _ O
the -X- _ O
training -X- _ O
phase -X- _ O
. -X- _ O

To -X- _ O
this -X- _ O
end -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
meta -X- _ O
constructor -X- _ O
to -X- _ O
construct -X- _ O
a -X- _ O
meta -X- _ O
validation -X- _ O
set -X- _ O
that -X- _ O
approximates -X- _ O
the -X- _ O
target -X- _ O
domain -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
select -X- _ O
the -X- _ O
reliable -X- _ O
instances -X- _ O
from -X- _ O
the -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
data -X- _ O
as -X- _ O
the -X- _ O
instances -X- _ O
in -X- _ O
the -X- _ O
meta -X- _ O
validation -X- _ O
set -X- _ O
. -X- _ O
To -X- _ O
evaluate -X- _ O
the -X- _ O
reliability -X- _ O
of -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
pseudo -X- _ O
instances -X- _ O
, -X- _ O
we -X- _ O
compute -X- _ O
their -X- _ O
prediction -X- _ O
entropy -X- _ O
via -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
8 -X- _ O
) -X- _ O
: -X- _ O

H -X- _ O
( -X- _ O
xi -X- _ O
) -X- _ O
= -X- _ O
− -X- _ O
C -X- _ O
c=1 -X- _ O
( -X- _ O
Φ -X- _ O
( -X- _ O
c|xi -X- _ O
; -X- _ O
θ -X- _ O
) -X- _ O
• -X- _ O
log -X- _ O
( -X- _ O
Φ -X- _ O
( -X- _ O
c|xi -X- _ O
; -X- _ O
θ -X- _ O
) -X- _ O
) -X- _ O
) -X- _ O
( -X- _ O
8 -X- _ O
) -X- _ O

where -X- _ O
Φ -X- _ O
( -X- _ O
c|x -X- _ O
i -X- _ O
; -X- _ O
θ -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
the -X- _ O
instance -X- _ O
x -X- _ O
i -X- _ O
belongs -X- _ O
to -X- _ O
the -X- _ O
c -X- _ O
th -X- _ O
category -X- _ O
. -X- _ O

In -X- _ O
general -X- _ O
, -X- _ O
a -X- _ O
lower -X- _ O
prediction -X- _ O
entropy -X- _ O
indicates -X- _ O
a -X- _ O
higher -X- _ O
prediction -X- _ O
correctness -X- _ O
( -X- _ O
Nguyen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
sort -X- _ O
the -X- _ O
D -X- _ O
p -X- _ O
T -X- _ O
( -X- _ O
pseudo -X- _ O
labeled -X- _ O
dataset -X- _ O
) -X- _ O
in -X- _ O
ascending -X- _ O
order -X- _ O
according -X- _ O
to -X- _ O
their -X- _ O
prediction -X- _ O
entropy -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
the -X- _ O
top -X- _ O
- -X- _ O
ranked -X- _ O
K -X- _ O
instances -X- _ O
, -X- _ O
denoted -X- _ O
as -X- _ O
D -X- _ O
E -X- _ O
, -X- _ O
are -X- _ O
selected -X- _ O
as -X- _ O
the -X- _ O
validation -X- _ O
instances -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
remaining -X- _ O
pseudo -X- _ O
samples -X- _ O
, -X- _ O
denoted -X- _ O
as -X- _ O
D -X- _ O
tr -X- _ O
T -X- _ O
, -X- _ O
are -X- _ O
preserved -X- _ O
in -X- _ O
the -X- _ O
meta -X- _ O
training -X- _ O
set -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
semi -X- _ O
- -X- _ O
supervised -X- _ O
domain -X- _ B-TaskName
adaptation -X- _ I-TaskName
, -X- _ O
we -X- _ O
take -X- _ O
the -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
dataset -X- _ O
to -X- _ O
initialize -X- _ O
the -X- _ O
meta -X- _ O
validation -X- _ O
dataset -X- _ O
and -X- _ O
use -X- _ O
D -X- _ O
E -X- _ O
to -X- _ O
expand -X- _ O
the -X- _ O
meta -X- _ O
validation -X- _ O
set -X- _ O
along -X- _ O
with -X- _ O
the -X- _ O
self -X- _ O
- -X- _ O
training -X- _ O
iterations -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
unsupervised -X- _ O
domain -X- _ O
adaptation -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
dataset -X- _ O
is -X- _ O
empty -X- _ O
, -X- _ O
we -X- _ O
directly -X- _ O
take -X- _ O
D -X- _ O
E -X- _ O
as -X- _ O
the -X- _ O
meta -X- _ O
validation -X- _ O
set -X- _ O
. -X- _ O
The -X- _ O
above -X- _ O
process -X- _ O
is -X- _ O
detailed -X- _ O
in -X- _ O
lines -X- _ O
2 -X- _ O
- -X- _ O
8 -X- _ O
of -X- _ O
Algorithm -X- _ O
1 -X- _ O
. -X- _ O

Here -X- _ O
, -X- _ O
meta -X- _ O
constructor -X- _ O
is -X- _ O
an -X- _ O
important -X- _ O
knot -X- _ O
that -X- _ O
combines -X- _ O
meta -X- _ O
- -X- _ O
learning -X- _ O
and -X- _ O
self -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
one -X- _ O
hand -X- _ O
, -X- _ O
traditional -X- _ O
machine -X- _ O
learning -X- _ O
approaches -X- _ O
can -X- _ O
not -X- _ O
exploit -X- _ O
the -X- _ O
pseudo -X- _ O
instances -X- _ O
with -X- _ O
high -X- _ O
prediction -X- _ O
entropy -X- _ O
, -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
inherent -X- _ O
label -X- _ O
noise -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
case -X- _ O
, -X- _ O
the -X- _ O
meta -X- _ O
constructor -X- _ O
uses -X- _ O
them -X- _ O
to -X- _ O
construct -X- _ O
the -X- _ O
meta -X- _ O
training -X- _ O
set -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
meta -X- _ O
- -X- _ O
learning -X- _ O
module -X- _ O
is -X- _ O
tolerant -X- _ O
to -X- _ O
the -X- _ O
label -X- _ O
noise -X- _ O
in -X- _ O
the -X- _ O
metatraining -X- _ O
set -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
pseudo -X- _ O
instances -X- _ O
with -X- _ O
low -X- _ O
prediction -X- _ O
entropy -X- _ O
can -X- _ O
not -X- _ O
provide -X- _ O
extra -X- _ O
information -X- _ O
for -X- _ O
improving -X- _ O
the -X- _ O
model -X- _ O
but -X- _ O
contain -X- _ O
less -X- _ O
label -X- _ O
noise -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
case -X- _ O
, -X- _ O
the -X- _ O
meta -X- _ O
constructor -X- _ O
uses -X- _ O
them -X- _ O
to -X- _ O
validate -X- _ O
the -X- _ O
model -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
uses -X- _ O
them -X- _ O
to -X- _ O
construct -X- _ O
or -X- _ O
expand -X- _ O
the -X- _ O
meta -X- _ O
validation -X- _ O
set -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
improve -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
the -X- _ O
meta -X- _ O
validation -X- _ O
set -X- _ O
. -X- _ O

Domain -X- _ B-MethodName
Adversarial -X- _ I-MethodName
Learning -X- _ I-MethodName

As -X- _ O
theoretically -X- _ O
explained -X- _ O
in -X- _ O
§ -X- _ O
4.1 -X- _ O
, -X- _ O
the -X- _ O
training -X- _ O
guidance -X- _ O
would -X- _ O
not -X- _ O
be -X- _ O
indicative -X- _ O
if -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
gradient -X- _ O
on -X- _ O
the -X- _ O
validation -X- _ O
instance -X- _ O
is -X- _ O
negligible -X- _ O
. -X- _ O
The -X- _ O
presence -X- _ O
of -X- _ O
domain -X- _ B-MethodName
adversarial -X- _ I-MethodName
learning -X- _ I-MethodName
can -X- _ O
prevent -X- _ O
the -X- _ O
gradient -X- _ O
vanishment -X- _ O
on -X- _ O
the -X- _ O
meta -X- _ O
validation -X- _ O
set -X- _ O
, -X- _ O
thereby -X- _ O
preventing -X- _ O
the -X- _ O
training -X- _ O
guidance -X- _ O
vanishment -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
domain -X- _ B-MethodName
adversarial -X- _ I-MethodName
learning -X- _ I-MethodName
can -X- _ O
explicitly -X- _ O
align -X- _ O
the -X- _ O
feature -X- _ O
space -X- _ O
along -X- _ O
with -X- _ O
the -X- _ O
self -X- _ O
- -X- _ O
training -X- _ O
iterations -X- _ O
. -X- _ O

To -X- _ O
present -X- _ O
the -X- _ O
details -X- _ O
in -X- _ O
the -X- _ O
domain -X- _ B-MethodName
adversarial -X- _ I-MethodName
learning -X- _ I-MethodName
module -X- _ O
, -X- _ O
we -X- _ O
divide -X- _ O
the -X- _ O
model -X- _ O
Φ -X- _ O
( -X- _ O
• -X- _ O
; -X- _ O
θ -X- _ O
) -X- _ O
into -X- _ O
two -X- _ O
parts -X- _ O
: -X- _ O
the -X- _ O
feature -X- _ O
extraction -X- _ O
layer -X- _ O
Φ -X- _ O
F -X- _ O
( -X- _ O
• -X- _ O
; -X- _ O
θ -X- _ O
F -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
layer -X- _ O
Φ -X- _ O
c -X- _ O
( -X- _ O
• -X- _ O
; -X- _ O
θ -X- _ O
c -X- _ O
) -X- _ O
. -X- _ O
Usually -X- _ O
, -X- _ O
θ -X- _ O
c -X- _ O
is -X- _ O
the -X- _ O
parameters -X- _ O
of -X- _ O
the -X- _ O
last -X- _ O
layer -X- _ O
in -X- _ O
the -X- _ O
model -X- _ O
, -X- _ O
whose -X- _ O
output -X- _ O
is -X- _ O
the -X- _ O
prediction -X- _ O
probability -X- _ O
of -X- _ O
each -X- _ O
category -X- _ O
. -X- _ O
The -X- _ O
prediction -X- _ O
process -X- _ O
in -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
: -X- _ O

Φ -X- _ O
( -X- _ O
xi -X- _ O
; -X- _ O
θ -X- _ O
) -X- _ O
= -X- _ O
Φc -X- _ O
( -X- _ O
ΦF -X- _ O
( -X- _ O
xi -X- _ O
; -X- _ O
θF -X- _ O
) -X- _ O
; -X- _ O
θc -X- _ O
) -X- _ O
( -X- _ O
9 -X- _ O
) -X- _ O

Following -X- _ O
Ganin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
an -X- _ O
extra -X- _ O
domain -X- _ O
discriminator -X- _ O
to -X- _ O
discriminate -X- _ O
the -X- _ O
instances -X- _ O
' -X- _ O
domains -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
ϕ -X- _ O
( -X- _ O
• -X- _ O
; -X- _ O
ϑ -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
ϑ -X- _ O
is -X- _ O
the -X- _ O
parameters -X- _ O
. -X- _ O
On -X- _ O
a -X- _ O
training -X- _ O
batch -X- _ O
B -X- _ O
, -X- _ O
the -X- _ O
risk -X- _ O
loss -X- _ O
for -X- _ O
domain -X- _ B-MethodName
adversarial -X- _ I-MethodName
learning -X- _ I-MethodName
is -X- _ O
: -X- _ O

LDA -X- _ O
( -X- _ O
θF -X- _ O
, -X- _ O
ϑ -X- _ O
, -X- _ O
B -X- _ O
) -X- _ O
= -X- _ O
1 -X- _ O
|B| -X- _ O
x -X- _ O
i -X- _ O
, -X- _ O
d -X- _ O
i -X- _ O
∈B -X- _ O
E -X- _ O
( -X- _ O
ϕ -X- _ O
( -X- _ O
ΦF -X- _ O
( -X- _ O
xi -X- _ O
; -X- _ O
θF -X- _ O
) -X- _ O
; -X- _ O
ϑ -X- _ O
) -X- _ O
, -X- _ O
di -X- _ O
) -X- _ O
( -X- _ O
10 -X- _ O
) -X- _ O

where -X- _ O
d -X- _ O
i -X- _ O
is -X- _ O
a -X- _ O
one -X- _ O
- -X- _ O
hot -X- _ O
vector -X- _ O
representing -X- _ O
the -X- _ O
domain -X- _ O
of -X- _ O
x -X- _ O
i -X- _ O
, -X- _ O
E -X- _ O
is -X- _ O
the -X- _ O
cross -X- _ O
- -X- _ O
entropy -X- _ O
function -X- _ O
. -X- _ O
The -X- _ O
specific -X- _ O
training -X- _ O
process -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
domain -X- _ B-MethodName
adversarial -X- _ I-MethodName
learning -X- _ I-MethodName
module -X- _ O
is -X- _ O
depicted -X- _ O
in -X- _ O
Algorithm -X- _ O
1 -X- _ O
, -X- _ O
lines -X- _ O
25 -X- _ O
- -X- _ O
35 -X- _ O
. -X- _ O

Theoretical -X- _ O
Analysis -X- _ O

This -X- _ O
section -X- _ O
first -X- _ O
introduces -X- _ O
the -X- _ O
training -X- _ O
guidance -X- _ O
vanishment -X- _ O
problem -X- _ O
and -X- _ O
then -X- _ O
explains -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
DaMSTF -X- _ B-MethodName
in -X- _ O
achieving -X- _ O
domain -X- _ O
adaptation -X- _ O
. -X- _ O
The -X- _ O
proofs -X- _ O
are -X- _ O
detailed -X- _ O
in -X- _ O
Appendix -X- _ O
. -X- _ O
A -X- _ O
and -X- _ O
Appendix -X- _ O
. -X- _ O
B -X- _ O
. -X- _ O

Training -X- _ O
Guidance -X- _ O
Vanishment -X- _ O

Theorem -X- _ O
1 -X- _ O
. -X- _ O
Let -X- _ O
w -X- _ O
i -X- _ O
be -X- _ O
the -X- _ O
weight -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
instance -X- _ O
i -X- _ O
, -X- _ O
denoted -X- _ O
as -X- _ O
( -X- _ O
x -X- _ O
i -X- _ O
, -X- _ O
y -X- _ O
i -X- _ O
) -X- _ O
, -X- _ O
in -X- _ O
B -X- _ O
, -X- _ O
the -X- _ O
gradient -X- _ O
of -X- _ O
w -X- _ O
i -X- _ O
on -X- _ O
L -X- _ O
M -X- _ O
can -X- _ O
be -X- _ O
represented -X- _ O
by -X- _ O
the -X- _ O
similarity -X- _ O
between -X- _ O
the -X- _ O
gradients -X- _ O
on -X- _ O
training -X- _ O
instance -X- _ O
i -X- _ O
and -X- _ O
the -X- _ O
gradients -X- _ O
on -X- _ O
the -X- _ O
meta -X- _ O
validation -X- _ O
set -X- _ O
: -X- _ O

∂LM -X- _ O
( -X- _ O
θ -X- _ O
( -X- _ O
w -X- _ O
) -X- _ O
) -X- _ O
∂wi -X- _ O
= -X- _ O
− -X- _ O
η -X- _ O
|B| -X- _ O
• -X- _ O
[ -X- _ O
1 -X- _ O
|DM -X- _ O
| -X- _ O
|D -X- _ O
M -X- _ O
| -X- _ O
j=1 -X- _ O
gθ -X- _ O
( -X- _ O
xj -X- _ O
, -X- _ O
yj -X- _ O
) -X- _ O
T -X- _ O
] -X- _ O
• -X- _ O
g -X- _ O
θ -X- _ O
( -X- _ O
xi -X- _ O
, -X- _ O
yi -X- _ O
) -X- _ O

where -X- _ O

1 -X- _ O
|D -X- _ O
M -X- _ O
| -X- _ O
|D -X- _ O
M -X- _ O
| -X- _ O
j=1 -X- _ O
gθ -X- _ O
( -X- _ O
x -X- _ O
j -X- _ O
, -X- _ O
y -X- _ O
j -X- _ O
) -X- _ O
T -X- _ O
is -X- _ O
the -X- _ O
gradients -X- _ O
of -X- _ O
θ -X- _ O
on -X- _ O
D -X- _ O
M -X- _ O
, -X- _ O
g -X- _ O
i -X- _ O
θ -X- _ O
( -X- _ O
x -X- _ O
i -X- _ O
, -X- _ O
y -X- _ O
i -X- _ O
) -X- _ O

is -X- _ O
the -X- _ O
gradients -X- _ O
of -X- _ O
θ -X- _ O
on -X- _ O
the -X- _ O
training -X- _ O
instance -X- _ O
i -X- _ O
, -X- _ O
η -X- _ O
is -X- _ O
the -X- _ O
learning -X- _ O
rate -X- _ O
in -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
According -X- _ O
to -X- _ O
Theorem -X- _ O
1 -X- _ O
, -X- _ O
∂L -X- _ O
M -X- _ O
( -X- _ O
θ -X- _ O
( -X- _ O
w -X- _ O
) -X- _ O
) -X- _ O
∂w -X- _ O
i -X- _ O
is -X- _ O
not -X- _ O
indicative -X- _ O
for -X- _ O
every -X- _ O
training -X- _ O
instance -X- _ O
if -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
gradient -X- _ O
on -X- _ O
the -X- _ O
meta -X- _ O
validation -X- _ O
set -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O

1 -X- _ O
|D -X- _ O
M -X- _ O
| -X- _ O
|D -X- _ O
M -X- _ O
| -X- _ O
j=1 -X- _ O
gθ -X- _ O
( -X- _ O
x -X- _ O
j -X- _ O
, -X- _ O
y -X- _ O
j -X- _ O
) -X- _ O

) -X- _ O
is -X- _ O
very -X- _ O
small -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
named -X- _ O
as -X- _ O
the -X- _ O
training -X- _ O
guidance -X- _ O
vanishment -X- _ O
problem -X- _ O
. -X- _ O
In -X- _ O
DaMSTF -X- _ B-MethodName
, -X- _ O
the -X- _ O
meta -X- _ O
- -X- _ O
learning -X- _ O
module -X- _ O
is -X- _ O
challenged -X- _ O
by -X- _ O
the -X- _ O
training -X- _ O
guidance -X- _ O
vanishment -X- _ O
problem -X- _ O
from -X- _ O
the -X- _ O
following -X- _ O
aspects -X- _ O
. -X- _ O

Firstly -X- _ O
, -X- _ O
the -X- _ O
meta -X- _ O
validation -X- _ O
set -X- _ O
is -X- _ O
much -X- _ O
smaller -X- _ O
than -X- _ O
the -X- _ O
meta -X- _ O
training -X- _ O
set -X- _ O
, -X- _ O
so -X- _ O
the -X- _ O
model -X- _ O
converges -X- _ O
faster -X- _ O
on -X- _ O
the -X- _ O
meta -X- _ O
validation -X- _ O
set -X- _ O
than -X- _ O
that -X- _ O
on -X- _ O
the -X- _ O
meta -X- _ O
training -X- _ O
set -X- _ O
. -X- _ O
Considering -X- _ O
the -X- _ O
optimization -X- _ O
on -X- _ O
neural -X- _ O
networks -X- _ O
is -X- _ O
non -X- _ O
- -X- _ O
convex -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
can -X- _ O
converge -X- _ O
to -X- _ O
an -X- _ O
inferior -X- _ O
optimal -X- _ O
if -X- _ O
it -X- _ O
converges -X- _ O
too -X- _ O
early -X- _ O
on -X- _ O
the -X- _ O
meta -X- _ O
validation -X- _ O
set -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
case -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
gradient -X- _ O
on -X- _ O
the -X- _ O
meta -X- _ O
validation -X- _ O
set -X- _ O
is -X- _ O
very -X- _ O
small -X- _ O
, -X- _ O
which -X- _ O
results -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
guidance -X- _ O
vanishment -X- _ O
. -X- _ O

Secondly -X- _ O
, -X- _ O
the -X- _ O
instances -X- _ O
in -X- _ O
D -X- _ O
E -X- _ O
are -X- _ O
the -X- _ O
ones -X- _ O
with -X- _ O
small -X- _ O
prediction -X- _ O
entropy -X- _ O
. -X- _ O
Since -X- _ O
the -X- _ O
supervision -X- _ O
for -X- _ O
the -X- _ O
pseudo -X- _ O
instances -X- _ O
is -X- _ O
exactly -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
predictions -X- _ O
, -X- _ O
lower -X- _ O
prediction -X- _ O
entropy -X- _ O
results -X- _ O
in -X- _ O
lower -X- _ O
risk -X- _ O
loss -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
the -X- _ O
gradients -X- _ O
back -X- _ O
- -X- _ O
propagated -X- _ O
from -X- _ O
the -X- _ O
risk -X- _ O
loss -X- _ O
are -X- _ O
negligible -X- _ O
, -X- _ O
which -X- _ O
also -X- _ O
results -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
guidance -X- _ O
vanishment -X- _ O
. -X- _ O

Theoretical -X- _ O
Explanation -X- _ O
of -X- _ O
DaMSTF -X- _ B-MethodName

The -X- _ O
disagreement -X- _ O
and -X- _ O
H∆H -X- _ O
- -X- _ O
distance -X- _ O
were -X- _ O
first -X- _ O
proposed -X- _ O
in -X- _ O
Ben -X- _ O
- -X- _ O
David -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2010 -X- _ O
) -X- _ O
and -X- _ O
have -X- _ O
been -X- _ O
widely -X- _ O
applied -X- _ O
to -X- _ O
analyze -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
domain -X- _ O
adaptation -X- _ O
approaches -X- _ O
( -X- _ O
Saito -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Du -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
any -X- _ O
two -X- _ O
different -X- _ O
hypotheses -X- _ O
h -X- _ O
1 -X- _ O
and -X- _ O
h -X- _ O
2 -X- _ O
, -X- _ O
disagreement -X- _ O
D -X- _ O
( -X- _ O
h -X- _ O
1 -X- _ O
, -X- _ O
h -X- _ O
2 -X- _ O
) -X- _ O
quantifies -X- _ O
the -X- _ O
discrepancy -X- _ O
of -X- _ O
their -X- _ O
different -X- _ O
predictions -X- _ O
on -X- _ O
a -X- _ O
specific -X- _ O
dataset -X- _ O
D. -X- _ O
When -X- _ O
h -X- _ O
2 -X- _ O
is -X- _ O
an -X- _ O
ideal -X- _ O
hypothesis -X- _ O
that -X- _ O
can -X- _ O
correctly -X- _ O
map -X- _ O
all -X- _ O
instances -X- _ O
in -X- _ O
D -X- _ O
, -X- _ O
D -X- _ O
( -X- _ O
h -X- _ O
1 -X- _ O
, -X- _ O
h -X- _ O
2 -X- _ O
) -X- _ O
also -X- _ O
represents -X- _ O
the -X- _ O
error -X- _ O
rate -X- _ O
of -X- _ O
the -X- _ O
hypothesis -X- _ O
h -X- _ O
1 -X- _ O
on -X- _ O
dataset -X- _ O
D -X- _ O
, -X- _ O
abbreviated -X- _ O
as -X- _ O
D -X- _ O
( -X- _ O
h -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
H∆H -X- _ O
- -X- _ O
distance -X- _ O
is -X- _ O
a -X- _ O
metric -X- _ O
for -X- _ O
evaluating -X- _ O
the -X- _ O
divergence -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
distribution -X- _ O
between -X- _ O
two -X- _ O
datasets -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
only -X- _ O
relevant -X- _ O
to -X- _ O
the -X- _ O
input -X- _ O
space -X- _ O
of -X- _ O
the -X- _ O
datasets -X- _ O
. -X- _ O
Theorem -X- _ O
2 -X- _ O
. -X- _ O
Assume -X- _ O
there -X- _ O
exists -X- _ O
an -X- _ O
ideal -X- _ O
hypothesis -X- _ O
, -X- _ O
denoted -X- _ O
as -X- _ O
h -X- _ O
* -X- _ O
, -X- _ O
which -X- _ O
correctly -X- _ O
maps -X- _ O
all -X- _ O
instances -X- _ O
in -X- _ O
the -X- _ O
target -X- _ O
domain -X- _ O
to -X- _ O
their -X- _ O
groud -X- _ O
- -X- _ O
truth -X- _ O
labels -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
self -X- _ O
- -X- _ O
training -X- _ O
iteration -X- _ O
t -X- _ O
, -X- _ O
let -X- _ O
D -X- _ O
l -X- _ O
T -X- _ O
( -X- _ O
h -X- _ O
t -X- _ O
) -X- _ O
and -X- _ O
D -X- _ O
E -X- _ O
( -X- _ O
h -X- _ O
t -X- _ O
) -X- _ O
be -X- _ O
the -X- _ O
error -X- _ O
rate -X- _ O
of -X- _ O
the -X- _ O
hypothesis -X- _ O
h -X- _ O
t -X- _ O
on -X- _ O
D -X- _ O
l -X- _ O
T -X- _ O
and -X- _ O
D -X- _ O
E -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
the -X- _ O
error -X- _ O
rate -X- _ O
of -X- _ O
the -X- _ O
hypothesis -X- _ O
h -X- _ O
t -X- _ O
on -X- _ O
the -X- _ O
target -X- _ O
domain -X- _ O
is -X- _ O
upper -X- _ O
bounded -X- _ O
by -X- _ O
: -X- _ O

D -X- _ O
T -X- _ O
( -X- _ O
h -X- _ O
t -X- _ O
) -X- _ O
≤ -X- _ O
D -X- _ O
l -X- _ O
T -X- _ O
∪D -X- _ O
E -X- _ O
( -X- _ O
h -X- _ O
t -X- _ O
) -X- _ O
+ -X- _ O
1 -X- _ O
2 -X- _ O
dH∆H -X- _ O
( -X- _ O
DT -X- _ O
, -X- _ O
D -X- _ O
l -X- _ O
T -X- _ O
∪ -X- _ O
DE -X- _ O
) -X- _ O
+ -X- _ O
ρ -X- _ O
• -X- _ O
D -X- _ O
E -X- _ O
( -X- _ O
h -X- _ O
* -X- _ O
, -X- _ O
h -X- _ O
t−1 -X- _ O
) -X- _ O

where -X- _ O

ρ -X- _ O
= -X- _ O
|D -X- _ O
E -X- _ O
| -X- _ O
|D -X- _ O
l -X- _ O
T -X- _ O
|+|D -X- _ O
E -X- _ O
| -X- _ O
is -X- _ O
a -X- _ O
coefficient -X- _ O
related -X- _ O
to -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
D -X- _ O
l -X- _ O
T -X- _ O
and -X- _ O
D -X- _ O
E -X- _ O
, -X- _ O
D -X- _ O
l -X- _ O
T -X- _ O
∪D -X- _ O
E -X- _ O
( -X- _ O
h -X- _ O
t -X- _ O
) -X- _ O

is -X- _ O
the -X- _ O
error -X- _ O
rate -X- _ O
of -X- _ O
the -X- _ O
hypothesis -X- _ O
h -X- _ O
t -X- _ O
on -X- _ O
the -X- _ O
union -X- _ O
of -X- _ O
D -X- _ O
l -X- _ O
T -X- _ O
and -X- _ O
D -X- _ O
E -X- _ O
. -X- _ O
Theorem -X- _ O
3 -X- _ O
. -X- _ O
Assume -X- _ O
there -X- _ O
exists -X- _ O
three -X- _ O
datasets -X- _ O
, -X- _ O
D -X- _ O
1 -X- _ O
, -X- _ O
D -X- _ O
2 -X- _ O
, -X- _ O
D -X- _ O
3 -X- _ O
, -X- _ O
and -X- _ O
let -X- _ O
X -X- _ O
1 -X- _ O
, -X- _ O
X -X- _ O
2 -X- _ O
, -X- _ O
X -X- _ O
3 -X- _ O
denotes -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
input -X- _ O
cases -X- _ O
in -X- _ O
these -X- _ O
three -X- _ O
datasets -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O

X -X- _ O
1 -X- _ O
= -X- _ O
{ -X- _ O
x -X- _ O
i -X- _ O
| -X- _ O
( -X- _ O
x -X- _ O
i -X- _ O
, -X- _ O
y -X- _ O
i -X- _ O
) -X- _ O
∈ -X- _ O
D -X- _ O
1 -X- _ O
} -X- _ O
, -X- _ O
X -X- _ O
2 -X- _ O
= -X- _ O
{ -X- _ O
x -X- _ O
i -X- _ O
| -X- _ O
( -X- _ O
x -X- _ O
i -X- _ O
, -X- _ O
y -X- _ O
i -X- _ O
) -X- _ O
∈ -X- _ O
D -X- _ O
2 -X- _ O
} -X- _ O
, -X- _ O
X -X- _ O
3 -X- _ O
= -X- _ O
{ -X- _ O
x -X- _ O
i -X- _ O
| -X- _ O
( -X- _ O
x -X- _ O
i -X- _ O
, -X- _ O
y -X- _ O
i -X- _ O
) -X- _ O
∈ -X- _ O
D -X- _ O
3 -X- _ O
} -X- _ O
. -X- _ O
If -X- _ O
X -X- _ O
1 -X- _ O
⊆ -X- _ O
X -X- _ O
2 -X- _ O
⊆ -X- _ O
X -X- _ O
3 -X- _ O
, -X- _ O
then -X- _ O
d -X- _ O
H∆H -X- _ O
( -X- _ O
D -X- _ O
2 -X- _ O
, -X- _ O
D -X- _ O
3 -X- _ O
) -X- _ O
≤ -X- _ O
d -X- _ O
H∆H -X- _ O
( -X- _ O
D -X- _ O
1 -X- _ O
, -X- _ O
D -X- _ O
3 -X- _ O
) -X- _ O
holds -X- _ O

Based -X- _ O
on -X- _ O
Theorem -X- _ O
2 -X- _ O
, -X- _ O
we -X- _ O
demonstrate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
DaMSTF -X- _ O
from -X- _ O
the -X- _ O
following -X- _ O
aspects -X- _ O
. -X- _ O

First -X- _ O
of -X- _ O
all -X- _ O
, -X- _ O
expanding -X- _ O
the -X- _ O
meta -X- _ O
validation -X- _ O
set -X- _ O
can -X- _ O
decrease -X- _ O
the -X- _ O
second -X- _ O
term -X- _ O
in -X- _ O
Theorem -X- _ O
2 -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
Last -X- _ O
but -X- _ O
not -X- _ O
least -X- _ O
, -X- _ O
by -X- _ O
selecting -X- _ O
examples -X- _ O
that -X- _ O
have -X- _ O
the -X- _ O
lowest -X- _ O
prediction -X- _ O
entropy -X- _ O
, -X- _ O
the -X- _ O
error -X- _ O
rate -X- _ O
on -X- _ O
D -X- _ O
E -X- _ O
is -X- _ O
much -X- _ O
lower -X- _ O
than -X- _ O
that -X- _ O
of -X- _ O
the -X- _ O
expected -X- _ O
error -X- _ O
rates -X- _ O
on -X- _ O
D -X- _ O
p -X- _ O
T -X- _ O
, -X- _ O
formally -X- _ O
, -X- _ O

D -X- _ O
E -X- _ O
( -X- _ O
h -X- _ O
* -X- _ O
, -X- _ O
h -X- _ O
t−1 -X- _ O
) -X- _ O
< -X- _ O
D -X- _ O
p -X- _ O
T -X- _ O
( -X- _ O
h -X- _ O
* -X- _ O
, -X- _ O
h -X- _ O
t−1 -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
other -X- _ O
words -X- _ O
, -X- _ O
the -X- _ O
data -X- _ O
selection -X- _ O
process -X- _ O
in -X- _ O
the -X- _ O
meta -X- _ O
constructor -X- _ O
reduces -X- _ O
the -X- _ O
third -X- _ O
term -X- _ O
in -X- _ O
Theorem -X- _ O
2 -X- _ O
, -X- _ O
i.e -X- _ O
. -X- _ O
, -X- _ O
ρ -X- _ O
• -X- _ O
D -X- _ O
E -X- _ O
( -X- _ O
h -X- _ O
* -X- _ O
, -X- _ O
h -X- _ O
t−1 -X- _ O
) -X- _ O
. -X- _ O

Experiments -X- _ O

We -X- _ O
provide -X- _ O
the -X- _ O
experiment -X- _ O
settings -X- _ O
in -X- _ O
§ -X- _ O
5.1 -X- _ O
and -X- _ O
compare -X- _ O
DaMSTF -X- _ B-MethodName
with -X- _ O
previous -X- _ O
domain -X- _ B-TaskName
adaptation -X- _ I-TaskName
approaches -X- _ O
in -X- _ O
§ -X- _ O
5.2 -X- _ O
. -X- _ O
In -X- _ O
§ -X- _ O
5.3 -X- _ O
, -X- _ O
we -X- _ O
analyze -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
meta -X- _ O
constructor -X- _ O
and -X- _ O
the -X- _ O
domain -X- _ B-MethodName
adversarial -X- _ I-MethodName
learning -X- _ I-MethodName
module -X- _ O
with -X- _ O
an -X- _ O
ablation -X- _ O
study -X- _ O
. -X- _ O
§ -X- _ O
5.4 -X- _ O
validate -X- _ O
that -X- _ O
exposing -X- _ O
more -X- _ O
unlabeled -X- _ O
data -X- _ O
to -X- _ O
DaMSTF -X- _ B-MethodName
can -X- _ O
improve -X- _ O
the -X- _ O
domain -X- _ B-TaskName
adaptation -X- _ I-TaskName
performance -X- _ O
( -X- _ O
Theorem -X- _ O
3 -X- _ O
) -X- _ O
. -X- _ O
Appendix -X- _ O
E -X- _ O
provides -X- _ O
extra -X- _ O
experiments -X- _ O
of -X- _ O
the -X- _ O
domain -X- _ B-MethodName
adversarial -X- _ I-MethodName
learning -X- _ I-MethodName
module -X- _ O
in -X- _ O
preventing -X- _ O
the -X- _ O
training -X- _ O
guidance -X- _ O
vanishment -X- _ O
problem -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
meta -X- _ O
- -X- _ O
learning -X- _ O
module -X- _ O
in -X- _ O
highlighting -X- _ O
the -X- _ O
hard -X- _ O
and -X- _ O
correct -X- _ O
pseudo -X- _ O
instances -X- _ O
. -X- _ O

Experiment -X- _ O
Settings -X- _ O

Dataset -X- _ O
On -X- _ O
the -X- _ O
rumor -X- _ B-TaskName
detection -X- _ I-TaskName
task -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
experiments -X- _ O
with -X- _ O
the -X- _ O
public -X- _ O
dataset -X- _ O
TWIT -X- _ B-DatasetName
- -X- _ I-DatasetName
TER -X- _ I-DatasetName
( -X- _ O
Zubiaga -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
As -X- _ O
the -X- _ O
instances -X- _ O
in -X- _ O
the -X- _ O
TWITTER -X- _ B-DatasetName
dataset -X- _ O
are -X- _ O
collected -X- _ O
with -X- _ O
five -X- _ O
topics -X- _ O
, -X- _ O
we -X- _ O
categorized -X- _ O
the -X- _ O
instances -X- _ O
into -X- _ O
five -X- _ O
domains -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
sentiment -X- _ B-TaskName
classification -X- _ I-TaskName
task -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
experiments -X- _ O
withs -X- _ O
the -X- _ O
public -X- _ O
dataset -X- _ O
Amazon -X- _ B-DatasetName
( -X- _ O
Blitzer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2007 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
follow -X- _ O
the -X- _ O
method -X- _ O
in -X- _ O
( -X- _ O
He -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
to -X- _ O
preprocess -X- _ O
the -X- _ O
Amazon -X- _ B-DatasetName
dataset -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
resultant -X- _ O
dataset -X- _ O
consists -X- _ O
of -X- _ O
8,000 -X- _ O
instances -X- _ O
from -X- _ O
four -X- _ O
domains -X- _ O
: -X- _ O
books -X- _ O
, -X- _ O
dvd -X- _ O
, -X- _ O
electronics -X- _ O
, -X- _ O
and -X- _ O
kitchen -X- _ O
. -X- _ O
More -X- _ O
statistics -X- _ O
about -X- _ O
the -X- _ O
TWITTER -X- _ B-DatasetName
dataset -X- _ O
and -X- _ O
the -X- _ O
Amazon -X- _ B-DatasetName
dataset -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Appendix -X- _ O
D -X- _ O
. -X- _ O

Implementation -X- _ O
Details -X- _ O
The -X- _ O
base -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
rumor -X- _ B-TaskName
detection -X- _ I-TaskName
task -X- _ O
is -X- _ O
BiGCN -X- _ B-MethodName
( -X- _ O
Bian -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
base -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
sentiment -X- _ B-TaskName
classification -X- _ I-TaskName
task -X- _ O
is -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
benchmark -X- _ O
datasets -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
domain -X- _ B-TaskName
adaptation -X- _ I-TaskName
experiments -X- _ O
on -X- _ O
every -X- _ O
domain -X- _ O
. -X- _ O
When -X- _ O
one -X- _ O
domain -X- _ O
is -X- _ O
taken -X- _ O
as -X- _ O
the -X- _ O
target -X- _ O
domain -X- _ O
for -X- _ O
evaluation -X- _ O
, -X- _ O
the -X- _ O
rest -X- _ O
domains -X- _ O
are -X- _ O
merged -X- _ O
as -X- _ O
the -X- _ O
source -X- _ O
domain -X- _ O
. -X- _ O
More -X- _ O
impelementation -X- _ O
details -X- _ O
are -X- _ O
provided -X- _ O
in -X- _ O
Appendix -X- _ O
C -X- _ O
. -X- _ O

Comparing -X- _ O
Methods -X- _ O
Since -X- _ O
the -X- _ O
DaMSTF -X- _ B-MethodName
can -X- _ O
be -X- _ O
customized -X- _ O
to -X- _ O
both -X- _ O
semi -X- _ O
- -X- _ O
supervised -X- _ O
and -X- _ O
unsupervised -X- _ O
domain -X- _ B-TaskName
adaptation -X- _ I-TaskName
scenarios -X- _ O
, -X- _ O
the -X- _ O
baselines -X- _ O
contain -X- _ O
both -X- _ O
unsupervised -X- _ O
and -X- _ O
semisupervised -X- _ O
domain -X- _ O
adaptation -X- _ O
approaches -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
unsupervised -X- _ O
domain -X- _ B-TaskName
adaptation -X- _ I-TaskName
, -X- _ O
Out -X- _ B-MethodName
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
DANN -X- _ B-MethodName
( -X- _ O
Ganin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
and -X- _ O
CRST -X- _ B-MethodName
( -X- _ O
Zou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
are -X- _ O
selected -X- _ O
as -X- _ O
the -X- _ O
baselines -X- _ O
, -X- _ O
while -X- _ O
In+Out -X- _ B-MethodName
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
MME -X- _ B-MethodName
( -X- _ O
Saito -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
BiAT -X- _ B-MethodName
( -X- _ O
Jiang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
Wind -X- _ B-MethodName
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
are -X- _ O
selected -X- _ O
as -X- _ O
the -X- _ O
baselines -X- _ O
for -X- _ O
the -X- _ O
semi -X- _ O
- -X- _ O
supervised -X- _ O
domain -X- _ B-TaskName
adaptation -X- _ I-TaskName
. -X- _ O
Out -X- _ O
and -X- _ O
In+Out -X- _ B-MethodName
are -X- _ O
two -X- _ O
straightforward -X- _ O
ways -X- _ O
for -X- _ O
realizing -X- _ O
unsupervised -X- _ O
and -X- _ O
semi -X- _ O
- -X- _ O
supervised -X- _ O
domain -X- _ B-TaskName
adaptation -X- _ I-TaskName
, -X- _ O
where -X- _ O
Out -X- _ B-MethodName
means -X- _ O
the -X- _ O
base -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
domain -X- _ O
data -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
labeled -X- _ O
source -X- _ O
domain -X- _ O
data -X- _ O
) -X- _ O
and -X- _ O
In+Out -X- _ B-MethodName
means -X- _ O
the -X- _ O
base -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
both -X- _ O
the -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
and -X- _ O
the -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
domain -X- _ O
data -X- _ O
. -X- _ O
The -X- _ O
core -X- _ O
of -X- _ O
DANN -X- _ B-MethodName
is -X- _ O
an -X- _ O
adversarial -X- _ O
learning -X- _ O
algorithm -X- _ O
that -X- _ O
takes -X- _ O
the -X- _ O
domain -X- _ O
classification -X- _ O
loss -X- _ O
as -X- _ O
an -X- _ O
auxiliary -X- _ O
loss -X- _ O
. -X- _ O
CRST -X- _ B-MethodName
is -X- _ O
also -X- _ O
a -X- _ O
self -X- _ O
- -X- _ O
training -X- _ O
method -X- _ O
that -X- _ O
uses -X- _ O
a -X- _ O
label -X- _ O
regularization -X- _ O
technique -X- _ O
to -X- _ O
reduce -X- _ O
the -X- _ O
label -X- _ O
noise -X- _ O
from -X- _ O
mislabeled -X- _ O
data -X- _ O
. -X- _ O
WIND -X- _ B-MethodName
is -X- _ O
a -X- _ O
meta -X- _ O
- -X- _ O
learning -X- _ O
- -X- _ O
based -X- _ O
domain -X- _ O
adaptation -X- _ O
approach -X- _ O
that -X- _ O
optimizes -X- _ O
the -X- _ O
weights -X- _ O
of -X- _ O
different -X- _ O
training -X- _ O
instances -X- _ O
. -X- _ O
The -X- _ O
difference -X- _ O
between -X- _ O
the -X- _ O
WIND -X- _ B-MethodName
and -X- _ O
DaMSTF -X- _ B-MethodName
lies -X- _ O
in -X- _ O
that -X- _ O
, -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
WIND -X- _ B-MethodName
only -X- _ O
use -X- _ O
the -X- _ O
labeled -X- _ O
source -X- _ O
data -X- _ O
to -X- _ O
construct -X- _ O
the -X- _ O
meta -X- _ O
training -X- _ O
set -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
meta -X- _ O
training -X- _ O
set -X- _ O
in -X- _ O
the -X- _ O
DaMSTF -X- _ B-MethodName
contains -X- _ O
both -X- _ O
the -X- _ O
labeled -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
source -X- _ O
domain -X- _ O
and -X- _ O
the -X- _ O
pseudo -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
target -X- _ O
domain -X- _ O
. -X- _ O
( -X- _ O
ii -X- _ O
) -X- _ O
WIND -X- _ B-MethodName
does -X- _ O
not -X- _ O
consider -X- _ O
the -X- _ O
training -X- _ O
guidance -X- _ O
vanishment -X- _ O
problem -X- _ O
and -X- _ O
the -X- _ O
bias -X- _ O
between -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
target -X- _ O
domain -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
meta -X- _ O
validation -X- _ O
set -X- _ O
. -X- _ O

Results -X- _ O

To -X- _ O
validate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
meta -X- _ O
selftraining -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
unsupervised -X- _ O
and -X- _ O
semisupervised -X- _ O
domain -X- _ B-TaskName
adaptation -X- _ I-TaskName
experiments -X- _ O
on -X- _ O
two -X- _ O
benchmark -X- _ O
datasets -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
BiGCN -X- _ B-MethodName
on -X- _ O
TWITTER -X- _ B-DatasetName
, -X- _ O
and -X- _ O
BERT -X- _ B-MethodName
on -X- _ O
Amazon -X- _ B-DatasetName
. -X- _ O
Since -X- _ O
the -X- _ O
rumor -X- _ B-TaskName
detec -X- _ I-TaskName
- -X- _ I-TaskName
tion -X- _ I-TaskName
task -X- _ O
focuses -X- _ O
more -X- _ O
on -X- _ O
the -X- _ O
' -X- _ O
rumor -X- _ O
' -X- _ O
category -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
different -X- _ O
models -X- _ O
by -X- _ O
their -X- _ O
F1 -X- _ B-MetricName
score -X- _ O
in -X- _ O
classifying -X- _ O
the -X- _ O
' -X- _ O
rumor -X- _ O
' -X- _ O
category -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
sentiment -X- _ B-TaskName
classification -X- _ I-TaskName
task -X- _ O
, -X- _ O
the -X- _ O
prediction -X- _ O
accuracy -X- _ B-MetricName
of -X- _ O
different -X- _ O
classes -X- _ O
is -X- _ O
equally -X- _ O
important -X- _ O
, -X- _ O
so -X- _ O
we -X- _ O
take -X- _ O
the -X- _ O
macro -X- _ B-MetricName
- -X- _ I-MetricName
F1 -X- _ I-MetricName
score -X- _ O
to -X- _ O
evaluate -X- _ O
different -X- _ O
models -X- _ O
. -X- _ O
For -X- _ O
semi -X- _ O
- -X- _ O
supervised -X- _ O
domain -X- _ B-TaskName
adaptation -X- _ I-TaskName
, -X- _ O
100 -X- _ O
labeled -X- _ O
instances -X- _ O
in -X- _ O
the -X- _ O
target -X- _ O
domain -X- _ O
are -X- _ O
taken -X- _ O
as -X- _ O
the -X- _ O
indomain -X- _ O
dataset -X- _ O
. -X- _ O
The -X- _ O
experiment -X- _ O
results -X- _ O
are -X- _ O
listed -X- _ O
in -X- _ O
Tab -X- _ O
. -X- _ O
1 -X- _ O
, -X- _ O
Tab -X- _ O
. -X- _ O
2 -X- _ O
. -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Tab -X- _ O
. -X- _ O
1 -X- _ O
, -X- _ O
Tab -X- _ O
. -X- _ O
2 -X- _ O
, -X- _ O
DaMSTF -X- _ B-MethodName
outperforms -X- _ O
all -X- _ O
baseline -X- _ O
approaches -X- _ O
on -X- _ O
all -X- _ O
benchmark -X- _ O
datasets -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
rumor -X- _ B-TaskName
detection -X- _ I-TaskName
task -X- _ O
, -X- _ O
DaMSTF -X- _ B-MethodName
surpasses -X- _ O
the -X- _ O
best -X- _ O
baseline -X- _ O
approaches -X- _ O
( -X- _ O
CRST -X- _ B-MethodName
for -X- _ O
unsupervised -X- _ O
domain -X- _ B-TaskName
adaptation -X- _ I-TaskName
, -X- _ O
WIND -X- _ B-MethodName
for -X- _ O
semisupervised -X- _ O
domain -X- _ B-TaskName
adaptation -X- _ I-TaskName
) -X- _ O
by -X- _ O
nearly -X- _ O
5 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
average -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
" -X- _ O
Fer -X- _ O
. -X- _ O
" -X- _ O
domain -X- _ O
, -X- _ O
where -X- _ O
most -X- _ O
approaches -X- _ O
perform -X- _ O
worse -X- _ O
than -X- _ O
the -X- _ O
Out -X- _ B-MethodName
and -X- _ O
In+Out -X- _ B-MethodName
, -X- _ O
DaMSTF -X- _ B-MethodName
still -X- _ O
achieves -X- _ O
an -X- _ O
F1 -X- _ B-MetricName
value -X- _ O
of -X- _ O
0.629 -X- _ B-MetricValue
, -X- _ O
which -X- _ O
is -X- _ O
40 -X- _ B-MetricValue
% -X- _ I-MetricValue
higher -X- _ O
than -X- _ O
that -X- _ O
of -X- _ O
the -X- _ O
In+Out -X- _ B-MethodName
. -X- _ O
On -X- _ O
the -X- _ O
sentiment -X- _ B-TaskName
classification -X- _ I-TaskName
task -X- _ O
, -X- _ O
DaMSTF -X- _ B-MethodName
also -X- _ O
outperforms -X- _ O
other -X- _ O
approaches -X- _ O
. -X- _ O
Under -X- _ O
the -X- _ O
unsupervised -X- _ O
domain -X- _ B-TaskName
adaptation -X- _ I-TaskName
scenario -X- _ O
, -X- _ O
DaMSTF -X- _ B-MethodName
surpasses -X- _ O
the -X- _ O
best -X- _ O
baseline -X- _ O
approach -X- _ O
( -X- _ O
DANN -X- _ B-MethodName
on -X- _ O
the -X- _ O
Amazon -X- _ B-DatasetName
dataset -X- _ O
) -X- _ O
by -X- _ O
nearly -X- _ O
2 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
average -X- _ O
. -X- _ O
Under -X- _ O
the -X- _ O
semisupervised -X- _ O
domain -X- _ B-TaskName
adaptation -X- _ I-TaskName
scenario -X- _ O
, -X- _ O
DaMSTF -X- _ B-MethodName
surpasses -X- _ O
Wind -X- _ B-MethodName
, -X- _ O
the -X- _ O
best -X- _ O
baseline -X- _ O
approach -X- _ O
on -X- _ O
the -X- _ O
Amazon -X- _ B-DatasetName
dataset -X- _ O
, -X- _ O
by -X- _ O
nearly -X- _ O
3 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
average -X- _ O
. -X- _ O

Ablation -X- _ O
Study -X- _ O

This -X- _ O
subsection -X- _ O
presents -X- _ O
an -X- _ O
ablation -X- _ O
study -X- _ O
to -X- _ O
understand -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
DaMSTF -X- _ B-MethodName
. -X- _ O
As -X- _ O
illustrated -X- _ O
in -X- _ O
§ -X- _ O
3 -X- _ O
and -X- _ O
§ -X- _ O
4.2 -X- _ O
, -X- _ O
DaMSTF -X- _ B-MethodName
combines -X- _ O
metalearning -X- _ O
and -X- _ O
self -X- _ O
- -X- _ O
training -X- _ O
via -X- _ O
two -X- _ O
strategies -X- _ O
: -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
expanding -X- _ O
the -X- _ O
meta -X- _ O
validation -X- _ O
set -X- _ O
with -X- _ O
a -X- _ O
meta -X- _ O
constructor -X- _ O
; -X- _ O
( -X- _ O
ii -X- _ O
) -X- _ O
preventing -X- _ O
the -X- _ O
training -X- _ O
guidance -X- _ O
vanishment -X- _ O
problem -X- _ O
with -X- _ O
a -X- _ O
domain -X- _ B-MethodName
adversarial -X- _ I-MethodName
module -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
we -X- _ O
separately -X- _ O
remove -X- _ O
the -X- _ O
above -X- _ O
strategies -X- _ O
from -X- _ O
the -X- _ O
DaMSTF -X- _ B-MethodName
, -X- _ O
yielding -X- _ O
three -X- _ O
different -X- _ O
variants -X- _ O
, -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Tab -X- _ O
. -X- _ O
3 -X- _ O
and -X- _ O
Tab -X- _ O
. -X- _ O
4 -X- _ O
, -X- _ O
both -X- _ O
strategies -X- _ O
are -X- _ O
indispensable -X- _ O
for -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
DaMSTF -X- _ B-MethodName
, -X- _ O
and -X- _ O
removing -X- _ O
either -X- _ O
strategy -X- _ O
can -X- _ O
result -X- _ O
in -X- _ O
performance -X- _ O
degeneration -X- _ O
. -X- _ O
Removing -X- _ O
the -X- _ O
domain -X- _ B-MethodName
adversarial -X- _ I-MethodName
learning -X- _ I-MethodName
module -X- _ O
( -X- _ O
DaMSTF -X- _ B-MethodName
-w -X- _ I-MethodName
/ -X- _ I-MethodName
o -X- _ I-MethodName
D -X- _ I-MethodName
) -X- _ O
leads -X- _ O
to -X- _ O
an -X- _ O
average -X- _ O
decrease -X- _ O
from -X- _ O
0.713 -X- _ B-MetricValue
to -X- _ O
0.623 -X- _ B-MetricValue
on -X- _ O
the -X- _ O
TWITTER -X- _ B-DatasetName
dataset -X- _ O
and -X- _ O
from -X- _ O
0.942 -X- _ B-MetricValue
to -X- _ O
0.918 -X- _ B-MetricValue
on -X- _ O
the -X- _ O
Amazon -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O
Without -X- _ O
expanding -X- _ O
the -X- _ O
meta -X- _ O
validation -X- _ O
set -X- _ O
, -X- _ O
DaMSTF -X- _ B-MethodName
-w -X- _ I-MethodName
/ -X- _ I-MethodName
o -X- _ I-MethodName
E -X- _ I-MethodName
performs -X- _ O
worse -X- _ O
than -X- _ O
DaMSTF -X- _ B-MethodName
on -X- _ O
both -X- _ O
the -X- _ O
TWITTER -X- _ B-DatasetName
dataset -X- _ O
( -X- _ O
0.630 -X- _ B-MetricValue
vs. -X- _ O
0.731 -X- _ B-MetricValue
on -X- _ O
average -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
Amazon -X- _ B-DatasetName
dataset -X- _ O
( -X- _ O
0.931 -X- _ B-MetricValue
vs. -X- _ O
0.942 -X- _ B-MetricValue
on -X- _ O
average -X- _ O
) -X- _ O
. -X- _ O
After -X- _ O
removing -X- _ O
both -X- _ O
strategies -X- _ O
, -X- _ O
DaMSTF -X- _ B-MethodName
suffers -X- _ O
a -X- _ O
severe -X- _ O
performance -X- _ O
deterioration -X- _ O
on -X- _ O
both -X- _ O
benchmark -X- _ O
datasets -X- _ O
. -X- _ O

Effect -X- _ O
of -X- _ O
the -X- _ O
unlabeled -X- _ O
dataset -X- _ O
size -X- _ O

As -X- _ O
illustrated -X- _ O
in -X- _ O
§ -X- _ O
4.2 -X- _ O
, -X- _ O
the -X- _ O
second -X- _ O
term -X- _ O

d -X- _ O
H∆H -X- _ O
( -X- _ O
D -X- _ O
T -X- _ O
, -X- _ O
D -X- _ O
l -X- _ O
T -X- _ O
∪ -X- _ O
D -X- _ O
E -X- _ O
) -X- _ O
is -X- _ O
close -X- _ O
to -X- _ O
d -X- _ O
H∆H -X- _ O
( -X- _ O
D -X- _ O
T -X- _ O
, -X- _ O
D -X- _ O
u -X- _ O
T -X- _ O
) -X- _ O

in -X- _ O
the -X- _ O
whole -X- _ O
training -X- _ O
process -X- _ O
. -X- _ O
From -X- _ O
this -X- _ O
perspective -X- _ O
, -X- _ O
increasing -X- _ O
the -X- _ O
size -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
the -X- _ I-HyperparameterName
unlabeled -X- _ I-HyperparameterName
dataset -X- _ I-HyperparameterName
can -X- _ O
improve -X- _ O
the -X- _ O
performance -X- _ O
. -X- _ O
To -X- _ O
validate -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
separately -X- _ O
expose -X- _ O
0 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
, -X- _ O
5 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
, -X- _ O
10 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
, -X- _ O
20 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
, -X- _ O
30 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
, -X- _ O
40 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
, -X- _ O
50 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
, -X- _ O
60 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
, -X- _ O
70 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
, -X- _ O
80 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
, -X- _ O
90 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
, -X- _ O
100 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
of -X- _ O
the -X- _ O
unlabeled -X- _ B-HyperparameterName
data -X- _ I-HyperparameterName
during -X- _ O
the -X- _ O
training -X- _ O
. -X- _ O
These -X- _ O
new -X- _ O
unlabeled -X- _ B-HyperparameterName
dataset -X- _ I-HyperparameterName
are -X- _ O
denote -X- _ O
as -X- _ O
D -X- _ O
u -X- _ O
T -X- _ O
( -X- _ O
0 -X- _ O
% -X- _ O
) -X- _ O
, -X- _ O
D -X- _ O
u -X- _ O
T -X- _ O
( -X- _ O
5 -X- _ O
% -X- _ O
) -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
D -X- _ O
u -X- _ O
T -X- _ O
( -X- _ O
100 -X- _ O
% -X- _ O
) -X- _ O
respectively -X- _ O
. -X- _ O
The -X- _ O
experiments -X- _ O
are -X- _ O
conducted -X- _ O
on -X- _ O
" -X- _ O
Ott -X- _ O
. -X- _ O
" -X- _ O
Domain -X- _ O
of -X- _ O
TWITTER -X- _ B-DatasetName
and -X- _ O
the -X- _ O
results -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
Fig -X- _ O
. -X- _ O
2 -X- _ O
. -X- _ O
From -X- _ O
Fig -X- _ O
. -X- _ O
2 -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
performs -X- _ O
poorly -X- _ O
when -X- _ O
using -X- _ O
a -X- _ O
small -X- _ O
proportion -X- _ O
of -X- _ O
the -X- _ O
unlabeled -X- _ B-HyperparameterName
data -X- _ I-HyperparameterName
in -X- _ O
the -X- _ O
training -X- _ O
process -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
exposing -X- _ O
D -X- _ O
u -X- _ O
T -X- _ O
( -X- _ O
5 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
) -X- _ O
to -X- _ O
the -X- _ O
DaMSTF -X- _ B-MethodName
only -X- _ O
achieves -X- _ O
an -X- _ O
F1 -X- _ B-MetricName
score -X- _ O
of -X- _ O
0.701 -X- _ B-MetricValue
, -X- _ O
which -X- _ O
is -X- _ O
14.2 -X- _ B-MetricValue
% -X- _ I-MetricValue
lower -X- _ O
than -X- _ O
the -X- _ O
0.843 -X- _ B-MetricValue
achieved -X- _ O
by -X- _ O
exposing -X- _ O
the -X- _ O
D -X- _ O
u -X- _ O
T -X- _ O
( -X- _ O
100 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
) -X- _ O
. -X- _ O
From -X- _ O
0 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
to -X- _ O
50 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
, -X- _ O
increasing -X- _ O
the -X- _ O
exposure -X- _ B-HyperparameterName
ratio -X- _ I-HyperparameterName
consistently -X- _ O
improves -X- _ O
the -X- _ O
F1 -X- _ B-MetricName
score -X- _ O
. -X- _ O
The -X- _ O
improvements -X- _ O
saturate -X- _ O
after -X- _ O
more -X- _ O
than -X- _ O
50 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
of -X- _ O
the -X- _ O
unlabeled -X- _ B-HyperparameterName
data -X- _ I-HyperparameterName
are -X- _ O
exposed -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
explained -X- _ O
by -X- _ O
the -X- _ O
law -X- _ O
of -X- _ O
large -X- _ O
numbers -X- _ O
in -X- _ O
the -X- _ O
statistic -X- _ O
theory -X- _ O
( -X- _ O
Kraaikamp -X- _ O
and -X- _ O
Meester -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
. -X- _ O
An -X- _ O
exposure -X- _ B-HyperparameterName
ratio -X- _ I-HyperparameterName
of -X- _ O
50 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
can -X- _ O
be -X- _ O
regarded -X- _ O
as -X- _ O
a -X- _ O
large -X- _ O
number -X- _ O
for -X- _ O
approaching -X- _ O
the -X- _ O
unlabeled -X- _ B-HyperparameterName
dataset -X- _ I-HyperparameterName
. -X- _ O
Thus -X- _ O
, -X- _ O
D -X- _ O
u -X- _ O
T -X- _ O
( -X- _ O
50 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
) -X- _ O
is -X- _ O
close -X- _ O
to -X- _ O
D -X- _ O
u -X- _ O
T -X- _ O
( -X- _ O
100 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
) -X- _ O
and -X- _ O
d -X- _ O
H∆H -X- _ O
( -X- _ O
D -X- _ O
T -X- _ O
, -X- _ O
D -X- _ O
u -X- _ O
T -X- _ O
( -X- _ O
50 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
) -X- _ O
) -X- _ O
approximates -X- _ O
d -X- _ O
H∆H -X- _ O
( -X- _ O
D -X- _ O
T -X- _ O
, -X- _ O
D -X- _ O
u -X- _ O
T -X- _ O
( -X- _ O
100 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
) -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
leads -X- _ O
to -X- _ O
the -X- _ O
performance -X- _ O
saturation -X- _ O
. -X- _ O

6 -X- _ O
Related -X- _ O
Work -X- _ O

Domain -X- _ B-TaskName
Adaptation -X- _ I-TaskName

Inspired -X- _ O
by -X- _ O
the -X- _ O
taxonomy -X- _ O
in -X- _ O
Ramponi -X- _ O
and -X- _ O
Plank -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
categorize -X- _ O
the -X- _ O
domain -X- _ B-TaskName
adaptation -X- _ I-TaskName
approaches -X- _ O
into -X- _ O
two -X- _ O
categories -X- _ O
: -X- _ O
Feature -X- _ O
- -X- _ O
Alignment -X- _ O
approaches -X- _ O
and -X- _ O
Data -X- _ O
- -X- _ O
Centric -X- _ O
approaches -X- _ O
. -X- _ O
Feature -X- _ O
- -X- _ O
Alignment -X- _ O
approaches -X- _ O
( -X- _ O
Tzeng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
; -X- _ O
Ganin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Saito -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
focus -X- _ O
on -X- _ O
aligning -X- _ O
the -X- _ O
feature -X- _ O
space -X- _ O
across -X- _ O
domains -X- _ O
. -X- _ O
The -X- _ O
most -X- _ O
well -X- _ O
- -X- _ O
known -X- _ O
feature -X- _ O
- -X- _ O
alignment -X- _ O
approach -X- _ O
is -X- _ O
DANN -X- _ B-MethodName
( -X- _ O
Ganin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
aligns -X- _ O
the -X- _ O
feature -X- _ O
space -X- _ O
by -X- _ O
min -X- _ O
- -X- _ O
max -X- _ O
the -X- _ O
domain -X- _ O
classification -X- _ O
loss -X- _ O
. -X- _ O
With -X- _ O
similar -X- _ O
efforts -X- _ O
, -X- _ O
MME -X- _ B-MethodName
( -X- _ O
Saito -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
min -X- _ O
- -X- _ O
max -X- _ O
the -X- _ O
conditional -X- _ O
entropy -X- _ O
on -X- _ O
the -X- _ O
unlabeled -X- _ O
data -X- _ O
. -X- _ O
VAT -X- _ O
( -X- _ O
Miyato -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
BiAT -X- _ B-MethodName
( -X- _ O
Jiang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
propose -X- _ O
to -X- _ O
decouple -X- _ O
the -X- _ O
min -X- _ O
- -X- _ O
max -X- _ O
optimization -X- _ O
process -X- _ O
, -X- _ O
which -X- _ O
first -X- _ O
imposes -X- _ O
a -X- _ O
gradient -X- _ O
- -X- _ O
based -X- _ O
perturbation -X- _ O
on -X- _ O
the -X- _ O
input -X- _ O
space -X- _ O
to -X- _ O
maximize -X- _ O
the -X- _ O
risk -X- _ O
loss -X- _ O
and -X- _ O
then -X- _ O
minimize -X- _ O
the -X- _ O
final -X- _ O
objective -X- _ O
on -X- _ O
the -X- _ O
perturbed -X- _ O
input -X- _ O
cases -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
Data -X- _ O
- -X- _ O
Centric -X- _ O
approaches -X- _ O
exploit -X- _ O
the -X- _ O
unlabeled -X- _ O
data -X- _ O
in -X- _ O
the -X- _ O
target -X- _ O
domain -X- _ O
or -X- _ O
select -X- _ O
the -X- _ O
relevant -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
source -X- _ O
domain -X- _ O
. -X- _ O
To -X- _ O
select -X- _ O
relevant -X- _ O
data -X- _ O
, -X- _ O
( -X- _ O
Moore -X- _ O
and -X- _ O
Lewis -X- _ O
, -X- _ O
2010 -X- _ O
; -X- _ O
Plank -X- _ O
and -X- _ O
van -X- _ O
Noord -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
design -X- _ O
a -X- _ O
technique -X- _ O
based -X- _ O
on -X- _ O
topic -X- _ O
models -X- _ O
for -X- _ O
measuring -X- _ O
the -X- _ O
domain -X- _ O
similarity -X- _ O
. -X- _ O
To -X- _ O
exploit -X- _ O
the -X- _ O
unlabeled -X- _ O
data -X- _ O
, -X- _ O
pseudo -X- _ O
labeling -X- _ O
approaches -X- _ O
, -X- _ O
including -X- _ O
self -X- _ O
- -X- _ O
training -X- _ O
( -X- _ O
Zou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
co -X- _ O
- -X- _ O
training -X- _ O
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
tri -X- _ O
- -X- _ O
training -X- _ O
( -X- _ O
Saito -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
are -X- _ O
widely -X- _ O
applied -X- _ O
and -X- _ O
become -X- _ O
an -X- _ O
important -X- _ O
direction -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
research -X- _ O
of -X- _ O
self -X- _ O
- -X- _ O
training -X- _ O
for -X- _ O
domain -X- _ B-TaskName
adaptation -X- _ I-TaskName
, -X- _ O
many -X- _ O
efforts -X- _ O
are -X- _ O
put -X- _ O
into -X- _ O
reducing -X- _ O
the -X- _ O
label -X- _ O
noise -X- _ O
of -X- _ O
pseudo -X- _ O
instances -X- _ O
( -X- _ O
Zou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
( -X- _ O
Zou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
, -X- _ O
2018Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Among -X- _ O
them -X- _ O
, -X- _ O
CRST -X- _ O
( -X- _ O
Zou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
proposes -X- _ O
a -X- _ O
label -X- _ O
regularization -X- _ O
technique -X- _ O
to -X- _ O
reduce -X- _ O
label -X- _ O
noise -X- _ O
while -X- _ O
CST -X- _ O
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
takes -X- _ O
Tsallis -X- _ O
- -X- _ O
entropy -X- _ O
as -X- _ O
a -X- _ O
confidence -X- _ O
- -X- _ O
friendly -X- _ O
regularize -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
adopt -X- _ O
metalearning -X- _ O
to -X- _ O
automatically -X- _ O
reduce -X- _ O
label -X- _ O
noise -X- _ O
. -X- _ O

Meta -X- _ O
- -X- _ O
Learning -X- _ O

Meta -X- _ O
- -X- _ O
learning -X- _ O
is -X- _ O
an -X- _ O
emerging -X- _ O
new -X- _ O
branch -X- _ O
in -X- _ O
machine -X- _ O
learning -X- _ O
that -X- _ O
focuses -X- _ O
on -X- _ O
providing -X- _ O
better -X- _ O
hyperparameters -X- _ O
for -X- _ O
model -X- _ O
training -X- _ O
, -X- _ O
including -X- _ O
but -X- _ O
not -X- _ O
limited -X- _ O
to -X- _ O
better -X- _ O
initial -X- _ O
model -X- _ O
parameters -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
MAML -X- _ O
( -X- _ O
Finn -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
better -X- _ O
learning -X- _ O
rates -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
MetaSGD -X- _ O
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
better -X- _ O
neural -X- _ O
network -X- _ O
architect -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
DARTs -X- _ O
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
Recent -X- _ O
studies -X- _ O
revealed -X- _ O
the -X- _ O
prospect -X- _ O
of -X- _ O
providing -X- _ O
better -X- _ O
instance -X- _ O
weights -X- _ O
( -X- _ O
Ren -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Shu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Kye -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
When -X- _ O
using -X- _ O
prototypi -X- _ O
- -X- _ O
cal -X- _ O
learning -X- _ O
on -X- _ O
the -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
image -X- _ O
classification -X- _ O
task -X- _ O
, -X- _ O
MCT -X- _ O
( -X- _ O
Kye -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
involves -X- _ O
a -X- _ O
reweighing -X- _ O
process -X- _ O
to -X- _ O
obtain -X- _ O
a -X- _ O
more -X- _ O
accurate -X- _ O
class -X- _ O
prototype -X- _ O
. -X- _ O
Oriented -X- _ O
to -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
tasks -X- _ O
, -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
use -X- _ O
the -X- _ O
optimization -X- _ O
- -X- _ O
based -X- _ O
meta -X- _ O
- -X- _ O
reweighting -X- _ O
algorithm -X- _ O
to -X- _ O
refine -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
. -X- _ O
Similar -X- _ O
to -X- _ O
DaMSTF -X- _ B-MethodName
, -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
also -X- _ O
proposes -X- _ O
to -X- _ O
combine -X- _ O
the -X- _ O
metalearning -X- _ O
algorithm -X- _ O
and -X- _ O
the -X- _ O
self -X- _ O
- -X- _ O
training -X- _ O
approach -X- _ O
, -X- _ O
but -X- _ O
their -X- _ O
method -X- _ O
focuses -X- _ O
on -X- _ O
the -X- _ O
neural -X- _ O
sequence -X- _ O
labeling -X- _ O
task -X- _ O
rather -X- _ O
than -X- _ O
the -X- _ O
domain -X- _ B-TaskName
adaptation -X- _ I-TaskName
task -X- _ O
. -X- _ O
Also -X- _ O
, -X- _ O
they -X- _ O
do -X- _ O
not -X- _ O
consider -X- _ O
the -X- _ O
bias -X- _ O
between -X- _ O
the -X- _ O
meta -X- _ O
- -X- _ O
validation -X- _ O
set -X- _ O
and -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
, -X- _ O
whereas -X- _ O
reducing -X- _ O
such -X- _ O
bias -X- _ O
is -X- _ O
an -X- _ O
important -X- _ O
contribution -X- _ O
of -X- _ O
the -X- _ O
DaMSTF -X- _ B-MethodName
. -X- _ O
WIND -X- _ B-MethodName
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
meta -X- _ O
- -X- _ O
learning -X- _ O
- -X- _ O
based -X- _ O
domain -X- _ B-TaskName
adaptation -X- _ I-TaskName
approach -X- _ O
, -X- _ O
the -X- _ O
differences -X- _ O
between -X- _ O
WIND -X- _ B-MethodName
and -X- _ O
DaMSTF -X- _ B-MethodName
are -X- _ O
discussed -X- _ O
in -X- _ O
§ -X- _ O
5.1 -X- _ O
. -X- _ O

Conclusion -X- _ O

This -X- _ O
paper -X- _ O
proposes -X- _ O
an -X- _ O
improved -X- _ O
self -X- _ O
- -X- _ O
training -X- _ O
framework -X- _ O
for -X- _ O
domain -X- _ B-TaskName
adaptation -X- _ I-TaskName
, -X- _ O
named -X- _ O
DaMSTF -X- _ B-MethodName
. -X- _ O
DaMSTF -X- _ B-MethodName
extends -X- _ O
the -X- _ O
basic -X- _ O
framework -X- _ O
for -X- _ O
selftraining -X- _ O
approaches -X- _ O
by -X- _ O
involving -X- _ O
a -X- _ O
meta -X- _ O
- -X- _ O
learning -X- _ O
module -X- _ O
, -X- _ O
which -X- _ O
alleviates -X- _ O
the -X- _ O
label -X- _ O
noise -X- _ O
problem -X- _ O
in -X- _ O
self -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O
To -X- _ O
guarantee -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
meta -X- _ O
- -X- _ O
learning -X- _ O
module -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
meta -X- _ O
constructor -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
the -X- _ O
meta -X- _ O
validation -X- _ O
set -X- _ O
, -X- _ O
and -X- _ O
propose -X- _ O
a -X- _ O
domain -X- _ B-MethodName
adversarial -X- _ I-MethodName
module -X- _ O
to -X- _ O
prevent -X- _ O
the -X- _ O
training -X- _ O
guidance -X- _ O
vanishment -X- _ O
. -X- _ O
Also -X- _ O
, -X- _ O
the -X- _ O
domain -X- _ O
adversarial -X- _ O
learning -X- _ O
module -X- _ O
can -X- _ O
align -X- _ O
the -X- _ O
feature -X- _ O
space -X- _ O
along -X- _ O
with -X- _ O
the -X- _ O
self -X- _ O
- -X- _ O
training -X- _ O
iterations -X- _ O
. -X- _ O
Extensive -X- _ O
experiments -X- _ O
on -X- _ O
two -X- _ O
popular -X- _ O
models -X- _ O
, -X- _ O
BiGCN -X- _ B-MethodName
and -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
verify -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
DaMSTF -X- _ B-MethodName
. -X- _ O
The -X- _ O
ablation -X- _ O
studies -X- _ O
demonstrate -X- _ O
that -X- _ O
the -X- _ O
meta -X- _ O
- -X- _ O
learning -X- _ O
module -X- _ O
, -X- _ O
the -X- _ O
meta -X- _ O
constructor -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
domain -X- _ O
adversarial -X- _ O
module -X- _ O
are -X- _ O
indispensable -X- _ O
for -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
DaMSTF -X- _ B-MethodName
. -X- _ O
The -X- _ O
limitation -X- _ O
, -X- _ O
ethical -X- _ O
considerations -X- _ O
, -X- _ O
and -X- _ O
social -X- _ O
impacts -X- _ O
of -X- _ O
this -X- _ O
paper -X- _ O
are -X- _ O
in -X- _ O
Appendix -X- _ O
F -X- _ O
and -X- _ O
G -X- _ O
. -X- _ O

A -X- _ O
Proof -X- _ O
For -X- _ O
Theorem -X- _ O
1 -X- _ O
Theorem -X- _ O
1 -X- _ O
. -X- _ O
Let -X- _ O
w -X- _ O
i -X- _ O
be -X- _ O
the -X- _ O
weight -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
instance -X- _ O
i -X- _ O
, -X- _ O
denoted -X- _ O
as -X- _ O
( -X- _ O
x -X- _ O
i -X- _ O
, -X- _ O
y -X- _ O
i -X- _ O
) -X- _ O
, -X- _ O
in -X- _ O
B -X- _ O
, -X- _ O
the -X- _ O
gradient -X- _ O
of -X- _ O
w -X- _ O
i -X- _ O
on -X- _ O
L -X- _ O
M -X- _ O
can -X- _ O
be -X- _ O
represented -X- _ O
by -X- _ O
the -X- _ O
similarity -X- _ O
between -X- _ O
the -X- _ O
gradients -X- _ O
on -X- _ O
training -X- _ O
instance -X- _ O
i -X- _ O
and -X- _ O
the -X- _ O
gradients -X- _ O
on -X- _ O
the -X- _ O
meta -X- _ O
validation -X- _ O
set -X- _ O
: -X- _ O

∂LM -X- _ O
( -X- _ O
θ -X- _ O
( -X- _ O
w -X- _ O
) -X- _ O
) -X- _ O
∂wi -X- _ O
= -X- _ O
− -X- _ O
η -X- _ O
|B| -X- _ O
• -X- _ O
[ -X- _ O
1 -X- _ O
|DM -X- _ O
| -X- _ O
|D -X- _ O
M -X- _ O
| -X- _ O
j=1 -X- _ O
gθ -X- _ O
( -X- _ O
xj -X- _ O
, -X- _ O
yj -X- _ O
) -X- _ O
T -X- _ O
] -X- _ O
• -X- _ O
g -X- _ O
θ -X- _ O
( -X- _ O
xi -X- _ O
, -X- _ O
yi -X- _ O
) -X- _ O

where -X- _ O

1 -X- _ O
|D -X- _ O
M -X- _ O
| -X- _ O
|D -X- _ O
M -X- _ O
| -X- _ O
j=1 -X- _ O
gθ -X- _ O
( -X- _ O
x -X- _ O
j -X- _ O
, -X- _ O
y -X- _ O
j -X- _ O
) -X- _ O
T -X- _ O
is -X- _ O
the -X- _ O
gradients -X- _ O
of -X- _ O
θ -X- _ O
on -X- _ O
D -X- _ O
M -X- _ O
, -X- _ O
g -X- _ O
i -X- _ O
θ -X- _ O
( -X- _ O
x -X- _ O
i -X- _ O
, -X- _ O
y -X- _ O
i -X- _ O
) -X- _ O

is -X- _ O
the -X- _ O
gradients -X- _ O
of -X- _ O
θ -X- _ O
on -X- _ O
the -X- _ O
training -X- _ O
instance -X- _ O
i -X- _ O
, -X- _ O
η -X- _ O
is -X- _ O
the -X- _ O
learning -X- _ O
rate -X- _ O
in -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
Proof -X- _ O
. -X- _ O
Based -X- _ O
on -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
and -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
in -X- _ O
§ -X- _ O
3.2 -X- _ O
, -X- _ O
we -X- _ O
conclude -X- _ O
the -X- _ O
pseudo -X- _ O
updated -X- _ O
parametersθ -X- _ O
( -X- _ O
w -X- _ O
) -X- _ O
as -X- _ O
: -X- _ O

θ -X- _ O
( -X- _ O
w -X- _ O
) -X- _ O
= -X- _ O
θ -X- _ O
− -X- _ O
η -X- _ O
• -X- _ O
1 -X- _ O
|B| -X- _ O
• -X- _ O
x -X- _ O
i -X- _ O
, -X- _ O
y -X- _ O
i -X- _ O
∈B -X- _ O
σ -X- _ O
( -X- _ O
wi -X- _ O
) -X- _ O
• -X- _ O
∂E -X- _ O
( -X- _ O
Φ -X- _ O
( -X- _ O
xi -X- _ O
; -X- _ O
θ -X- _ O
) -X- _ O
, -X- _ O
yi -X- _ O
) -X- _ O
∂θ -X- _ O
( -X- _ O
11 -X- _ O
) -X- _ O

We -X- _ O
then -X- _ O
take -X- _ O
the -X- _ O
gradient -X- _ O
of -X- _ O
w -X- _ O
i -X- _ O
onθ -X- _ O
( -X- _ O
w -X- _ O
) -X- _ O
as -X- _ O
: -X- _ O

∂θ -X- _ O
( -X- _ O
w -X- _ O
) -X- _ O
∂σ -X- _ O
( -X- _ O
wi -X- _ O
) -X- _ O
= -X- _ O
− -X- _ O
η -X- _ O
|B| -X- _ O
• -X- _ O
∂E -X- _ O
( -X- _ O
Φ -X- _ O
( -X- _ O
xi -X- _ O
; -X- _ O
θ -X- _ O
) -X- _ O
, -X- _ O
yi -X- _ O
) -X- _ O
∂θ -X- _ O
( -X- _ O
12 -X- _ O
) -X- _ O

Based -X- _ O
on -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
12 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
derivate -X- _ O
the -X- _ O
gradient -X- _ O
of -X- _ O
w -X- _ O
i -X- _ O
on -X- _ O
L -X- _ O
M -X- _ O
as -X- _ O
: -X- _ O

∂LM -X- _ O
( -X- _ O
θ -X- _ O
( -X- _ O
w -X- _ O
) -X- _ O
) -X- _ O
∂wi -X- _ O
= -X- _ O
[ -X- _ O
∂LM -X- _ O
( -X- _ O
θ -X- _ O
( -X- _ O
w -X- _ O
) -X- _ O
) -X- _ O
∂θ -X- _ O
( -X- _ O
w -X- _ O
) -X- _ O
] -X- _ O
T -X- _ O
• -X- _ O
[ -X- _ O
∂θ -X- _ O
( -X- _ O
w -X- _ O
) -X- _ O
∂σ -X- _ O
( -X- _ O
wi -X- _ O
) -X- _ O
] -X- _ O
• -X- _ O
[ -X- _ O
∂σ -X- _ O
( -X- _ O
w -X- _ O
) -X- _ O
∂w -X- _ O
] -X- _ O
= -X- _ O
[ -X- _ O
1 -X- _ O
|DM -X- _ O
| -X- _ O
• -X- _ O
|D -X- _ O
M -X- _ O
| -X- _ O
j=1 -X- _ O
∂E -X- _ O
( -X- _ O
Φ -X- _ O
( -X- _ O
xj -X- _ O
; -X- _ O
θ -X- _ O
( -X- _ O
w -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
yj -X- _ O
) -X- _ O
∂θ -X- _ O
( -X- _ O
w -X- _ O
) -X- _ O
] -X- _ O
T -X- _ O
• -X- _ O
[ -X- _ O
− -X- _ O
η -X- _ O
|B| -X- _ O
• -X- _ O
∂E -X- _ O
( -X- _ O
Φ -X- _ O
( -X- _ O
xi -X- _ O
; -X- _ O
θ -X- _ O
) -X- _ O
, -X- _ O
yi -X- _ O
) -X- _ O
∂θ -X- _ O
] -X- _ O
• -X- _ O
[ -X- _ O
σ -X- _ O
( -X- _ O
wi -X- _ O
) -X- _ O
( -X- _ O
1 -X- _ O
− -X- _ O
σ -X- _ O
( -X- _ O
wi -X- _ O
) -X- _ O
) -X- _ O
] -X- _ O
= -X- _ O
− -X- _ O
ησ -X- _ O
( -X- _ O
wi -X- _ O
) -X- _ O
( -X- _ O
1 -X- _ O
− -X- _ O
σ -X- _ O
( -X- _ O
wi -X- _ O
) -X- _ O
) -X- _ O
|B| -X- _ O
• -X- _ O
[ -X- _ O
1 -X- _ O
|DM -X- _ O
| -X- _ O
|D -X- _ O
M -X- _ O
| -X- _ O
j=1 -X- _ O
gθ -X- _ O
( -X- _ O
xj -X- _ O
, -X- _ O
yj -X- _ O
) -X- _ O
T -X- _ O
] -X- _ O
• -X- _ O
g -X- _ O
θ -X- _ O
( -X- _ O
xi -X- _ O
, -X- _ O
yi -X- _ O
) -X- _ O
( -X- _ O
13 -X- _ O
) -X- _ O

where -X- _ O
the -X- _ O
second -X- _ O
line -X- _ O
is -X- _ O
obtained -X- _ O
by -X- _ O
substituting -X- _ O
L -X- _ O
M -X- _ O
andθ -X- _ O
with -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
and -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
11 -X- _ O
) -X- _ O
. -X- _ O
Substitute -X- _ O
gθ -X- _ O
( -X- _ O
x -X- _ O
j -X- _ O
, -X- _ O
y -X- _ O
j -X- _ O
) -X- _ O
= -X- _ O
∂E -X- _ O
( -X- _ O
Φ -X- _ O
( -X- _ O
x -X- _ O
j -X- _ O
; -X- _ O
θ -X- _ O
( -X- _ O
w -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
y -X- _ O
j -X- _ O
) -X- _ O
∂θ -X- _ O
( -X- _ O
w -X- _ O
) -X- _ O
and -X- _ O
g -X- _ O
θ -X- _ O
( -X- _ O
x -X- _ O
i -X- _ O
, -X- _ O
y -X- _ O
i -X- _ O
) -X- _ O
= -X- _ O
∂E -X- _ O
( -X- _ O
Φ -X- _ O
( -X- _ O
x -X- _ O
i -X- _ O
; -X- _ O
θ -X- _ O
) -X- _ O
, -X- _ O
y -X- _ O
i -X- _ O
) -X- _ O
∂θ -X- _ O
and -X- _ O
rearrange -X- _ O
the -X- _ O
terms -X- _ O
, -X- _ O
we -X- _ O
obtain -X- _ O
the -X- _ O
third -X- _ O
line -X- _ O
. -X- _ O
The -X- _ O
proof -X- _ O
of -X- _ O
Theorem -X- _ O
1 -X- _ O
is -X- _ O
completed -X- _ O
. -X- _ O

B -X- _ O
Proof -X- _ O
For -X- _ O
Theorem -X- _ O
2 -X- _ O
and -X- _ O
Theorem -X- _ O
3 -X- _ O
Definition -X- _ O
1 -X- _ O
. -X- _ O
disagreement -X- _ O
is -X- _ O
a -X- _ O
measure -X- _ O
to -X- _ O
quantify -X- _ O
the -X- _ O
different -X- _ O
performances -X- _ O
of -X- _ O
two -X- _ O
different -X- _ O
hypotheses -X- _ O
on -X- _ O
a -X- _ O
specific -X- _ O
dataset -X- _ O
. -X- _ O
Denote -X- _ O
the -X- _ O
two -X- _ O
hypotheses -X- _ O
as -X- _ O
h -X- _ O
1 -X- _ O
and -X- _ O
h -X- _ O
2 -X- _ O
, -X- _ O
and -X- _ O
denote -X- _ O
the -X- _ O
specific -X- _ O
dataset -X- _ O
as -X- _ O
D -X- _ O
, -X- _ O
then -X- _ O
the -X- _ O
disagreement -X- _ O
of -X- _ O
h -X- _ O
1 -X- _ O
and -X- _ O
h -X- _ O
2 -X- _ O
on -X- _ O
D -X- _ O
is -X- _ O
formulated -X- _ O
as -X- _ O
: -X- _ O

D -X- _ O
( -X- _ O
h1 -X- _ O
, -X- _ O
h2 -X- _ O
) -X- _ O
= -X- _ O
1 -X- _ O
|D| -X- _ O
|D| -X- _ O
i=1 -X- _ O
[ -X- _ O
1 -X- _ O
C -X- _ O
* -X- _ O
||h1 -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
− -X- _ O
h2 -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
||1 -X- _ O
] -X- _ O
( -X- _ O
14 -X- _ O
) -X- _ O

where -X- _ O
C -X- _ O
is -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
classes -X- _ O
, -X- _ O
h -X- _ O
1 -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
and -X- _ O
h -X- _ O
2 -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
are -X- _ O
one -X- _ O
- -X- _ O
hot -X- _ O
vectors -X- _ O
representing -X- _ O
the -X- _ O
models -X- _ O
' -X- _ O
predictions -X- _ O
. -X- _ O
Definition -X- _ O
2 -X- _ O
. -X- _ O
H∆H -X- _ O
- -X- _ O
distance -X- _ O
is -X- _ O
a -X- _ O
metric -X- _ O
for -X- _ O
evaluating -X- _ O
the -X- _ O
divergence -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
distribution -X- _ O
between -X- _ O
two -X- _ O
datasets -X- _ O
. -X- _ O
Formally -X- _ O
, -X- _ O
H∆H -X- _ O
- -X- _ O
distance -X- _ O
is -X- _ O
computed -X- _ O
as -X- _ O
: -X- _ O

dH∆H -X- _ O
( -X- _ O
D1 -X- _ O
, -X- _ O
D2 -X- _ O
) -X- _ O
= -X- _ O
2 -X- _ O
sup -X- _ O
h -X- _ O
1 -X- _ O
, -X- _ O
h -X- _ O
2 -X- _ O
∈H -X- _ O
| -X- _ O
D -X- _ O
1 -X- _ O
( -X- _ O
h1 -X- _ O
, -X- _ O
h2 -X- _ O
) -X- _ O
− -X- _ O
D -X- _ O
2 -X- _ O
( -X- _ O
h1 -X- _ O
, -X- _ O
h2 -X- _ O
) -X- _ O
| -X- _ O
( -X- _ O
15 -X- _ O

) -X- _ O

where -X- _ O
H -X- _ O
is -X- _ O
the -X- _ O
hypothesis -X- _ O
space -X- _ O
and -X- _ O
sup -X- _ O
denotes -X- _ O
the -X- _ O
supremum -X- _ O
. -X- _ O

The -X- _ O
concepts -X- _ O
disagreement -X- _ O
and -X- _ O
H∆H -X- _ O
- -X- _ O
distance -X- _ O
are -X- _ O
introduced -X- _ O
in -X- _ O
Definition -X- _ O
1 -X- _ O
and -X- _ O
Definition -X- _ O
2 -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
Based -X- _ O
on -X- _ O
the -X- _ O
disagreement -X- _ O
and -X- _ O
H∆Hdistance -X- _ O
, -X- _ O
the -X- _ O
proof -X- _ O
for -X- _ O
Theorem -X- _ O
2 -X- _ O
is -X- _ O
presented -X- _ O
as -X- _ O
below -X- _ O
. -X- _ O

Lemma -X- _ O
1 -X- _ O
. -X- _ O
Assume -X- _ O
there -X- _ O
exists -X- _ O
two -X- _ O
dataset -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O

D -X- _ O
1 -X- _ O
, -X- _ O
D -X- _ O
2 -X- _ O
. -X- _ O
Let -X- _ O
X -X- _ O
1 -X- _ O
= -X- _ O
{ -X- _ O
x -X- _ O
i -X- _ O
| -X- _ O
( -X- _ O
x -X- _ O
i -X- _ O
, -X- _ O
y -X- _ O
i -X- _ O
) -X- _ O
∈ -X- _ O
D -X- _ O
1 -X- _ O
} -X- _ O
and -X- _ O
X -X- _ O
2 -X- _ O
= -X- _ O
{ -X- _ O
x -X- _ O
i -X- _ O
| -X- _ O
( -X- _ O
x -X- _ O
i -X- _ O
, -X- _ O
y -X- _ O
i -X- _ O
) -X- _ O
∈ -X- _ O
D -X- _ O
2 -X- _ O
} -X- _ O
denotes -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
input -X- _ O
case -X- _ O
from -X- _ O
D -X- _ O
1 -X- _ O
and -X- _ O
D -X- _ O
2 -X- _ O
. -X- _ O
If -X- _ O
X -X- _ O
1 -X- _ O
⊆ -X- _ O
X -X- _ O
2 -X- _ O
, -X- _ O
then -X- _ O
d -X- _ O
H∆H -X- _ O
( -X- _ O
D -X- _ O
1 -X- _ O
, -X- _ O
D -X- _ O
2 -X- _ O
) -X- _ O
= -X- _ O
2 -X- _ O
• -X- _ O
|D -X- _ O
2 -X- _ O
| -X- _ O
− -X- _ O
|D -X- _ O
1 -X- _ O
| -X- _ O
|D -X- _ O
2 -X- _ O
| -X- _ O
holds -X- _ O
. -X- _ O
Proof -X- _ O
. -X- _ O
Let -X- _ O
I -X- _ O
k -X- _ O
( -X- _ O
h -X- _ O
1 -X- _ O
, -X- _ O
h -X- _ O
2 -X- _ O
) -X- _ O
= -X- _ O
1 -X- _ O
C -X- _ O
* -X- _ O
||h -X- _ O
1 -X- _ O
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O
− -X- _ O
h -X- _ O
2 -X- _ O
( -X- _ O
x -X- _ O
k -X- _ O
) -X- _ O

|| -X- _ O
1 -X- _ O
denote -X- _ O
the -X- _ O
difference -X- _ O
of -X- _ O
two -X- _ O
hypothesis -X- _ O
h -X- _ O
1 -X- _ O
and -X- _ O
h -X- _ O
2 -X- _ O
on -X- _ O
instance -X- _ O
x -X- _ O
k -X- _ O
, -X- _ O
then -X- _ O
the -X- _ O
disagreement -X- _ O
of -X- _ O
h -X- _ O
1 -X- _ O
and -X- _ O
h -X- _ O
2 -X- _ O
on -X- _ O
the -X- _ O
dataset -X- _ O
D -X- _ O
can -X- _ O
be -X- _ O
rewritten -X- _ O
as -X- _ O
: -X- _ O

D -X- _ O
( -X- _ O
h -X- _ O
1 -X- _ O
, -X- _ O
h -X- _ O
2 -X- _ O
) -X- _ O
= -X- _ O
1 -X- _ O
|D| -X- _ O
|D| -X- _ O
i=1 -X- _ O
I -X- _ O
i -X- _ O
( -X- _ O
h -X- _ O
1 -X- _ O
, -X- _ O
h -X- _ O
2 -X- _ O
) -X- _ O

Based -X- _ O
on -X- _ O
the -X- _ O
Definition -X- _ O
2 -X- _ O
, -X- _ O
the -X- _ O
H∆H -X- _ O
distance -X- _ O
between -X- _ O
D -X- _ O
1 -X- _ O
and -X- _ O
D -X- _ O
2 -X- _ O
is -X- _ O
as -X- _ O
below -X- _ O
: -X- _ O

dH∆H -X- _ O
( -X- _ O
D1 -X- _ O
, -X- _ O
D2 -X- _ O
) -X- _ O
= -X- _ O
2 -X- _ O
sup -X- _ O
h -X- _ O
1 -X- _ O
, -X- _ O
h -X- _ O
2 -X- _ O
∈H -X- _ O
| -X- _ O
D -X- _ O
1 -X- _ O
( -X- _ O
h1 -X- _ O
, -X- _ O
h2 -X- _ O
) -X- _ O
− -X- _ O
D -X- _ O
1 -X- _ O
( -X- _ O
h1 -X- _ O
, -X- _ O
h2 -X- _ O
) -X- _ O
| -X- _ O
( -X- _ O
16 -X- _ O
) -X- _ O

Expanding -X- _ O
the -X- _ O
item -X- _ O
D -X- _ O
1 -X- _ O
( -X- _ O
h1 -X- _ O
, -X- _ O
h2 -X- _ O
) -X- _ O
and -X- _ O
D -X- _ O
1 -X- _ O
( -X- _ O
h1 -X- _ O
, -X- _ O
h2 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
obtain -X- _ O
: -X- _ O

| -X- _ O
D -X- _ O
2 -X- _ O
( -X- _ O
h1 -X- _ O
, -X- _ O
h2 -X- _ O
) -X- _ O
− -X- _ O
D -X- _ O
1 -X- _ O
( -X- _ O
h1 -X- _ O
, -X- _ O
h2 -X- _ O
) -X- _ O
| -X- _ O
= -X- _ O
| -X- _ O
1 -X- _ O
|X2| -X- _ O
x -X- _ O
i -X- _ O
∈X -X- _ O
2 -X- _ O
Ii -X- _ O
( -X- _ O
h1 -X- _ O
, -X- _ O
h2 -X- _ O
) -X- _ O
− -X- _ O
1 -X- _ O
|X1| -X- _ O
x -X- _ O
i -X- _ O
∈X -X- _ O
1 -X- _ O
Ii -X- _ O
( -X- _ O
h1 -X- _ O
, -X- _ O
h2 -X- _ O
) -X- _ O
| -X- _ O
= -X- _ O
| -X- _ O
|X1| -X- _ O
|X2| -X- _ O
* -X- _ O
1 -X- _ O
|X1| -X- _ O
x -X- _ O
i -X- _ O
∈X -X- _ O
1 -X- _ O
Ii -X- _ O
( -X- _ O
h1 -X- _ O
, -X- _ O
h2 -X- _ O
) -X- _ O
+ -X- _ O
|X1| -X- _ O
|X2| -X- _ O
* -X- _ O
1 -X- _ O
|X1| -X- _ O
x -X- _ O
k -X- _ O
∈X -X- _ O
1 -X- _ O
Ii -X- _ O
( -X- _ O
h1 -X- _ O
, -X- _ O
h2 -X- _ O
) -X- _ O
− -X- _ O
1 -X- _ O
|X1| -X- _ O
x -X- _ O
i -X- _ O
∈X -X- _ O
1 -X- _ O
Ii -X- _ O
( -X- _ O
h1 -X- _ O
, -X- _ O
h2 -X- _ O
) -X- _ O
| -X- _ O
= -X- _ O
| -X- _ O
1 -X- _ O
|X2| -X- _ O
x -X- _ O
k -X- _ O
∈X -X- _ O
1 -X- _ O
I -X- _ O
k -X- _ O
( -X- _ O
h1 -X- _ O
, -X- _ O
h2 -X- _ O
) -X- _ O
− -X- _ O
|X2| -X- _ O
− -X- _ O
|X1| -X- _ O
|X2| -X- _ O
• -X- _ O
1 -X- _ O
|X1| -X- _ O
x -X- _ O
i -X- _ O
∈X -X- _ O
1 -X- _ O
Ii -X- _ O
( -X- _ O
h1 -X- _ O
, -X- _ O
h2 -X- _ O
) -X- _ O
| -X- _ O
= -X- _ O
1 -X- _ O
|X2| -X- _ O
| -X- _ O
x -X- _ O
k -X- _ O
∈X -X- _ O
1 -X- _ O
I -X- _ O
k -X- _ O
( -X- _ O
h1 -X- _ O
, -X- _ O
h2 -X- _ O
) -X- _ O
− -X- _ O
|X1| -X- _ O
|X1| -X- _ O
• -X- _ O
x -X- _ O
i -X- _ O
∈X -X- _ O
1 -X- _ O
Ii -X- _ O
( -X- _ O
h1 -X- _ O
, -X- _ O
h2 -X- _ O
) -X- _ O
| -X- _ O
= -X- _ O
|X1| -X- _ O
|X2| -X- _ O
| -X- _ O
D -X- _ O
1 -X- _ O
( -X- _ O
h1 -X- _ O
, -X- _ O
h2 -X- _ O
) -X- _ O
− -X- _ O
D -X- _ O
1 -X- _ O
( -X- _ O
h1 -X- _ O
, -X- _ O
h2 -X- _ O
) -X- _ O
| -X- _ O
( -X- _ O
17 -X- _ O

) -X- _ O

whereX -X- _ O
1 -X- _ O
is -X- _ O
the -X- _ O
complement -X- _ O
set -X- _ O
of -X- _ O
X -X- _ O
1 -X- _ O
in -X- _ O
X -X- _ O
2 -X- _ O
, -X- _ O
i.e -X- _ O
, -X- _ O
X -X- _ O
1 -X- _ O
= -X- _ O
X -X- _ O
2 -X- _ O
− -X- _ O
X -X- _ O
1 -X- _ O
. -X- _ O
Correspondingly -X- _ O
, -X- _ O
D -X- _ O
1 -X- _ O
= -X- _ O
{ -X- _ O
( -X- _ O
x -X- _ O
i -X- _ O
, -X- _ O
y -X- _ O
i -X- _ O
) -X- _ O
| -X- _ O
( -X- _ O
x -X- _ O
i -X- _ O
, -X- _ O
y -X- _ O
i -X- _ O
) -X- _ O
∈ -X- _ O
D -X- _ O
2 -X- _ O
and -X- _ O
x -X- _ O
i -X- _ O
∈X -X- _ O
} -X- _ O
, -X- _ O
and -X- _ O
thus -X- _ O
|X -X- _ O
1 -X- _ O
| -X- _ O
= -X- _ O
|D -X- _ O
1 -X- _ O
| -X- _ O
holds -X- _ O
. -X- _ O
As -X- _ O
0 -X- _ O
≤ -X- _ O
D -X- _ O
1 -X- _ O
( -X- _ O
h -X- _ O
1 -X- _ O
, -X- _ O
h -X- _ O
2 -X- _ O
) -X- _ O
≤ -X- _ O
1 -X- _ O
and -X- _ O
0 -X- _ O
≤ -X- _ O
D -X- _ O
1 -X- _ O
( -X- _ O
h -X- _ O
1 -X- _ O
, -X- _ O
h -X- _ O
2 -X- _ O
) -X- _ O
≤ -X- _ O
1 -X- _ O
, -X- _ O

we -X- _ O
conclude -X- _ O
the -X- _ O
inequation -X- _ O
below -X- _ O
: -X- _ O

| -X- _ O
D -X- _ O
1 -X- _ O
( -X- _ O
h -X- _ O
1 -X- _ O
, -X- _ O
h -X- _ O
2 -X- _ O
) -X- _ O
− -X- _ O
D -X- _ O
1 -X- _ O
( -X- _ O
h -X- _ O
1 -X- _ O
, -X- _ O
h -X- _ O
2 -X- _ O
) -X- _ O
| -X- _ O
≤ -X- _ O
1 -X- _ O
( -X- _ O
18 -X- _ O
) -X- _ O

Since -X- _ O
D -X- _ O
1 -X- _ O
andD -X- _ O
1 -X- _ O
do -X- _ O
not -X- _ O
overlap -X- _ O
, -X- _ O
D -X- _ O
1 -X- _ O
( -X- _ O
h -X- _ O
1 -X- _ O
, -X- _ O
h -X- _ O
2 -X- _ O
) -X- _ O
is -X- _ O
independent -X- _ O
of -X- _ O
D -X- _ O
1 -X- _ O
( -X- _ O
h -X- _ O
1 -X- _ O
, -X- _ O
h -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
maximize -X- _ O
the -X- _ O
left -X- _ O
term -X- _ O
in -X- _ O
inequation -X- _ O
( -X- _ O
18 -X- _ O
) -X- _ O
by -X- _ O
finding -X- _ O
two -X- _ O
hypothesesĥ -X- _ O
1 -X- _ O
andĥ -X- _ O
2 -X- _ O
, -X- _ O
which -X- _ O
make -X- _ O
D -X- _ O
1 -X- _ O
( -X- _ O
ĥ -X- _ O
1 -X- _ O
, -X- _ O
ĥ -X- _ O
2 -X- _ O
) -X- _ O
= -X- _ O
1 -X- _ O
and -X- _ O
D -X- _ O
1 -X- _ O
( -X- _ O
ĥ -X- _ O
1 -X- _ O
, -X- _ O
ĥ -X- _ O
2 -X- _ O
) -X- _ O
= -X- _ O
0 -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O

dH∆H -X- _ O
( -X- _ O
D1 -X- _ O
, -X- _ O
D2 -X- _ O
) -X- _ O
= -X- _ O
2 -X- _ O
sup -X- _ O
h -X- _ O
1 -X- _ O
, -X- _ O
h -X- _ O
2 -X- _ O
∈H -X- _ O
| -X- _ O
D -X- _ O
2 -X- _ O
( -X- _ O
h1 -X- _ O
, -X- _ O
h2 -X- _ O
) -X- _ O
− -X- _ O
D -X- _ O
1 -X- _ O
( -X- _ O
h1 -X- _ O
, -X- _ O
h2 -X- _ O
) -X- _ O
| -X- _ O
= -X- _ O
2 -X- _ O
• -X- _ O
|X1| -X- _ O
|X2| -X- _ O
sup -X- _ O
h -X- _ O
1 -X- _ O
, -X- _ O
h -X- _ O
2 -X- _ O
∈H -X- _ O
| -X- _ O
D -X- _ O
1 -X- _ O
( -X- _ O
h1 -X- _ O
, -X- _ O
h2 -X- _ O
) -X- _ O
− -X- _ O
D -X- _ O
1 -X- _ O
( -X- _ O
h1 -X- _ O
, -X- _ O
h2 -X- _ O
) -X- _ O
| -X- _ O
= -X- _ O
2 -X- _ O
• -X- _ O
|D1| -X- _ O
|D2| -X- _ O
sup -X- _ O
h -X- _ O
1 -X- _ O
, -X- _ O
h -X- _ O
2 -X- _ O
∈H -X- _ O
| -X- _ O
D -X- _ O
1 -X- _ O
( -X- _ O
h1 -X- _ O
, -X- _ O
h2 -X- _ O
) -X- _ O
− -X- _ O
D -X- _ O
1 -X- _ O
( -X- _ O
h1 -X- _ O
, -X- _ O
h2 -X- _ O
) -X- _ O
| -X- _ O
= -X- _ O
2 -X- _ O
• -X- _ O
|D1| -X- _ O
|D2| -X- _ O
| -X- _ O
D -X- _ O
1 -X- _ O
( -X- _ O
ĥ1 -X- _ O
, -X- _ O
ĥ2 -X- _ O
) -X- _ O
− -X- _ O
D -X- _ O
1 -X- _ O
( -X- _ O
ĥ1 -X- _ O
, -X- _ O
ĥ2 -X- _ O
) -X- _ O
| -X- _ O
= -X- _ O
2 -X- _ O
• -X- _ O
|D1| -X- _ O
|D2| -X- _ O
= -X- _ O
2 -X- _ O
• -X- _ O
|D2| -X- _ O
− -X- _ O
|D1| -X- _ O
|D2| -X- _ O

The -X- _ O
proof -X- _ O
of -X- _ O
Lemma -X- _ O
1 -X- _ O
is -X- _ O
completed -X- _ O
. -X- _ O

Theorem -X- _ O
2 -X- _ O
. -X- _ O
Assume -X- _ O
there -X- _ O
exists -X- _ O
an -X- _ O
ideal -X- _ O
hypothesis -X- _ O
, -X- _ O
denoted -X- _ O
as -X- _ O
h -X- _ O
* -X- _ O
, -X- _ O
which -X- _ O
correctly -X- _ O
map -X- _ O
all -X- _ O
instances -X- _ O
in -X- _ O
the -X- _ O
target -X- _ O
domain -X- _ O
to -X- _ O
their -X- _ O
groud -X- _ O
- -X- _ O
truth -X- _ O
labels -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
self -X- _ O
- -X- _ O
training -X- _ O
iteration -X- _ O
t -X- _ O
, -X- _ O
let -X- _ O
D -X- _ O
l -X- _ O
T -X- _ O
( -X- _ O
h -X- _ O
t -X- _ O
) -X- _ O
and -X- _ O
D -X- _ O
E -X- _ O
( -X- _ O
h -X- _ O
t -X- _ O
) -X- _ O
be -X- _ O
the -X- _ O
error -X- _ O
rate -X- _ O
of -X- _ O
the -X- _ O
hypothesis -X- _ O
h -X- _ O
t -X- _ O
on -X- _ O
D -X- _ O
l -X- _ O
T -X- _ O
and -X- _ O
D -X- _ O
E -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
the -X- _ O
error -X- _ O
rate -X- _ O
of -X- _ O
the -X- _ O
hypothesis -X- _ O
h -X- _ O
t -X- _ O
on -X- _ O
the -X- _ O
target -X- _ O
domain -X- _ O
is -X- _ O
upper -X- _ O
bounded -X- _ O
by -X- _ O
: -X- _ O

D -X- _ O
T -X- _ O
( -X- _ O
h -X- _ O
t -X- _ O
) -X- _ O
≤ -X- _ O
D -X- _ O
l -X- _ O
T -X- _ O
∪D -X- _ O
E -X- _ O
( -X- _ O
h -X- _ O
t -X- _ O
) -X- _ O
+ -X- _ O
1 -X- _ O
2 -X- _ O
dH∆H -X- _ O
( -X- _ O
DT -X- _ O
, -X- _ O
D -X- _ O
l -X- _ O
T -X- _ O
∪ -X- _ O
DE -X- _ O
) -X- _ O
+ -X- _ O
ρ -X- _ O
• -X- _ O
D -X- _ O
E -X- _ O
( -X- _ O
h -X- _ O
* -X- _ O
, -X- _ O
h -X- _ O
t−1 -X- _ O
) -X- _ O
( -X- _ O
19 -X- _ O
) -X- _ O

where -X- _ O

ρ -X- _ O
= -X- _ O
|D -X- _ O
E -X- _ O
| -X- _ O
|D -X- _ O
l -X- _ O

T -X- _ O
|+|D -X- _ O
E -X- _ O
| -X- _ O
is -X- _ O
a -X- _ O
coefficient -X- _ O
related -X- _ O
to -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
D -X- _ O
l -X- _ O
T -X- _ O
and -X- _ O
D -X- _ O
E -X- _ O
, -X- _ O
D -X- _ O
l -X- _ O
T -X- _ O
∪D -X- _ O
E -X- _ O
( -X- _ O
h -X- _ O
t -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
error -X- _ O
rate -X- _ O
of -X- _ O
the -X- _ O
hypothesis -X- _ O
h -X- _ O
t -X- _ O
on -X- _ O
the -X- _ O
union -X- _ O
of -X- _ O
D -X- _ O
l -X- _ O
T -X- _ O
and -X- _ O
D -X- _ O
E -X- _ O
. -X- _ O
Proof -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
meta -X- _ O
- -X- _ O
learning -X- _ O
module -X- _ O
, -X- _ O
the -X- _ O
final -X- _ O
objective -X- _ O
is -X- _ O
to -X- _ O
minimize -X- _ O
the -X- _ O
risk -X- _ O
loss -X- _ O
on -X- _ O
the -X- _ O
meta -X- _ O
validation -X- _ O
set -X- _ O
D -X- _ O
l -X- _ O
T -X- _ O
∪ -X- _ O
D -X- _ O
E -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
learning -X- _ O
theory -X- _ O
( -X- _ O
Ben -X- _ O
- -X- _ O
David -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2010 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
upper -X- _ O
bound -X- _ O
of -X- _ O
the -X- _ O
error -X- _ O
rate -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
the -X- _ O
target -X- _ O
domain -X- _ O
) -X- _ O
is -X- _ O
: -X- _ O

D -X- _ O
T -X- _ O
( -X- _ O
h -X- _ O
t -X- _ O
) -X- _ O
≤ -X- _ O
D -X- _ O
l -X- _ O
T -X- _ O
∪D -X- _ O
E -X- _ O
( -X- _ O
h -X- _ O
t -X- _ O
) -X- _ O
+ -X- _ O
1 -X- _ O
2 -X- _ O
dH∆H -X- _ O
( -X- _ O
DT -X- _ O
, -X- _ O
D -X- _ O
l -X- _ O
T -X- _ O
∪ -X- _ O
DE -X- _ O
) -X- _ O
+ -X- _ O
D -X- _ O
T -X- _ O
( -X- _ O
h -X- _ O
* -X- _ O
) -X- _ O
+ -X- _ O
D -X- _ O
l -X- _ O
T -X- _ O
∪D -X- _ O
E -X- _ O
( -X- _ O
h -X- _ O
* -X- _ O
) -X- _ O
( -X- _ O
20 -X- _ O
) -X- _ O

Because -X- _ O
h -X- _ O
* -X- _ O
is -X- _ O
an -X- _ O
ideal -X- _ O
hypothesis -X- _ O
on -X- _ O
the -X- _ O
target -X- _ O
domain -X- _ O
, -X- _ O
D -X- _ O
T -X- _ O
( -X- _ O
h -X- _ O
* -X- _ O
) -X- _ O
= -X- _ O
0 -X- _ O
holds -X- _ O
true -X- _ O
. -X- _ O
Expanding -X- _ O
D -X- _ O
l -X- _ O
T -X- _ O
∪D -X- _ O
E -X- _ O
( -X- _ O
h -X- _ O
* -X- _ O
) -X- _ O
with -X- _ O
the -X- _ O
definition -X- _ O
in -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
14 -X- _ O
) -X- _ O
, -X- _ O

D -X- _ O
l -X- _ O
T -X- _ O
∪D -X- _ O
E -X- _ O
( -X- _ O
h -X- _ O
* -X- _ O
) -X- _ O
= -X- _ O
1 -X- _ O
|D -X- _ O
l -X- _ O
T -X- _ O
| -X- _ O
+ -X- _ O
|DE| -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
∈D -X- _ O
l -X- _ O
T -X- _ O
∪D -X- _ O
E -X- _ O
[ -X- _ O
1 -X- _ O
C -X- _ O
* -X- _ O
||h -X- _ O
* -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
− -X- _ O
y||1 -X- _ O
] -X- _ O
= -X- _ O
1 -X- _ O
|D -X- _ O
l -X- _ O
T -X- _ O
| -X- _ O
+ -X- _ O
|DE| -X- _ O
{ -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
∈D -X- _ O
l -X- _ O
T -X- _ O
[ -X- _ O
1 -X- _ O
C -X- _ O
* -X- _ O
||h -X- _ O
* -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
− -X- _ O
y||1 -X- _ O
] -X- _ O
+ -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
∈D -X- _ O
E -X- _ O
[ -X- _ O
1 -X- _ O
C -X- _ O
* -X- _ O
||h -X- _ O
* -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
− -X- _ O
y||1 -X- _ O
] -X- _ O
} -X- _ O
= -X- _ O
1 -X- _ O
|D -X- _ O
l -X- _ O
T -X- _ O
| -X- _ O
+ -X- _ O
|DE| -X- _ O
{ -X- _ O
|D -X- _ O
l -X- _ O
T -X- _ O
| -X- _ O
• -X- _ O
D -X- _ O
l -X- _ O
T -X- _ O
( -X- _ O
h -X- _ O
* -X- _ O
) -X- _ O
+ -X- _ O
|DE| -X- _ O
• -X- _ O
D -X- _ O
E -X- _ O
( -X- _ O
h -X- _ O
* -X- _ O
) -X- _ O
} -X- _ O
( -X- _ O
21 -X- _ O
) -X- _ O

Substituting -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
21 -X- _ O
) -X- _ O
into -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
20 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
: -X- _ O

D -X- _ O
T -X- _ O
( -X- _ O
h -X- _ O
t -X- _ O
) -X- _ O
≤ -X- _ O
D -X- _ O
l -X- _ O
T -X- _ O
∪D -X- _ O
E -X- _ O
( -X- _ O
h -X- _ O
t -X- _ O
) -X- _ O
+ -X- _ O
1 -X- _ O
2 -X- _ O
dH∆H -X- _ O
( -X- _ O
DT -X- _ O
, -X- _ O
D -X- _ O
l -X- _ O
T -X- _ O
∪ -X- _ O
DE -X- _ O
) -X- _ O
+ -X- _ O
D -X- _ O
T -X- _ O
( -X- _ O
h -X- _ O
* -X- _ O
) -X- _ O
+ -X- _ O
1 -X- _ O
|D -X- _ O
l -X- _ O
T -X- _ O
| -X- _ O
+ -X- _ O
|DE| -X- _ O
{ -X- _ O
|D -X- _ O
l -X- _ O
T -X- _ O
| -X- _ O
• -X- _ O
D -X- _ O
l -X- _ O
T -X- _ O
( -X- _ O
h -X- _ O
* -X- _ O
) -X- _ O
+ -X- _ O
|DE| -X- _ O
• -X- _ O
D -X- _ O
E -X- _ O
( -X- _ O
h -X- _ O
* -X- _ O
) -X- _ O
} -X- _ O
( -X- _ O
22 -X- _ O

) -X- _ O

For -X- _ O
any -X- _ O
instance -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
∈ -X- _ O
D -X- _ O
E -X- _ O
, -X- _ O
y -X- _ O
is -X- _ O
the -X- _ O
pseudo -X- _ O
label -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
the -X- _ O
prediction -X- _ O
of -X- _ O
hypothesis -X- _ O
h -X- _ O
t−1 -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
: -X- _ O

D -X- _ O
E -X- _ O
( -X- _ O
h -X- _ O
* -X- _ O
) -X- _ O
= -X- _ O
1 -X- _ O
|DE| -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
∈D -X- _ O
E -X- _ O
[ -X- _ O
1 -X- _ O
C -X- _ O
* -X- _ O
||h -X- _ O
* -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
− -X- _ O
y||1 -X- _ O
] -X- _ O
= -X- _ O
1 -X- _ O
|DE| -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
∈D -X- _ O
E -X- _ O
[ -X- _ O
1 -X- _ O
C -X- _ O
* -X- _ O
||h -X- _ O
* -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
− -X- _ O
h -X- _ O
t−1 -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
||1 -X- _ O
] -X- _ O
= -X- _ O
D -X- _ O
E -X- _ O
( -X- _ O
h -X- _ O
* -X- _ O
, -X- _ O
h -X- _ O
t−1 -X- _ O
) -X- _ O
( -X- _ O
23 -X- _ O
) -X- _ O

Since -X- _ O
D -X- _ O
l -X- _ O
T -X- _ O
is -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
D -X- _ O
T -X- _ O
, -X- _ O
D -X- _ O
l -X- _ O
T -X- _ O
( -X- _ O
h -X- _ O
* -X- _ O
) -X- _ O
= -X- _ O
0 -X- _ O
holds -X- _ O
true -X- _ O
. -X- _ O

By -X- _ O
eliminating -X- _ O
D -X- _ O
T -X- _ O
( -X- _ O
h -X- _ O
* -X- _ O
) -X- _ O
and -X- _ O
D -X- _ O
l -X- _ O
T -X- _ O
( -X- _ O
h -X- _ O
* -X- _ O
) -X- _ O
in -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
22 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
substituting -X- _ O
D -X- _ O
E -X- _ O
( -X- _ O
h -X- _ O
* -X- _ O
) -X- _ O
with -X- _ O
D -X- _ O
E -X- _ O
( -X- _ O
h -X- _ O
* -X- _ O
, -X- _ O
h -X- _ O
t−1 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
: -X- _ O

D -X- _ O
T -X- _ O
( -X- _ O
h -X- _ O
t -X- _ O
) -X- _ O
≤ -X- _ O
D -X- _ O
l -X- _ O
T -X- _ O
∪D -X- _ O
E -X- _ O
( -X- _ O
h -X- _ O
t -X- _ O
) -X- _ O
+ -X- _ O
1 -X- _ O
2 -X- _ O
dH∆H -X- _ O
( -X- _ O
DT -X- _ O
, -X- _ O
D -X- _ O
l -X- _ O
T -X- _ O
∪ -X- _ O
DE -X- _ O
) -X- _ O
+ -X- _ O
|DE| -X- _ O
|D -X- _ O
l -X- _ O
T -X- _ O
| -X- _ O
+ -X- _ O
|DE| -X- _ O
• -X- _ O
D -X- _ O
E -X- _ O
( -X- _ O
h -X- _ O
* -X- _ O
, -X- _ O
h -X- _ O
t−1 -X- _ O
) -X- _ O
} -X- _ O

The -X- _ O
proof -X- _ O
of -X- _ O
Theorem -X- _ O
2 -X- _ O
is -X- _ O
completed -X- _ O
. -X- _ O

Theorem -X- _ O
3 -X- _ O
. -X- _ O
Assume -X- _ O
there -X- _ O
exists -X- _ O
three -X- _ O
datasets -X- _ O
, -X- _ O
D -X- _ O
1 -X- _ O
, -X- _ O
D -X- _ O
2 -X- _ O
, -X- _ O
D -X- _ O
3 -X- _ O
, -X- _ O
and -X- _ O
let -X- _ O
X -X- _ O
1 -X- _ O
, -X- _ O
X -X- _ O
2 -X- _ O
, -X- _ O
X -X- _ O
3 -X- _ O
denotes -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
input -X- _ O
cases -X- _ O
in -X- _ O
these -X- _ O
three -X- _ O
datasets -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
X -X- _ O
1 -X- _ O
= -X- _ O

{ -X- _ O
x -X- _ O
i -X- _ O
| -X- _ O
( -X- _ O
x -X- _ O
i -X- _ O
, -X- _ O
y -X- _ O
i -X- _ O
) -X- _ O
∈ -X- _ O
D -X- _ O
1 -X- _ O
} -X- _ O
, -X- _ O
X -X- _ O
2 -X- _ O
= -X- _ O
{ -X- _ O
x -X- _ O
i -X- _ O
| -X- _ O
( -X- _ O
x -X- _ O
i -X- _ O
, -X- _ O
y -X- _ O
i -X- _ O
) -X- _ O
∈ -X- _ O
D -X- _ O
2 -X- _ O
} -X- _ O
, -X- _ O
X -X- _ O
3 -X- _ O
= -X- _ O
{ -X- _ O
x -X- _ O
i -X- _ O
| -X- _ O
( -X- _ O
x -X- _ O
i -X- _ O
, -X- _ O
y -X- _ O
i -X- _ O
) -X- _ O
∈ -X- _ O
D -X- _ O
3 -X- _ O
} -X- _ O
. -X- _ O
If -X- _ O
X -X- _ O
1 -X- _ O
⊆ -X- _ O
X -X- _ O
2 -X- _ O
⊆ -X- _ O
X -X- _ O
3 -X- _ O
, -X- _ O
then -X- _ O
d -X- _ O
H∆H -X- _ O
( -X- _ O
D -X- _ O
2 -X- _ O
, -X- _ O
D -X- _ O
3 -X- _ O
) -X- _ O
≤ -X- _ O
d -X- _ O
H∆H -X- _ O
( -X- _ O
D -X- _ O
1 -X- _ O
, -X- _ O
D -X- _ O
3 -X- _ O
) -X- _ O
holds -X- _ O
Proof -X- _ O
. -X- _ O
According -X- _ O
to -X- _ O
Lemma -X- _ O
1 -X- _ O
, -X- _ O
d -X- _ O
H∆H -X- _ O
( -X- _ O
D -X- _ O
2 -X- _ O
, -X- _ O
D -X- _ O
3 -X- _ O
) -X- _ O
= -X- _ O
2 -X- _ O
• -X- _ O
|D -X- _ O
3 -X- _ O
| -X- _ O
− -X- _ O
|D -X- _ O
2 -X- _ O
| -X- _ O
|D -X- _ O
3 -X- _ O
| -X- _ O
d -X- _ O
H∆H -X- _ O
( -X- _ O
D -X- _ O
1 -X- _ O
, -X- _ O
D -X- _ O
3 -X- _ O
) -X- _ O
= -X- _ O
2 -X- _ O
• -X- _ O
|D -X- _ O
3 -X- _ O
| -X- _ O
− -X- _ O
|D -X- _ O
1 -X- _ O
| -X- _ O
|D -X- _ O
3 -X- _ O
| -X- _ O
Since -X- _ O
X -X- _ O
1 -X- _ O
⊆ -X- _ O
X -X- _ O
2 -X- _ O
, -X- _ O
|D -X- _ O
1 -X- _ O
| -X- _ O
≤ -X- _ O
|D -X- _ O
2 -X- _ O
| -X- _ O
holds -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
d -X- _ O
H∆H -X- _ O
( -X- _ O
D -X- _ O
2 -X- _ O
, -X- _ O
D -X- _ O
3 -X- _ O
) -X- _ O
< -X- _ O
d -X- _ O
H∆H -X- _ O
( -X- _ O
D -X- _ O
1 -X- _ O
, -X- _ O
D -X- _ O
3 -X- _ O
) -X- _ O
holds -X- _ O
. -X- _ O

The -X- _ O
proof -X- _ O
of -X- _ O
Theorem -X- _ O
3 -X- _ O
is -X- _ O
completed -X- _ O
. -X- _ O

C -X- _ O
Implementation -X- _ O
Details -X- _ O

The -X- _ O
base -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
rumor -X- _ B-TaskName
detection -X- _ I-TaskName
task -X- _ O
is -X- _ O
BiGCN -X- _ B-MethodName
( -X- _ O
Bian -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
base -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
sentiment -X- _ B-TaskName
classification -X- _ I-TaskName
task -X- _ O
is -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
benchmark -X- _ O
datasets -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
domain -X- _ B-TaskName
adaptation -X- _ I-TaskName
experiments -X- _ O
on -X- _ O
every -X- _ O
domain -X- _ O
. -X- _ O
When -X- _ O
one -X- _ O
domain -X- _ O
is -X- _ O
taken -X- _ O
as -X- _ O
the -X- _ O
target -X- _ O
domain -X- _ O
for -X- _ O
evaluation -X- _ O
, -X- _ O
the -X- _ O
rest -X- _ O
domains -X- _ O
are -X- _ O
merged -X- _ O
as -X- _ O
the -X- _ O
source -X- _ O
domain -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
when -X- _ O
the -X- _ O
" -X- _ O
books -X- _ O
" -X- _ O
domain -X- _ O
in -X- _ O
the -X- _ O
Amazon -X- _ B-DatasetName
dataset -X- _ O
is -X- _ O
taken -X- _ O
as -X- _ O
the -X- _ O
target -X- _ O
domain -X- _ O
, -X- _ O
the -X- _ O
" -X- _ O
dvd -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
electronics -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
kitchen -X- _ O
" -X- _ O
domains -X- _ O
are -X- _ O
merged -X- _ O
as -X- _ O
the -X- _ O
source -X- _ O
domain -X- _ O
. -X- _ O

The -X- _ O
unlabeled -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
target -X- _ O
domain -X- _ O
are -X- _ O
used -X- _ O
for -X- _ O
training -X- _ O
the -X- _ O
model -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
labeled -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
target -X- _ O
domain -X- _ O
are -X- _ O
used -X- _ O
for -X- _ O
testing -X- _ O
and -X- _ O
validating -X- _ O
the -X- _ O
model -X- _ O
( -X- _ O
with -X- _ O
a -X- _ O
ratio -X- _ O
of -X- _ O
7:3 -X- _ B-HyperparameterValue
) -X- _ O
. -X- _ O
Notes -X- _ O
that -X- _ O
the -X- _ O
TWITTER -X- _ B-DatasetName
dataset -X- _ O
does -X- _ O
not -X- _ O
contain -X- _ O
extra -X- _ O
unlabeled -X- _ O
data -X- _ O
, -X- _ O
we -X- _ O
take -X- _ O
70 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
of -X- _ O
the -X- _ O
labeled -X- _ O
data -X- _ O
on -X- _ O
the -X- _ O
target -X- _ O
domain -X- _ O
as -X- _ O
the -X- _ O
unlabeled -X- _ O
data -X- _ O
for -X- _ O
training -X- _ B-HyperparameterName
, -X- _ O
and -X- _ O
the -X- _ O
rest -X- _ O
will -X- _ O
be -X- _ O
preserved -X- _ O
for -X- _ O
testing -X- _ O
and -X- _ O
validating -X- _ O
. -X- _ O
The -X- _ O
experiments -X- _ O
on -X- _ O
TWITTER -X- _ B-DatasetName
are -X- _ O
conducted -X- _ O
on -X- _ O
" -X- _ O
Cha -X- _ O
. -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
Fer -X- _ O
. -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
Ott -X- _ O
. -X- _ O
" -X- _ O
, -X- _ O
and -X- _ O
" -X- _ O
Syd -X- _ O
. -X- _ O
" -X- _ O
1 -X- _ O
. -X- _ O

The -X- _ O
implementation -X- _ O
of -X- _ O
BiGCN -X- _ B-MethodName
to -X- _ O
realize -X- _ O
the -X- _ O
rumor -X- _ B-TaskName
detection -X- _ I-TaskName
task -X- _ O
is -X- _ O
provided -X- _ O
in -X- _ O
( -X- _ O
Bian -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
follow -X- _ O
the -X- _ O
description -X- _ O
in -X- _ O
( -X- _ O
Bian -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
to -X- _ O
train -X- _ O
the -X- _ O
BiGCN -X- _ B-MethodName
model -X- _ O
with -X- _ O
the -X- _ O
TWIT -X- _ B-DatasetName
- -X- _ I-DatasetName
TER -X- _ I-DatasetName
dataset -X- _ O
. -X- _ O
The -X- _ O
implementation -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
to -X- _ O
realize -X- _ O
the -X- _ O
sentiment -X- _ B-TaskName
analysis -X- _ I-TaskName
task -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
download -X- _ O
the -X- _ O
pretrained -X- _ O
BERT -X- _ B-MethodName
from -X- _ O
https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
huggingface -X- _ O
. -X- _ O
co -X- _ O
/ -X- _ O
bert -X- _ O
- -X- _ O
base -X- _ O
- -X- _ O
uncased -X- _ O
2 -X- _ O
and -X- _ O
fit -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
on -X- _ O
the -X- _ O
Amazon -X- _ B-DatasetName
dataset -X- _ O
with -X- _ O
the -X- _ O
instruction -X- _ O
in -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Since -X- _ O
DANN -X- _ B-MethodName
, -X- _ O
FixMatch -X- _ B-MethodName
, -X- _ O
CST -X- _ B-MethodName
, -X- _ O
MME -X- _ B-MethodName
, -X- _ O
WIND -X- _ B-MethodName
, -X- _ O
and -X- _ O
BiAT -X- _ B-MethodName
are -X- _ O
model -X- _ O
agnostic -X- _ O
, -X- _ O
we -X- _ O
implement -X- _ O
them -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
cited -X- _ O
references -X- _ O
( -X- _ O
Ganin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Sohn -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Saito -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Wang -X- _ O
and -X- _ O
Zhang -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
symbols -X- _ O
in -X- _ O
Algorithm -X- _ O
1 -X- _ O
, -X- _ O
we -X- _ O
set -X- _ O
T -X- _ B-HyperparameterName
M -X- _ I-HyperparameterName
as -X- _ O
5 -X- _ B-HyperparameterValue
, -X- _ O
T -X- _ B-HyperparameterName
D -X- _ I-HyperparameterName
as -X- _ O
5 -X- _ B-HyperparameterValue
, -X- _ O
T -X- _ B-HyperparameterName
G -X- _ I-HyperparameterName
as -X- _ O
1 -X- _ B-HyperparameterValue
. -X- _ O
We -X- _ O
set -X- _ O
η -X- _ B-HyperparameterName
1 -X- _ I-HyperparameterName
and -X- _ O
η -X- _ B-HyperparameterName
2 -X- _ I-HyperparameterName
in -X- _ O
Algorithm -X- _ O
1 -X- _ O
as -X- _ O
5e -X- _ B-HyperparameterValue
− -X- _ I-HyperparameterValue
4 -X- _ I-HyperparameterValue
and -X- _ O
5e -X- _ B-HyperparameterValue
− -X- _ I-HyperparameterValue
3 -X- _ I-HyperparameterValue
for -X- _ O
the -X- _ O
BiGCN -X- _ B-MethodName
model -X- _ O
, -X- _ O
and -X- _ O
as -X- _ O
5e -X- _ B-HyperparameterValue
− -X- _ I-HyperparameterValue
6 -X- _ I-HyperparameterValue
and -X- _ O
2e -X- _ B-HyperparameterValue
− -X- _ I-HyperparameterValue
5 -X- _ I-HyperparameterValue
for -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
. -X- _ O
We -X- _ O
set -X- _ O
η -X- _ B-HyperparameterName
in -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
as -X- _ O
5e -X- _ B-HyperparameterValue
− -X- _ I-HyperparameterValue
5 -X- _ I-HyperparameterValue
for -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
, -X- _ O
and -X- _ O
5e -X- _ B-HyperparameterValue
− -X- _ I-HyperparameterValue
3 -X- _ I-HyperparameterValue
for -X- _ O
the -X- _ O
BiGCN -X- _ B-MethodName
model -X- _ O
. -X- _ O
We -X- _ O
set -X- _ O
γ -X- _ B-HyperparameterName
in -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
6 -X- _ O
) -X- _ O
as -X- _ O
0.1 -X- _ B-HyperparameterValue
for -X- _ O
both -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
the -X- _ O
BiGCN -X- _ B-MethodName
model -X- _ O
. -X- _ O
We -X- _ O
conduct -X- _ O
all -X- _ O
experiments -X- _ O
the -X- _ O
GeForce -X- _ O
RTX -X- _ O
3090 -X- _ O
GPU -X- _ O
with -X- _ O
24 -X- _ O
GB -X- _ O
memory -X- _ O
. -X- _ O

E -X- _ O
Extra -X- _ O
Experiments -X- _ O
E.1 -X- _ O
Instance -X- _ O
Reweighting -X- _ O

To -X- _ O
investigate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
metalearning -X- _ O
module -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
an -X- _ O
experiment -X- _ O
to -X- _ O
visualize -X- _ O
the -X- _ O
optimized -X- _ O
instance -X- _ O
weights -X- _ O
on -X- _ O
different -X- _ O
pseudo -X- _ O
instances -X- _ O
. -X- _ O
In -X- _ O
detail -X- _ O
, -X- _ O
the -X- _ O
experiments -X- _ O
are -X- _ O
conducted -X- _ O
on -X- _ O
the -X- _ O
' -X- _ O
Cha -X- _ O
. -X- _ O
' -X- _ O
domain -X- _ O
of -X- _ O
the -X- _ O
TWITTER -X- _ B-DatasetName
3 -X- _ O
https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
figshare.com -X- _ O
/ -X- _ O
ndownloader -X- _ O
/ -X- _ O
articles -X- _ O
/ -X- _ O
6392078 -X- _ O
/ -X- _ O
dataset -X- _ O
. -X- _ O
Since -X- _ O
the -X- _ O
unlabeled -X- _ O
data -X- _ O
in -X- _ O
the -X- _ O
TWITTER -X- _ B-DatasetName
dataset -X- _ O
is -X- _ O
constructed -X- _ O
with -X- _ O
the -X- _ O
labeled -X- _ O
data -X- _ O
in -X- _ O
the -X- _ O
target -X- _ O
domain -X- _ O
( -X- _ O
illustrated -X- _ O
in -X- _ O
§ -X- _ O
5 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
are -X- _ O
aware -X- _ O
of -X- _ O
the -X- _ O
pseudo -X- _ O
labels -X- _ O
' -X- _ O
correctness -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
visualize -X- _ O
the -X- _ O
relevance -X- _ O
among -X- _ O
the -X- _ O
instance -X- _ O
weights -X- _ O
, -X- _ O
pseudo -X- _ O
labels -X- _ O
' -X- _ O
correctness -X- _ O
, -X- _ O
and -X- _ O
pseudo -X- _ O
labels -X- _ O
' -X- _ O
confidence -X- _ O
, -X- _ O
the -X- _ O
experiment -X- _ O
results -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Fig -X- _ O
. -X- _ O
3 -X- _ O
. -X- _ O
Fig -X- _ O
. -X- _ O
3 -X- _ O
is -X- _ O
a -X- _ O
violin -X- _ O
plot -X- _ O
in -X- _ O
a -X- _ O
horizontal -X- _ O
direction -X- _ O
, -X- _ O
where -X- _ O
each -X- _ O
curve -X- _ O
represents -X- _ O
a -X- _ O
distribution -X- _ O
of -X- _ O
the -X- _ O
instance -X- _ O
weights -X- _ O
. -X- _ O
The -X- _ O
height -X- _ O
of -X- _ O
the -X- _ O
curve -X- _ O
represents -X- _ O
the -X- _ O
probability -X- _ O
density -X- _ O
. -X- _ O
In -X- _ O
each -X- _ O
confidence -X- _ O
interval -X- _ O
, -X- _ O
the -X- _ O
yellow -X- _ O
curve -X- _ O
is -X- _ O
the -X- _ O
distribution -X- _ O
over -X- _ O
the -X- _ O
correct -X- _ O
pseudo -X- _ O
instances -X- _ O
while -X- _ O
the -X- _ O
blue -X- _ O
curve -X- _ O
is -X- _ O
the -X- _ O
distribution -X- _ O
over -X- _ O
the -X- _ O
wrong -X- _ O
pseudo -X- _ O
instances -X- _ O
. -X- _ O
It -X- _ O
should -X- _ O
be -X- _ O
noted -X- _ O
that -X- _ O
the -X- _ O
probability -X- _ O
density -X- _ O
is -X- _ O
normalized -X- _ O
in -X- _ O
each -X- _ O
confidence -X- _ O
interval -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
the -X- _ O
area -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
kinds -X- _ O
curves -X- _ O
is -X- _ O
equal -X- _ O
to -X- _ O
1.0 -X- _ O
in -X- _ O
each -X- _ O
confidence -X- _ O
interval -X- _ O
. -X- _ O
From -X- _ O
Fig -X- _ O
. -X- _ O
3 -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
obtain -X- _ O
the -X- _ O
following -X- _ O
observations -X- _ O
. -X- _ O
Firstly -X- _ O
, -X- _ O
the -X- _ O
meta -X- _ O
- -X- _ O
learning -X- _ O
module -X- _ O
is -X- _ O
effective -X- _ O
in -X- _ O
reducing -X- _ O
label -X- _ O
noise -X- _ O
. -X- _ O
In -X- _ O
different -X- _ O
confidence -X- _ O
intervals -X- _ O
, -X- _ O
especially -X- _ O
in -X- _ O
[ -X- _ O
0.5 -X- _ O
- -X- _ O
0.6 -X- _ O
] -X- _ O
and -X- _ O
[ -X- _ O
0.6 -X- _ O
- -X- _ O
0.7 -X- _ O
] -X- _ O
, -X- _ O
the -X- _ O
peak -X- _ O
of -X- _ O
the -X- _ O
blue -X- _ O
curve -X- _ O
is -X- _ O
smaller -X- _ O
than -X- _ O
0.2 -X- _ O
, -X- _ O
meaning -X- _ O
that -X- _ O
the -X- _ O
wrong -X- _ O
pseudo -X- _ O
instances -X- _ O
are -X- _ O
mainly -X- _ O
allocated -X- _ O
low -X- _ O
instance -X- _ O
weights -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
the -X- _ O
adverse -X- _ O
impact -X- _ O
from -X- _ O
the -X- _ O
wrong -X- _ O
pseudo -X- _ O
instances -X- _ O
is -X- _ O
reduced -X- _ O
. -X- _ O

Secondly -X- _ O
, -X- _ O
larger -X- _ O
instance -X- _ O
weights -X- _ O
are -X- _ O
allocated -X- _ O
to -X- _ O
the -X- _ O
correct -X- _ O
pseudo -X- _ O
instances -X- _ O
with -X- _ O
low -X- _ O
confidence -X- _ O
. -X- _ O
In -X- _ O
specific -X- _ O
, -X- _ O
large -X- _ O
instance -X- _ O
weights -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
> -X- _ O
0.5 -X- _ O
) -X- _ O
mainly -X- _ O
appears -X- _ O
in -X- _ O
the -X- _ O
bottom -X- _ O
two -X- _ O
sub -X- _ O
- -X- _ O
graph -X- _ O
, -X- _ O
so -X- _ O
the -X- _ O
large -X- _ O
instance -X- _ O
weights -X- _ O
are -X- _ O
mainly -X- _ O
allocated -X- _ O
to -X- _ O
the -X- _ O
correct -X- _ O
pseudo -X- _ O
instances -X- _ O
whose -X- _ O
confidence -X- _ O
is -X- _ O
lower -X- _ O
than -X- _ O
0.7 -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
the -X- _ O
meta -X- _ O
- -X- _ O
learning -X- _ O
module -X- _ O
is -X- _ O
also -X- _ O
effective -X- _ O
in -X- _ O
mining -X- _ O
hard -X- _ O
pseudo -X- _ O
examples -X- _ O
. -X- _ O

E.2 -X- _ O
Error -X- _ O
rates -X- _ O
on -X- _ O
the -X- _ O
expansion -X- _ O
examples -X- _ O

According -X- _ O
to -X- _ O
Theorem -X- _ O
2 -X- _ O
in -X- _ O
§ -X- _ O
4 -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
DaMSTF -X- _ B-MethodName
is -X- _ O
limited -X- _ O
by -X- _ O
the -X- _ O
error -X- _ O
rate -X- _ O
of -X- _ O
the -X- _ O
expansion -X- _ O
examples -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
D -X- _ O
E -X- _ O
( -X- _ O
h -X- _ O
* -X- _ O
, -X- _ O
h -X- _ O
t−1 -X- _ O
) -X- _ O
. -X- _ O
By -X- _ O
selecting -X- _ O
the -X- _ O
examples -X- _ O
with -X- _ O
the -X- _ O
lowest -X- _ O
prediction -X- _ O
entropy -X- _ O
as -X- _ O
the -X- _ O
expansion -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
meta -X- _ O
constructor -X- _ O
can -X- _ O
reduce -X- _ O
D -X- _ O
E -X- _ O
( -X- _ O
h -X- _ O
* -X- _ O
, -X- _ O
h -X- _ O
t−1 -X- _ O
) -X- _ O
, -X- _ O
thereby -X- _ O
can -X- _ O
improve -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
DaMSTF -X- _ B-MethodName
. -X- _ O
In -X- _ O
this -X- _ O
subsection -X- _ O
, -X- _ O
we -X- _ O
examine -X- _ O
the -X- _ O
reliability -X- _ O
of -X- _ O
the -X- _ O
meta -X- _ O
constructor -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
visualizing -X- _ O
the -X- _ O
relationship -X- _ O
between -X- _ O
the -X- _ O
prediction -X- _ O
entropy -X- _ O
and -X- _ O
the -X- _ O
prediction -X- _ O
correctness -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
compute -X- _ O
and -X- _ O
sort -X- _ O
the -X- _ O
prediction -X- _ O
entropy -X- _ O
on -X- _ O
the -X- _ O
" -X- _ O
Syd -X- _ O
. -X- _ O
" -X- _ O
domain -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
select -X- _ O
the -X- _ O
top -X- _ O
5 -X- _ O
% -X- _ O
, -X- _ O
10 -X- _ O
% -X- _ O
, -X- _ O
20 -X- _ O
% -X- _ O
, -X- _ O
30 -X- _ O
% -X- _ O
, -X- _ O
40 -X- _ O
% -X- _ O
, -X- _ O
50 -X- _ O
% -X- _ O
, -X- _ O
60 -X- _ O
% -X- _ O
, -X- _ O
70 -X- _ O
% -X- _ O
, -X- _ O
80 -X- _ O
% -X- _ O
, -X- _ O
90 -X- _ O
% -X- _ O
, -X- _ O
100 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
pseudo -X- _ O
instances -X- _ O
to -X- _ O
compute -X- _ O
the -X- _ O
error -X- _ O
rate -X- _ O
between -X- _ O
the -X- _ O
selected -X- _ O
predictions -X- _ O
and -X- _ O
their -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
labels -X- _ O
. -X- _ O
We -X- _ O
summarize -X- _ O
the -X- _ O
experiment -X- _ O
results -X- _ O
in -X- _ O
Fig -X- _ O
. -X- _ O
4 -X- _ O
. -X- _ O

E.3 -X- _ O
Risk -X- _ O
loss -X- _ O
on -X- _ O
the -X- _ O
expansion -X- _ O
examples -X- _ O

As -X- _ O
discussed -X- _ O
in -X- _ O
§ -X- _ O
4.1 -X- _ O
, -X- _ O
expanding -X- _ O
the -X- _ O
meta -X- _ O
validation -X- _ O
set -X- _ O
is -X- _ O
challenged -X- _ O
by -X- _ O
the -X- _ O
training -X- _ O
guidance -X- _ O
vanishment -X- _ O
problem -X- _ O
, -X- _ O
since -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
risk -X- _ O
loss -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
gradient -X- _ O
, -X- _ O
on -X- _ O
the -X- _ O
expansion -X- _ O
examples -X- _ O
is -X- _ O
negligible -X- _ O
. -X- _ O
As -X- _ O
a -X- _ O
complementary -X- _ O
, -X- _ O
we -X- _ O
design -X- _ O
a -X- _ O
domain -X- _ B-MethodName
adversarial -X- _ I-MethodName
learning -X- _ I-MethodName
module -X- _ O
to -X- _ O
perturb -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
parameters -X- _ O
, -X- _ O
thereby -X- _ O
increasing -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
gradients -X- _ O
on -X- _ O
the -X- _ O
expansion -X- _ O
examples -X- _ O
. -X- _ O
Here -X- _ O
, -X- _ O
we -X- _ O
provide -X- _ O
an -X- _ O
intuitive -X- _ O
explanation -X- _ O
for -X- _ O
the -X- _ O
necessity -X- _ O
of -X- _ O
introducing -X- _ O
domain -X- _ O
adversarial -X- _ O
learning -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
exhibit -X- _ O
the -X- _ O
relationship -X- _ O
between -X- _ O
the -X- _ O
predictive -X- _ O
entropy -X- _ O
and -X- _ O
the -X- _ O
risk -X- _ O
loss -X- _ O
, -X- _ O
and -X- _ O
present -X- _ O
the -X- _ O
changes -X- _ O
of -X- _ O
the -X- _ O
risk -X- _ O
loss -X- _ O
before -X- _ O
and -X- _ O
after -X- _ O
the -X- _ O
parameters -X- _ O
perturbation -X- _ O
. -X- _ O
The -X- _ O
experimental -X- _ O
settings -X- _ O
are -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
§ -X- _ O
E.2 -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
summarize -X- _ O
the -X- _ O
results -X- _ O
in -X- _ O
Fig -X- _ O
. -X- _ O
5 -X- _ O
. -X- _ O
From -X- _ O
Fig -X- _ O
. -X- _ O
5 -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
mean -X- _ O
risk -X- _ B-MetricName
loss -X- _ I-MetricName
decreases -X- _ O
along -X- _ O
with -X- _ O
the -X- _ O
decrease -X- _ O
of -X- _ O
the -X- _ O
selection -X- _ O
rate -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
risk -X- _ O
loss -X- _ O
on -X- _ O
the -X- _ O
examples -X- _ O
with -X- _ O
small -X- _ O
predictive -X- _ O
entropy -X- _ O
is -X- _ O
negligible -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
examples -X- _ O
with -X- _ O
the -X- _ O
lowest -X- _ O
10 -X- _ O
% -X- _ O
predictive -X- _ O
entropy -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
expansion -X- _ O
examples -X- _ O
in -X- _ O
our -X- _ O
setting -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
mean -X- _ O
risk -X- _ B-MetricName
loss -X- _ I-MetricName
is -X- _ O
only -X- _ O
0.015 -X- _ B-MetricValue
. -X- _ O
Considering -X- _ O
that -X- _ O
the -X- _ O
gradient -X- _ O
is -X- _ O
back -X- _ O
- -X- _ O
propagated -X- _ O
from -X- _ O
the -X- _ O
risk -X- _ O
loss -X- _ O
, -X- _ O
these -X- _ O
expansion -X- _ O
examples -X- _ O
can -X- _ O
not -X- _ O
produce -X- _ O
acceptable -X- _ O
gradients -X- _ O
. -X- _ O
Accordingly -X- _ O
, -X- _ O
these -X- _ O
expansion -X- _ O
examples -X- _ O
can -X- _ O
not -X- _ O
provide -X- _ O
indicative -X- _ O
training -X- _ O
guidance -X- _ O
. -X- _ O
After -X- _ O
perturbing -X- _ O
the -X- _ O
model -X- _ O
parameters -X- _ O
with -X- _ O
the -X- _ O
domain -X- _ B-MethodName
adversarial -X- _ I-MethodName
learning -X- _ I-MethodName
module -X- _ O
, -X- _ O
the -X- _ O
risk -X- _ B-MetricName
loss -X- _ I-MetricName
on -X- _ O
the -X- _ O
expansion -X- _ O
examples -X- _ O
( -X- _ O
Selection -X- _ O
Ratio=0.1 -X- _ O
) -X- _ O
sharply -X- _ O
increases -X- _ O
from -X- _ O
0.015 -X- _ B-MetricValue
to -X- _ O
0.288 -X- _ B-MetricValue
. -X- _ O
Thus -X- _ O
, -X- _ O
the -X- _ O
domain -X- _ O
adversarial -X- _ O
learning -X- _ O
module -X- _ O
is -X- _ O
an -X- _ O
indispensable -X- _ O
complement -X- _ O
to -X- _ O
the -X- _ O
meta -X- _ O
constructor -X- _ O
. -X- _ O

F -X- _ O
Limitation -X- _ O

Although -X- _ O
our -X- _ O
approach -X- _ O
produces -X- _ O
promising -X- _ O
results -X- _ O
on -X- _ O
two -X- _ O
datasets -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
certain -X- _ O
limitations -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
future -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
continue -X- _ O
to -X- _ O
dig -X- _ O
into -X- _ O
these -X- _ O
concerns -X- _ O
. -X- _ O

Firstly -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
the -X- _ O
DaMSTF -X- _ B-MethodName
on -X- _ O
two -X- _ O
classification -X- _ B-TaskName
tasks -X- _ O
. -X- _ O
We -X- _ O
do -X- _ O
not -X- _ O
conduct -X- _ O
experiments -X- _ O
on -X- _ O
other -X- _ O
NLP -X- _ O
tasks -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
machine -X- _ O
translation -X- _ O
( -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
or -X- _ O
named -X- _ O
entity -X- _ O
recognition -X- _ O
( -X- _ O
Jia -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Nonetheless -X- _ O
, -X- _ O
as -X- _ O
text -X- _ B-TaskName
classification -X- _ I-TaskName
is -X- _ O
a -X- _ O
fundamental -X- _ O
task -X- _ O
, -X- _ O
other -X- _ O
NLP -X- _ O
applications -X- _ O
can -X- _ O
be -X- _ O
specified -X- _ O
as -X- _ O
a -X- _ O
case -X- _ O
of -X- _ O
classification -X- _ B-TaskName
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
named -X- _ O
entity -X- _ O
recognition -X- _ O
can -X- _ O
be -X- _ O
formulated -X- _ O
as -X- _ O
a -X- _ O
wordword -X- _ O
relation -X- _ O
classification -X- _ O
task -X- _ O
. -X- _ O

Secondly -X- _ O
, -X- _ O
the -X- _ O
meta -X- _ O
- -X- _ O
learning -X- _ O
module -X- _ O
carries -X- _ O
out -X- _ O
extra -X- _ O
computation -X- _ O
overhead -X- _ O
. -X- _ O
As -X- _ O
the -X- _ O
bi -X- _ O
- -X- _ O
level -X- _ O
hyperparameters -X- _ O
optimization -X- _ O
involves -X- _ O
a -X- _ O
second -X- _ O
- -X- _ O
order -X- _ O
derivate -X- _ O
on -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
parameters -X- _ O
, -X- _ O
their -X- _ O
computation -X- _ O
overhead -X- _ O
is -X- _ O
quadratic -X- _ O
to -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
parameters -X- _ O
. -X- _ O
In -X- _ O
DaMSTF -X- _ B-MethodName
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
approximation -X- _ O
techniques -X- _ O
in -X- _ O
WIND -X- _ B-MethodName
to -X- _ O
compute -X- _ O
the -X- _ O
derivate -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
linear -X- _ O
to -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
parameters -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
future -X- _ O
, -X- _ O
we -X- _ O

Acknowledgements -X- _ O

