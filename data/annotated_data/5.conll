-DOCSTART- -X- O
No -X- _ O
clues -X- _ O
, -X- _ O
good -X- _ O
clues -X- _ O
: -X- _ O
Out -X- _ O
of -X- _ O
context -X- _ O
Lexical -X- _ B-TaskName
Relation -X- _ I-TaskName
Classification -X- _ I-TaskName

The -X- _ O
accurate -X- _ O
prediction -X- _ B-TaskName
of -X- _ I-TaskName
lexical -X- _ I-TaskName
relations -X- _ I-TaskName
between -X- _ O
words -X- _ O
is -X- _ O
a -X- _ O
challenging -X- _ O
task -X- _ O
in -X- _ O
Natural -X- _ O
Language -X- _ O
Processing -X- _ O
( -X- _ O
NLP -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
most -X- _ O
recent -X- _ O
advances -X- _ O
in -X- _ O
this -X- _ O
direction -X- _ O
come -X- _ O
with -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
pre -X- _ B-MethodName
- -X- _ I-MethodName
trained -X- _ I-MethodName
language -X- _ I-MethodName
models -X- _ I-MethodName
( -X- _ O
PTLMs -X- _ B-MethodName
) -X- _ O
. -X- _ O
A -X- _ O
PTLM -X- _ B-MethodName
typically -X- _ O
needs -X- _ O
" -X- _ O
well -X- _ O
- -X- _ O
formed -X- _ O
" -X- _ O
verbalized -X- _ O
text -X- _ O
to -X- _ O
interact -X- _ O
with -X- _ O
it -X- _ O
, -X- _ O
either -X- _ O
to -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
it -X- _ O
or -X- _ O
to -X- _ O
exploit -X- _ O
it -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
indications -X- _ O
that -X- _ O
commonly -X- _ O
used -X- _ O
PTLMs -X- _ B-MethodName
already -X- _ O
encode -X- _ O
enough -X- _ O
linguistic -X- _ O
knowledge -X- _ O
to -X- _ O
allow -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
minimal -X- _ O
( -X- _ O
or -X- _ O
none -X- _ O
) -X- _ O
textual -X- _ O
context -X- _ O
for -X- _ O
some -X- _ O
linguistically -X- _ O
motivated -X- _ O
tasks -X- _ O
, -X- _ O
thus -X- _ O
notably -X- _ O
reducing -X- _ O
human -X- _ O
effort -X- _ O
, -X- _ O
the -X- _ O
need -X- _ O
for -X- _ O
data -X- _ O
pre -X- _ O
- -X- _ O
processing -X- _ O
, -X- _ O
and -X- _ O
favoring -X- _ O
techniques -X- _ O
that -X- _ O
are -X- _ O
language -X- _ O
neutral -X- _ O
since -X- _ O
do -X- _ O
not -X- _ O
rely -X- _ O
on -X- _ O
syntactic -X- _ O
structures -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
explore -X- _ O
this -X- _ O
idea -X- _ O
for -X- _ O
the -X- _ O
tasks -X- _ O
of -X- _ O
lexical -X- _ B-TaskName
relation -X- _ I-TaskName
classification -X- _ I-TaskName
( -X- _ O
LRC -X- _ B-TaskName
) -X- _ O
and -X- _ O
graded -X- _ B-TaskName
Lexical -X- _ I-TaskName
Entailment -X- _ I-TaskName
( -X- _ O
LE -X- _ B-TaskName
) -X- _ O
. -X- _ O
After -X- _ O
finetuning -X- _ O
PTLMs -X- _ B-MethodName
for -X- _ O
LRC -X- _ B-TaskName
with -X- _ O
different -X- _ O
verbalizations -X- _ O
, -X- _ O
our -X- _ O
evaluation -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
very -X- _ O
simple -X- _ O
prompts -X- _ O
are -X- _ O
competitive -X- _ O
for -X- _ O
LRC -X- _ B-TaskName
and -X- _ O
significantly -X- _ O
outperform -X- _ O
graded -X- _ B-TaskName
LE -X- _ I-TaskName
SoTA -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
gain -X- _ O
a -X- _ O
better -X- _ O
insight -X- _ O
into -X- _ O
this -X- _ O
phenomenon -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
a -X- _ O
number -X- _ O
of -X- _ O
quantitative -X- _ O
statistical -X- _ O
analyses -X- _ O
on -X- _ O
the -X- _ O
results -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
a -X- _ O
qualitative -X- _ O
visual -X- _ O
exploration -X- _ O
based -X- _ O
on -X- _ O
embedding -X- _ O
projections -X- _ O
. -X- _ O

Introduction -X- _ O

Lexical -X- _ B-TaskName
Relation -X- _ I-TaskName
Classification -X- _ I-TaskName
( -X- _ O
LRC -X- _ B-TaskName
) -X- _ O
is -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
predicting -X- _ O
which -X- _ O
lexical -X- _ O
relation -X- _ O
exists -X- _ O
between -X- _ O
two -X- _ O
given -X- _ O
words -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
' -X- _ O
tall -X- _ O
' -X- _ O
and -X- _ O
' -X- _ O
small -X- _ O
' -X- _ O
are -X- _ O
related -X- _ O
by -X- _ O
the -X- _ O
antonymy -X- _ O
relation -X- _ O
) -X- _ O
, -X- _ O
from -X- _ O
a -X- _ O
finite -X- _ O
catalogue -X- _ O
of -X- _ O
lexical -X- _ O
relations -X- _ O
. -X- _ O
Discovering -X- _ O
lexico -X- _ O
- -X- _ O
semantic -X- _ O
relations -X- _ O
between -X- _ O
words -X- _ O
has -X- _ O
received -X- _ O
attention -X- _ O
in -X- _ O
the -X- _ O
NLP -X- _ O
community -X- _ O
since -X- _ O
Hearst -X- _ O
's -X- _ O
seminal -X- _ O
research -X- _ O
in -X- _ O
1992 -X- _ O
on -X- _ O
the -X- _ O
automatic -X- _ O
acquisition -X- _ O
of -X- _ O
hyponyms -X- _ O
from -X- _ O
large -X- _ O
text -X- _ O
corpora -X- _ O
based -X- _ O
on -X- _ O
pre -X- _ O
- -X- _ O
designed -X- _ O
patterns -X- _ O
( -X- _ O
Hearst -X- _ O
, -X- _ O
1992 -X- _ O
) -X- _ O
. -X- _ O
Despite -X- _ O
many -X- _ O
recent -X- _ O
advancements -X- _ O
, -X- _ O
LRC -X- _ B-TaskName
continues -X- _ O
to -X- _ O
be -X- _ O
an -X- _ O
open -X- _ O
research -X- _ O
topic -X- _ O
in -X- _ O
the -X- _ O
NLP -X- _ O
field -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Ushio -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Applications -X- _ O
of -X- _ O
the -X- _ O
task -X- _ O
are -X- _ O
numerous -X- _ O
: -X- _ O
automatic -X- _ O
thesauri -X- _ O
creation -X- _ O
, -X- _ O
paraphrasing -X- _ O
, -X- _ O
textual -X- _ O
entailment -X- _ O
, -X- _ O
sentiment -X- _ O
analysis -X- _ O
, -X- _ O
ontology -X- _ O
learning -X- _ O
, -X- _ O
and -X- _ O
ontology -X- _ O
population -X- _ O
, -X- _ O
among -X- _ O
others -X- _ O
( -X- _ O
Weeds -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
; -X- _ O
Cimiano -X- _ O
, -X- _ O
2006 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
most -X- _ O
recent -X- _ O
advances -X- _ O
in -X- _ O
LRC -X- _ B-TaskName
come -X- _ O
with -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
pre -X- _ B-MethodName
- -X- _ I-MethodName
trained -X- _ I-MethodName
language -X- _ I-MethodName
models -X- _ I-MethodName
( -X- _ O
PTLMs -X- _ B-MethodName
) -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
transformers -X- _ B-MethodName
architecture -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
have -X- _ O
been -X- _ O
proven -X- _ O
to -X- _ O
capture -X- _ O
a -X- _ O
large -X- _ O
amount -X- _ O
of -X- _ O
lexico -X- _ O
- -X- _ O
semantic -X- _ O
knowledge -X- _ O
from -X- _ O
text -X- _ O
successfully -X- _ O
. -X- _ O
One -X- _ O
of -X- _ O
the -X- _ O
main -X- _ O
benefits -X- _ O
of -X- _ O
the -X- _ O
adoption -X- _ O
of -X- _ O
PLTMs -X- _ B-MethodName
is -X- _ O
that -X- _ O
, -X- _ O
while -X- _ O
they -X- _ O
were -X- _ O
trained -X- _ O
for -X- _ O
a -X- _ O
general -X- _ O
task -X- _ O
( -X- _ O
text -X- _ O
generation -X- _ O
) -X- _ O
following -X- _ O
a -X- _ O
masked -X- _ O
language -X- _ O
model -X- _ O
( -X- _ O
MLM -X- _ O
) -X- _ O
objective -X- _ O
in -X- _ O
an -X- _ O
unsupervised -X- _ O
way -X- _ O
, -X- _ O
they -X- _ O
can -X- _ O
be -X- _ O
easily -X- _ O
adapted -X- _ O
to -X- _ O
different -X- _ O
downstream -X- _ O
tasks -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
text -X- _ O
classification -X- _ O
, -X- _ O
text -X- _ O
summarization -X- _ O
, -X- _ O
sentiment -X- _ O
analysis -X- _ O
) -X- _ O
by -X- _ O
introducing -X- _ O
additional -X- _ O
parameters -X- _ O
and -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
them -X- _ O
using -X- _ O
objective -X- _ O
functions -X- _ O
specific -X- _ O
to -X- _ O
the -X- _ O
task -X- _ O
. -X- _ O
That -X- _ O
avoids -X- _ O
the -X- _ O
need -X- _ O
to -X- _ O
train -X- _ O
the -X- _ O
model -X- _ O
from -X- _ O
scratch -X- _ O
, -X- _ O
still -X- _ O
obtaining -X- _ O
SoTA -X- _ O
results -X- _ O
, -X- _ O
while -X- _ O
decreasing -X- _ O
computational -X- _ O
costs -X- _ O
and -X- _ O
the -X- _ O
need -X- _ O
for -X- _ O
very -X- _ O
large -X- _ O
amounts -X- _ O
of -X- _ O
data -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

More -X- _ O
recently -X- _ O
, -X- _ O
the -X- _ O
" -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
, -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
" -X- _ O
procedure -X- _ O
is -X- _ O
shifting -X- _ O
in -X- _ O
NLP -X- _ O
tasks -X- _ O
towards -X- _ O
the -X- _ O
" -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
, -X- _ O
prompt -X- _ O
, -X- _ O
and -X- _ O
predict -X- _ O
" -X- _ O
paradigm -X- _ O
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2023 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
that -X- _ O
case -X- _ O
, -X- _ O
instead -X- _ O
of -X- _ O
adapting -X- _ O
PTLMs -X- _ B-MethodName
to -X- _ O
the -X- _ O
downstream -X- _ O
task -X- _ O
via -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
, -X- _ O
the -X- _ O
task -X- _ O
is -X- _ O
reformulated -X- _ O
to -X- _ O
look -X- _ O
more -X- _ O
like -X- _ O
those -X- _ O
solved -X- _ O
during -X- _ O
the -X- _ O
original -X- _ O
model -X- _ O
training -X- _ O
with -X- _ O
the -X- _ O
help -X- _ O
of -X- _ O
a -X- _ O
textual -X- _ O
prompt -X- _ O
. -X- _ O
Following -X- _ O
the -X- _ O
example -X- _ O
in -X- _ O
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2023 -X- _ O
) -X- _ O
, -X- _ O
when -X- _ O
recognizing -X- _ O
the -X- _ O
emotion -X- _ O
of -X- _ O
a -X- _ O
sentence -X- _ O
, -X- _ O
" -X- _ O
I -X- _ O
missed -X- _ O
the -X- _ O
bus -X- _ O
today -X- _ O
. -X- _ O
" -X- _ O
, -X- _ O
we -X- _ O
may -X- _ O
continue -X- _ O
with -X- _ O
a -X- _ O
prompt -X- _ O
" -X- _ O
I -X- _ O
felt -X- _ O
very -X- _ O
" -X- _ O
, -X- _ O
and -X- _ O
ask -X- _ O
the -X- _ O
PTLM -X- _ B-MethodName
to -X- _ O
fill -X- _ O
the -X- _ O
blank -X- _ O
with -X- _ O
an -X- _ O
emotion -X- _ O
- -X- _ O
bearing -X- _ O
word -X- _ O
. -X- _ O

A -X- _ O
PTLM -X- _ B-MethodName
typically -X- _ O
needs -X- _ O
" -X- _ O
well -X- _ O
- -X- _ O
formed -X- _ O
" -X- _ O
verbalized -X- _ O
text -X- _ O
to -X- _ O
interact -X- _ O
with -X- _ O
it -X- _ O
, -X- _ O
either -X- _ O
to -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
it -X- _ O
or -X- _ O
to -X- _ O
exploit -X- _ O
it -X- _ O
via -X- _ O
prompt -X- _ O
engineering -X- _ O
. -X- _ O
While -X- _ O
some -X- _ O
authors -X- _ O
claim -X- _ O
that -X- _ O
longer -X- _ O
, -X- _ O
more -X- _ O
complex -X- _ O
verbalizations -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
data -X- _ O
work -X- _ O
best -X- _ O
for -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
text -X- _ B-TaskName
classification -X- _ I-TaskName
tasks -X- _ O
( -X- _ O
Schick -X- _ O
and -X- _ O
Schütze -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
, -X- _ O
or -X- _ O
relation -X- _ O
classification -X- _ O
( -X- _ O
Bouraoui -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
other -X- _ O
authors -X- _ O
( -X- _ O
LoganIV -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
have -X- _ O
collected -X- _ O
indications -X- _ O
in -X- _ O
the -X- _ O
opposite -X- _ O
direction -X- _ O
for -X- _ O
a -X- _ O
wide -X- _ O
range -X- _ O
of -X- _ O
NLP -X- _ O
tasks -X- _ O
( -X- _ O
such -X- _ O
as -X- _ O
paraphrasing -X- _ O
, -X- _ O
textual -X- _ O
similarity -X- _ O
, -X- _ O
or -X- _ O
sentiment -X- _ O
analysis -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
share -X- _ O
the -X- _ O
hypothesis -X- _ O
that -X- _ O
commonly -X- _ O
used -X- _ O
PTLMs -X- _ B-MethodName
already -X- _ O
encode -X- _ O
enough -X- _ O
linguistic -X- _ O
knowledge -X- _ O
to -X- _ O
allow -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
minimal -X- _ O
( -X- _ O
or -X- _ O
none -X- _ O
) -X- _ O
textual -X- _ O
context -X- _ O
for -X- _ O
some -X- _ O
linguistically -X- _ O
motivated -X- _ O
tasks -X- _ O
. -X- _ O
In -X- _ O
such -X- _ O
cases -X- _ O
, -X- _ O
very -X- _ O
simple -X- _ O
prompts -X- _ O
work -X- _ O
almost -X- _ O
as -X- _ O
well -X- _ O
or -X- _ O
even -X- _ O
better -X- _ O
than -X- _ O
hand -X- _ O
- -X- _ O
crafted -X- _ O
, -X- _ O
more -X- _ O
complex -X- _ O
verbalizations -X- _ O
. -X- _ O
Reducing -X- _ O
the -X- _ O
need -X- _ O
of -X- _ O
complex -X- _ O
prompting -X- _ O
notably -X- _ O
reduces -X- _ O
the -X- _ O
need -X- _ O
of -X- _ O
human -X- _ O
effort -X- _ O
and -X- _ O
the -X- _ O
need -X- _ O
for -X- _ O
data -X- _ O
pre -X- _ O
- -X- _ O
processing -X- _ O
, -X- _ O
and -X- _ O
favors -X- _ O
techniques -X- _ O
that -X- _ O
are -X- _ O
language -X- _ O
neutral -X- _ O
since -X- _ O
they -X- _ O
do -X- _ O
not -X- _ O
rely -X- _ O
on -X- _ O
syntactic -X- _ O
structures -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
work -X- _ O
1 -X- _ O
, -X- _ O
we -X- _ O
explore -X- _ O
this -X- _ O
idea -X- _ O
for -X- _ O
the -X- _ O
LRC -X- _ B-TaskName
task -X- _ I-TaskName
, -X- _ O
and -X- _ O
we -X- _ O
extend -X- _ O
it -X- _ O
to -X- _ O
graded -X- _ B-TaskName
lexical -X- _ I-TaskName
entailment -X- _ I-TaskName
( -X- _ O
LE -X- _ B-TaskName
) -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
discovering -X- _ O
the -X- _ O
strength -X- _ O
of -X- _ O
the -X- _ O
taxonomical -X- _ O
asymmetric -X- _ O
hyponymy -X- _ O
- -X- _ O
hypernymy -X- _ O
relation -X- _ O
between -X- _ O
two -X- _ O
words -X- _ O
( -X- _ O
Vulić -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
previous -X- _ O
works -X- _ O
, -X- _ O
other -X- _ O
authors -X- _ O
have -X- _ O
explored -X- _ O
complex -X- _ O
verbalizations -X- _ O
for -X- _ O
LRC -X- _ B-TaskName
( -X- _ O
Ushio -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
while -X- _ O
others -X- _ O
have -X- _ O
essayed -X- _ O
shorter -X- _ O
ones -X- _ O
( -X- _ O
Wachowiak -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
there -X- _ O
has -X- _ O
been -X- _ O
no -X- _ O
systematic -X- _ O
study -X- _ O
on -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
long -X- _ O
/ -X- _ O
short -X- _ O
prompting -X- _ O
for -X- _ O
LRC -X- _ B-TaskName
so -X- _ O
far -X- _ O
. -X- _ O
To -X- _ O
that -X- _ O
end -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
experimented -X- _ O
with -X- _ O
different -X- _ O
verbalizations -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
and -X- _ O
test -X- _ O
data -X- _ O
in -X- _ O
an -X- _ O
LRC -X- _ B-TaskName
experiment -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
analysed -X- _ O
which -X- _ O
verbalization -X- _ O
produces -X- _ O
better -X- _ O
predictions -X- _ O
for -X- _ O
at -X- _ O
least -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
lexico -X- _ O
- -X- _ O
semantic -X- _ O
relations -X- _ O
entailed -X- _ O
between -X- _ O
a -X- _ O
pair -X- _ O
of -X- _ O
words -X- _ O
. -X- _ O
We -X- _ O
experiment -X- _ O
with -X- _ O
widely -X- _ O
used -X- _ O
benchmarks -X- _ O
for -X- _ O
LRC -X- _ B-TaskName
namely -X- _ O
, -X- _ O
CogALexV -X- _ B-DatasetName
( -X- _ O
Santus -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016a -X- _ O
) -X- _ O
, -X- _ O
BLESS -X- _ B-DatasetName
( -X- _ O
Baroni -X- _ O
and -X- _ O
Lenci -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
, -X- _ O
EVALution -X- _ B-DatasetName
( -X- _ O
Santus -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
, -X- _ O
K -X- _ B-DatasetName
& -X- _ I-DatasetName
H+N -X- _ I-DatasetName
( -X- _ O
Necsulescu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
ROOT9 -X- _ B-DatasetName
( -X- _ O
Santus -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016b -X- _ O
) -X- _ O
. -X- _ O
Besides -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
such -X- _ O
models -X- _ O
with -X- _ O
the -X- _ O
Hyperlex -X- _ B-DatasetName
( -X- _ O
Vulić -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
dataset -X- _ O
for -X- _ O
graded -X- _ B-TaskName
LE -X- _ I-TaskName
. -X- _ O

Our -X- _ O
main -X- _ O
contributions -X- _ O
are -X- _ O
: -X- _ O

1 -X- _ O
. -X- _ O
We -X- _ O
show -X- _ O
empirically -X- _ O
that -X- _ O
SoTA -X- _ O
results -X- _ O
for -X- _ O
LRC -X- _ B-TaskName
can -X- _ O
be -X- _ O
reached -X- _ O
by -X- _ O
providing -X- _ O
very -X- _ O
simple -X- _ O
verbalizations -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
or -X- _ O
even -X- _ O
no -X- _ O
verbalization -X- _ O
at -X- _ O
all -X- _ O
( -X- _ O
null -X- _ O
prompting -X- _ O
) -X- _ O
when -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
and -X- _ O
testing -X- _ O
a -X- _ O
PTLM -X- _ B-MethodName
. -X- _ O

2 -X- _ O
. -X- _ O
We -X- _ O
test -X- _ O
the -X- _ O
generalizability -X- _ O
of -X- _ O
such -X- _ O
models -X- _ O
trained -X- _ O
with -X- _ O
minimal -X- _ O
prompting -X- _ O
to -X- _ O
similar -X- _ O
tasks -X- _ O
by -X- _ O
testing -X- _ O
them -X- _ O
in -X- _ O
graded -X- _ B-TaskName
LE -X- _ I-TaskName
, -X- _ O
where -X- _ O
they -X- _ O
outperform -X- _ O
SoTA -X- _ O
results -X- _ O
. -X- _ O

3 -X- _ O
. -X- _ O
We -X- _ O
provide -X- _ O
an -X- _ O
extensive -X- _ O
analysis -X- _ O
of -X- _ O
the -X- _ O
results -X- _ O
( -X- _ O
including -X- _ O
error -X- _ O
analysis -X- _ O
) -X- _ O
to -X- _ O
further -X- _ O
observe -X- _ O
the -X- _ O
strengths -X- _ O
and -X- _ O
limitations -X- _ O
of -X- _ O
minimal -X- _ O
prompting -X- _ O
for -X- _ O
LRC -X- _ B-TaskName
. -X- _ O

4 -X- _ O
. -X- _ O
To -X- _ O
further -X- _ O
understand -X- _ O
the -X- _ O
models -X- _ O
' -X- _ O
behaviour -X- _ O
, -X- _ O
we -X- _ O
add -X- _ O
a -X- _ O
qualitative -X- _ O
analysis -X- _ O
of -X- _ O
their -X- _ O
learning -X- _ O
process -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
visualisation -X- _ O
of -X- _ O
the -X- _ O
embeddings -X- _ O
that -X- _ O
are -X- _ O
built -X- _ O
in -X- _ O
their -X- _ O
different -X- _ O
layers -X- _ O
. -X- _ O

Our -X- _ O
paper -X- _ O
is -X- _ O
structured -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
first -X- _ O
, -X- _ O
in -X- _ O
Section -X- _ O
3 -X- _ O
, -X- _ O
we -X- _ O
formally -X- _ O
describe -X- _ O
both -X- _ O
the -X- _ O
LRC -X- _ B-TaskName
task -X- _ O
and -X- _ O
the -X- _ O
LE -X- _ B-TaskName
task -X- _ O
. -X- _ O
Secondly -X- _ O
, -X- _ O
in -X- _ O
Section -X- _ O
4 -X- _ O
, -X- _ O
we -X- _ O
describe -X- _ O
the -X- _ O
chosen -X- _ O
templates -X- _ O
for -X- _ O
the -X- _ O
input -X- _ O
verbalizations -X- _ O
, -X- _ O
the -X- _ O
used -X- _ O
datasets -X- _ O
and -X- _ O
baselines -X- _ O
we -X- _ O
compare -X- _ O
with -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
hyper -X- _ O
parameter -X- _ O
and -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
setting -X- _ O
of -X- _ O
our -X- _ O
models -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
in -X- _ O
Section -X- _ O
5 -X- _ O
, -X- _ O
we -X- _ O
analyze -X- _ O
our -X- _ O
results -X- _ O
showing -X- _ O
: -X- _ O
a -X- _ O
) -X- _ O
our -X- _ O
quantitative -X- _ O
results -X- _ O
, -X- _ O
analyzing -X- _ O
which -X- _ O
template -X- _ O
, -X- _ O
model -X- _ O
, -X- _ O
and -X- _ O
method -X- _ O
work -X- _ O
best -X- _ O
on -X- _ O
each -X- _ O
dataset -X- _ O
, -X- _ O
b -X- _ O
) -X- _ O
the -X- _ O
error -X- _ O
analysis -X- _ O
, -X- _ O
checking -X- _ O
how -X- _ O
the -X- _ O
distribution -X- _ O
and -X- _ O
linguistic -X- _ O
characteristics -X- _ O
of -X- _ O
the -X- _ O
different -X- _ O
datasets -X- _ O
affected -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
models -X- _ O
and -X- _ O
what -X- _ O
examples -X- _ O
and -X- _ O
categories -X- _ O
were -X- _ O
the -X- _ O
most -X- _ O
difficult -X- _ O
ones -X- _ O
, -X- _ O
and -X- _ O
c -X- _ O
) -X- _ O
a -X- _ O
visualization -X- _ O
of -X- _ O
the -X- _ O
embedding -X- _ O
projection -X- _ O
, -X- _ O
highlighting -X- _ O
which -X- _ O
layers -X- _ O
are -X- _ O
more -X- _ O
informative -X- _ O
for -X- _ O
relation -X- _ O
classification -X- _ O
and -X- _ O
how -X- _ O
the -X- _ O
model -X- _ O
learns -X- _ O
them -X- _ O
through -X- _ O
the -X- _ O
different -X- _ O
epochs -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
in -X- _ O
Section -X- _ O
6 -X- _ O
, -X- _ O
we -X- _ O
summarize -X- _ O
the -X- _ O
conclusions -X- _ O
and -X- _ O
possible -X- _ O
future -X- _ O
work -X- _ O
, -X- _ O
stating -X- _ O
the -X- _ O
limitations -X- _ O
of -X- _ O
our -X- _ O
work -X- _ O
. -X- _ O

Related -X- _ O
Work -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
we -X- _ O
give -X- _ O
an -X- _ O
overview -X- _ O
of -X- _ O
some -X- _ O
related -X- _ O
approaches -X- _ O
that -X- _ O
are -X- _ O
relevant -X- _ O
to -X- _ O
our -X- _ O
work -X- _ O
. -X- _ O

Prompt -X- _ O
- -X- _ O
based -X- _ O
Learning -X- _ O

In -X- _ O
their -X- _ O
extensive -X- _ O
review -X- _ O
, -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2023 -X- _ O
) -X- _ O
have -X- _ O
analyzed -X- _ O
the -X- _ O
prompt -X- _ O
- -X- _ O
based -X- _ O
learning -X- _ O
paradigm -X- _ O
, -X- _ O
exploring -X- _ O
different -X- _ O
verbalization -X- _ O
techniques -X- _ O
used -X- _ O
to -X- _ O
input -X- _ O
text -X- _ O
to -X- _ O
PTLMs -X- _ B-MethodName
, -X- _ O
as -X- _ O
a -X- _ O
key -X- _ O
point -X- _ O
to -X- _ O
reach -X- _ O
SoTA -X- _ O
results -X- _ O
in -X- _ O
few -X- _ O
and -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
learning -X- _ O
scenarios -X- _ O
. -X- _ O
The -X- _ O
currently -X- _ O
under -X- _ O
research -X- _ O
question -X- _ O
is -X- _ O
: -X- _ O
what -X- _ O
kind -X- _ O
of -X- _ O
verbalizations -X- _ O
work -X- _ O
better -X- _ O
? -X- _ O
Here -X- _ O
, -X- _ O
two -X- _ O
different -X- _ O
trends -X- _ O
arise -X- _ O
: -X- _ O
a -X- _ O
) -X- _ O
automatically -X- _ O
searched -X- _ O
prompts -X- _ O
( -X- _ O
Shin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
; -X- _ O
Li -X- _ O
and -X- _ O
Liang -X- _ O
) -X- _ O
and -X- _ O
b -X- _ O
) -X- _ O
handcrafted -X- _ O
prompts -X- _ O
Schütze -X- _ O
, -X- _ O
2021 -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
main -X- _ O
drawback -X- _ O
of -X- _ O
the -X- _ O
first -X- _ O
one -X- _ O
is -X- _ O
the -X- _ O
necessity -X- _ O
of -X- _ O
additional -X- _ O
training -X- _ O
and -X- _ O
computational -X- _ O
resources -X- _ O
to -X- _ O
find -X- _ O
the -X- _ O
best -X- _ O
prompt -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
second -X- _ O
's -X- _ O
major -X- _ O
issue -X- _ O
is -X- _ O
the -X- _ O
necessity -X- _ O
of -X- _ O
manual -X- _ O
effort -X- _ O
( -X- _ O
Lo -X- _ O
- -X- _ O
ganIV -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
; -X- _ O
Mahabadi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
A -X- _ O
third -X- _ O
option -X- _ O
is -X- _ O
however -X- _ O
possible -X- _ O
: -X- _ O
null -X- _ O
prompts -X- _ O
( -X- _ O
LoganIV -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
where -X- _ O
the -X- _ O
mask -X- _ O
token -X- _ O
is -X- _ O
simply -X- _ O
added -X- _ O
to -X- _ O
the -X- _ O
input -X- _ O
sentence -X- _ O
. -X- _ O

Currently -X- _ O
, -X- _ O
no -X- _ O
consensus -X- _ O
has -X- _ O
been -X- _ O
reached -X- _ O
on -X- _ O
which -X- _ O
kind -X- _ O
of -X- _ O
verbalizations -X- _ O
work -X- _ O
best -X- _ O
, -X- _ O
and -X- _ O
, -X- _ O
while -X- _ O
authors -X- _ O
such -X- _ O
as -X- _ O
Schick -X- _ O
and -X- _ O
Schütze -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
obtain -X- _ O
the -X- _ O
best -X- _ O
results -X- _ O
in -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
NLP -X- _ O
tasks -X- _ O
with -X- _ O
handcrafted -X- _ O
verbalizations -X- _ O
, -X- _ O
others -X- _ O
( -X- _ O
LoganIV -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
; -X- _ O
Mahabadi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
defend -X- _ O
the -X- _ O
advantages -X- _ O
of -X- _ O
short -X- _ O
or -X- _ O
even -X- _ O
null -X- _ O
prompts -X- _ O
while -X- _ O
still -X- _ O
achieving -X- _ O
competitive -X- _ O
results -X- _ O
. -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
found -X- _ O
different -X- _ O
behavior -X- _ O
for -X- _ O
their -X- _ O
Ptuning -X- _ O
- -X- _ O
v2 -X- _ O
method -X- _ O
depending -X- _ O
on -X- _ O
the -X- _ O
task -X- _ O
: -X- _ O
simple -X- _ O
classification -X- _ B-TaskName
tasks -X- _ O
prefer -X- _ O
shorter -X- _ O
prompts -X- _ O
, -X- _ O
while -X- _ O
hard -X- _ O
sequence -X- _ O
labeling -X- _ O
tasks -X- _ O
prefer -X- _ O
longer -X- _ O
ones -X- _ O
. -X- _ O

Other -X- _ O
open -X- _ O
questions -X- _ O
about -X- _ O
prompting -X- _ O
rely -X- _ O
on -X- _ O
the -X- _ O
selection -X- _ O
of -X- _ O
the -X- _ O
label -X- _ O
to -X- _ O
verbalize -X- _ O
the -X- _ O
mask -X- _ O
and -X- _ O
the -X- _ O
order -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
mask -X- _ O
and -X- _ O
input -X- _ O
are -X- _ O
provided -X- _ O
. -X- _ O
Labels -X- _ O
given -X- _ O
in -X- _ O
benchmark -X- _ O
datasets -X- _ O
are -X- _ O
often -X- _ O
multiword -X- _ O
or -X- _ O
rare -X- _ O
expressions -X- _ O
consisting -X- _ O
of -X- _ O
more -X- _ O
than -X- _ O
one -X- _ O
token -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
the -X- _ O
mask -X- _ O
needs -X- _ O
to -X- _ O
be -X- _ O
filled -X- _ O
by -X- _ O
just -X- _ O
one -X- _ O
token -X- _ O
( -X- _ O
Schick -X- _ O
and -X- _ O
Schütze -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
thus -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
need -X- _ O
to -X- _ O
select -X- _ O
the -X- _ O
label -X- _ O
either -X- _ O
automatically -X- _ O
or -X- _ O
manually -X- _ O
. -X- _ O
The -X- _ O
order -X- _ O
in -X- _ O
which -X- _ O
input -X- _ O
and -X- _ O
mask -X- _ O
are -X- _ O
entered -X- _ O
is -X- _ O
also -X- _ O
under -X- _ O
current -X- _ O
research -X- _ O
( -X- _ O
Mahabadi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O

Previous -X- _ O
comparisons -X- _ O
of -X- _ O
different -X- _ O
prompting -X- _ O
techniques -X- _ O
have -X- _ O
been -X- _ O
mostly -X- _ O
applied -X- _ O
to -X- _ O
highly -X- _ O
context -X- _ O
- -X- _ O
dependent -X- _ O
NLP -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
sentiment -X- _ O
analysis -X- _ O
, -X- _ O
subjectivity -X- _ O
, -X- _ O
classification -X- _ B-TaskName
, -X- _ O
question -X- _ O
classification -X- _ O
, -X- _ O
natural -X- _ O
language -X- _ O
inference -X- _ O
, -X- _ O
question -X- _ O
answering -X- _ O
, -X- _ O
word -X- _ O
sense -X- _ O
disambiguation -X- _ O
or -X- _ O
paraphrasing -X- _ O
( -X- _ O
LoganIV -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
; -X- _ O
Schick -X- _ O
and -X- _ O
Schütze -X- _ O
, -X- _ O
2022 -X- _ O
; -X- _ O
Mahabadi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
were -X- _ O
the -X- _ O
input -X- _ O
example -X- _ O
already -X- _ O
consists -X- _ O
of -X- _ O
a -X- _ O
well -X- _ O
- -X- _ O
formed -X- _ O
sentence -X- _ O
. -X- _ O
Yet -X- _ O
, -X- _ O
other -X- _ O
NLP -X- _ O
tasks -X- _ O
that -X- _ O
are -X- _ O
less -X- _ O
context -X- _ O
- -X- _ O
sensitive -X- _ O
such -X- _ O
as -X- _ O
LRC -X- _ B-TaskName
, -X- _ O
Relation -X- _ O
Extraction -X- _ O
, -X- _ O
or -X- _ O
Lexical -X- _ B-TaskName
Entailment -X- _ I-TaskName
, -X- _ O
have -X- _ O
received -X- _ O
little -X- _ O
or -X- _ O
no -X- _ O
attention -X- _ O
so -X- _ O
far -X- _ O
in -X- _ O
prompt -X- _ O
comparison -X- _ O
studies -X- _ O
. -X- _ O

Lexical -X- _ B-TaskName
Relation -X- _ I-TaskName
Classification -X- _ I-TaskName

Seminal -X- _ O
work -X- _ O
on -X- _ O
LRC -X- _ B-TaskName
started -X- _ O
exploring -X- _ O
patternbased -X- _ O
techniques -X- _ O
( -X- _ O
Hearst -X- _ O
, -X- _ O
1992 -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
patterns -X- _ O
that -X- _ O
elicit -X- _ O
the -X- _ O
relation -X- _ O
entailed -X- _ O
between -X- _ O
a -X- _ O
pair -X- _ O
of -X- _ O
words -X- _ O
is -X- _ O
defined -X- _ O
. -X- _ O
A -X- _ O
drawback -X- _ O
of -X- _ O
this -X- _ O
method -X- _ O
is -X- _ O
that -X- _ O
not -X- _ O
all -X- _ O
lexical -X- _ O
relations -X- _ O
are -X- _ O
explicit -X- _ O
in -X- _ O
texts -X- _ O
by -X- _ O
a -X- _ O
closed -X- _ O
set -X- _ O
of -X- _ O
patterns -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
the -X- _ O
approach -X- _ O
towards -X- _ O
LRC -X- _ B-TaskName
shifted -X- _ O
to -X- _ O
distributional -X- _ O
semantics -X- _ O
with -X- _ O
static -X- _ O
embeddings -X- _ O
, -X- _ O
meaning -X- _ O
one -X- _ O
vector -X- _ O
is -X- _ O
given -X- _ O
to -X- _ O
represent -X- _ O
each -X- _ O
word -X- _ O
in -X- _ O
the -X- _ O
embeddings -X- _ O
space -X- _ O
( -X- _ O
Weeds -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
; -X- _ O
Santus -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016a -X- _ O
; -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
. -X- _ O
Such -X- _ O
techniques -X- _ O
were -X- _ O
found -X- _ O
beneficial -X- _ O
to -X- _ O
LRC -X- _ B-TaskName
tasks -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
words -X- _ O
were -X- _ O
normally -X- _ O
provided -X- _ O
without -X- _ O
additional -X- _ O
context -X- _ O
( -X- _ O
Barkan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

Recent -X- _ O
work -X- _ O
in -X- _ O
LRC -X- _ B-TaskName
has -X- _ O
focused -X- _ O
on -X- _ O
PTLMs -X- _ B-MethodName
and -X- _ O
their -X- _ O
dynamic -X- _ O
embeddings -X- _ O
, -X- _ O
owing -X- _ O
to -X- _ O
their -X- _ O
capacity -X- _ O
to -X- _ O
better -X- _ O
capture -X- _ O
polysemy -X- _ O
than -X- _ O
static -X- _ O
embeddings -X- _ O
, -X- _ O
which -X- _ O
led -X- _ O
to -X- _ O
better -X- _ O
results -X- _ O
( -X- _ O
Karmakar -X- _ O
and -X- _ O
McCrae -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Ushio -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Such -X- _ O
works -X- _ O
have -X- _ O
already -X- _ O
used -X- _ O
prompting -X- _ O
to -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
PTLMs -X- _ B-MethodName
. -X- _ O
However -X- _ O
, -X- _ O
none -X- _ O
of -X- _ O
them -X- _ O
has -X- _ O
focused -X- _ O
on -X- _ O
analyzing -X- _ O
what -X- _ O
kind -X- _ O
of -X- _ O
verbalization -X- _ O
can -X- _ O
be -X- _ O
better -X- _ O
used -X- _ O
to -X- _ O
extract -X- _ O
relation -X- _ O
information -X- _ O
, -X- _ O
as -X- _ O
we -X- _ O
do -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
while -X- _ O
in -X- _ O
( -X- _ O
Ushio -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
the -X- _ O
authors -X- _ O
opted -X- _ O
to -X- _ O
use -X- _ O
hand -X- _ O
- -X- _ O
crafted -X- _ O
complex -X- _ O
verbalizations -X- _ O
motivated -X- _ O
by -X- _ O
previous -X- _ O
research -X- _ O
( -X- _ O
Bouraoui -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Jiang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
Wachowiak -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
used -X- _ O
minimal -X- _ O
prompts -X- _ O
, -X- _ O
and -X- _ O
in -X- _ O
( -X- _ O
Karmakar -X- _ O
and -X- _ O
Mc -X- _ O
- -X- _ O
Crae -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
null -X- _ O
prompting -X- _ O
was -X- _ O
used -X- _ O
. -X- _ O

The -X- _ O
focus -X- _ O
of -X- _ O
our -X- _ O
work -X- _ O
is -X- _ O
comparing -X- _ O
the -X- _ O
verbalizations -X- _ O
enumerated -X- _ O
by -X- _ O
Schick -X- _ O
and -X- _ O
Schütze -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
in -X- _ O
their -X- _ O
work -X- _ O
: -X- _ O
null -X- _ O
- -X- _ O
prompting -X- _ O
, -X- _ O
null -X- _ O
- -X- _ O
prompting -X- _ O
with -X- _ O
punctuation -X- _ O
, -X- _ O
short -X- _ O
templates -X- _ O
and -X- _ O
long -X- _ O
templates -X- _ O
and -X- _ O
see -X- _ O
how -X- _ O
they -X- _ O
interact -X- _ O
with -X- _ O
a -X- _ O
lexical -X- _ O
- -X- _ O
focused -X- _ O
task -X- _ O
when -X- _ O
some -X- _ O
artificial -X- _ O
context -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
not -X- _ O
initially -X- _ O
available -X- _ O
in -X- _ O
the -X- _ O
dataset -X- _ O
) -X- _ O
is -X- _ O
added -X- _ O
to -X- _ O
the -X- _ O
prompt -X- _ O
, -X- _ O
versus -X- _ O
when -X- _ O
no -X- _ O
context -X- _ O
other -X- _ O
than -X- _ O
two -X- _ O
words -X- _ O
is -X- _ O
provided -X- _ O
( -X- _ O
as -X- _ O
in -X- _ O
null -X- _ O
prompting -X- _ O
) -X- _ O
. -X- _ O

Problem -X- _ O
Statement -X- _ O

Let -X- _ O
V -X- _ O
= -X- _ O
{ -X- _ O
w -X- _ O
1 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
w -X- _ O
n -X- _ O
} -X- _ O
be -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
words -X- _ O
( -X- _ O
our -X- _ O
vocabulary -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
sentence -X- _ O
s -X- _ O
be -X- _ O
any -X- _ O
finite -X- _ O
sequence -X- _ O
of -X- _ O
words -X- _ O
from -X- _ O
V -X- _ O
. -X- _ O
The -X- _ O
set -X- _ O
of -X- _ O
all -X- _ O
sentences -X- _ O
over -X- _ O
V -X- _ O
is -X- _ O
denoted -X- _ O
by -X- _ O
S. -X- _ O
Given -X- _ O
a -X- _ O
word -X- _ O
w -X- _ O
∈ -X- _ O
V -X- _ O
, -X- _ O
a -X- _ O
context -X- _ O
c -X- _ O
of -X- _ O
w -X- _ O
is -X- _ O
any -X- _ O
sentence -X- _ O
such -X- _ O
that -X- _ O
w -X- _ O
∈ -X- _ O
c. -X- _ O
The -X- _ O
set -X- _ O
of -X- _ O
all -X- _ O
contexts -X- _ O
of -X- _ O
a -X- _ O
word -X- _ O
w -X- _ O
is -X- _ O
denoted -X- _ O
by -X- _ O
C -X- _ O
w -X- _ O
. -X- _ O

A -X- _ O
binary -X- _ O
relation -X- _ O
r -X- _ O
between -X- _ O
words -X- _ O
is -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
V -X- _ O
× -X- _ O
V -X- _ O
. -X- _ O
Let -X- _ O
us -X- _ O
denote -X- _ O
by -X- _ O
R -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
all -X- _ O
binary -X- _ O
relations -X- _ O
over -X- _ O
the -X- _ O
vocabulary -X- _ O
V -X- _ O
, -X- _ O
that -X- _ O
is -X- _ O
, -X- _ O
R -X- _ O
is -X- _ O
the -X- _ O
power -X- _ O
set -X- _ O
of -X- _ O
V -X- _ O
× -X- _ O
V -X- _ O
. -X- _ O
We -X- _ O
say -X- _ O
that -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
relations -X- _ O
, -X- _ O
R -X- _ O
= -X- _ O
{ -X- _ O
r -X- _ O
1 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
r -X- _ O
k -X- _ O
} -X- _ O
, -X- _ O
where -X- _ O
r -X- _ O
i -X- _ O
∈ -X- _ O
R -X- _ O
, -X- _ O
is -X- _ O
mutually -X- _ O
exclusive -X- _ O
if -X- _ O
the -X- _ O
relations -X- _ O
in -X- _ O
R -X- _ O
are -X- _ O
disjoint -X- _ O
; -X- _ O
and -X- _ O
we -X- _ O
say -X- _ O
that -X- _ O
R -X- _ O
is -X- _ O
complete -X- _ O
if -X- _ O
the -X- _ O
union -X- _ O
of -X- _ O
the -X- _ O
relations -X- _ O
is -X- _ O
equal -X- _ O
to -X- _ O
V -X- _ O
× -X- _ O
V -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
we -X- _ O
can -X- _ O
make -X- _ O
a -X- _ O
relation -X- _ O
set -X- _ O
R -X- _ O
complete -X- _ O
by -X- _ O
adding -X- _ O
a -X- _ O
relation -X- _ O
named -X- _ O
unknown -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
complementary -X- _ O
of -X- _ O
all -X- _ O
the -X- _ O
relations -X- _ O
in -X- _ O
R -X- _ O
. -X- _ O

We -X- _ O
consider -X- _ O
that -X- _ O
any -X- _ O
context -X- _ O
of -X- _ O
two -X- _ O
words -X- _ O
induces -X- _ O
a -X- _ O
relation -X- _ O
from -X- _ O
a -X- _ O
predefined -X- _ O
set -X- _ O
of -X- _ O
relations -X- _ O
, -X- _ O
that -X- _ O
is -X- _ O
, -X- _ O
there -X- _ O
exists -X- _ O
a -X- _ O
function -X- _ O
f -X- _ O
R -X- _ O
: -X- _ O
P -X- _ O
→ -X- _ O
R -X- _ O
, -X- _ O
where -X- _ O

P -X- _ O
= -X- _ O
{ -X- _ O
c -X- _ O
∈ -X- _ O
S -X- _ O
| -X- _ O
c -X- _ O
∈ -X- _ O
C -X- _ O
w -X- _ O
1 -X- _ O
∩ -X- _ O
C -X- _ O
w -X- _ O
2 -X- _ O
, -X- _ O
w -X- _ O
1 -X- _ O
, -X- _ O
w -X- _ O
2 -X- _ O
∈ -X- _ O
V -X- _ O
} -X- _ O
. -X- _ O

For -X- _ O
instance -X- _ O
, -X- _ O
given -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
relations -X- _ O
R -X- _ O
= -X- _ O
{ -X- _ O
partOf -X- _ O
, -X- _ O
unknown -X- _ O
} -X- _ O
, -X- _ O
the -X- _ O
common -X- _ O
context -X- _ O
for -X- _ O
the -X- _ O
words -X- _ O
bank -X- _ O
and -X- _ O
river -X- _ O
, -X- _ O
" -X- _ O
I -X- _ O
play -X- _ O
by -X- _ O
the -X- _ O
bank -X- _ O
of -X- _ O
the -X- _ O
river -X- _ O
" -X- _ O
, -X- _ O
induces -X- _ O
the -X- _ O
relation -X- _ O
partOf -X- _ O
, -X- _ O
while -X- _ O
" -X- _ O
I -X- _ O
will -X- _ O
deposit -X- _ O
the -X- _ O
money -X- _ O
in -X- _ O
the -X- _ O
bank -X- _ O
beside -X- _ O
the -X- _ O
river -X- _ O
" -X- _ O
would -X- _ O
induce -X- _ O
the -X- _ O
unknown -X- _ O
relation -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
Relation -X- _ O
Classification -X- _ O
( -X- _ O
RC -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
using -X- _ O
a -X- _ O
functionf -X- _ O
R -X- _ O
that -X- _ O
estimates -X- _ O
f -X- _ O
R -X- _ O
. -X- _ O

Lexical -X- _ B-TaskName
Relation -X- _ I-TaskName
Classification -X- _ I-TaskName
( -X- _ O
LRC -X- _ B-TaskName
) -X- _ O
is -X- _ O
a -X- _ O
subtype -X- _ O
of -X- _ O
RC -X- _ O
where -X- _ O
the -X- _ O
relation -X- _ O
between -X- _ O
words -X- _ O
is -X- _ O
a -X- _ O
lexical -X- _ O
one -X- _ O
. -X- _ O
The -X- _ O
most -X- _ O
usual -X- _ O
and -X- _ O
important -X- _ O
lexical -X- _ O
relations -X- _ O
are -X- _ O
hyponymy -X- _ O
, -X- _ O
hyperonymy -X- _ O
, -X- _ O
antonymy -X- _ O
, -X- _ O
synonymy -X- _ O
, -X- _ O
and -X- _ O
meronymy -X- _ O
. -X- _ O
Among -X- _ O
these -X- _ O
relations -X- _ O
, -X- _ O
hyponymy -X- _ O
and -X- _ O
, -X- _ O
its -X- _ O
counterpart -X- _ O
, -X- _ O
hyperonymy -X- _ O
are -X- _ O
especially -X- _ O
important -X- _ O
in -X- _ O
NLP -X- _ O
and -X- _ O
ontology -X- _ O
engineering -X- _ O
. -X- _ O

Finally -X- _ O
, -X- _ O
Lexical -X- _ B-TaskName
Entailment -X- _ I-TaskName
( -X- _ O
LE -X- _ B-TaskName
) -X- _ O
is -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
detecting -X- _ O
the -X- _ O
hyponymy -X- _ O
relationship -X- _ O
between -X- _ O
two -X- _ O
words -X- _ O
. -X- _ O
This -X- _ O
task -X- _ O
becomes -X- _ O
graded -X- _ B-TaskName
LE -X- _ I-TaskName
when -X- _ O
we -X- _ O
have -X- _ O
to -X- _ O
calculate -X- _ O
the -X- _ O
numerical -X- _ O
degree -X- _ O
to -X- _ O
which -X- _ O
a -X- _ O
word -X- _ O
w -X- _ O
1 -X- _ O
is -X- _ O
a -X- _ O
type -X- _ O
of -X- _ O
w -X- _ O
2 -X- _ O
, -X- _ O
becoming -X- _ O
a -X- _ O
more -X- _ O
challenging -X- _ O
regression -X- _ O
task -X- _ O
. -X- _ O

Experimental -X- _ O
Setup -X- _ O

The -X- _ O
main -X- _ O
goals -X- _ O
of -X- _ O
our -X- _ O
experiments -X- _ O
are -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
to -X- _ O
check -X- _ O
if -X- _ O
LRC -X- _ B-TaskName
can -X- _ O
be -X- _ O
conducted -X- _ O
without -X- _ O
adding -X- _ O
artificial -X- _ O
context -X- _ O
when -X- _ O
just -X- _ O
a -X- _ O
pair -X- _ O
of -X- _ O
words -X- _ O
out -X- _ O
of -X- _ O
context -X- _ O
is -X- _ O
given -X- _ O
, -X- _ O
2 -X- _ O
) -X- _ O
if -X- _ O
so -X- _ O
, -X- _ O
to -X- _ O
analyze -X- _ O
which -X- _ O
verbalization -X- _ O
works -X- _ O
best -X- _ O
for -X- _ O
model -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
, -X- _ O
and -X- _ O
3 -X- _ O
) -X- _ O
to -X- _ O
check -X- _ O
the -X- _ O
generalizability -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
to -X- _ O
other -X- _ O
languagerelated -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
graded -X- _ B-TaskName
LE -X- _ I-TaskName
. -X- _ O

Chosen -X- _ O
Verbalization -X- _ O

Similarly -X- _ O
to -X- _ O
( -X- _ O
Schick -X- _ O
and -X- _ O
Schütze -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
null -X- _ O
prompts -X- _ O
to -X- _ O
punctuated -X- _ O
ones -X- _ O
( -X- _ O
just -X- _ O
the -X- _ O
target -X- _ O
and -X- _ O
source -X- _ O
words -X- _ O
with -X- _ O
added -X- _ O
punctuation -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
longer -X- _ O
template -X- _ O
( -X- _ O
the -X- _ O
best -X- _ O
performing -X- _ O
one -X- _ O
in -X- _ O
( -X- _ O
Ushio -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
chosen -X- _ O
mask -X- _ O
order -X- _ O
and -X- _ O
wording -X- _ O
placement -X- _ O
in -X- _ O
the -X- _ O
verbalization -X- _ O
is -X- _ O
the -X- _ O
best -X- _ O
performing -X- _ O
one -X- _ O
in -X- _ O
( -X- _ O
Mahabadi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
, -X- _ O
inserting -X- _ O
the -X- _ O
mask -X- _ O
token -X- _ O
between -X- _ O
both -X- _ O
words -X- _ O
. -X- _ O
Table -X- _ O
1 -X- _ O
presents -X- _ O
our -X- _ O
chosen -X- _ O
prompts -X- _ O
. -X- _ O

We -X- _ O
explore -X- _ O
two -X- _ O
different -X- _ O
options -X- _ O
: -X- _ O
a -X- _ O
) -X- _ O
adopting -X- _ O
a -X- _ O
sentence -X- _ O
classification -X- _ O
scheme -X- _ O
, -X- _ O
where -X- _ O
a -X- _ O
classification -X- _ O
layer -X- _ O
is -X- _ O
added -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
the -X- _ O
output -X- _ O
layer -X- _ O
( -X- _ O
templates -X- _ O
T1 -X- _ O
, -X- _ O
T2 -X- _ O
, -X- _ O
T3 -X- _ O
, -X- _ O
and -X- _ O
T4 -X- _ O
) -X- _ O
to -X- _ O
classify -X- _ O
the -X- _ O
CLS -X- _ O
( -X- _ O
special -X- _ O
classification -X- _ O
token -X- _ O
) -X- _ O
that -X- _ O
is -X- _ O
added -X- _ O
at -X- _ O
the -X- _ O
beginning -X- _ O
of -X- _ O
every -X- _ O
template -X- _ O
, -X- _ O
and -X- _ O
b -X- _ O
) -X- _ O
instantiating -X- _ O
the -X- _ O
task -X- _ O
as -X- _ O
a -X- _ O
fill -X- _ O
in -X- _ O
the -X- _ O
blank -X- _ O
task -X- _ O
( -X- _ O
templates -X- _ O
TM1 -X- _ O
, -X- _ O
TM2 -X- _ O
, -X- _ O
and -X- _ O
TM3 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
T4 -X- _ O
as -X- _ O
a -X- _ O
control -X- _ O
case -X- _ O
to -X- _ O
check -X- _ O
what -X- _ O
happens -X- _ O
when -X- _ O
train -X- _ O
and -X- _ O
test -X- _ O
templates -X- _ O
are -X- _ O
different -X- _ O
. -X- _ O

Datasets -X- _ O
and -X- _ O
Baselines -X- _ O

LRC -X- _ B-TaskName
We -X- _ O
conducted -X- _ O
experiments -X- _ O
on -X- _ O
five -X- _ O
datasets -X- _ O
2 -X- _ O
: -X- _ O
CogALexV -X- _ B-DatasetName
( -X- _ O
Santus -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016a -X- _ O
) -X- _ O
, -X- _ O
BLESS -X- _ B-DatasetName
( -X- _ O
Baroni -X- _ O
and -X- _ O
Lenci -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
, -X- _ O
EVALution -X- _ B-DatasetName
( -X- _ O
Santus -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
, -X- _ O
K -X- _ B-DatasetName
& -X- _ I-DatasetName
H+N -X- _ I-DatasetName
( -X- _ O
Necsulescu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
ROOT9 -X- _ B-DatasetName
( -X- _ O
Santus -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016b -X- _ O
) -X- _ O
. -X- _ O
These -X- _ O
datasets -X- _ O
contain -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
lexical -X- _ O
relations -X- _ O
, -X- _ O
including -X- _ O
hypernyms -X- _ O
, -X- _ O
meronyms -X- _ O
, -X- _ O
synonyms -X- _ O
, -X- _ O
antonyms -X- _ O
, -X- _ O
and -X- _ O
random -X- _ O
( -X- _ O
equivalent -X- _ O
to -X- _ O
unknown -X- _ O
relation -X- _ O
defined -X- _ O
in -X- _ O
S3 -X- _ O
) -X- _ O
3 -X- _ O
. -X- _ O
For -X- _ O
a -X- _ O
deeper -X- _ O
analysis -X- _ O
( -X- _ O
error -X- _ O
analysis -X- _ O
and -X- _ O
visualization -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
focus -X- _ O
on -X- _ O
CogALexV -X- _ B-DatasetName
as -X- _ O
it -X- _ O
contains -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
the -X- _ O
most -X- _ O
complicated -X- _ O
examples -X- _ O
of -X- _ O
EVALution -X- _ B-DatasetName
. -X- _ O
To -X- _ O
compare -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
different -X- _ O
verbalizations -X- _ O
in -X- _ O
PTLM -X- _ B-MethodName
fine -X- _ O
- -X- _ O
tuning -X- _ O
to -X- _ O
SoTA -X- _ O
methods -X- _ O
, -X- _ O
we -X- _ O
selected -X- _ O
the -X- _ O
following -X- _ O
baseline -X- _ O
models -X- _ O
: -X- _ O
LexNet -X- _ B-MethodName
, -X- _ O
SphereRE -X- _ B-MethodName
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
KEML -X- _ B-MethodName
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
RelBERT -X- _ B-MethodName
( -X- _ O
Ushio -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

Graded -X- _ B-TaskName
LE -X- _ I-TaskName
We -X- _ O
use -X- _ O
Hyperlex -X- _ B-DatasetName
dataset -X- _ O
( -X- _ O
Vulić -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
consists -X- _ O
of -X- _ O
2616 -X- _ O
pairs -X- _ O
of -X- _ O
words -X- _ O
( -X- _ O
2163 -X- _ O
nouns -X- _ O
and -X- _ O
453 -X- _ O
verbs -X- _ O
) -X- _ O
. -X- _ O
Each -X- _ O
pair -X- _ O
was -X- _ O
presented -X- _ O
to -X- _ O
at -X- _ O
least -X- _ O
ten -X- _ O
human -X- _ O
annotators -X- _ O
to -X- _ O
answer -X- _ O
the -X- _ O
question -X- _ O
To -X- _ O
what -X- _ O
degree -X- _ O
X -X- _ O
is -X- _ O
a -X- _ O
type -X- _ O
of -X- _ O
Y -X- _ O
? -X- _ O
rang -X- _ O
- -X- _ O
ing -X- _ O
from -X- _ O
0 -X- _ O
to -X- _ O
6 -X- _ O
. -X- _ O
The -X- _ O
final -X- _ O
given -X- _ O
score -X- _ O
for -X- _ O
each -X- _ O
pair -X- _ O
is -X- _ O
the -X- _ O
median -X- _ O
of -X- _ O
the -X- _ O
human -X- _ O
annotations -X- _ O
. -X- _ O
The -X- _ O
authors -X- _ O
of -X- _ O
Hyperlex -X- _ B-DatasetName
provide -X- _ O
an -X- _ O
upper -X- _ O
bound -X- _ O
of -X- _ O
the -X- _ O
Inter -X- _ B-MetricName
- -X- _ I-MetricName
Annotator -X- _ I-MetricName
Agreement -X- _ I-MetricName
( -X- _ O
IAA -X- _ B-MetricName
) -X- _ O
calculated -X- _ O
as -X- _ O
the -X- _ O
average -X- _ O
Spearman -X- _ O
correlation -X- _ O
of -X- _ O
a -X- _ O
human -X- _ O
rater -X- _ O
with -X- _ O
the -X- _ O
average -X- _ O
of -X- _ O
all -X- _ O
the -X- _ O
other -X- _ O
raters -X- _ O
; -X- _ O
in -X- _ O
particular -X- _ O
, -X- _ O
the -X- _ O
annotation -X- _ O
reaches -X- _ O
an -X- _ O
IAA -X- _ B-MetricName
- -X- _ I-MetricName
ρ -X- _ I-MetricName
of -X- _ O
0.864 -X- _ B-MetricValue
( -X- _ O
for -X- _ O
nouns -X- _ O
, -X- _ O
IAA -X- _ B-MetricName
- -X- _ I-MetricName
ρ -X- _ I-MetricName
= -X- _ O
0.864 -X- _ B-MetricValue
, -X- _ O
and -X- _ O
for -X- _ O
verbs -X- _ O
, -X- _ O
IAAρ -X- _ B-MetricName
= -X- _ O
0.862 -X- _ B-MetricValue
) -X- _ O
. -X- _ O
To -X- _ O
train -X- _ O
supervised -X- _ O
systems -X- _ O
, -X- _ O
Hyperlex -X- _ B-DatasetName
is -X- _ O
split -X- _ O
into -X- _ O
train -X- _ O
/ -X- _ O
val -X- _ O
/ -X- _ O
test -X- _ O
datasets -X- _ O
in -X- _ O
two -X- _ O
configurations -X- _ O
: -X- _ O
a -X- _ O
) -X- _ O
random -X- _ O
split -X- _ O
: -X- _ O
data -X- _ O
are -X- _ O
randomly -X- _ O
split -X- _ O
into -X- _ O
1831 -X- _ B-HyperparameterValue
/ -X- _ I-HyperparameterValue
130 -X- _ I-HyperparameterValue
/ -X- _ I-HyperparameterValue
655 -X- _ I-HyperparameterValue
train -X- _ B-HyperparameterName
/ -X- _ I-HyperparameterName
val -X- _ I-HyperparameterName
/ -X- _ I-HyperparameterName
test -X- _ I-HyperparameterName
pairs -X- _ O
, -X- _ O
respectively -X- _ O
( -X- _ O
all -X- _ O
the -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
test -X- _ O
split -X- _ O
appear -X- _ O
in -X- _ O
the -X- _ O
train -X- _ O
/ -X- _ O
val -X- _ O
splits -X- _ O
) -X- _ O
; -X- _ O
b -X- _ O
) -X- _ O
lexical -X- _ O
split -X- _ O
: -X- _ O
to -X- _ O
avoid -X- _ O
lexical -X- _ O
memorization -X- _ O
, -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
test -X- _ O
split -X- _ O
are -X- _ O
forced -X- _ O
not -X- _ O
to -X- _ O
appear -X- _ O
in -X- _ O
the -X- _ O
train -X- _ B-HyperparameterName
/ -X- _ I-HyperparameterName
val -X- _ I-HyperparameterName
splits -X- _ O
, -X- _ O
leading -X- _ O
to -X- _ O
fewer -X- _ O
pairs -X- _ O
in -X- _ O
each -X- _ O
split -X- _ O
, -X- _ O
1133 -X- _ B-HyperparameterValue
/ -X- _ I-HyperparameterValue
85 -X- _ I-HyperparameterValue
/ -X- _ I-HyperparameterValue
269 -X- _ I-HyperparameterValue
, -X- _ O
respectively -X- _ O
. -X- _ O
To -X- _ O
compare -X- _ O
our -X- _ O
proposal -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
considered -X- _ O
the -X- _ O
following -X- _ O
SoTA -X- _ O
models -X- _ O
as -X- _ O
baselines -X- _ O
: -X- _ O
LEAR -X- _ B-MethodName
( -X- _ O
Vulić -X- _ O
and -X- _ O
Mrkšić -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
SDNS -X- _ B-MethodName
( -X- _ O
Rei -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
GLEN -X- _ B-MethodName
, -X- _ O
POSTLE -X- _ B-MethodName
( -X- _ O
Kamath -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
LexSub -X- _ B-MethodName
( -X- _ O
Arora -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
Hierarchy -X- _ B-MethodName
- -X- _ I-MethodName
fitting -X- _ I-MethodName
( -X- _ O
HF -X- _ B-MethodName
) -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
all -X- _ O
these -X- _ O
models -X- _ O
use -X- _ O
non -X- _ O
- -X- _ O
contextual -X- _ O
embeddings -X- _ O
; -X- _ O
however -X- _ O
, -X- _ O
as -X- _ O
far -X- _ O
as -X- _ O
our -X- _ O
knowledge -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
no -X- _ O
models -X- _ O
in -X- _ O
the -X- _ O
literature -X- _ O
that -X- _ O
use -X- _ O
contextual -X- _ O
embeddings -X- _ O
for -X- _ O
graded -X- _ B-TaskName
LE -X- _ I-TaskName
as -X- _ O
we -X- _ O
do -X- _ O
. -X- _ O

Fine -X- _ O
- -X- _ O
tuning -X- _ O
Setting -X- _ O

We -X- _ O
begin -X- _ O
by -X- _ O
briefly -X- _ O
describing -X- _ O
the -X- _ O
models -X- _ O
we -X- _ O
use -X- _ O
, -X- _ O
continue -X- _ O
by -X- _ O
explaining -X- _ O
how -X- _ O
the -X- _ O
models -X- _ O
are -X- _ O
finetuned -X- _ O
for -X- _ O
LRC -X- _ B-TaskName
and -X- _ O
graded -X- _ B-TaskName
LE -X- _ I-TaskName
, -X- _ O
and -X- _ O
how -X- _ O
the -X- _ O
finetuned -X- _ O
models -X- _ O
are -X- _ O
used -X- _ O
for -X- _ O
inference -X- _ O
, -X- _ O
and -X- _ O
conclude -X- _ O
the -X- _ O
section -X- _ O
by -X- _ O
describing -X- _ O
the -X- _ O
hyperparameter -X- _ O
setup -X- _ O
. -X- _ O

Chosen -X- _ O
PTLMs -X- _ B-MethodName
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
chose -X- _ O
to -X- _ O
use -X- _ O
RoBERTa -X- _ B-MethodName
and -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
both -X- _ O
recognized -X- _ O
as -X- _ O
SoTA -X- _ O
models -X- _ O
for -X- _ O
general -X- _ O
domains -X- _ O
and -X- _ O
tasks -X- _ O
in -X- _ O
English -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
both -X- _ O
their -X- _ O
base -X- _ O
and -X- _ O
large -X- _ O
versions -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
downloaded -X- _ O
using -X- _ O
the -X- _ O
Huggingface -X- _ O
transformers -X- _ O
library -X- _ O
( -X- _ O
Wolf -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
4 -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
appropriate -X- _ O
version -X- _ O
depending -X- _ O
on -X- _ O
the -X- _ O
actual -X- _ O
underlying -X- _ O
task -X- _ O
we -X- _ O
are -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
, -X- _ O
whether -X- _ O
it -X- _ O
is -X- _ O
sequence -X- _ B-TaskName
classification -X- _ I-TaskName
( -X- _ O
T1 -X- _ O
- -X- _ O
4 -X- _ O
) -X- _ O
or -X- _ O
fillin -X- _ B-TaskName
- -X- _ I-TaskName
the -X- _ I-TaskName
- -X- _ I-TaskName
mask -X- _ I-TaskName
( -X- _ O
TM1 -X- _ O
- -X- _ O
3 -X- _ O
) -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
note -X- _ O
that -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
RoBERTa -X- _ B-MethodName
have -X- _ O
different -X- _ O
- -X- _ O
sized -X- _ O
vocabularies -X- _ O
and -X- _ O
treat -X- _ O
white -X- _ O
spaces -X- _ O
differently -X- _ O
; -X- _ O
thus -X- _ O
, -X- _ O
we -X- _ O
must -X- _ O
bear -X- _ O
in -X- _ O
mind -X- _ O
these -X- _ O
differences -X- _ O
to -X- _ O
adapt -X- _ O
the -X- _ O
templates -X- _ O
and -X- _ O
prompts -X- _ O
for -X- _ O
each -X- _ O
model -X- _ O
. -X- _ O
4 -X- _ O
Both -X- _ O
models -X- _ O
are -X- _ O
open -X- _ O
source -X- _ O
with -X- _ O
Apache -X- _ O
2.0 -X- _ O
and -X- _ O
MIT -X- _ O
licenses -X- _ O
LRC -X- _ B-TaskName
Our -X- _ O
setup -X- _ O
for -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
a -X- _ O
model -X- _ O
has -X- _ O
four -X- _ O
components -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
a -X- _ O
PTLM -X- _ B-MethodName
M -X- _ O
and -X- _ O
its -X- _ O
token -X- _ O
vocabulary -X- _ O
V -X- _ O
M -X- _ O
; -X- _ O
2 -X- _ O
) -X- _ O
a -X- _ O
training -X- _ O
set -X- _ O
T -X- _ O
= -X- _ O
{ -X- _ O
( -X- _ O
w -X- _ O
i -X- _ O
, -X- _ O
y -X- _ O
i -X- _ O
) -X- _ O
| -X- _ O
i -X- _ O
= -X- _ O
1 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
n -X- _ O
} -X- _ O
, -X- _ O
where -X- _ O
w -X- _ O
i -X- _ O
= -X- _ O
( -X- _ O
w -X- _ O
1 -X- _ O
i -X- _ O
, -X- _ O
w -X- _ O
2 -X- _ O
i -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
pair -X- _ O
of -X- _ O
words -X- _ O
and -X- _ O
y -X- _ O
i -X- _ O
∈ -X- _ O
Y -X- _ O
is -X- _ O
the -X- _ O
label -X- _ O
of -X- _ O
a -X- _ O
lexical -X- _ O
relation -X- _ O
( -X- _ O
|Y -X- _ O
| -X- _ O
= -X- _ O
K -X- _ O
) -X- _ O
; -X- _ O
3 -X- _ O
) -X- _ O
an -X- _ O
injective -X- _ O
function -X- _ O
from -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
labels -X- _ O
to -X- _ O
the -X- _ O
vocabulary -X- _ O
of -X- _ O
tokens -X- _ O
V -X- _ O
M -X- _ O
, -X- _ O
v -X- _ O
: -X- _ O
Y -X- _ O
→ -X- _ O
V -X- _ O
M -X- _ O
, -X- _ O
called -X- _ O
the -X- _ O
mask -X- _ O
verbalizer -X- _ O
function -X- _ O
; -X- _ O
and -X- _ O
4 -X- _ O
) -X- _ O
a -X- _ O
training -X- _ O
and -X- _ O
a -X- _ O
testing -X- _ O
template -X- _ O
, -X- _ O
T -X- _ O
t -X- _ O
and -X- _ O
T -X- _ O
e -X- _ O
, -X- _ O
used -X- _ O
to -X- _ O
verbalize -X- _ O
w -X- _ O
i -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
context -X- _ O
, -X- _ O
a -X- _ O
template -X- _ O
T -X- _ O
is -X- _ O
a -X- _ O
function -X- _ O
, -X- _ O
T -X- _ O
: -X- _ O
V -X- _ O
× -X- _ O
V -X- _ O
→ -X- _ O
S -X- _ O
, -X- _ O
from -X- _ O
pairs -X- _ O
of -X- _ O
the -X- _ O
word -X- _ O
vocabulary -X- _ O
to -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
sentences -X- _ O
where -X- _ O
the -X- _ O
CLS -X- _ O
, -X- _ O
SEP -X- _ O
and -X- _ O
MASK -X- _ O
special -X- _ O
tokens -X- _ O
of -X- _ O
the -X- _ O
PTLM -X- _ B-MethodName
can -X- _ O
appear -X- _ O
in -X- _ O
the -X- _ O
sentence -X- _ O
. -X- _ O
We -X- _ O
denote -X- _ O
by -X- _ O
T -X- _ O
( -X- _ O
w -X- _ O
) -X- _ O
C -X- _ O
and -X- _ O
T -X- _ O
( -X- _ O
w -X- _ O
) -X- _ O
M -X- _ O
to -X- _ O
the -X- _ O
CLS -X- _ O
and -X- _ O
MASK -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
sentence -X- _ O
T -X- _ O
( -X- _ O
w -X- _ O
) -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O

Depending -X- _ O
on -X- _ O
the -X- _ O
template -X- _ O
used -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
following -X- _ O
two -X- _ O
training -X- _ O
objectives -X- _ O
: -X- _ O
( -X- _ O
T1 -X- _ O
- -X- _ O
4 -X- _ O
) -X- _ O
a -X- _ O
classification -X- _ B-TaskName
objective -X- _ O
to -X- _ O
estimate -X- _ O
the -X- _ O
probability -X- _ O
P -X- _ O
( -X- _ O
Y -X- _ O
= -X- _ O
y -X- _ O
j -X- _ O
|T -X- _ O
t -X- _ O
( -X- _ O
w -X- _ O
i -X- _ O
) -X- _ O
C -X- _ O
) -X- _ O
; -X- _ O
and -X- _ O
( -X- _ O
TM1 -X- _ O
- -X- _ O
3 -X- _ O
) -X- _ O
a -X- _ O
mask -X- _ B-TaskName
prediction -X- _ I-TaskName
objective -X- _ O
to -X- _ O
estimate -X- _ O
P -X- _ O
( -X- _ O
T -X- _ O
t -X- _ O
( -X- _ O
w -X- _ O
i -X- _ O
) -X- _ O
M -X- _ O
= -X- _ O
t -X- _ O
j -X- _ O
|T -X- _ O
t -X- _ O
( -X- _ O
w -X- _ O
i -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
t -X- _ O
j -X- _ O
∈ -X- _ O
V -X- _ O
M -X- _ O
is -X- _ O
any -X- _ O
token -X- _ O
in -X- _ O
the -X- _ O
vocabulary -X- _ O
of -X- _ O
the -X- _ O
PTLM -X- _ B-MethodName
. -X- _ O
At -X- _ O
inference -X- _ O
time -X- _ O
, -X- _ O
for -X- _ O
a -X- _ O
model -X- _ O
trained -X- _ O
with -X- _ O
a -X- _ O
classification -X- _ B-TaskName
objective -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
testing -X- _ O
template -X- _ O
T -X- _ O
e -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
label -X- _ O
with -X- _ O
argmax -X- _ O
y -X- _ O
i -X- _ O
∈Y -X- _ O
{ -X- _ O
P -X- _ O
( -X- _ O
Y -X- _ O
= -X- _ O
y -X- _ O
i -X- _ O
|T -X- _ O
e -X- _ O
( -X- _ O
w -X- _ O
) -X- _ O
C -X- _ O
) -X- _ O
} -X- _ O
, -X- _ O
and -X- _ O
for -X- _ O
the -X- _ O
mask -X- _ O
objective -X- _ O
, -X- _ O
argmax -X- _ O
y -X- _ O
i -X- _ O
∈Y -X- _ O
{ -X- _ O
P -X- _ O
( -X- _ O
T -X- _ O
e -X- _ O
( -X- _ O
w -X- _ O
) -X- _ O
M -X- _ O
= -X- _ O
v -X- _ O
( -X- _ O
y -X- _ O
j -X- _ O
) -X- _ O
|T -X- _ O
e -X- _ O
( -X- _ O
w -X- _ O
) -X- _ O
) -X- _ O
} -X- _ O
. -X- _ O
For -X- _ O
this -X- _ O
latter -X- _ O
case -X- _ O
, -X- _ O
note -X- _ O
that -X- _ O
at -X- _ O
inference -X- _ O
time -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
use -X- _ O
the -X- _ O
tokens -X- _ O
given -X- _ O
by -X- _ O
the -X- _ O
mask -X- _ O
verbalizer -X- _ O
function -X- _ O
v -X- _ O
. -X- _ O

Graded -X- _ B-TaskName
LE -X- _ I-TaskName
In -X- _ O
this -X- _ O
task -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
a -X- _ O
similar -X- _ O
setup -X- _ O
to -X- _ O
the -X- _ O
LRC -X- _ B-TaskName
one -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
tuples -X- _ O
are -X- _ O
extended -X- _ O
with -X- _ O
the -X- _ O
hyponymy -X- _ O
score -X- _ O
for -X- _ O
the -X- _ O
pair -X- _ O
of -X- _ O
words -X- _ O
, -X- _ O
s -X- _ O
i -X- _ O
∈ -X- _ O
R -X- _ O
; -X- _ O
thus -X- _ O
, -X- _ O
T -X- _ O
= -X- _ O
{ -X- _ O
( -X- _ O
w -X- _ O
i -X- _ O
, -X- _ O
s -X- _ O
i -X- _ O
, -X- _ O
y -X- _ O
i -X- _ O
) -X- _ O
} -X- _ O
. -X- _ O
We -X- _ O
first -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
a -X- _ O
model -X- _ O
M -X- _ O
using -X- _ O
only -X- _ O
the -X- _ O
labels -X- _ O
y -X- _ O
i -X- _ O
as -X- _ O
for -X- _ O
the -X- _ O
LRC -X- _ B-TaskName
task -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
M -X- _ O
produces -X- _ O
a -X- _ O
logit -X- _ O
, -X- _ O
l -X- _ O
j -X- _ O
i -X- _ O
∈ -X- _ O
R -X- _ O
for -X- _ O
each -X- _ O
pair -X- _ O
w -X- _ O
i -X- _ O
∈ -X- _ O
T -X- _ O
and -X- _ O
label -X- _ O
y -X- _ O
j -X- _ O
( -X- _ O
token -X- _ O
v -X- _ O
( -X- _ O
y -X- _ O
j -X- _ O
) -X- _ O
) -X- _ O
for -X- _ O
a -X- _ O
model -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
with -X- _ O
a -X- _ O
classification -X- _ O
( -X- _ O
masked -X- _ O
) -X- _ O
objective -X- _ O
. -X- _ O
Let -X- _ O
us -X- _ O
denote -X- _ O
by -X- _ O
M -X- _ O
( -X- _ O
w -X- _ O
i -X- _ O
) -X- _ O
= -X- _ O
( -X- _ O
l -X- _ O
1 -X- _ O
i -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
l -X- _ O
K -X- _ O
i -X- _ O
) -X- _ O
the -X- _ O
logit -X- _ O
vector -X- _ O
produced -X- _ O
by -X- _ O
the -X- _ O
model -X- _ O
and -X- _ O
by -X- _ O
A -X- _ O
= -X- _ O
[ -X- _ O
M -X- _ O
( -X- _ O
w -X- _ O
i -X- _ O
) -X- _ O
] -X- _ O
∈ -X- _ O
R -X- _ O
n×K -X- _ O
the -X- _ O
matrix -X- _ O
of -X- _ O
logits -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
a -X- _ O
linear -X- _ O
regression -X- _ O
model -X- _ O
is -X- _ O
fitted -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
scores -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
{ -X- _ O
s -X- _ O
i -X- _ O
| -X- _ O
i -X- _ O
= -X- _ O
1 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
n -X- _ O
} -X- _ O
with -X- _ O
the -X- _ O
logits -X- _ O
A. -X- _ O
We -X- _ O
obtain -X- _ O
K -X- _ O
regression -X- _ O
coefficients -X- _ O
β -X- _ O
= -X- _ O
( -X- _ O
β -X- _ O
1 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
β -X- _ O
K -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
an -X- _ O
unseen -X- _ O
pair -X- _ O
w -X- _ O
, -X- _ O
the -X- _ O
predicted -X- _ O
score -X- _ O
is -X- _ O
the -X- _ O
linear -X- _ O
combination -X- _ O
of -X- _ O
the -X- _ O
fitted -X- _ O
regression -X- _ O
coefficients -X- _ O
and -X- _ O
the -X- _ O
logits -X- _ O
produced -X- _ O
by -X- _ O
the -X- _ O
model -X- _ O
M -X- _ O
, -X- _ O
that -X- _ O
is -X- _ O
, -X- _ O
the -X- _ O
scalar -X- _ O
product -X- _ O
score -X- _ O
( -X- _ O
w -X- _ O
) -X- _ O
= -X- _ O
β -X- _ O
• -X- _ O
M -X- _ O
( -X- _ O
w -X- _ O
) -X- _ O
. -X- _ O

Hyperparameters -X- _ O
and -X- _ O
Fine -X- _ O
- -X- _ O
tuning -X- _ O
Setup -X- _ O

Training -X- _ O
and -X- _ O
evaluation -X- _ O
were -X- _ O
performed -X- _ O
on -X- _ O
a -X- _ O
Tesla -X- _ O
- -X- _ O
T4 -X- _ O
GPU -X- _ O
through -X- _ O
Google -X- _ O
Colab -X- _ O
. -X- _ O
Overall -X- _ O
we -X- _ O
consumed -X- _ O
around -X- _ O
850h -X- _ O
of -X- _ O
GPU -X- _ O
usage -X- _ O
. -X- _ O
To -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
the -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
the -X- _ O
following -X- _ O
hyperparameters -X- _ O
: -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
32 -X- _ B-HyperparameterValue
, -X- _ O
Adam -X- _ O
weight -X- _ O
optimizer -X- _ O
, -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
2e -X- _ B-HyperparameterValue
−5 -X- _ I-HyperparameterValue
, -X- _ O
weight -X- _ B-HyperparameterName
decay -X- _ I-HyperparameterName
of -X- _ O
0.01 -X- _ B-HyperparameterValue
, -X- _ O
no -X- _ O
warmup -X- _ O
, -X- _ O
10 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
, -X- _ O
and -X- _ O
5 -X- _ B-HyperparameterValue
runs -X- _ I-HyperparameterValue
of -X- _ O
training -X- _ B-HyperparameterName
and -X- _ I-HyperparameterName
evaluation -X- _ I-HyperparameterName
to -X- _ O
asses -X- _ O
model -X- _ O
's -X- _ O
performance -X- _ O
variability -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
train -X- _ B-HyperparameterName
, -X- _ I-HyperparameterName
validation -X- _ I-HyperparameterName
, -X- _ I-HyperparameterName
and -X- _ I-HyperparameterName
test -X- _ I-HyperparameterName
splits -X- _ I-HyperparameterName
provided -X- _ O
by -X- _ O
the -X- _ O
original -X- _ O
datasets -X- _ O
, -X- _ O
and -X- _ O
, -X- _ O
when -X- _ O
no -X- _ O
validation -X- _ O
split -X- _ O
was -X- _ O
provided -X- _ O
, -X- _ O
we -X- _ O
did -X- _ O
not -X- _ O
use -X- _ O
any -X- _ O
. -X- _ O
We -X- _ O
report -X- _ O
the -X- _ O
F1 -X- _ B-MetricName
- -X- _ O
score -X- _ O
weighted -X- _ O
by -X- _ O
the -X- _ O
support -X- _ O
of -X- _ O
the -X- _ O
labels -X- _ O
to -X- _ O
compare -X- _ O
ourselves -X- _ O
with -X- _ O
the -X- _ O
other -X- _ O
baselines -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
case -X- _ O
of -X- _ O
CogALexV -X- _ B-DatasetName
, -X- _ O
we -X- _ O
take -X- _ O
out -X- _ O
the -X- _ O
results -X- _ O
for -X- _ O
RANDOM -X- _ B-DatasetName
before -X- _ O
reporting -X- _ O
the -X- _ O
results -X- _ O
as -X- _ O
advised -X- _ O
by -X- _ O
its -X- _ O
authors -X- _ O
in -X- _ O
( -X- _ O
Santus -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016a -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
graded -X- _ B-TaskName
LE -X- _ I-TaskName
and -X- _ O
Hyperlex -X- _ B-DatasetName
dataset -X- _ O
, -X- _ O
the -X- _ O
Spearman -X- _ B-MetricName
correlation -X- _ I-MetricName
between -X- _ O
the -X- _ O
median -X- _ O
human -X- _ O
annotators -X- _ O
scores -X- _ O
and -X- _ O
our -X- _ O
proposed -X- _ O
score -X- _ O
is -X- _ O
reported -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
report -X- _ O
the -X- _ O
Spearman -X- _ B-MetricName
correlation -X- _ I-MetricName
restricted -X- _ O
to -X- _ O
nouns -X- _ O
and -X- _ O
verbs -X- _ O
. -X- _ O

Results -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
report -X- _ O
the -X- _ O
qualitative -X- _ O
and -X- _ O
quantitative -X- _ O
results -X- _ O
of -X- _ O
our -X- _ O
experiments -X- _ O
. -X- _ O

Quantitative -X- _ O
Results -X- _ O

LRC -X- _ B-TaskName
Results -X- _ O

We -X- _ O
report -X- _ O
our -X- _ O
results -X- _ O
5 -X- _ O
in -X- _ O
Tables -X- _ O
2 -X- _ O
and -X- _ O
3 -X- _ O
, -X- _ O
comparing -X- _ O
them -X- _ O
to -X- _ O
the -X- _ O
SoTA -X- _ O
6 -X- _ O
results -X- _ O
. -X- _ O
We -X- _ O
report -X- _ O
the -X- _ O
mean -X- _ O
value -X- _ O
of -X- _ O
the -X- _ O
5 -X- _ O
runs -X- _ O
for -X- _ O
each -X- _ O
measure -X- _ O
, -X- _ O
underlining -X- _ O
the -X- _ O
highest -X- _ O
value -X- _ O
achieved -X- _ O
for -X- _ O
each -X- _ O
dataset -X- _ O
( -X- _ O
column -X- _ O
- -X- _ O
wise -X- _ O
) -X- _ O
. -X- _ O
Boldened -X- _ O
numbers -X- _ O
mark -X- _ O
no -X- _ O
statistical -X- _ O
significance -X- _ O
( -X- _ O
at -X- _ O
confident -X- _ O
level -X- _ O
α -X- _ O
= -X- _ O
0.01 -X- _ O
) -X- _ O
to -X- _ O
be -X- _ O
different -X- _ O
from -X- _ O
the -X- _ O
greatest -X- _ O
mean -X- _ O
value -X- _ O
applying -X- _ O
Welch -X- _ O
's -X- _ O
t -X- _ O
- -X- _ O
test -X- _ O
. -X- _ O
Except -X- _ O
for -X- _ O
KHN -X- _ B-DatasetName
, -X- _ O
we -X- _ O
improve -X- _ O
the -X- _ O
F1 -X- _ B-MetricName
- -X- _ O
score -X- _ O
in -X- _ O
all -X- _ O
the -X- _ O
datasets -X- _ O
. -X- _ O
In -X- _ O
some -X- _ O
of -X- _ O
them -X- _ O
( -X- _ O
EVALution -X- _ B-DatasetName
and -X- _ O
CogALexV -X- _ B-DatasetName
) -X- _ O
, -X- _ O
we -X- _ O
outperform -X- _ O
the -X- _ O
baselines -X- _ O
by -X- _ O
almost -X- _ O
10 -X- _ B-MetricValue
points -X- _ O
. -X- _ O
We -X- _ O
hypothesize -X- _ O
that -X- _ O
not -X- _ O
biasing -X- _ O
the -X- _ O
model -X- _ O
by -X- _ O
adding -X- _ O
external -X- _ O
artificial -X- _ O
context -X- _ O
might -X- _ O
let -X- _ O
it -X- _ O
choose -X- _ O
the -X- _ O
best -X- _ O
sense -X- _ O
of -X- _ O
both -X- _ O
words -X- _ O
. -X- _ O
Coincidentally -X- _ O
with -X- _ O
( -X- _ O
Schick -X- _ O
and -X- _ O
Schütze -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
longer -X- _ O
hand -X- _ O
- -X- _ O
crafted -X- _ O
template -X- _ O
( -X- _ O
T3 -X- _ O
) -X- _ O
obtained -X- _ O
the -X- _ O
best -X- _ O
results -X- _ O
in -X- _ O
most -X- _ O
datasets -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
difference -X- _ O
with -X- _ O
simpler -X- _ O
templates -X- _ O
( -X- _ O
T1 -X- _ O
, -X- _ O
T2 -X- _ O
) -X- _ O
, -X- _ O
was -X- _ O
very -X- _ O
small -X- _ O
and -X- _ O
statistically -X- _ O
not -X- _ O
significant -X- _ O
in -X- _ O
most -X- _ O
cases -X- _ O
. -X- _ O
T4 -X- _ O
reported -X- _ O
the -X- _ O
worst -X- _ O
performance -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
differences -X- _ O
between -X- _ O
train -X- _ O
and -X- _ O
test -X- _ O
which -X- _ O
misguided -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
learning -X- _ O
. -X- _ O
We -X- _ O
must -X- _ O
point -X- _ O
out -X- _ O
that -X- _ O
masked -X- _ O
variants -X- _ O
exhibited -X- _ O
more -X- _ O
stability -X- _ O
when -X- _ O
small -X- _ O
models -X- _ O
, -X- _ O
small -X- _ O
prompts -X- _ O
, -X- _ O
and -X- _ O
small -X- _ O
datasets -X- _ O
are -X- _ O
jointly -X- _ O
used -X- _ O
, -X- _ O
as -X- _ O
, -X- _ O
in -X- _ O
some -X- _ O
instances -X- _ O
with -X- _ O
this -X- _ O
setting -X- _ O
, -X- _ O
T1 -X- _ O
and -X- _ O
T2 -X- _ O
did -X- _ O
not -X- _ O
manage -X- _ O
to -X- _ O
converge -X- _ O
, -X- _ O
entering -X- _ O
a -X- _ O
poor -X- _ O
minimal -X- _ O
local -X- _ O
. -X- _ O
Such -X- _ O
situations -X- _ O
were -X- _ O
solved -X- _ O
by -X- _ O
relaunching -X- _ O
the -X- _ O
training -X- _ O
. -X- _ O

Graded -X- _ B-TaskName
LE -X- _ I-TaskName
results -X- _ O

The -X- _ O
results -X- _ O
for -X- _ O
graded -X- _ B-TaskName
LE -X- _ I-TaskName
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
see -X- _ O
how -X- _ O
models -X- _ O
trained -X- _ O
with -X- _ O
a -X- _ O
mask -X- _ O
objective -X- _ O
( -X- _ O
TM1 -X- _ O
- -X- _ O
TM3 -X- _ O
) -X- _ O
obtain -X- _ O
the -X- _ O
best -X- _ O
results -X- _ O
, -X- _ O
and -X- _ O
improve -X- _ O
the -X- _ O
SoTA -X- _ O
results -X- _ O
by -X- _ O
more -X- _ O
than -X- _ O
10 -X- _ B-MetricValue
points -X- _ O
globally -X- _ O
( -X- _ O
all -X- _ O
) -X- _ O
and -X- _ O
focusing -X- _ O
only -X- _ O
on -X- _ O
noun -X- _ O
pairs -X- _ O
( -X- _ O
nouns -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
lexical -X- _ O
split -X- _ O
, -X- _ O
our -X- _ O
results -X- _ O
are -X- _ O
about -X- _ O
20 -X- _ B-MetricValue
points -X- _ O
above -X- _ O
previous -X- _ O
proposals -X- _ O
. -X- _ O
Note -X- _ O
as -X- _ O
well -X- _ O
that -X- _ O
the -X- _ O
difference -X- _ O
of -X- _ O
the -X- _ O
results -X- _ O
in -X- _ O
the -X- _ O
lexical -X- _ O
split -X- _ O
is -X- _ O
only -X- _ O
about -X- _ O
4 -X- _ B-MetricValue
points -X- _ O
less -X- _ O
than -X- _ O
in -X- _ O
the -X- _ O
random -X- _ O
split -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
good -X- _ O
indicator -X- _ O
of -X- _ O
the -X- _ O
generalization -X- _ O
capabilities -X- _ O
of -X- _ O
our -X- _ O
models -X- _ O
. -X- _ O
To -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
our -X- _ O
knowledge -X- _ O
, -X- _ O
previous -X- _ O
studies -X- _ O
reported -X- _ O
results -X- _ O
just -X- _ O
on -X- _ O
all -X- _ O
POS -X- _ O
together -X- _ O
, -X- _ O
and -X- _ O
some -X- _ O
focused -X- _ O
on -X- _ O
nouns -X- _ O
as -X- _ O
well -X- _ O
. -X- _ O
We -X- _ O
expand -X- _ O
this -X- _ O
research -X- _ O
to -X- _ O
verbs -X- _ O
considering -X- _ O
the -X- _ O
results -X- _ O
promising -X- _ O
as -X- _ O
, -X- _ O
even -X- _ O
if -X- _ O
they -X- _ O
are -X- _ O
lower -X- _ O
than -X- _ O
for -X- _ O
nouns -X- _ O
, -X- _ O
they -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
part -X- _ O
of -X- _ O
speech -X- _ O
has -X- _ O
influence -X- _ O
in -X- _ O
our -X- _ O
models -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
want -X- _ O
to -X- _ O
remark -X- _ O
that -X- _ O
our -X- _ O
models -X- _ O
push -X- _ O
up -X- _ O
the -X- _ O
results -X- _ O
for -X- _ O
nouns -X- _ O
near -X- _ O
to -X- _ O
the -X- _ O
IAA -X- _ B-MetricName
given -X- _ O
by -X- _ O
humans -X- _ O
( -X- _ O
0.837 -X- _ B-MetricValue
vs. -X- _ O
0.864 -X- _ B-MetricValue
) -X- _ O
. -X- _ O

LRC -X- _ B-TaskName
Error -X- _ O
Analysis -X- _ O

Results -X- _ O
obtained -X- _ O
for -X- _ O
EVALution -X- _ B-DatasetName
and -X- _ O
CogALexV -X- _ B-DatasetName
datasets -X- _ O
are -X- _ O
noticeably -X- _ O
lower -X- _ O
. -X- _ O
We -X- _ O
hypothesize -X- _ O
a -X- _ O
reason -X- _ O
for -X- _ O
this -X- _ O
is -X- _ O
that -X- _ O
EVALution -X- _ B-DatasetName
is -X- _ O
an -X- _ O
extended -X- _ O
version -X- _ O
of -X- _ O
BLESS -X- _ B-DatasetName
dataset -X- _ O
where -X- _ O
the -X- _ O
relations -X- _ O
of -X- _ O
synonyms -X- _ O
and -X- _ O
antonyms -X- _ O
were -X- _ O
added -X- _ O
. -X- _ O
Adding -X- _ O
such -X- _ O
relations -X- _ O
makes -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
LRC -X- _ B-TaskName
more -X- _ O
challenging -X- _ O
as -X- _ O
, -X- _ O
particularly -X- _ O
, -X- _ O
synonyms -X- _ O
are -X- _ O
a -X- _ O
very -X- _ O
heterogeneous -X- _ O
class -X- _ O
difficult -X- _ O
to -X- _ O
be -X- _ O
delimited -X- _ O
even -X- _ O
for -X- _ O
humans -X- _ O
. -X- _ O
CogALexV -X- _ B-DatasetName
becomes -X- _ O
even -X- _ O
more -X- _ O
challenging -X- _ O
as -X- _ O
it -X- _ O
consists -X- _ O
of -X- _ O
a -X- _ O
selected -X- _ O
subset -X- _ O
of -X- _ O
EVALution -X- _ B-DatasetName
, -X- _ O
where -X- _ O
words -X- _ O
were -X- _ O
stemmed -X- _ O
, -X- _ O
decreasing -X- _ O
possible -X- _ O
morpho -X- _ O
- -X- _ O
semantic -X- _ O
cues -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
both -X- _ O
EVALution -X- _ B-DatasetName
and -X- _ O
CogALexV -X- _ B-DatasetName
were -X- _ O
created -X- _ O
to -X- _ O
avoid -X- _ O
lexical -X- _ O
memorization -X- _ O
, -X- _ O
this -X- _ O
meaning -X- _ O
, -X- _ O
they -X- _ O
consistently -X- _ O
use -X- _ O
words -X- _ O
that -X- _ O
participate -X- _ O
in -X- _ O
various -X- _ O
relations -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
the -X- _ O
bigger -X- _ O
dataset -X- _ O
size -X- _ O
of -X- _ O
BLESS -X- _ B-DatasetName
, -X- _ O
ROOT09 -X- _ B-DatasetName
, -X- _ O
and -X- _ O
K -X- _ B-DatasetName
& -X- _ I-DatasetName
H+N -X- _ I-DatasetName
should -X- _ O
also -X- _ O
have -X- _ O
a -X- _ O
beneficial -X- _ O
impact -X- _ O
on -X- _ O
the -X- _ O
results -X- _ O
. -X- _ O

From -X- _ O
now -X- _ O
on -X- _ O
, -X- _ O
we -X- _ O
focus -X- _ O
our -X- _ O
error -X- _ O
analysis -X- _ O
on -X- _ O
EVALution -X- _ B-DatasetName
and -X- _ O
CogALexV -X- _ B-DatasetName
as -X- _ O
they -X- _ O
contain -X- _ O
the -X- _ O
most -X- _ O
challenging -X- _ O
examples -X- _ O
7 -X- _ O
. -X- _ O
Unknown -X- _ O
( -X- _ O
or -X- _ O
equivalently -X- _ O
Random -X- _ O
) -X- _ O
relations -X- _ O
and -X- _ O
models -X- _ O
trained -X- _ O
with -X- _ O
the -X- _ O
T4 -X- _ O
control -X- _ O
template -X- _ O
have -X- _ O
been -X- _ O
excluded -X- _ O
from -X- _ O
this -X- _ O
analysis -X- _ O
. -X- _ O
We -X- _ O
focused -X- _ O
this -X- _ O
analysis -X- _ O
on -X- _ O
the -X- _ O
best -X- _ O
- -X- _ O
performing -X- _ O
model -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
, -X- _ O
Roberta -X- _ B-MethodName
- -X- _ O
large -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
got -X- _ O
two -X- _ O
groups -X- _ O
of -X- _ O
word -X- _ O
pairs -X- _ O
, -X- _ O
those -X- _ O
which -X- _ O
were -X- _ O
well -X- _ O
and -X- _ O
wrongly -X- _ O
classified -X- _ O
with -X- _ O
all -X- _ O
templates -X- _ O
. -X- _ O
For -X- _ O
these -X- _ O
two -X- _ O
groups -X- _ O
, -X- _ O
we -X- _ O
analyzed -X- _ O
different -X- _ O
features -X- _ O
( -X- _ O
presented -X- _ O
below -X- _ O
) -X- _ O
, -X- _ O
checking -X- _ O
whether -X- _ O
there -X- _ O
was -X- _ O
a -X- _ O
statistically -X- _ O
significant -X- _ O
difference -X- _ O
between -X- _ O
the -X- _ O
two -X- _ O
groups -X- _ O
by -X- _ O
using -X- _ O
χ -X- _ O
2 -X- _ O
-tests -X- _ O
or -X- _ O
Welch -X- _ O
's -X- _ O
t -X- _ O
- -X- _ O
tests -X- _ O
. -X- _ O
We -X- _ O
considered -X- _ O
that -X- _ O
a -X- _ O
feature -X- _ O
had -X- _ O
a -X- _ O
significant -X- _ O
impact -X- _ O
when -X- _ O
the -X- _ O
p -X- _ O
- -X- _ O
value -X- _ O
was -X- _ O
below -X- _ O
0.05 -X- _ O
. -X- _ O

-- -X- _ O
-- -X- _ O
-0.174 -X- _ B-MetricValue
/ -X- _ O
-- -X- _ O
-- -X- _ O
- -X- _ O
/ -X- _ O
-- -X- _ O
-- -X- _ O
- -X- _ O
SDNS -X- _ B-MethodName
0.692 -X- _ B-MetricValue
/ -X- _ O
-- -X- _ O
-- -X- _ O
- -X- _ O
/ -X- _ O
-- -X- _ O
-- -X- _ O
-- -X- _ O
-- -X- _ O
-- -X- _ O
/ -X- _ O
-- -X- _ O
-- -X- _ O
- -X- _ O
/ -X- _ O
-- -X- _ O
-- -X- _ O
- -X- _ O
GLEN -X- _ B-MethodName
0.520 -X- _ B-MetricValue
/ -X- _ O
-- -X- _ O
-- -X- _ O
- -X- _ O
/ -X- _ O
-- -X- _ O
-- -X- _ O
-0.481 -X- _ B-MetricValue
/ -X- _ O
-- -X- _ O
-- -X- _ O
- -X- _ O
/ -X- _ O
-- -X- _ O
-- -X- _ O
- -X- _ O
POSTLE -X- _ B-MethodName
0.686 -X- _ B-MetricValue
/ -X- _ O
-- -X- _ O
-- -X- _ O
- -X- _ O
/ -X- _ O
-- -X- _ O
-- -X- _ O
-- -X- _ O
-- -X- _ O
-- -X- _ O
/ -X- _ O
0.600 -X- _ B-MetricValue
/ -X- _ O
-- -X- _ O
-- -X- _ O
- -X- _ O
LexSub -X- _ B-MethodName
0.533 -X- _ B-MetricValue
/ -X- _ O
-- -X- _ O
-- -X- _ O
- -X- _ O
/ -X- _ O
-- -X- _ O
-- -X- _ O
-- -X- _ O
-- -X- _ O
-- -X- _ O
/ -X- _ O
-- -X- _ O
-- -X- _ O
- -X- _ O
/ -X- _ O
-- -X- _ O
-- -X- _ O
- -X- _ O
HF -X- _ B-MethodName
0.690 -X- _ B-MetricValue
/ -X- _ O
-- -X- _ O
-- -X- _ O
- -X- _ O
/ -X- _ O
-- -X- _ O
-- -X- _ O
-- -X- _ O
-- -X- _ O
-- -X- _ O
/ -X- _ O
-- -X- _ O
-- -X- _ O
- -X- _ O
/ -X- _ O
-- -X- _ O
-- -X- _ O
- -X- _ O
IAA -X- _ B-MetricName
0.864 -X- _ B-MetricValue
/ -X- _ O
0.864 -X- _ B-MetricValue
/ -X- _ O
0.862 -X- _ B-MetricValue

Relationship -X- _ O
Type -X- _ O

We -X- _ O
observed -X- _ O
that -X- _ O
, -X- _ O
in -X- _ O
both -X- _ O
datasets -X- _ O
, -X- _ O
all -X- _ O
the -X- _ O
trained -X- _ O
models -X- _ O
struggled -X- _ O
correctly -X- _ O
classifying -X- _ O
synonyms -X- _ O
, -X- _ O
while -X- _ O
they -X- _ O
are -X- _ O
particularly -X- _ O
good -X- _ O
at -X- _ O
predicting -X- _ O
antonyms -X- _ O
. -X- _ O
In -X- _ O
comparison -X- _ O
to -X- _ O
previous -X- _ O
studies -X- _ O
with -X- _ O
static -X- _ O
embeddings -X- _ O
( -X- _ O
Etcheverry -X- _ O
and -X- _ O
Wonsever -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Samenko -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
antonyms -X- _ O
and -X- _ O
synonyms -X- _ O
were -X- _ O
mutually -X- _ O
confused -X- _ O
in -X- _ O
the -X- _ O
classification -X- _ O
, -X- _ O
with -X- _ O
our -X- _ O
setting -X- _ O
we -X- _ O
overcame -X- _ O
this -X- _ O
problem -X- _ O
. -X- _ O
Yet -X- _ O
, -X- _ O
synonyms -X- _ O
, -X- _ O
in -X- _ O
line -X- _ O
with -X- _ O
previous -X- _ O
studies -X- _ O
( -X- _ O
Santus -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016a -X- _ O
) -X- _ O
, -X- _ O
remain -X- _ O
the -X- _ O
most -X- _ O
challenging -X- _ O
class -X- _ O
. -X- _ O

Polysemy -X- _ O
Initially -X- _ O
, -X- _ O
we -X- _ O
expected -X- _ O
more -X- _ O
polysemous -X- _ O
words -X- _ O
would -X- _ O
be -X- _ O
more -X- _ O
problematic -X- _ O
and -X- _ O
worse -X- _ O
predicted -X- _ O
, -X- _ O
as -X- _ O
, -X- _ O
at -X- _ O
first -X- _ O
sight -X- _ O
, -X- _ O
a -X- _ O
wider -X- _ O
range -X- _ O
of -X- _ O
categories -X- _ O
could -X- _ O
describe -X- _ O
different -X- _ O
relations -X- _ O
between -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
words -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
we -X- _ O
expected -X- _ O
that -X- _ O
the -X- _ O
lack -X- _ O
of -X- _ O
context -X- _ O
( -X- _ O
or -X- _ O
the -X- _ O
addition -X- _ O
of -X- _ O
an -X- _ O
artificial -X- _ O
one -X- _ O
, -X- _ O
not -X- _ O
adapted -X- _ O
to -X- _ O
the -X- _ O
word -X- _ O
pair -X- _ O
context -X- _ O
) -X- _ O
in -X- _ O
our -X- _ O
approach -X- _ O
would -X- _ O
make -X- _ O
it -X- _ O
more -X- _ O
difficult -X- _ O
to -X- _ O
disambiguate -X- _ O
between -X- _ O
the -X- _ O
different -X- _ O
senses -X- _ O
, -X- _ O
and -X- _ O
thus -X- _ O
to -X- _ O
choose -X- _ O
the -X- _ O
best -X- _ O
relation -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
counterintuitively -X- _ O
, -X- _ O
we -X- _ O
did -X- _ O
not -X- _ O
find -X- _ O
statistical -X- _ O
evidence -X- _ O
that -X- _ O
polysemy -X- _ O
8 -X- _ O
affected -X- _ O
our -X- _ O
results -X- _ O
. -X- _ O

POS -X- _ O
When -X- _ O
looking -X- _ O
at -X- _ O
the -X- _ O
part -X- _ O
of -X- _ O
speech -X- _ O
, -X- _ O
we -X- _ O
found -X- _ O
out -X- _ O
that -X- _ O
adjectives -X- _ O
were -X- _ O
the -X- _ O
best -X- _ O
- -X- _ O
predicted -X- _ O
ones -X- _ O
, -X- _ O
compared -X- _ O
to -X- _ O
verbs -X- _ O
and -X- _ O
nouns -X- _ O
. -X- _ O
To -X- _ O
extract -X- _ O
the -X- _ O
part -X- _ O
of -X- _ O
speech -X- _ O
, -X- _ O
the -X- _ O
predominant -X- _ O
part -X- _ O
of -X- _ O
speech -X- _ O
annotated -X- _ O
for -X- _ O
the -X- _ O
CogALexV -X- _ B-DatasetName
and -X- _ O
EVALution -X- _ B-DatasetName
datasets -X- _ O
were -X- _ O
selected -X- _ O
. -X- _ O

Semantic -X- _ O
Domains -X- _ O
and -X- _ O
Prototypicality -X- _ O
These -X- _ O
datasets -X- _ O
provide -X- _ O
us -X- _ O
for -X- _ O
each -X- _ O
word -X- _ O
pair -X- _ O
with -X- _ O
humanannotated -X- _ O
semantic -X- _ O
domains -X- _ O
9 -X- _ O
for -X- _ O
both -X- _ O
the -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
words -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
their -X- _ O
prototypical -X- _ O
relation -X- _ O
. -X- _ O
We -X- _ O
found -X- _ O
out -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
predicted -X- _ O
better -X- _ O
word -X- _ O
pairs -X- _ O
that -X- _ O
contained -X- _ O
abstract -X- _ O
rather -X- _ O
than -X- _ O
concrete -X- _ O
words -X- _ O
, -X- _ O
and -X- _ O
objects -X- _ O
better -X- _ O
than -X- _ O
events -X- _ O
. -X- _ O
Our -X- _ O
error -X- _ O
analysis -X- _ O
strengthens -X- _ O
previous -X- _ O
studies -X- _ O
( -X- _ O
Necsulescu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
that -X- _ O
suggest -X- _ O
LRC -X- _ B-TaskName
is -X- _ O
sensitive -X- _ O
to -X- _ O
domain -X- _ O
bias -X- _ O
. -X- _ O
Regarding -X- _ O
prototypicality -X- _ O
, -X- _ O
as -X- _ O
previously -X- _ O
noted -X- _ O
in -X- _ O
( -X- _ O
Santus -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016a -X- _ O
) -X- _ O
, -X- _ O
categories -X- _ O
more -X- _ O
generally -X- _ O
associated -X- _ O
with -X- _ O
a -X- _ O
pair -X- _ O
of -X- _ O
words -X- _ O
were -X- _ O
the -X- _ O
best -X- _ O
- -X- _ O
predicted -X- _ O
ones -X- _ O
( -X- _ O
in -X- _ O
contrast -X- _ O
to -X- _ O
categories -X- _ O
where -X- _ O
human -X- _ O
annotators -X- _ O
doubted -X- _ O
the -X- _ O
accuracy -X- _ O
of -X- _ O
the -X- _ O
provided -X- _ O
annotations -X- _ O
) -X- _ O
. -X- _ O

Sampled -X- _ O
Errors -X- _ O

Embedding -X- _ O
Projection -X- _ O
Visualization -X- _ O

In -X- _ O
Figure -X- _ O
1 -X- _ O
In -X- _ O
the -X- _ O
visualization -X- _ O
of -X- _ O
the -X- _ O
embedding -X- _ O
projections -X- _ O
, -X- _ O
we -X- _ O
annotated -X- _ O
our -X- _ O
data -X- _ O
with -X- _ O
some -X- _ O
linguistic -X- _ O
features -X- _ O
such -X- _ O
as -X- _ O
polysemy -X- _ O
, -X- _ O
word -X- _ O
frequency -X- _ O
, -X- _ O
and -X- _ O
linguistic -X- _ O
register -X- _ O
( -X- _ O
formal -X- _ O
vs -X- _ O
colloquial -X- _ O
and -X- _ O
geographical -X- _ O
differences -X- _ O
) -X- _ O
extracted -X- _ O
from -X- _ O
WordNet -X- _ O
to -X- _ O
check -X- _ O
whether -X- _ O
any -X- _ O
clear -X- _ O
clusters -X- _ O
appeared -X- _ O
for -X- _ O
the -X- _ O
unattested -X- _ O
relations -X- _ O
group -X- _ O
. -X- _ O
Yet -X- _ O
, -X- _ O
in -X- _ O
this -X- _ O
initial -X- _ O
exploration -X- _ O
, -X- _ O
we -X- _ O
could -X- _ O
not -X- _ O
find -X- _ O
any -X- _ O
clear -X- _ O
clustering -X- _ O
. -X- _ O

Conclusions -X- _ O
and -X- _ O
Future -X- _ O
Work -X- _ O

Our -X- _ O
experiments -X- _ O
show -X- _ O
that -X- _ O
minimal -X- _ O
prompts -X- _ O
work -X- _ O
equally -X- _ O
well -X- _ O
to -X- _ O
more -X- _ O
complex -X- _ O
ones -X- _ O
for -X- _ O
the -X- _ O
LRC -X- _ B-TaskName
task -X- _ O
, -X- _ O
thus -X- _ O
, -X- _ O
allowing -X- _ O
less -X- _ O
human -X- _ O
effort -X- _ O
and -X- _ O
computational -X- _ O
cost -X- _ O
, -X- _ O
and -X- _ O
following -X- _ O
a -X- _ O
language -X- _ O
- -X- _ O
neutral -X- _ O
approach -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
minimal -X- _ O
prompting -X- _ O
outperforms -X- _ O
SoTA -X- _ O
results -X- _ O
in -X- _ O
graded -X- _ B-TaskName
LE -X- _ I-TaskName
. -X- _ O
We -X- _ O
conducted -X- _ O
an -X- _ O
extensive -X- _ O
error -X- _ O
analysis -X- _ O
showing -X- _ O
that -X- _ O
: -X- _ O
synonymy -X- _ O
remains -X- _ O
the -X- _ O
hardest -X- _ O
category -X- _ O
to -X- _ O
classify -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
some -X- _ O
domain -X- _ O
and -X- _ O
POS -X- _ O
bias -X- _ O
, -X- _ O
and -X- _ O
polysemy -X- _ O
was -X- _ O
proven -X- _ O
to -X- _ O
be -X- _ O
an -X- _ O
issue -X- _ O
. -X- _ O
We -X- _ O
highlight -X- _ O
the -X- _ O
need -X- _ O
of -X- _ O
crafting -X- _ O
more -X- _ O
balanced -X- _ O
datasets -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
POS -X- _ O
and -X- _ O
domain -X- _ O
, -X- _ O
with -X- _ O
finer -X- _ O
- -X- _ O
graded -X- _ O
annotations -X- _ O
for -X- _ O
the -X- _ O
different -X- _ O
types -X- _ O
of -X- _ O
synonyms -X- _ O
. -X- _ O
As -X- _ O
future -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
a -X- _ O
) -X- _ O
address -X- _ O
LRC -X- _ B-TaskName
as -X- _ O
a -X- _ O
multilabel -X- _ O
classification -X- _ O
task -X- _ O
to -X- _ O
alleviate -X- _ O
the -X- _ O
polysemy -X- _ O
challenge -X- _ O
, -X- _ O
b -X- _ O
) -X- _ O
check -X- _ O
the -X- _ O
approach -X- _ O
with -X- _ O
other -X- _ O
languages -X- _ O
, -X- _ O
c -X- _ O
) -X- _ O
extend -X- _ O
the -X- _ O
study -X- _ O
to -X- _ O
other -X- _ O
semantic -X- _ O
relations -X- _ O
, -X- _ O
and -X- _ O
d -X- _ O
) -X- _ O
gain -X- _ O
insights -X- _ O
in -X- _ O
why -X- _ O
null -X- _ O
prompting -X- _ O
improves -X- _ O
the -X- _ O
SoTA -X- _ O
for -X- _ O
LRC -X- _ B-TaskName
and -X- _ O
if -X- _ O
this -X- _ O
line -X- _ O
of -X- _ O
research -X- _ O
could -X- _ O
be -X- _ O
generalized -X- _ O
to -X- _ O
other -X- _ O
relations -X- _ O
, -X- _ O
or -X- _ O
if -X- _ O
not -X- _ O
, -X- _ O
what -X- _ O
characterizes -X- _ O
Lexico -X- _ O
- -X- _ O
Semantic -X- _ O
relations -X- _ O
to -X- _ O
fit -X- _ O
this -X- _ O
well -X- _ O
the -X- _ O
null -X- _ O
prompting -X- _ O
approach -X- _ O
. -X- _ O

Limitations -X- _ O

1 -X- _ O
. -X- _ O
Computational -X- _ O
cost -X- _ O
: -X- _ O
For -X- _ O
our -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
almost -X- _ O
850h -X- _ O
of -X- _ O
GPUs -X- _ O
. -X- _ O
In -X- _ O
future -X- _ O
research -X- _ O
, -X- _ O
we -X- _ O
could -X- _ O
try -X- _ O
to -X- _ O
lower -X- _ O
this -X- _ O
cost -X- _ O
by -X- _ O
experimenting -X- _ O
with -X- _ O
prompting -X- _ O
for -X- _ O
LRC -X- _ B-TaskName
task -X- _ O
in -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
scenarios -X- _ O
, -X- _ O
which -X- _ O
would -X- _ O
also -X- _ O
help -X- _ O
when -X- _ O
conducting -X- _ O
the -X- _ O
task -X- _ O
for -X- _ O
low -X- _ O
- -X- _ O
researched -X- _ O
languages -X- _ O
. -X- _ O

2 -X- _ O
. -X- _ O
Language -X- _ O
: -X- _ O
Our -X- _ O
experiments -X- _ O
were -X- _ O
conducted -X- _ O
just -X- _ O
for -X- _ O
the -X- _ O
English -X- _ O
language -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
and -X- _ O
with -X- _ O
the -X- _ O
advantage -X- _ O
derived -X- _ O
from -X- _ O
minimal -X- _ O
prompting -X- _ O
of -X- _ O
being -X- _ O
language -X- _ O
independent -X- _ O
, -X- _ O
in -X- _ O
further -X- _ O
research -X- _ O
we -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
expand -X- _ O
our -X- _ O
experiments -X- _ O
to -X- _ O
multilingual -X- _ O
datasets -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
ones -X- _ O
from -X- _ O
( -X- _ O
Wachowiak -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

3 -X- _ O
. -X- _ O
Original -X- _ O
dataset -X- _ O
limitations -X- _ O
: -X- _ O
In -X- _ O
line -X- _ O
with -X- _ O
( -X- _ O
Lang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
found -X- _ O
some -X- _ O
misleading -X- _ O
annotations -X- _ O
in -X- _ O
CogALexV -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O
This -X- _ O
not -X- _ O
only -X- _ O
decrease -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
but -X- _ O
can -X- _ O
also -X- _ O
lead -X- _ O
to -X- _ O
hard -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
detect -X- _ O
biases -X- _ O
. -X- _ O

Once -X- _ O
again -X- _ O
, -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
tuning -X- _ O
would -X- _ O
decrease -X- _ O
the -X- _ O
annotation -X- _ O
cost -X- _ O
, -X- _ O
making -X- _ O
it -X- _ O
possible -X- _ O
to -X- _ O
train -X- _ O
with -X- _ O
, -X- _ O
although -X- _ O
less -X- _ O
, -X- _ O
better -X- _ O
- -X- _ O
annotated -X- _ O
examples -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
synonymy -X- _ O
remains -X- _ O
the -X- _ O
most -X- _ O
difficult -X- _ O
relation -X- _ O
to -X- _ O
capture -X- _ O
, -X- _ O
a -X- _ O
more -X- _ O
fine -X- _ O
- -X- _ O
graded -X- _ O
annotation -X- _ O
of -X- _ O
the -X- _ O
different -X- _ O
kinds -X- _ O
of -X- _ O
synonyms -X- _ O
could -X- _ O
improve -X- _ O
their -X- _ O
classification -X- _ O
. -X- _ O

Domain -X- _ O
dependence -X- _ O
: -X- _ O

The -X- _ O
limitation -X- _ O
spotted -X- _ O
by -X- _ O
( -X- _ O
Necsulescu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
is -X- _ O
persistent -X- _ O
in -X- _ O
our -X- _ O
model -X- _ O
. -X- _ O
A -X- _ O
richer -X- _ O
domain -X- _ O
annotation -X- _ O
would -X- _ O
be -X- _ O
advised -X- _ O
to -X- _ O
better -X- _ O
research -X- _ O
domain -X- _ O
bias -X- _ O
in -X- _ O
the -X- _ O
LRC -X- _ B-TaskName
task -X- _ O
. -X- _ O

Aknowledgements -X- _ O

Supported -X- _ O
by -X- _ O
the -X- _ O
Spanish -X- _ O
project -X- _ O
PID2020 -X- _ O
- -X- _ O
113903RB -X- _ O
- -X- _ O
I00 -X- _ O
( -X- _ O
AEI -X- _ O
/ -X- _ O
FEDER -X- _ O
, -X- _ O
UE -X- _ O
) -X- _ O
, -X- _ O
by -X- _ O
DGA -X- _ O
/ -X- _ O
FEDER -X- _ O
, -X- _ O
by -X- _ O
the -X- _ O
Agencia -X- _ O
Estatal -X- _ O
de -X- _ O
Investigación -X- _ O
of -X- _ O
the -X- _ O
Spanish -X- _ O
Ministry -X- _ O
of -X- _ O
Economy -X- _ O
and -X- _ O
Competitiveness -X- _ O
and -X- _ O
the -X- _ O
European -X- _ O
Social -X- _ O
Fund -X- _ O
through -X- _ O
the -X- _ O
" -X- _ O
Ramón -X- _ O
y -X- _ O
Cajal -X- _ O
" -X- _ O
program -X- _ O
( -X- _ O
RYC2019 -X- _ O
- -X- _ O
028112 -X- _ O
- -X- _ O
I -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
by -X- _ O
the -X- _ O
EU -X- _ O
research -X- _ O
and -X- _ O
innovation -X- _ O
program -X- _ O
HORIZON -X- _ O
Europe -X- _ O
2021 -X- _ O
through -X- _ O
the -X- _ O
" -X- _ O
4D -X- _ O
PICTURE -X- _ O
" -X- _ O
project -X- _ O
under -X- _ O
grant -X- _ O
agreement -X- _ O
101057332 -X- _ O
. -X- _ O

A -X- _ O
Datasets -X- _ O
Description -X- _ O

All -X- _ O
the -X- _ O
five -X- _ O
datasets -X- _ O
used -X- _ O
for -X- _ O
LRC -X- _ B-TaskName
, -X- _ O
except -X- _ O
K -X- _ B-DatasetName
& -X- _ I-DatasetName
H+N -X- _ I-DatasetName
, -X- _ O
are -X- _ O
to -X- _ O
some -X- _ O
extent -X- _ O
expansions -X- _ O
and -X- _ O
modified -X- _ O
versions -X- _ O
of -X- _ O
the -X- _ O
BLESS -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O
BLESS -X- _ B-DatasetName
aimed -X- _ O
to -X- _ O
provide -X- _ O
pair -X- _ O
of -X- _ O
words -X- _ O
to -X- _ O
conduct -X- _ O
research -X- _ O
on -X- _ O
distributional -X- _ O
semantics -X- _ O
through -X- _ O
analogies -X- _ O
. -X- _ O
This -X- _ O
first -X- _ O
dataset -X- _ O
used -X- _ O
the -X- _ O
McRae -X- _ O
norms -X- _ O
, -X- _ O
Wordnet -X- _ O
and -X- _ O
Con -X- _ O
- -X- _ O
ceptNet -X- _ O
as -X- _ O
sources -X- _ O
. -X- _ O
They -X- _ O
used -X- _ O
single -X- _ O
words -X- _ O
instead -X- _ O
of -X- _ O
multiwords -X- _ O
and -X- _ O
crowdsourced -X- _ O
random -X- _ O
words -X- _ O
to -X- _ O
create -X- _ O
noise -X- _ O
in -X- _ O
the -X- _ O
dataset -X- _ O
at -X- _ O
the -X- _ O
same -X- _ O
time -X- _ O
that -X- _ O
they -X- _ O
assured -X- _ O
no -X- _ O
relation -X- _ O
between -X- _ O
them -X- _ O
was -X- _ O
entailed -X- _ O
. -X- _ O
They -X- _ O
tried -X- _ O
to -X- _ O
avoid -X- _ O
ambiguities -X- _ O
, -X- _ O
and -X- _ O
relied -X- _ O
on -X- _ O
prototypical -X- _ O
terms -X- _ O
to -X- _ O
stay -X- _ O
as -X- _ O
' -X- _ O
little -X- _ O
controversial -X- _ O
as -X- _ O
possible -X- _ O
' -X- _ O
. -X- _ O
As -X- _ O
categories -X- _ O
, -X- _ O
they -X- _ O
study -X- _ O
meronyms -X- _ O
and -X- _ O
hyponyms -X- _ O
, -X- _ O
excluding -X- _ O
synonyms -X- _ O
due -X- _ O
the -X- _ O
alleged -X- _ O
problematic -X- _ O
description -X- _ O
and -X- _ O
heterogeneity -X- _ O
. -X- _ O

EVAlution -X- _ B-DatasetName
was -X- _ O
developed -X- _ O
as -X- _ O
an -X- _ O
expansion -X- _ O
of -X- _ O
BLESS -X- _ B-DatasetName
, -X- _ O
to -X- _ O
which -X- _ O
synonyms -X- _ O
and -X- _ O
antonyms -X- _ O
were -X- _ O
added -X- _ O
, -X- _ O
containing -X- _ O
IsA -X- _ O
( -X- _ O
hypernymy -X- _ O
) -X- _ O
, -X- _ O
antonymy -X- _ O
, -X- _ O
synonymy -X- _ O
, -X- _ O
meronymy -X- _ O
( -X- _ O
part -X- _ O
of -X- _ O
, -X- _ O
member -X- _ O
of -X- _ O
, -X- _ O
and -X- _ O
made -X- _ O
of -X- _ O
) -X- _ O
, -X- _ O
entailment -X- _ O
, -X- _ O
hasA -X- _ O
( -X- _ O
possession -X- _ O
) -X- _ O
, -X- _ O
has -X- _ O
property -X- _ O
( -X- _ O
attribution -X- _ O
) -X- _ O
relations -X- _ O
with -X- _ O
heterogeneous -X- _ O
distribution -X- _ O
of -X- _ O
them -X- _ O
. -X- _ O
Complementary -X- _ O
linguistic -X- _ O
data -X- _ O
is -X- _ O
also -X- _ O
provided -X- _ O
, -X- _ O
as -X- _ O
for -X- _ O
example -X- _ O
the -X- _ O
domain -X- _ O
11 -X- _ O
. -X- _ O
Co -X- _ B-DatasetName
- -X- _ I-DatasetName
gALexV -X- _ I-DatasetName
dataset -X- _ O
was -X- _ O
provided -X- _ O
at -X- _ O
the -X- _ O
ACL -X- _ O
lexical -X- _ O
relation -X- _ O
classification -X- _ O
workshop -X- _ O
in -X- _ O
2016 -X- _ O
as -X- _ O
a -X- _ O
challenging -X- _ O
subset -X- _ O
of -X- _ O
Evalution -X- _ O
, -X- _ O
where -X- _ O
words -X- _ O
were -X- _ O
stemmed -X- _ O
. -X- _ O
ROOT9 -X- _ B-DatasetName
is -X- _ O
an -X- _ O
expansion -X- _ O
of -X- _ O
CogALexV -X- _ B-DatasetName
. -X- _ O

K -X- _ B-DatasetName
& -X- _ I-DatasetName
+N -X- _ I-DatasetName
is -X- _ O
an -X- _ O
expansion -X- _ O
of -X- _ O
Kozareva -X- _ O
and -X- _ O
Hongs -X- _ O
, -X- _ O
2010 -X- _ O
dataset -X- _ O
, -X- _ O
which -X- _ O
extracted -X- _ O
its -X- _ O
original -X- _ O
data -X- _ O
from -X- _ O
hyponymy -X- _ O
and -X- _ O
hypernymy -X- _ O
relations -X- _ O
in -X- _ O
Wordnet -X- _ O
, -X- _ O
for -X- _ O
animal -X- _ O
, -X- _ O
plant -X- _ O
and -X- _ O
vehicle -X- _ O
domains -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
current -X- _ O
K -X- _ B-DatasetName
& -X- _ I-DatasetName
H+N -X- _ I-DatasetName
dataset -X- _ O
, -X- _ O
cohyponyms -X- _ O
and -X- _ O
meronyms -X- _ O
were -X- _ O
added -X- _ O
. -X- _ O
As -X- _ O
in -X- _ O
the -X- _ O
previous -X- _ O
datasets -X- _ O
, -X- _ O
multiwords -X- _ O
were -X- _ O
avoided -X- _ O
. -X- _ O

Most -X- _ O
datasets -X- _ O
, -X- _ O
by -X- _ O
being -X- _ O
descendants -X- _ O
of -X- _ O
BLESS -X- _ B-DatasetName
, -X- _ O
contain -X- _ O
the -X- _ O
same -X- _ O
limitations -X- _ O
, -X- _ O
being -X- _ O
mostly -X- _ O
the -X- _ O
elusion -X- _ O
of -X- _ O
rare -X- _ O
vocabulary -X- _ O
and -X- _ O
ambiguous -X- _ O
words -X- _ O
. -X- _ O

For -X- _ O
graded -X- _ B-TaskName
LE -X- _ I-TaskName
, -X- _ O
in -X- _ O
the -X- _ O
original -X- _ O
Hyperlex -X- _ B-DatasetName
dataset -X- _ O
, -X- _ O
the -X- _ O
hyponym -X- _ O
pairs -X- _ O
are -X- _ O
annotated -X- _ O
in -X- _ O
four -X- _ O
levels -X- _ O
, -X- _ O
namely -X- _ O
hyp -X- _ O
- -X- _ O
i -X- _ O
, -X- _ O
1 -X- _ O
≤i≤ -X- _ O
4 -X- _ O
, -X- _ O
where -X- _ O
i -X- _ O
is -X- _ O
the -X- _ O
path -X- _ O
length -X- _ O
in -X- _ O
the -X- _ O
WordNet -X- _ O
hierarchy -X- _ O
. -X- _ O
We -X- _ O
collapse -X- _ O
all -X- _ O
labels -X- _ O
hyp -X- _ O
- -X- _ O
i -X- _ O
to -X- _ O
hyp -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
. -X- _ O
The -X- _ O
same -X- _ O
rationale -X- _ O
is -X- _ O
applied -X- _ O
to -X- _ O
the -X- _ O
hyperonym -X- _ O
labels -X- _ O
r -X- _ O
- -X- _ O
hyp -X- _ O
- -X- _ O
i -X- _ O
. -X- _ O

In -X- _ O
Table -X- _ O
6 -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
pairs -X- _ O
for -X- _ O
relation -X- _ O
in -X- _ O
the -X- _ O
train -X- _ B-HyperparameterName
/ -X- _ I-HyperparameterName
validation -X- _ I-HyperparameterName
/ -X- _ I-HyperparameterName
test -X- _ I-HyperparameterName
splits -X- _ I-HyperparameterName
. -X- _ O

11 -X- _ O
Domain -X- _ O
information -X- _ O
was -X- _ O
crowdsourced -X- _ O
and -X- _ O
not -X- _ O
always -X- _ O
reliable -X- _ O
, -X- _ O
thus -X- _ O
, -X- _ O
authors -X- _ O
advised -X- _ O
to -X- _ O
only -X- _ O
take -X- _ O
domains -X- _ O
as -X- _ O
valid -X- _ O
when -X- _ O
two -X- _ O
or -X- _ O
more -X- _ O
raters -X- _ O
annotated -X- _ O
the -X- _ O
word -X- _ O
as -X- _ O
belonging -X- _ O
to -X- _ O
the -X- _ O
same -X- _ O
domain -X- _ O

B -X- _ O
Detailed -X- _ O
Error -X- _ O
Analysis -X- _ O

To -X- _ O
conduct -X- _ O
the -X- _ O
error -X- _ O
analysis -X- _ O
, -X- _ O
we -X- _ O
take -X- _ O
the -X- _ O
easiest -X- _ O
and -X- _ O
the -X- _ O
most -X- _ O
difficult -X- _ O
examples -X- _ O
to -X- _ O
classify -X- _ O
trained -X- _ O
with -X- _ O
RoBERTa -X- _ B-MethodName
( -X- _ O
large -X- _ O
) -X- _ O
for -X- _ O
CogaALexV -X- _ B-DatasetName
and -X- _ O
EVA -X- _ B-DatasetName
- -X- _ I-DatasetName
Lution -X- _ I-DatasetName
datasets -X- _ O
. -X- _ O
We -X- _ O
take -X- _ O
two -X- _ O
groups -X- _ O
of -X- _ O
pairs -X- _ O
: -X- _ O
those -X- _ O
which -X- _ O
were -X- _ O
well -X- _ O
and -X- _ O
wrongly -X- _ O
classified -X- _ O
in -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
5 -X- _ O
runs -X- _ O
and -X- _ O
all -X- _ O
templates -X- _ O
, -X- _ O
except -X- _ O
for -X- _ O
template -X- _ O
T -X- _ O
4 -X- _ O
. -X- _ O
We -X- _ O
test -X- _ O
if -X- _ O
there -X- _ O
is -X- _ O
statistical -X- _ O
evidence -X- _ O
that -X- _ O
some -X- _ O
features -X- _ O
influence -X- _ O
the -X- _ O
well -X- _ O
/ -X- _ O
wrongly -X- _ O
classified -X- _ O
pairs -X- _ O
. -X- _ O
We -X- _ O
have -X- _ O
a -X- _ O
total -X- _ O
of -X- _ O
1527 -X- _ O
pairs -X- _ O
, -X- _ O
586 -X- _ O
from -X- _ O
CogALexV -X- _ B-DatasetName
and -X- _ O
941 -X- _ O
from -X- _ O
EVALution -X- _ B-DatasetName
, -X- _ O
divided -X- _ O
into -X- _ O
1359 -X- _ O
/ -X- _ O
168 -X- _ O
well -X- _ O
/ -X- _ O
wrongly -X- _ O
predicted -X- _ O
pairs -X- _ O
. -X- _ O

The -X- _ O
first -X- _ O
studied -X- _ O
feature -X- _ O
is -X- _ O
the -X- _ O
relation -X- _ O
between -X- _ O
the -X- _ O
words -X- _ O
, -X- _ O
that -X- _ O
is -X- _ O
, -X- _ O
we -X- _ O
ask -X- _ O
if -X- _ O
there -X- _ O
is -X- _ O
some -X- _ O
lexical -X- _ O
relation -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
easier -X- _ O
/ -X- _ O
harder -X- _ O
to -X- _ O
predict -X- _ O
. -X- _ O
Figure -X- _ O
2 -X- _ O
contains -X- _ O
a -X- _ O
visualization -X- _ O
of -X- _ O
the -X- _ O
contingency -X- _ O
tables -X- _ O
of -X- _ O
the -X- _ O
well -X- _ O
/ -X- _ O
wrongly -X- _ O
predicted -X- _ O
pairs -X- _ O
by -X- _ O
relation -X- _ O
. -X- _ O
In -X- _ O
both -X- _ O
datasets -X- _ O
, -X- _ O
applying -X- _ O
a -X- _ O
χ -X- _ O
2 -X- _ O
-test -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
statistical -X- _ O
evidence -X- _ O
that -X- _ O
the -X- _ O
relation -X- _ O
type -X- _ O
influences -X- _ O
the -X- _ O
prediction -X- _ O
( -X- _ O
p -X- _ O
- -X- _ O
values -X- _ O
< -X- _ O
< -X- _ O
0.05 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
great -X- _ O
difference -X- _ O
in -X- _ O
the -X- _ O
predictions -X- _ O
for -X- _ O
antonyms -X- _ O
and -X- _ O
synonyms -X- _ O
, -X- _ O
the -X- _ O
former -X- _ O
being -X- _ O
better -X- _ O
predicted -X- _ O
than -X- _ O
the -X- _ O
latter -X- _ O
. -X- _ O

We -X- _ O
check -X- _ O
if -X- _ O
the -X- _ O
pairs -X- _ O
containing -X- _ O
polysemous -X- _ O
words -X- _ O
are -X- _ O
more -X- _ O
difficult -X- _ O
to -X- _ O
predict -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
Word -X- _ O
- -X- _ O
Net -X- _ O
to -X- _ O
obtain -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
synsets -X- _ O
for -X- _ O
each -X- _ O
word -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
consider -X- _ O
that -X- _ O
the -X- _ O
polysemous -X- _ O
level -X- _ O
of -X- _ O
a -X- _ O
pair -X- _ O
is -X- _ O
the -X- _ O
product -X- _ O
of -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
synsets -X- _ O
of -X- _ O
the -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
pair -X- _ O
. -X- _ O
Although -X- _ O
the -X- _ O
mean -X- _ O
of -X- _ O
the -X- _ O
polysemous -X- _ O
level -X- _ O
is -X- _ O
less -X- _ O
for -X- _ O
well -X- _ O
- -X- _ O
predicted -X- _ O
pairs -X- _ O
, -X- _ O
108.5 -X- _ O
vs. -X- _ O
120.6 -X- _ O
, -X- _ O
performing -X- _ O
a -X- _ O
Welch -X- _ O
's -X- _ O
t -X- _ O
- -X- _ O
test -X- _ O
to -X- _ O
evaluate -X- _ O
if -X- _ O
the -X- _ O
means -X- _ O
are -X- _ O
different -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
statistical -X- _ O
evidence -X- _ O
, -X- _ O
with -X- _ O
a -X- _ O
high -X- _ O
p -X- _ O
- -X- _ O
value -X- _ O
equal -X- _ O
to -X- _ O
0.40 -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
study -X- _ O
if -X- _ O
the -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
speech -X- _ O
( -X- _ O
POS -X- _ O
) -X- _ O
influences -X- _ O
the -X- _ O
predictions -X- _ O
. -X- _ O
CogALexV -X- _ B-DatasetName
and -X- _ O
EVA -X- _ B-DatasetName
- -X- _ I-DatasetName
Lution -X- _ I-DatasetName
datasets -X- _ O
are -X- _ O
also -X- _ O
annotated -X- _ O
with -X- _ O
the -X- _ O
predominant -X- _ O
POS -X- _ O
and -X- _ O
a -X- _ O
list -X- _ O
of -X- _ O
the -X- _ O
different -X- _ O
possible -X- _ O
POS -X- _ O
of -X- _ O
each -X- _ O
word -X- _ O
. -X- _ O
We -X- _ O
restrict -X- _ O
our -X- _ O
POS -X- _ O
study -X- _ O
to -X- _ O
the -X- _ O
well -X- _ O
/ -X- _ O
wrongly -X- _ O
predicted -X- _ O
pairs -X- _ O
where -X- _ O
both -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
pairs -X- _ O
have -X- _ O
the -X- _ O
same -X- _ O
predominant -X- _ O
POS -X- _ O
or -X- _ O
there -X- _ O
is -X- _ O
only -X- _ O
one -X- _ O
POS -X- _ O
in -X- _ O
the -X- _ O
intersection -X- _ O
lists -X- _ O
of -X- _ O
possible -X- _ O
POS -X- _ O
. -X- _ O
As -X- _ O
it -X- _ O
is -X- _ O
appreciated -X- _ O
in -X- _ O
the -X- _ O
contingency -X- _ O
table -X- _ O
( -X- _ O
Figure -X- _ O
3 -X- _ O
) -X- _ O
, -X- _ O
adjectives -X- _ O
are -X- _ O
easier -X- _ O
to -X- _ O
predict -X- _ O
than -X- _ O
nouns -X- _ O
and -X- _ O
verbs -X- _ O
. -X- _ O

The -X- _ O
domain -X- _ O
of -X- _ O
the -X- _ O
words -X- _ O
in -X- _ O
CogALexV -X- _ B-DatasetName
and -X- _ O
EVALution -X- _ B-DatasetName
were -X- _ O
annotated -X- _ O
by -X- _ O
humans -X- _ O
. -X- _ O
We -X- _ O
get -X- _ O
pairs -X- _ O
with -X- _ O
common -X- _ O
domains -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
restrict -X- _ O
the -X- _ O
study -X- _ O
to -X- _ O
the -X- _ O
most -X- _ O
common -X- _ O
domains -X- _ O
: -X- _ O
abstract -X- _ O
, -X- _ O
concrete -X- _ O
, -X- _ O
event -X- _ O
and -X- _ O
object -X- _ O
domains -X- _ O
. -X- _ O
The -X- _ O
visualization -X- _ O
of -X- _ O
the -X- _ O
contingency -X- _ O
table -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
in -X- _ O
Figure -X- _ O
4 -X- _ O
. -X- _ O
There -X- _ O
is -X- _ O
statistical -X- _ O
evidence -X- _ O
( -X- _ O
p -X- _ O
- -X- _ O
value -X- _ O
< -X- _ O
< -X- _ O
0.5 -X- _ O
) -X- _ O
that -X- _ O
the -X- _ O
domain -X- _ O
influences -X- _ O
the -X- _ O
correctness -X- _ O
of -X- _ O
the -X- _ O
prediction -X- _ O
: -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
abstract -X- _ O
and -X- _ O
object -X- _ O
domains -X- _ O
are -X- _ O
better -X- _ O
predicted -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
CogALexV -X- _ B-DatasetName
and -X- _ O
EVALution -X- _ B-DatasetName
were -X- _ O
annotated -X- _ O
by -X- _ O
humans -X- _ O
with -X- _ O
the -X- _ O
prototypicality -X- _ O
of -X- _ O
the -X- _ O
annotated -X- _ O
relation -X- _ O
. -X- _ O
The -X- _ O
pairs -X- _ O
of -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
datasets -X- _ O
were -X- _ O
exposed -X- _ O
to -X- _ O
five -X- _ O
humans -X- _ O
to -X- _ O
answer -X- _ O
to -X- _ O
what -X- _ O
extent -X- _ O
they -X- _ O
agreed -X- _ O
with -X- _ O
the -X- _ O
annotated -X- _ O
relation -X- _ O
( -X- _ O
from -X- _ O
0 -X- _ O
- -X- _ O
strongly -X- _ O
disagree -X- _ O
to -X- _ O
5 -X- _ O
- -X- _ O
strongly -X- _ O
agree -X- _ O
) -X- _ O
. -X- _ O
So -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
interesting -X- _ O
to -X- _ O
check -X- _ O
if -X- _ O
the -X- _ O
prototypicality -X- _ O
is -X- _ O
higher -X- _ O
for -X- _ O
well -X- _ O
- -X- _ O
predicted -X- _ O
pairs -X- _ O
. -X- _ O
We -X- _ O
perform -X- _ O
a -X- _ O
Welch -X- _ O
's -X- _ O
t -X- _ O
- -X- _ O
test -X- _ O
to -X- _ O
test -X- _ O
if -X- _ O
the -X- _ O
prototypicality -X- _ O
means -X- _ O
for -X- _ O
well -X- _ O
/ -X- _ O
wrongly -X- _ O
predicted -X- _ O
pairs -X- _ O
are -X- _ O
equal -X- _ O
. -X- _ O
We -X- _ O
get -X- _ O
that -X- _ O
well -X- _ O
/ -X- _ O
wrongly -X- _ O
means -X- _ O
are -X- _ O
4.63 -X- _ O
/ -X- _ O
4.51 -X- _ O
with -X- _ O
p -X- _ O
- -X- _ O
value -X- _ O
< -X- _ O
< -X- _ O
0.05 -X- _ O
, -X- _ O
so -X- _ O
they -X- _ O
are -X- _ O
different -X- _ O
. -X- _ O
Although -X- _ O
the -X- _ O
means -X- _ O
seem -X- _ O
quite -X- _ O
similar -X- _ O
, -X- _ O
take -X- _ O
into -X- _ O
account -X- _ O
that -X- _ O
about -X- _ O
90 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
prototypicality -X- _ O
in -X- _ O
the -X- _ O
datasets -X- _ O
range -X- _ O
from -X- _ O
4 -X- _ O
to -X- _ O
5 -X- _ O
. -X- _ O

C -X- _ O
Mask -X- _ O
Verbalizer -X- _ O

In -X- _ O
Table -X- _ O
7 -X- _ O
it -X- _ O
is -X- _ O
shown -X- _ O
the -X- _ O
used -X- _ O
tokens -X- _ O
to -X- _ O
verbalize -X- _ O
the -X- _ O
mask -X- _ O
token -X- _ O
in -X- _ O
templates -X- _ O
TM1 -X- _ O
, -X- _ O
TM2 -X- _ O
and -X- _ O
TM3 -X- _ O
. -X- _ O

D -X- _ O
Complete -X- _ O
Results -X- _ O

We -X- _ O
present -X- _ O
the -X- _ O
results -X- _ O
for -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
RoBERTa -X- _ B-MethodName
( -X- _ O
large -X- _ O
and -X- _ O
base -X- _ O
) -X- _ O
models -X- _ O
. -X- _ O
Table -X- _ O
8 -X- _ O
contains -X- _ O
the -X- _ O
mean -X- _ O
of -X- _ O
the -X- _ O
weighted -X- _ O
by -X- _ O
the -X- _ O
support -X- _ O
labels -X- _ O
of -X- _ O
precision -X- _ B-MetricName
of -X- _ O
the -X- _ O
5 -X- _ O
runs -X- _ O
, -X- _ O
recall -X- _ B-MetricName
and -X- _ O
F1 -X- _ B-MetricName
- -X- _ O
score -X- _ O
. -X- _ O
The -X- _ O
greatest -X- _ O
value -X- _ O
for -X- _ O
each -X- _ O
measure -X- _ O
( -X- _ O
column -X- _ O
) -X- _ O
is -X- _ O
underlined -X- _ O
. -X- _ O
A -X- _ O
value -X- _ O
is -X- _ O
boldened -X- _ O
if -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
statistical -X- _ O
evidence -X- _ O
to -X- _ O
be -X- _ O
different -X- _ O
from -X- _ O
the -X- _ O
greatest -X- _ O
one -X- _ O
performing -X- _ O
a -X- _ O
Welch -X- _ O
's -X- _ O
t -X- _ O
- -X- _ O
test -X- _ O
for -X- _ O
the -X- _ O
mean -X- _ O
values -X- _ O
. -X- _ O
A -X- _ O
similar -X- _ O
rationale -X- _ O
is -X- _ O
applied -X- _ O
for -X- _ O
Table -X- _ O
9 -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
complete -X- _ O
results -X- _ O
for -X- _ O
CogALexV -X- _ B-DatasetName
dataset -X- _ O
and -X- _ O
Table -X- _ O
10 -X- _ O
CogALexV -X- _ B-DatasetName
EVALution -X- _ B-DatasetName

