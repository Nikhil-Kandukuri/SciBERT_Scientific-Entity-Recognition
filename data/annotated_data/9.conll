-DOCSTART- -X- O
MINER -X- _ B-MethodName
: -X- _ O
Improving -X- _ O
Out -X- _ B-TaskName
- -X- _ I-TaskName
of -X- _ I-TaskName
- -X- _ I-TaskName
Vocabulary -X- _ I-TaskName
Named -X- _ I-TaskName
Entity -X- _ I-TaskName
Recognition -X- _ I-TaskName
from -X- _ O
an -X- _ O
Information -X- _ O
Theoretic -X- _ O
Perspective -X- _ O

NER -X- _ B-TaskName
model -X- _ O
has -X- _ O
achieved -X- _ O
promising -X- _ O
performance -X- _ O
on -X- _ O
standard -X- _ O
NER -X- _ B-TaskName
benchmarks -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
recent -X- _ O
studies -X- _ O
show -X- _ O
that -X- _ O
previous -X- _ O
approaches -X- _ O
may -X- _ O
over -X- _ O
- -X- _ O
rely -X- _ O
on -X- _ O
entity -X- _ O
mention -X- _ O
information -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
poor -X- _ O
performance -X- _ O
on -X- _ O
out -X- _ B-TaskName
- -X- _ I-TaskName
of -X- _ I-TaskName
- -X- _ I-TaskName
vocabulary -X- _ I-TaskName
( -X- _ I-TaskName
OOV -X- _ I-TaskName
) -X- _ I-TaskName
entity -X- _ I-TaskName
recognition -X- _ I-TaskName
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
MINER -X- _ B-MethodName
, -X- _ O
a -X- _ O
novel -X- _ O
NER -X- _ B-TaskName
learning -X- _ O
framework -X- _ O
, -X- _ O
to -X- _ O
remedy -X- _ O
this -X- _ O
issue -X- _ O
from -X- _ O
an -X- _ O
information -X- _ O
- -X- _ O
theoretic -X- _ O
perspective -X- _ O
. -X- _ O
The -X- _ O
proposed -X- _ O
approach -X- _ O
contains -X- _ O
two -X- _ O
mutual -X- _ O
information -X- _ O
- -X- _ O
based -X- _ O
training -X- _ O
objectives -X- _ O
: -X- _ O
i -X- _ O
) -X- _ O
generalizing -X- _ O
information -X- _ O
maximization -X- _ O
, -X- _ O
which -X- _ O
enhances -X- _ O
representation -X- _ O
via -X- _ O
deep -X- _ O
understanding -X- _ O
of -X- _ O
context -X- _ O
and -X- _ O
entity -X- _ O
surface -X- _ O
forms -X- _ O
; -X- _ O
ii -X- _ O
) -X- _ O
superfluous -X- _ O
information -X- _ O
minimization -X- _ O
, -X- _ O
which -X- _ O
discourages -X- _ O
representation -X- _ O
from -X- _ O
rote -X- _ O
memorizing -X- _ O
entity -X- _ O
names -X- _ O
or -X- _ O
exploiting -X- _ O
biased -X- _ O
cues -X- _ O
in -X- _ O
data -X- _ O
. -X- _ O
Experiments -X- _ O
on -X- _ O
various -X- _ O
settings -X- _ O
and -X- _ O
datasets -X- _ O
demonstrate -X- _ O
that -X- _ O
it -X- _ O
achieves -X- _ O
better -X- _ O
performance -X- _ O
in -X- _ O
predicting -X- _ O
OOV -X- _ O
entities -X- _ O
. -X- _ O

Introduction -X- _ O

Named -X- _ B-TaskName
Entity -X- _ I-TaskName
Recognition -X- _ I-TaskName
( -X- _ O
NER -X- _ B-TaskName
) -X- _ O
aims -X- _ O
to -X- _ O
identify -X- _ O
and -X- _ O
classify -X- _ O
entity -X- _ O
mentions -X- _ O
from -X- _ O
unstructured -X- _ O
text -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
extracting -X- _ O
location -X- _ O
mention -X- _ O
" -X- _ O
Berlin -X- _ O
" -X- _ O
from -X- _ O
the -X- _ O
sentence -X- _ O
" -X- _ O
Berlin -X- _ O
is -X- _ O
wonderful -X- _ O
in -X- _ O
the -X- _ O
winter -X- _ O
" -X- _ O
. -X- _ O
NER -X- _ B-TaskName
is -X- _ O
a -X- _ O
key -X- _ O
component -X- _ O
in -X- _ O
information -X- _ O
retrieval -X- _ O
( -X- _ O
Tan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
question -X- _ O
answering -X- _ O
( -X- _ O
Min -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
dialog -X- _ O
systems -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
Traditional -X- _ O
NER -X- _ B-TaskName
models -X- _ O
are -X- _ O
feature -X- _ O
- -X- _ O
engineering -X- _ O
and -X- _ O
machine -X- _ O
learning -X- _ O
based -X- _ O
( -X- _ O
Zhou -X- _ O
and -X- _ O
Su -X- _ O
, -X- _ O
2002 -X- _ O
; -X- _ O
Takeuchi -X- _ O
and -X- _ O
Collier -X- _ O
, -X- _ O
2002 -X- _ O
; -X- _ O
Agerri -X- _ O
and -X- _ O
Rigau -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
Benefiting -X- _ O
from -X- _ O
the -X- _ O
development -X- _ O
of -X- _ O
deep -X- _ O
learning -X- _ O
, -X- _ O
neuralnetwork -X- _ O
- -X- _ O
based -X- _ O
NER -X- _ B-TaskName
models -X- _ O
have -X- _ O
achieved -X- _ O
stateof -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
results -X- _ O
on -X- _ O
several -X- _ O
public -X- _ O
benchmarks -X- _ O
( -X- _ O
Lample -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Yamada -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Yan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

Recent -X- _ O
studies -X- _ O
( -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Agarwal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
show -X- _ O
that -X- _ O
, -X- _ O
context -X- _ O
does -X- _ O
influence -X- _ O
predictions -X- _ O
Table -X- _ O
1 -X- _ O
: -X- _ O
The -X- _ O
comparison -X- _ O
between -X- _ O
the -X- _ O
in -X- _ O
- -X- _ O
dictionary -X- _ O
and -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
dictionary -X- _ O
parts -X- _ O
of -X- _ O
the -X- _ O
CoNLL -X- _ B-DatasetName
2003 -X- _ I-DatasetName
baseline -X- _ O
( -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
was -X- _ O
tested -X- _ O
on -X- _ O
Bert -X- _ O
- -X- _ O
CRF -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
obvious -X- _ O
that -X- _ O
the -X- _ O
performance -X- _ O
gap -X- _ O
between -X- _ O
InDict -X- _ O
and -X- _ O
OutDict -X- _ O
is -X- _ O
significantly -X- _ O
large -X- _ O
. -X- _ O

of -X- _ O
NER -X- _ B-TaskName
models -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
main -X- _ O
factor -X- _ O
driving -X- _ O
high -X- _ O
performance -X- _ O
is -X- _ O
learning -X- _ O
the -X- _ O
named -X- _ O
tokens -X- _ O
themselves -X- _ O
. -X- _ O
Consequently -X- _ O
, -X- _ O
NER -X- _ B-TaskName
models -X- _ O
underperform -X- _ O
when -X- _ O
predicting -X- _ O
entities -X- _ O
that -X- _ O
have -X- _ O
not -X- _ O
been -X- _ O
seen -X- _ O
during -X- _ O
training -X- _ O
( -X- _ O
Fu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
referred -X- _ O
to -X- _ O
as -X- _ O
an -X- _ O
Out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
Vocabulary -X- _ O
( -X- _ O
OOV -X- _ O
) -X- _ O
problem -X- _ O
. -X- _ O

There -X- _ O
are -X- _ O
three -X- _ O
classical -X- _ O
strategies -X- _ O
to -X- _ O
alleviate -X- _ O
the -X- _ O
OOV -X- _ O
problem -X- _ O
: -X- _ O
external -X- _ O
knowledge -X- _ O
, -X- _ O
OOV -X- _ O
word -X- _ O
embedding -X- _ O
, -X- _ O
and -X- _ O
contextualized -X- _ O
embedding -X- _ O
. -X- _ O
The -X- _ O
first -X- _ O
one -X- _ O
is -X- _ O
to -X- _ O
introduce -X- _ O
additional -X- _ O
features -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
entity -X- _ O
lexicons -X- _ O
( -X- _ O
Zhang -X- _ O
and -X- _ O
Yang -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
part -X- _ O
- -X- _ O
ofspeech -X- _ O
tags -X- _ O
, -X- _ O
which -X- _ O
alleviates -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
dependence -X- _ O
on -X- _ O
word -X- _ O
embeddings -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
external -X- _ O
knowledge -X- _ O
is -X- _ O
not -X- _ O
always -X- _ O
easy -X- _ O
to -X- _ O
obtain -X- _ O
. -X- _ O
The -X- _ O
second -X- _ O
strategy -X- _ O
is -X- _ O
to -X- _ O
get -X- _ O
a -X- _ O
better -X- _ O
OOV -X- _ O
word -X- _ O
embedding -X- _ O
( -X- _ O
Peng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Fukuda -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
strategy -X- _ O
is -X- _ O
learning -X- _ O
a -X- _ O
static -X- _ O
OOV -X- _ O
embedding -X- _ O
representation -X- _ O
, -X- _ O
but -X- _ O
not -X- _ O
directly -X- _ O
utilizing -X- _ O
the -X- _ O
context -X- _ O
. -X- _ O
Last -X- _ O
one -X- _ O
is -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
ELMo -X- _ O
( -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
BERT -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
provide -X- _ O
contextualized -X- _ O
word -X- _ O
representations -X- _ O
. -X- _ O
Unfortunately -X- _ O
, -X- _ O
Agarwal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
shows -X- _ O
that -X- _ O
the -X- _ O
higher -X- _ O
performance -X- _ O
of -X- _ O
pretrained -X- _ O
models -X- _ O
could -X- _ O
be -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
learning -X- _ O
the -X- _ O
subword -X- _ O
structure -X- _ O
better -X- _ O
. -X- _ O

How -X- _ O
do -X- _ O
we -X- _ O
make -X- _ O
the -X- _ O
model -X- _ O
focus -X- _ O
on -X- _ O
contextual -X- _ O
information -X- _ O
to -X- _ O
tackle -X- _ O
the -X- _ O
OOV -X- _ O
problem -X- _ O
? -X- _ O
Motivated -X- _ O
by -X- _ O
the -X- _ O
information -X- _ O
bottleneck -X- _ O
principle -X- _ O
( -X- _ O
Tishby -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2000 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
learning -X- _ O
framework -X- _ O
-Mutual -X- _ B-MethodName
Information -X- _ I-MethodName
based -X- _ I-MethodName
Named -X- _ I-MethodName
Entity -X- _ I-MethodName
Recognition -X- _ I-MethodName
( -X- _ O
MINER -X- _ B-MethodName
) -X- _ O
. -X- _ O
The -X- _ O
proposed -X- _ O
method -X- _ O
provides -X- _ O
an -X- _ O
information -X- _ O
- -X- _ O
theoretic -X- _ O
perspective -X- _ O
to -X- _ O
the -X- _ O
OOV -X- _ O
problem -X- _ O
by -X- _ O
training -X- _ O
an -X- _ O
encoder -X- _ O
to -X- _ O
minimize -X- _ O
task -X- _ O
- -X- _ O
irrelevant -X- _ O
nuisances -X- _ O
while -X- _ O
keeping -X- _ O
predictive -X- _ O
information -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
MINER -X- _ B-MethodName
contains -X- _ O
two -X- _ O
mutual -X- _ O
information -X- _ O
based -X- _ O
learning -X- _ O
objectives -X- _ O
: -X- _ O
i -X- _ O
) -X- _ O
generalizing -X- _ O
information -X- _ O
maximization -X- _ O
, -X- _ O
which -X- _ O
aims -X- _ O
to -X- _ O
maximize -X- _ O
the -X- _ O
mutual -X- _ O
information -X- _ O
between -X- _ O
representations -X- _ O
and -X- _ O
well -X- _ O
- -X- _ O
generalizing -X- _ O
features -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
context -X- _ O
and -X- _ O
entity -X- _ O
surface -X- _ O
forms -X- _ O
; -X- _ O
ii -X- _ O
) -X- _ O
superfluous -X- _ O
information -X- _ O
minimization -X- _ O
, -X- _ O
which -X- _ O
prevents -X- _ O
the -X- _ O
model -X- _ O
from -X- _ O
rote -X- _ O
memorizing -X- _ O
the -X- _ O
entity -X- _ O
names -X- _ O
or -X- _ O
exploiting -X- _ O
biased -X- _ O
cues -X- _ O
via -X- _ O
eliminating -X- _ O
entity -X- _ O
name -X- _ O
information -X- _ O
. -X- _ O
Our -X- _ O
codes -X- _ O
1 -X- _ O
are -X- _ O
publicly -X- _ O
available -X- _ O
. -X- _ O

Our -X- _ O
main -X- _ O
contributions -X- _ O
are -X- _ O
summarized -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

1 -X- _ O
. -X- _ O
We -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
learning -X- _ O
framework -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
MINER -X- _ B-MethodName
, -X- _ O
from -X- _ O
an -X- _ O
information -X- _ O
theory -X- _ O
perspective -X- _ O
, -X- _ O
aiming -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
robustness -X- _ O
of -X- _ O
entity -X- _ O
changes -X- _ O
by -X- _ O
eliminating -X- _ O
entity -X- _ O
- -X- _ O
specific -X- _ O
and -X- _ O
maximizing -X- _ O
wellgeneralizing -X- _ O
information -X- _ O
. -X- _ O

2 -X- _ O
. -X- _ O
We -X- _ O
show -X- _ O
its -X- _ O
effectiveness -X- _ O
on -X- _ O
several -X- _ O
settings -X- _ O
and -X- _ O
benchmarks -X- _ O
, -X- _ O
and -X- _ O
suggest -X- _ O
that -X- _ O
MINER -X- _ B-MethodName
is -X- _ O
a -X- _ O
reliable -X- _ O
approach -X- _ O
to -X- _ O
better -X- _ O
OOV -X- _ B-TaskName
entity -X- _ I-TaskName
recognition -X- _ I-TaskName
. -X- _ O

Background -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
highlight -X- _ O
the -X- _ O
information -X- _ O
bottleneck -X- _ O
principle -X- _ O
. -X- _ O
Subsequently -X- _ O
, -X- _ O
the -X- _ O
analysis -X- _ O
of -X- _ O
possible -X- _ O
issues -X- _ O
was -X- _ O
provided -X- _ O
when -X- _ O
applying -X- _ O
it -X- _ O
to -X- _ O
OOV -X- _ B-TaskName
entity -X- _ I-TaskName
recognition -X- _ I-TaskName
. -X- _ O
Furthermore -X- _ O
, -X- _ O
we -X- _ O
review -X- _ O
related -X- _ O
techniques -X- _ O
in -X- _ O
deriving -X- _ O
our -X- _ O
framework -X- _ O
. -X- _ O

Information -X- _ O
Bottleneck -X- _ O
( -X- _ O
IB -X- _ O
) -X- _ O
principle -X- _ O
originated -X- _ O
in -X- _ O
information -X- _ O
theory -X- _ O
, -X- _ O
and -X- _ O
provides -X- _ O
a -X- _ O
theoretical -X- _ O
framework -X- _ O
for -X- _ O
analyzing -X- _ O
deep -X- _ O
neural -X- _ O
networks -X- _ O
. -X- _ O
It -X- _ O
formulates -X- _ O
the -X- _ O
goal -X- _ O
of -X- _ O
representation -X- _ O
learning -X- _ O
as -X- _ O
an -X- _ O
information -X- _ O
trade -X- _ O
- -X- _ O
off -X- _ O
between -X- _ O
predictive -X- _ O
power -X- _ O
and -X- _ O
representation -X- _ O
compression -X- _ O
. -X- _ O
Given -X- _ O
the -X- _ O
input -X- _ O
dataset -X- _ O
( -X- _ O
X -X- _ O
, -X- _ O
Y -X- _ O
) -X- _ O
, -X- _ O
it -X- _ O
seeks -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
internal -X- _ O
representation -X- _ O
Z -X- _ O
of -X- _ O
some -X- _ O
intermediate -X- _ O
layers -X- _ O
by -X- _ O
: -X- _ O

L -X- _ O
IB -X- _ O
= -X- _ O
−I -X- _ O
( -X- _ O
Z -X- _ O
; -X- _ O
Y -X- _ O
) -X- _ O
+ -X- _ O
β -X- _ O
* -X- _ O
I -X- _ O
( -X- _ O
Z -X- _ O
; -X- _ O
X -X- _ O
) -X- _ O
, -X- _ O

where -X- _ O
I -X- _ O
represents -X- _ O
the -X- _ O
mutual -X- _ O
information -X- _ O
( -X- _ O
MI -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
measure -X- _ O
of -X- _ O
the -X- _ O
mutual -X- _ O
dependence -X- _ O
between -X- _ O
the -X- _ O
two -X- _ O
variables -X- _ O
. -X- _ O
The -X- _ O
trade -X- _ O
- -X- _ O
off -X- _ O
between -X- _ O
the -X- _ O
two -X- _ O
MI -X- _ O
terms -X- _ O
1 -X- _ O
https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
github.com -X- _ O
/ -X- _ O
BeyonderXX -X- _ O
/ -X- _ O
MINER -X- _ B-MethodName
is -X- _ O
controlled -X- _ O
by -X- _ O
the -X- _ O
Lagrange -X- _ O
multiplier -X- _ O
β -X- _ O
. -X- _ O
A -X- _ O
low -X- _ O
loss -X- _ O
indicates -X- _ O
that -X- _ O
representation -X- _ O
Z -X- _ O
does -X- _ O
not -X- _ O
keep -X- _ O
too -X- _ O
much -X- _ O
information -X- _ O
from -X- _ O
X -X- _ O
while -X- _ O
still -X- _ O
retaining -X- _ O
enough -X- _ O
information -X- _ O
to -X- _ O
predict -X- _ O
Y. -X- _ O
Section -X- _ O
5 -X- _ O
suggests -X- _ O
that -X- _ O
directly -X- _ O
applying -X- _ O
IB -X- _ O
to -X- _ O
NER -X- _ B-TaskName
can -X- _ O
not -X- _ O
bring -X- _ O
obvious -X- _ O
improvement -X- _ O
. -X- _ O
We -X- _ O
argue -X- _ O
that -X- _ O
IB -X- _ O
can -X- _ O
not -X- _ O
guarantee -X- _ O
well -X- _ O
- -X- _ O
generalizing -X- _ O
representation -X- _ O
. -X- _ O

On -X- _ O
the -X- _ O
one -X- _ O
hand -X- _ O
, -X- _ O
it -X- _ O
has -X- _ O
been -X- _ O
shown -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
challenging -X- _ O
to -X- _ O
find -X- _ O
a -X- _ O
trade -X- _ O
- -X- _ O
off -X- _ O
between -X- _ O
high -X- _ O
compression -X- _ O
and -X- _ O
high -X- _ O
predictive -X- _ O
power -X- _ O
( -X- _ O
Tishby -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2000 -X- _ O
; -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Piran -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
When -X- _ O
compressing -X- _ O
task -X- _ O
- -X- _ O
irrelevant -X- _ O
nuisances -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
useful -X- _ O
information -X- _ O
will -X- _ O
inevitably -X- _ O
be -X- _ O
left -X- _ O
out -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
unclear -X- _ O
for -X- _ O
the -X- _ O
IB -X- _ O
principle -X- _ O
which -X- _ O
parts -X- _ O
of -X- _ O
features -X- _ O
are -X- _ O
well -X- _ O
- -X- _ O
generalizing -X- _ O
and -X- _ O
which -X- _ O
are -X- _ O
not -X- _ O
, -X- _ O
as -X- _ O
we -X- _ O
usually -X- _ O
train -X- _ O
a -X- _ O
classifier -X- _ O
to -X- _ O
solely -X- _ O
maximize -X- _ O
accuracy -X- _ O
. -X- _ O
Consequently -X- _ O
, -X- _ O
neural -X- _ O
networks -X- _ O
tend -X- _ O
to -X- _ O
use -X- _ O
any -X- _ O
accessible -X- _ O
signal -X- _ O
to -X- _ O
do -X- _ O
so -X- _ O
( -X- _ O
Ilyas -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
referred -X- _ O
to -X- _ O
as -X- _ O
a -X- _ O
shortcut -X- _ O
learning -X- _ O
problem -X- _ O
( -X- _ O
Geirhos -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

For -X- _ O
training -X- _ O
sets -X- _ O
with -X- _ O
limited -X- _ O
size -X- _ O
, -X- _ O
it -X- _ O
may -X- _ O
be -X- _ O
easier -X- _ O
for -X- _ O
neural -X- _ O
networks -X- _ O
to -X- _ O
memorize -X- _ O
entity -X- _ O
names -X- _ O
rather -X- _ O
than -X- _ O
to -X- _ O
classify -X- _ O
them -X- _ O
by -X- _ O
context -X- _ O
and -X- _ O
common -X- _ O
entity -X- _ O
features -X- _ O
( -X- _ O
Agarwal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
Section -X- _ O
4 -X- _ O
, -X- _ O
we -X- _ O
demonstrate -X- _ O
how -X- _ O
we -X- _ O
extend -X- _ O
IB -X- _ O
to -X- _ O
the -X- _ O
NER -X- _ B-TaskName
task -X- _ O
and -X- _ O
address -X- _ O
these -X- _ O
issues -X- _ O
. -X- _ O

Model -X- _ O
Architecture -X- _ O

In -X- _ O
recent -X- _ O
years -X- _ O
, -X- _ O
NER -X- _ B-TaskName
systems -X- _ O
have -X- _ O
undergone -X- _ O
a -X- _ O
paradigm -X- _ O
shift -X- _ O
from -X- _ O
sequence -X- _ O
labeling -X- _ O
, -X- _ O
which -X- _ O
formulates -X- _ O
NER -X- _ B-TaskName
as -X- _ O
a -X- _ O
token -X- _ O
- -X- _ O
level -X- _ O
tagging -X- _ O
task -X- _ O
( -X- _ O
Chiu -X- _ O
and -X- _ O
Nichols -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Akbik -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Yan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
to -X- _ O
span -X- _ O
prediction -X- _ O
( -X- _ O
SpanNER -X- _ B-MethodName
) -X- _ O
, -X- _ O
which -X- _ O
regards -X- _ O
NER -X- _ B-TaskName
as -X- _ O
a -X- _ O
span -X- _ O
- -X- _ O
level -X- _ O
classification -X- _ O
task -X- _ O
( -X- _ O
Mengge -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Yamada -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Fu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
choose -X- _ O
SpanNER -X- _ B-MethodName
as -X- _ O
base -X- _ O
architecture -X- _ O
for -X- _ O
two -X- _ O
reasons -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
SpanNER -X- _ B-MethodName
can -X- _ O
yield -X- _ O
the -X- _ O
whole -X- _ O
span -X- _ O
representation -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
directly -X- _ O
used -X- _ O
for -X- _ O
optimize -X- _ O
information -X- _ O
. -X- _ O
2 -X- _ O
) -X- _ O
Compared -X- _ O
with -X- _ O
sequence -X- _ O
labeling -X- _ O
, -X- _ O
SpanNER -X- _ B-MethodName
does -X- _ O
better -X- _ O
in -X- _ O
sentences -X- _ O
with -X- _ O
more -X- _ O
OOV -X- _ O
words -X- _ O
( -X- _ O
Fu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

Overall -X- _ O
, -X- _ O
SpanNER -X- _ B-MethodName
consists -X- _ O
of -X- _ O
three -X- _ O
major -X- _ O
modules -X- _ O
: -X- _ O
token -X- _ O
representation -X- _ O
layer -X- _ O
, -X- _ O
span -X- _ O
representation -X- _ O
layer -X- _ O
, -X- _ O
and -X- _ O
span -X- _ O
classification -X- _ O
layer -X- _ O
. -X- _ O
Besides -X- _ O
, -X- _ O
our -X- _ O
method -X- _ O
inserts -X- _ O
a -X- _ O
bottleneck -X- _ O
layer -X- _ O
to -X- _ O
the -X- _ O
architecture -X- _ O
for -X- _ O
information -X- _ O
optimization -X- _ O
. -X- _ O

Token -X- _ O
Representation -X- _ O
Layer -X- _ O

Let -X- _ O
X -X- _ O
= -X- _ O
{ -X- _ O
x -X- _ O
1 -X- _ O
, -X- _ O
x -X- _ O
2 -X- _ O
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
x -X- _ O
n -X- _ O
} -X- _ O
represents -X- _ O
the -X- _ O
input -X- _ O
sentence -X- _ O
, -X- _ O
thus -X- _ O
, -X- _ O
the -X- _ O
token -X- _ O
representation -X- _ O
h -X- _ O
i -X- _ O
is -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

u -X- _ O
1 -X- _ O
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
u -X- _ O
n -X- _ O
= -X- _ O
Embedding -X- _ O
( -X- _ O
x -X- _ O
1 -X- _ O
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
x -X- _ O
n -X- _ O
) -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
h -X- _ O
1 -X- _ O
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
h -X- _ O
n -X- _ O
= -X- _ O
Encoder -X- _ O
( -X- _ O
u -X- _ O
1 -X- _ O
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
u -X- _ O
n -X- _ O
) -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O

where -X- _ O
Embedding -X- _ O
( -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
non -X- _ O
- -X- _ O
contextualized -X- _ O
word -X- _ O
embeddings -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
Glove -X- _ O
( -X- _ O
Pennington -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
or -X- _ O
contextualized -X- _ O
word -X- _ O
embeddings -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
ELMo -X- _ O
( -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
BERT -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
Encoder -X- _ O
( -X- _ O
) -X- _ O
can -X- _ O
be -X- _ O
any -X- _ O
network -X- _ O
structures -X- _ O
with -X- _ O
context -X- _ O
encoding -X- _ O
function -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
LSTM -X- _ O
( -X- _ O
Hochreiter -X- _ O
and -X- _ O
Schmidhuber -X- _ O
, -X- _ O
1997 -X- _ O
) -X- _ O
, -X- _ O
CNN -X- _ O
( -X- _ O
LeCun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
1995 -X- _ O
) -X- _ O
, -X- _ O
transformer -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
so -X- _ O
on -X- _ O
. -X- _ O

Span -X- _ O
Representation -X- _ O
Layer -X- _ O

For -X- _ O
all -X- _ O
possible -X- _ O
spans -X- _ O
S -X- _ O
= -X- _ O
{ -X- _ O
s -X- _ O
1 -X- _ O
, -X- _ O
s -X- _ O
2 -X- _ O
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
s -X- _ O
m -X- _ O
} -X- _ O
of -X- _ O
sentence -X- _ O
X -X- _ O
, -X- _ O
we -X- _ O
re -X- _ O
- -X- _ O
assign -X- _ O
a -X- _ O
label -X- _ O
y -X- _ O
∈ -X- _ O
Y -X- _ O
for -X- _ O
each -X- _ O
span -X- _ O
. -X- _ O
Take -X- _ O
" -X- _ O
Berlin -X- _ O
is -X- _ O
wonderful -X- _ O
" -X- _ O
as -X- _ O
an -X- _ O
example -X- _ O
, -X- _ O
its -X- _ O
possible -X- _ O
spans -X- _ O
and -X- _ O
labels -X- _ O
are -X- _ O

{ -X- _ O
( -X- _ O
1 -X- _ O
, -X- _ O
1 -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
1 -X- _ O
, -X- _ O
2 -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
1 -X- _ O
, -X- _ O
3 -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
2 -X- _ O
, -X- _ O
2 -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
2 -X- _ O
, -X- _ O
3 -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
3 -X- _ O
, -X- _ O
3 -X- _ O
) -X- _ O
} -X- _ O
and -X- _ O
{ -X- _ O
LOC -X- _ O
, -X- _ O
O -X- _ O
, -X- _ O
O -X- _ O
, -X- _ O
O -X- _ O
, -X- _ O
O -X- _ O
, -X- _ O
O -X- _ O
} -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O

Given -X- _ O
the -X- _ O
start -X- _ O
index -X- _ O
b -X- _ O
i -X- _ O
and -X- _ O
end -X- _ O
index -X- _ O
e -X- _ O
i -X- _ O
, -X- _ O
the -X- _ O
representation -X- _ O
of -X- _ O
span -X- _ O
s -X- _ O
i -X- _ O
can -X- _ O
be -X- _ O
calculated -X- _ O
by -X- _ O
two -X- _ O
parts -X- _ O
: -X- _ O
boundary -X- _ O
embedding -X- _ O
and -X- _ O
span -X- _ O
length -X- _ O
embedding -X- _ O
. -X- _ O

Boundary -X- _ O
embedding -X- _ O
: -X- _ O
This -X- _ O
part -X- _ O
is -X- _ O
calculated -X- _ O
by -X- _ O
concatenating -X- _ O
the -X- _ O
start -X- _ O
and -X- _ O
end -X- _ O
tokens -X- _ O
' -X- _ O
representation -X- _ O

t -X- _ O
b -X- _ O
i -X- _ O
= -X- _ O
[ -X- _ O
h -X- _ O
b -X- _ O
i -X- _ O
; -X- _ O
h -X- _ O
e -X- _ O
i -X- _ O
] -X- _ O
. -X- _ O

Span -X- _ O
length -X- _ O
embedding -X- _ O
: -X- _ O

In -X- _ O
order -X- _ O
to -X- _ O
introduce -X- _ O
the -X- _ O
length -X- _ O
feature -X- _ O
, -X- _ O
we -X- _ O
additionally -X- _ O
provide -X- _ O
the -X- _ O
length -X- _ O
embedding -X- _ O
t -X- _ O
l -X- _ O
i -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
obtained -X- _ O
by -X- _ O
a -X- _ O
learnable -X- _ O
look -X- _ O
- -X- _ O
up -X- _ O
table -X- _ O
. -X- _ O

Finally -X- _ O
, -X- _ O
the -X- _ O
span -X- _ O
representation -X- _ O
can -X- _ O
be -X- _ O
obtained -X- _ O
as -X- _ O
: -X- _ O

t -X- _ O
i -X- _ O
= -X- _ O
[ -X- _ O
t -X- _ O
b -X- _ O
i -X- _ O
; -X- _ O
t -X- _ O
l -X- _ O
i -X- _ O
] -X- _ O
. -X- _ O

Information -X- _ O
Bottleneck -X- _ O
Layer -X- _ O

In -X- _ O
order -X- _ O
to -X- _ O
optimize -X- _ O
the -X- _ O
information -X- _ O
in -X- _ O
the -X- _ O
span -X- _ O
representation -X- _ O
, -X- _ O
our -X- _ O
method -X- _ O
additionally -X- _ O
adds -X- _ O
an -X- _ O
information -X- _ O
bottleneck -X- _ O
layer -X- _ O
of -X- _ O
the -X- _ O
form -X- _ O
: -X- _ O

p -X- _ O
( -X- _ O
z|t -X- _ O
) -X- _ O
= -X- _ O
N -X- _ O
z -X- _ O
| -X- _ O
f -X- _ O
µ -X- _ O
e -X- _ O
( -X- _ O
t -X- _ O
) -X- _ O
, -X- _ O
f -X- _ O
Σ -X- _ O
e -X- _ O
( -X- _ O
t -X- _ O
) -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O

where -X- _ O
f -X- _ O
e -X- _ O
is -X- _ O
an -X- _ O
MLP -X- _ O
which -X- _ O
outputs -X- _ O
both -X- _ O
the -X- _ O
Kdimensional -X- _ O
mean -X- _ O
µ -X- _ O
of -X- _ O
z -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
K -X- _ O
* -X- _ O
K -X- _ O
covariance -X- _ O
matrix -X- _ O
Σ. -X- _ O
Then -X- _ O
we -X- _ O
can -X- _ O
use -X- _ O
the -X- _ O
reparameterization -X- _ O
trick -X- _ O
( -X- _ O
( -X- _ O
Kingma -X- _ O
and -X- _ O
Welling -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
) -X- _ O
to -X- _ O
get -X- _ O
the -X- _ O
compressed -X- _ O
representation -X- _ O
z -X- _ O
i -X- _ O
. -X- _ O

Span -X- _ O
Classification -X- _ O
Layer -X- _ O

Once -X- _ O
the -X- _ O
information -X- _ O
bottleneck -X- _ O
layer -X- _ O
is -X- _ O
finished -X- _ O
, -X- _ O
z -X- _ O
i -X- _ O
is -X- _ O
fed -X- _ O
into -X- _ O
the -X- _ O
classifier -X- _ O
to -X- _ O
obtain -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
its -X- _ O
label -X- _ O
y -X- _ O
i -X- _ O
. -X- _ O
Based -X- _ O
on -X- _ O
the -X- _ O
probability -X- _ O
, -X- _ O
the -X- _ O
basic -X- _ O
loss -X- _ O
function -X- _ O
can -X- _ O
be -X- _ O
calculated -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

L -X- _ O
base -X- _ O
= -X- _ O
− -X- _ O
score -X- _ O
( -X- _ O
z -X- _ O
i -X- _ O
, -X- _ O
y -X- _ O
i -X- _ O
) -X- _ O
y -X- _ O
′ -X- _ O
∈Y -X- _ O
score -X- _ O
( -X- _ O
z -X- _ O
i -X- _ O
, -X- _ O
y -X- _ O
′ -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O

where -X- _ O
score -X- _ O
( -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
function -X- _ O
that -X- _ O
measures -X- _ O
the -X- _ O
compatibility -X- _ O
between -X- _ O
a -X- _ O
specified -X- _ O
label -X- _ O
and -X- _ O
a -X- _ O
span -X- _ O
representation -X- _ O
: -X- _ O

score -X- _ O
( -X- _ O
z -X- _ O
i -X- _ O
, -X- _ O
y -X- _ O
k -X- _ O
) -X- _ O
= -X- _ O
exp -X- _ O
( -X- _ O
z -X- _ O
T -X- _ O
i -X- _ O
y -X- _ O
k -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
5 -X- _ O
) -X- _ O

where -X- _ O
y -X- _ O
k -X- _ O
is -X- _ O
a -X- _ O
learnable -X- _ O
representation -X- _ O
of -X- _ O
class -X- _ O
k. -X- _ O
Heuristic -X- _ O
Decoding -X- _ O
A -X- _ O
heuristic -X- _ O
decoding -X- _ O
solution -X- _ O
for -X- _ O
the -X- _ O
flat -X- _ O
NER -X- _ B-TaskName
is -X- _ O
provided -X- _ O
to -X- _ O
avoid -X- _ O
the -X- _ O
prediction -X- _ O
of -X- _ O
over -X- _ O
- -X- _ O
lapped -X- _ O
spans -X- _ O
. -X- _ O
For -X- _ O
those -X- _ O
overlapped -X- _ O
spans -X- _ O
, -X- _ O
we -X- _ O
keep -X- _ O
the -X- _ O
span -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
prediction -X- _ O
probability -X- _ O
and -X- _ O
drop -X- _ O
the -X- _ O
others -X- _ O
. -X- _ O

It -X- _ O
's -X- _ O
worth -X- _ O
noting -X- _ O
that -X- _ O
our -X- _ O
method -X- _ O
is -X- _ O
flexible -X- _ O
and -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
with -X- _ O
any -X- _ O
other -X- _ O
NER -X- _ B-TaskName
model -X- _ O
based -X- _ O
on -X- _ O
span -X- _ O
classification -X- _ O
. -X- _ O
In -X- _ O
next -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
introduce -X- _ O
two -X- _ O
additional -X- _ O
objectives -X- _ O
to -X- _ O
tackle -X- _ O
the -X- _ O
OOV -X- _ O
problem -X- _ O
of -X- _ O
NER -X- _ B-TaskName
. -X- _ O

MI -X- _ O
- -X- _ O
based -X- _ O
objectives -X- _ O

Motivated -X- _ O
by -X- _ O
IB -X- _ O
( -X- _ O
Tishby -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2000 -X- _ O
; -X- _ O
Federici -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
subdivide -X- _ O
I -X- _ O
( -X- _ O
X -X- _ O
; -X- _ O
Z -X- _ O
) -X- _ O
into -X- _ O
two -X- _ O
components -X- _ O
by -X- _ O
using -X- _ O
the -X- _ O
chain -X- _ O
rule -X- _ O
of -X- _ O
mutual -X- _ O
information -X- _ O
( -X- _ O
MI -X- _ O
) -X- _ O
: -X- _ O

I -X- _ O
( -X- _ O
X -X- _ O
; -X- _ O
Z -X- _ O
) -X- _ O
= -X- _ O
I -X- _ O
( -X- _ O
Y -X- _ O
; -X- _ O
Z -X- _ O
) -X- _ O
predictive -X- _ O
+ -X- _ O
I -X- _ O
( -X- _ O
X -X- _ O
; -X- _ O
Z|Y -X- _ O
) -X- _ O
superf -X- _ O
luous -X- _ O
, -X- _ O
( -X- _ O
6 -X- _ O
) -X- _ O

The -X- _ O
first -X- _ O
term -X- _ O
determines -X- _ O
how -X- _ O
much -X- _ O
information -X- _ O
about -X- _ O
Y -X- _ O
is -X- _ O
accessible -X- _ O
from -X- _ O
Z. -X- _ O
While -X- _ O
the -X- _ O
second -X- _ O
term -X- _ O
, -X- _ O
conditional -X- _ O
mutual -X- _ O
information -X- _ O
term -X- _ O
I -X- _ O
( -X- _ O
X -X- _ O
; -X- _ O
Z|Y -X- _ O
) -X- _ O
, -X- _ O
denotes -X- _ O
the -X- _ O
information -X- _ O
in -X- _ O
Z -X- _ O
that -X- _ O
is -X- _ O
not -X- _ O
predictive -X- _ O
of -X- _ O
Y -X- _ O
. -X- _ O

For -X- _ O
NER -X- _ B-TaskName
, -X- _ O
which -X- _ O
parts -X- _ O
of -X- _ O
the -X- _ O
information -X- _ O
retrieved -X- _ O
from -X- _ O
input -X- _ O
are -X- _ O
useful -X- _ O
and -X- _ O
which -X- _ O
are -X- _ O
redundant -X- _ O
? -X- _ O

From -X- _ O
human -X- _ O
intuition -X- _ O
, -X- _ O
text -X- _ O
context -X- _ O
should -X- _ O
be -X- _ O
the -X- _ O
main -X- _ O
predictive -X- _ O
information -X- _ O
for -X- _ O
NER -X- _ B-TaskName
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
" -X- _ O
The -X- _ O
CEO -X- _ O
of -X- _ O
X -X- _ O
resigned -X- _ O
" -X- _ O
, -X- _ O
the -X- _ O
type -X- _ O
of -X- _ O
X -X- _ O
in -X- _ O
each -X- _ O
of -X- _ O
these -X- _ O
contexts -X- _ O
should -X- _ O
always -X- _ O
be -X- _ O
" -X- _ O
ORG -X- _ O
" -X- _ O
. -X- _ O
Besides -X- _ O
, -X- _ O
entity -X- _ O
mentions -X- _ O
also -X- _ O
provide -X- _ O
much -X- _ O
information -X- _ O
for -X- _ O
entity -X- _ O
recognition -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
nearly -X- _ O
all -X- _ O
person -X- _ O
names -X- _ O
capitalize -X- _ O
the -X- _ O
first -X- _ O
letter -X- _ O
and -X- _ O
follow -X- _ O
the -X- _ O
" -X- _ O
firstName -X- _ O
lastName -X- _ O
" -X- _ O
or -X- _ O
" -X- _ O
lastName -X- _ O

! -X- _ O
! -X- _ O
" -X- _ O
Encoder -X- _ O
Encoder -X- _ O
Shared -X- _ O
IB -X- _ O
Shared -X- _ O
! -X- _ O
~ -X- _ O
( -X- _ O
! -X- _ O
| -X- _ O
! -X- _ O
) -X- _ O
" -X- _ O
~ -X- _ O
( -X- _ O
" -X- _ O
| -X- _ O
" -X- _ O
) -X- _ O
" -X- _ O
min -X- _ O
# -X- _ O
$ -X- _ O
Classifier -X- _ O
Shared -X- _ O
IB -X- _ O
Classifier -X- _ O
max -X- _ O
( -X- _ O
! -X- _ O
; -X- _ O
" -X- _ O
) -X- _ O

Figure -X- _ O
1 -X- _ O
: -X- _ O
Visualization -X- _ O
of -X- _ O
MINER -X- _ B-MethodName
, -X- _ O
where -X- _ O
x -X- _ O
1 -X- _ O
and -X- _ O
x -X- _ O
2 -X- _ O
share -X- _ O
the -X- _ O
same -X- _ O
context -X- _ O
and -X- _ O
entity -X- _ O
labels -X- _ O
, -X- _ O
while -X- _ O
their -X- _ O
entity -X- _ O
words -X- _ O
are -X- _ O
different -X- _ O
. -X- _ O
z -X- _ O
1 -X- _ O
and -X- _ O
z -X- _ O
2 -X- _ O
are -X- _ O
compressed -X- _ O
entity -X- _ O
representations -X- _ O
sampled -X- _ O
by -X- _ O
p -X- _ O
( -X- _ O
z -X- _ O
1 -X- _ O
|x -X- _ O
1 -X- _ O
) -X- _ O
and -X- _ O
p -X- _ O
( -X- _ O
z -X- _ O
2 -X- _ O
|x -X- _ O
2 -X- _ O
) -X- _ O
, -X- _ O
respectively -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
implemented -X- _ O
by -X- _ O
information -X- _ O
bottleneck -X- _ O
( -X- _ O
IB -X- _ O
) -X- _ O
layer -X- _ O
. -X- _ O
Our -X- _ O
method -X- _ O
add -X- _ O
two -X- _ O
additional -X- _ O
learning -X- _ O
objectives -X- _ O
to -X- _ O
basic -X- _ O
architecture -X- _ O
. -X- _ O
The -X- _ O
first -X- _ O
one -X- _ O
is -X- _ O
to -X- _ O
maximize -X- _ O
the -X- _ O
mutual -X- _ O
information -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
I -X- _ O
( -X- _ O
z -X- _ O
1 -X- _ O
; -X- _ O
z -X- _ O
2 -X- _ O
) -X- _ O
, -X- _ O
to -X- _ O
enhance -X- _ O
context -X- _ O
information -X- _ O
and -X- _ O
entity -X- _ O
surface -X- _ O
form -X- _ O
information -X- _ O
of -X- _ O
z -X- _ O
1 -X- _ O
and -X- _ O
z -X- _ O
2 -X- _ O
. -X- _ O
The -X- _ O
second -X- _ O
objective -X- _ O
is -X- _ O
to -X- _ O
minimize -X- _ O
the -X- _ O
Jensen -X- _ O
- -X- _ O
Shannon -X- _ O
divergence -X- _ O
, -X- _ O
representing -X- _ O
an -X- _ O
upper -X- _ O
bound -X- _ O
of -X- _ O
I -X- _ O
( -X- _ O
x -X- _ O
1 -X- _ O
; -X- _ O
z -X- _ O
1 -X- _ O
|x -X- _ O
2 -X- _ O
) -X- _ O
, -X- _ O
aiming -X- _ O
to -X- _ O
eliminate -X- _ O
task -X- _ O
- -X- _ O
irrelevant -X- _ O
nuisances -X- _ O
. -X- _ O

firstName -X- _ O
" -X- _ O
patterns -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
entity -X- _ O
name -X- _ O
is -X- _ O
not -X- _ O
a -X- _ O
well -X- _ O
- -X- _ O
generalizing -X- _ O
features -X- _ O
. -X- _ O
By -X- _ O
simply -X- _ O
memorizing -X- _ O
the -X- _ O
fact -X- _ O
which -X- _ O
span -X- _ O
is -X- _ O
an -X- _ O
entity -X- _ O
, -X- _ O
it -X- _ O
may -X- _ O
be -X- _ O
possible -X- _ O
for -X- _ O
it -X- _ O
to -X- _ O
fit -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
, -X- _ O
but -X- _ O
it -X- _ O
is -X- _ O
impossible -X- _ O
to -X- _ O
predict -X- _ O
entities -X- _ O
that -X- _ O
have -X- _ O
never -X- _ O
been -X- _ O
seen -X- _ O
before -X- _ O
. -X- _ O

We -X- _ O
convert -X- _ O
the -X- _ O
targets -X- _ O
of -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
6 -X- _ O
) -X- _ O
into -X- _ O
a -X- _ O
form -X- _ O
that -X- _ O
is -X- _ O
easier -X- _ O
to -X- _ O
solve -X- _ O
via -X- _ O
a -X- _ O
contrastive -X- _ O
strategy -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
consider -X- _ O
x -X- _ O
1 -X- _ O
and -X- _ O
x -X- _ O
2 -X- _ O
are -X- _ O
two -X- _ O
contrastive -X- _ O
samples -X- _ O
of -X- _ O
similar -X- _ O
context -X- _ O
, -X- _ O
and -X- _ O
contains -X- _ O
different -X- _ O
entity -X- _ O
mentions -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
entity -X- _ O
category -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
s -X- _ O
1 -X- _ O
and -X- _ O
s -X- _ O
2 -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
Assuming -X- _ O
both -X- _ O
x -X- _ O
1 -X- _ O
and -X- _ O
x -X- _ O
2 -X- _ O
are -X- _ O
both -X- _ O
sufficient -X- _ O
for -X- _ O
inferring -X- _ O
label -X- _ O
y. -X- _ O
The -X- _ O
mutual -X- _ O
information -X- _ O
between -X- _ O
x -X- _ O
1 -X- _ O
and -X- _ O
z -X- _ O
1 -X- _ O
can -X- _ O
be -X- _ O
factorized -X- _ O
to -X- _ O
two -X- _ O
parts -X- _ O
. -X- _ O

I -X- _ O
( -X- _ O
x -X- _ O
1 -X- _ O
; -X- _ O
z -X- _ O
1 -X- _ O
) -X- _ O
= -X- _ O
I -X- _ O
( -X- _ O
z -X- _ O
1 -X- _ O
; -X- _ O
x -X- _ O
2 -X- _ O
) -X- _ O
consistent -X- _ O
+ -X- _ O
I -X- _ O
( -X- _ O
x -X- _ O
1 -X- _ O
; -X- _ O
z -X- _ O
1 -X- _ O
|x -X- _ O
2 -X- _ O
) -X- _ O
specif -X- _ O
ic -X- _ O
, -X- _ O
( -X- _ O
7 -X- _ O
) -X- _ O

where -X- _ O
z -X- _ O
1 -X- _ O
and -X- _ O
z -X- _ O
2 -X- _ O
are -X- _ O
span -X- _ O
representations -X- _ O
of -X- _ O
s -X- _ O
1 -X- _ O
and -X- _ O
s -X- _ O
2 -X- _ O
, -X- _ O
respectively -X- _ O
, -X- _ O
I -X- _ O
( -X- _ O
z -X- _ O
1 -X- _ O
; -X- _ O
x -X- _ O
2 -X- _ O
) -X- _ O
denotes -X- _ O
the -X- _ O
information -X- _ O
that -X- _ O
is -X- _ O
n't -X- _ O
entity -X- _ O
- -X- _ O
specific -X- _ O
. -X- _ O
And -X- _ O
I -X- _ O
( -X- _ O
x -X- _ O
1 -X- _ O
; -X- _ O
z -X- _ O
1 -X- _ O
|x -X- _ O
2 -X- _ O
) -X- _ O
represents -X- _ O
the -X- _ O
information -X- _ O
in -X- _ O
z -X- _ O
1 -X- _ O
which -X- _ O
is -X- _ O
unique -X- _ O
to -X- _ O
x -X- _ O
1 -X- _ O
but -X- _ O
is -X- _ O
not -X- _ O
predictable -X- _ O
by -X- _ O
sentence -X- _ O
x -X- _ O
2 -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
entityspecific -X- _ O
information -X- _ O
. -X- _ O

Thus -X- _ O
any -X- _ O
representation -X- _ O
z -X- _ O
containing -X- _ O
all -X- _ O
information -X- _ O
shared -X- _ O
from -X- _ O
both -X- _ O
sentences -X- _ O
would -X- _ O
also -X- _ O
contain -X- _ O
the -X- _ O
necessary -X- _ O
label -X- _ O
information -X- _ O
, -X- _ O
and -X- _ O
sentencespecific -X- _ O
information -X- _ O
is -X- _ O
superfluous -X- _ O
. -X- _ O
So -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
6 -X- _ O
) -X- _ O
can -X- _ O
be -X- _ O
approximated -X- _ O
by -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
7 -X- _ O
) -X- _ O
by -X- _ O
: -X- _ O

maximize -X- _ O
I -X- _ O
( -X- _ O
z -X- _ O
1 -X- _ O
; -X- _ O
y -X- _ O
) -X- _ O
∼ -X- _ O
I -X- _ O
( -X- _ O
z -X- _ O
1 -X- _ O
; -X- _ O
x -X- _ O
2 -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
8 -X- _ O

) -X- _ O

minimize -X- _ O
I -X- _ O
( -X- _ O
x -X- _ O
1 -X- _ O
; -X- _ O
z -X- _ O
1 -X- _ O
|y -X- _ O
) -X- _ O
∼ -X- _ O
I -X- _ O
( -X- _ O
x -X- _ O
1 -X- _ O
; -X- _ O
z -X- _ O
1 -X- _ O
|x -X- _ O
2 -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
9 -X- _ O

) -X- _ O

The -X- _ O
target -X- _ O
of -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
8 -X- _ O
) -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O
generaliz -X- _ O
- -X- _ O
ing -X- _ O
information -X- _ O
maximization -X- _ O
. -X- _ O
We -X- _ O
proved -X- _ O
that -X- _ O
I -X- _ O
( -X- _ O
z -X- _ O
1 -X- _ O
; -X- _ O
z -X- _ O
2 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
lower -X- _ O
bound -X- _ O
of -X- _ O
I -X- _ O
( -X- _ O
z -X- _ O
1 -X- _ O
; -X- _ O
x -X- _ O
2 -X- _ O
) -X- _ O
( -X- _ O
proof -X- _ O
could -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
appendix -X- _ O
7 -X- _ O
) -X- _ O
. -X- _ O
InfoNCE -X- _ O
( -X- _ O
Oord -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
was -X- _ O
used -X- _ O
as -X- _ O
a -X- _ O
lower -X- _ O
bound -X- _ O
on -X- _ O
MI -X- _ O
and -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
approximate -X- _ O
I -X- _ O
( -X- _ O
z -X- _ O
1 -X- _ O
; -X- _ O
z -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O
Subsequently -X- _ O
, -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
optimized -X- _ O
by -X- _ O
: -X- _ O

Lgi -X- _ O
= -X- _ O
−Ep -X- _ O
gw -X- _ O
( -X- _ O
z1 -X- _ O
, -X- _ O
z2 -X- _ O
) -X- _ O
− -X- _ O
E -X- _ O
p -X- _ O
′ -X- _ O
log -X- _ O
z -X- _ O
′ -X- _ O
exp -X- _ O
gw -X- _ O
( -X- _ O
z1 -X- _ O
, -X- _ O
z -X- _ O
′ -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
10 -X- _ O
) -X- _ O

where -X- _ O
g -X- _ O
w -X- _ O
( -X- _ O
• -X- _ O
, -X- _ O
• -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
compatible -X- _ O
score -X- _ O
function -X- _ O
approximated -X- _ O
by -X- _ O
a -X- _ O
neural -X- _ O
network -X- _ O
, -X- _ O
z -X- _ O
2 -X- _ O
are -X- _ O
the -X- _ O
positive -X- _ O
entity -X- _ O
representations -X- _ O
from -X- _ O
the -X- _ O
joint -X- _ O
distribution -X- _ O
p -X- _ O
of -X- _ O
original -X- _ O
sample -X- _ O
and -X- _ O
corresponding -X- _ O
generated -X- _ O
sample -X- _ O
, -X- _ O
z -X- _ O
′ -X- _ O
are -X- _ O
the -X- _ O
negative -X- _ O
entity -X- _ O
representations -X- _ O
drawn -X- _ O
from -X- _ O
the -X- _ O
joint -X- _ O
distribution -X- _ O
of -X- _ O
the -X- _ O
original -X- _ O
sample -X- _ O
and -X- _ O
other -X- _ O
samples -X- _ O
. -X- _ O

The -X- _ O
target -X- _ O
of -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
9 -X- _ O
) -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O
superfluous -X- _ O
information -X- _ O
minimization -X- _ O
. -X- _ O
To -X- _ O
restrict -X- _ O
this -X- _ O
term -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
minimize -X- _ O
an -X- _ O
upper -X- _ O
bound -X- _ O
of -X- _ O
I -X- _ O
( -X- _ O
x -X- _ O
1 -X- _ O
; -X- _ O
z -X- _ O
1 -X- _ O
|x -X- _ O
2 -X- _ O
) -X- _ O
( -X- _ O
proofs -X- _ O
could -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
appendix -X- _ O
7 -X- _ O
) -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

L -X- _ O
si -X- _ O
= -X- _ O
E -X- _ O
x -X- _ O
1 -X- _ O
, -X- _ O
x -X- _ O
2 -X- _ O
E -X- _ O
z -X- _ O
1 -X- _ O
, -X- _ O
z -X- _ O
2 -X- _ O
[ -X- _ O
D -X- _ O
JS -X- _ O
[ -X- _ O
p -X- _ O
z -X- _ O
1 -X- _ O
||p -X- _ O
z -X- _ O
2 -X- _ O
] -X- _ O
] -X- _ O
, -X- _ O
( -X- _ O
11 -X- _ O
) -X- _ O

where -X- _ O
D -X- _ O
JS -X- _ O
means -X- _ O
Jensen -X- _ O
- -X- _ O
Shannon -X- _ O
divergence -X- _ O
, -X- _ O
p -X- _ O
z -X- _ O
1 -X- _ O
and -X- _ O
p -X- _ O
z -X- _ O
2 -X- _ O
represent -X- _ O
p -X- _ O
( -X- _ O
z -X- _ O
1 -X- _ O
|x -X- _ O
1 -X- _ O
) -X- _ O
and -X- _ O
p -X- _ O
( -X- _ O
z -X- _ O
2 -X- _ O
|x -X- _ O
2 -X- _ O
) -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
In -X- _ O
practice -X- _ O
, -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
11 -X- _ O
) -X- _ O
encourage -X- _ O
z -X- _ O
to -X- _ O
be -X- _ O
invariant -X- _ O
to -X- _ O
entity -X- _ O
changes -X- _ O
. -X- _ O
The -X- _ O
resulting -X- _ O
Mutual -X- _ B-MethodName
Information -X- _ I-MethodName
based -X- _ I-MethodName
Named -X- _ I-MethodName
Entity -X- _ I-MethodName
Recognition -X- _ I-MethodName
model -X- _ O
is -X- _ O
visualized -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
. -X- _ O

Contrastive -X- _ O
sample -X- _ O
generation -X- _ O

It -X- _ O
is -X- _ O
difficult -X- _ O
to -X- _ O
obtain -X- _ O
samples -X- _ O
with -X- _ O
similar -X- _ O
contexts -X- _ O
but -X- _ O
different -X- _ O
entity -X- _ O
words -X- _ O
. -X- _ O
We -X- _ O
generate -X- _ O
contrastive -X- _ O
samples -X- _ O
by -X- _ O
the -X- _ O
mention -X- _ O
replacement -X- _ O
mechanism -X- _ O
( -X- _ O
Dai -X- _ O
and -X- _ O
Adel -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
mention -X- _ O
in -X- _ O
the -X- _ O
sentence -X- _ O
, -X- _ O
we -X- _ O
replace -X- _ O
it -X- _ O
by -X- _ O
another -X- _ O
mention -X- _ O
from -X- _ O
the -X- _ O
original -X- _ O
training -X- _ O
set -X- _ O
, -X- _ O
which -X- _ O
has -X- _ O
the -X- _ O
same -X- _ O
entity -X- _ O
type -X- _ O
. -X- _ O
The -X- _ O
corresponding -X- _ O
span -X- _ O
label -X- _ O
can -X- _ O
be -X- _ O
changed -X- _ O
accordingly -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
" -X- _ O
LOC -X- _ O
" -X- _ O
mention -X- _ O
" -X- _ O
Berlin -X- _ O
" -X- _ O
in -X- _ O
sentence -X- _ O
" -X- _ O
Berlin -X- _ O
is -X- _ O
wonderful -X- _ O
in -X- _ O
the -X- _ O
winter -X- _ O
" -X- _ O
is -X- _ O
replaced -X- _ O
by -X- _ O
" -X- _ O
Iceland -X- _ O
" -X- _ O
. -X- _ O

Training -X- _ O

Combine -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
10 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
11 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
get -X- _ O
the -X- _ O
following -X- _ O
objective -X- _ O
function -X- _ O
, -X- _ O
which -X- _ O
try -X- _ O
to -X- _ O
minimize -X- _ O
: -X- _ O

L -X- _ O
= -X- _ O
L -X- _ O
base -X- _ O
+ -X- _ O
γ -X- _ O
* -X- _ O
L -X- _ O
gi -X- _ O
+ -X- _ O
β -X- _ O
* -X- _ O
L -X- _ O
si -X- _ O
, -X- _ O
( -X- _ O
12 -X- _ O
) -X- _ O

where -X- _ O
γ -X- _ O
and -X- _ O
β -X- _ O
are -X- _ O
the -X- _ O
weights -X- _ O
of -X- _ O
the -X- _ O
generalizing -X- _ O
information -X- _ O
loss -X- _ O
and -X- _ O
superfluous -X- _ O
information -X- _ O
loss -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O

Experiment -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
verify -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
method -X- _ O
on -X- _ O
five -X- _ O
OOV -X- _ O
datasets -X- _ O
, -X- _ O
and -X- _ O
compared -X- _ O
it -X- _ O
with -X- _ O
other -X- _ O
methods -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
We -X- _ O
tested -X- _ O
the -X- _ O
universality -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
method -X- _ O
in -X- _ O
various -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
. -X- _ O

Datasets -X- _ O
and -X- _ O
Metrics -X- _ O

Datasets -X- _ O
We -X- _ O
performed -X- _ O
experiments -X- _ O
on -X- _ O
: -X- _ O

1 -X- _ O
. -X- _ O
WNUT2017 -X- _ B-DatasetName
( -X- _ O
Derczynski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
dataset -X- _ O
focus -X- _ O
on -X- _ O
unusual -X- _ O
, -X- _ O
previous -X- _ O
- -X- _ O
unseen -X- _ O
entities -X- _ O
in -X- _ O
training -X- _ O
data -X- _ O
, -X- _ O
and -X- _ O
is -X- _ O
collected -X- _ O
from -X- _ O
social -X- _ O
media -X- _ O
. -X- _ O

2 -X- _ O
. -X- _ O
TwitterNER -X- _ B-DatasetName
, -X- _ O
an -X- _ O
English -X- _ O
NER -X- _ B-TaskName
dataset -X- _ O
created -X- _ O
from -X- _ O
Tweets -X- _ O
. -X- _ O

3 -X- _ O
. -X- _ O
BioNER -X- _ B-DatasetName
( -X- _ O
Kim -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
JNLPBA -X- _ O
2004 -X- _ O
Bio -X- _ O
- -X- _ O
NER -X- _ O
dataset -X- _ O
focus -X- _ O
on -X- _ O
technical -X- _ O
terms -X- _ O
in -X- _ O
the -X- _ O
biology -X- _ O
domain -X- _ O
. -X- _ O

4 -X- _ O
. -X- _ O
Conll03 -X- _ B-DatasetName
- -X- _ I-DatasetName
Typos -X- _ I-DatasetName
, -X- _ O
which -X- _ O
is -X- _ O
generated -X- _ O
from -X- _ O
Conll2003 -X- _ O
( -X- _ O
Sang -X- _ O
and -X- _ O
De -X- _ O
Meulder -X- _ O
, -X- _ O
2003 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
entities -X- _ O
in -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
are -X- _ O
replaced -X- _ O
by -X- _ O
typos -X- _ O
version -X- _ O
( -X- _ O
character -X- _ O
modify -X- _ O
, -X- _ O
insert -X- _ O
, -X- _ O
and -X- _ O
delete -X- _ O
operation -X- _ O
) -X- _ O
. -X- _ O

5 -X- _ O
. -X- _ O
Conll03 -X- _ B-DatasetName
- -X- _ I-DatasetName
OOV -X- _ I-DatasetName
, -X- _ O
which -X- _ O
is -X- _ O
generated -X- _ O
from -X- _ O
Conll2003 -X- _ O
( -X- _ O
Sang -X- _ O
and -X- _ O
De -X- _ O
Meulder -X- _ O
, -X- _ O
2003 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
entities -X- _ O
in -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
are -X- _ O
replaced -X- _ O
by -X- _ O
another -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
vocabulary -X- _ O
entity -X- _ O
in -X- _ O
test -X- _ O
set -X- _ O
. -X- _ O

Table -X- _ O
2 -X- _ O
reports -X- _ O
the -X- _ O
statistic -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
OOV -X- _ O
problem -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
sets -X- _ O
of -X- _ O
each -X- _ O
dataset -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
the -X- _ O
table -X- _ O
, -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
of -X- _ O
these -X- _ O
datasets -X- _ O
comprises -X- _ O
a -X- _ O
substantial -X- _ O
amount -X- _ O
of -X- _ O
OOV -X- _ O
entities -X- _ O
. -X- _ O

Metrics -X- _ O
We -X- _ O
measured -X- _ O
the -X- _ O
entity -X- _ O
- -X- _ O
level -X- _ O
micro -X- _ O
average -X- _ O
F1 -X- _ B-MetricName
score -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
to -X- _ O
compare -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
different -X- _ O
models -X- _ O
. -X- _ O
2020 -X- _ O
) -X- _ O
share -X- _ O
the -X- _ O
same -X- _ O
intuition -X- _ O
as -X- _ O
us -X- _ O
, -X- _ O
enriching -X- _ O
word -X- _ O
representations -X- _ O
with -X- _ O
context -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
work -X- _ O
is -X- _ O
neither -X- _ O
open -X- _ O
source -X- _ O
nor -X- _ O
reported -X- _ O
on -X- _ O
the -X- _ O
same -X- _ O
dataset -X- _ O
, -X- _ O
so -X- _ O
this -X- _ O
method -X- _ O
can -X- _ O
not -X- _ O
be -X- _ O
compared -X- _ O
with -X- _ O
MINER -X- _ B-MethodName
. -X- _ O
We -X- _ O
compare -X- _ O
our -X- _ O
method -X- _ O
with -X- _ O
baselines -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
• -X- _ O
Vanilla -X- _ B-MethodName
information -X- _ I-MethodName
bottleneck -X- _ I-MethodName
( -X- _ O
VaniIB -X- _ B-MethodName
) -X- _ O
, -X- _ O
a -X- _ O
method -X- _ O
employs -X- _ O
the -X- _ O
original -X- _ O
information -X- _ O
bottleneck -X- _ O
constraint -X- _ O
to -X- _ O
the -X- _ O
SpanNER -X- _ B-MethodName
, -X- _ O
which -X- _ O
is -X- _ O
optimized -X- _ O
based -X- _ O
on -X- _ O
Alemi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
Compared -X- _ O
with -X- _ O
our -X- _ O
method -X- _ O
, -X- _ O
it -X- _ O
directly -X- _ O
compresses -X- _ O
all -X- _ O
the -X- _ O
information -X- _ O
from -X- _ O
the -X- _ O
input -X- _ O
. -X- _ O
• -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
( -X- _ O
MIN -X- _ B-MethodName
) -X- _ O
, -X- _ O
which -X- _ O
utilizes -X- _ O
both -X- _ O
segment -X- _ O
- -X- _ O
level -X- _ O
information -X- _ O
and -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
dependencies -X- _ O
, -X- _ O
and -X- _ O
incorporates -X- _ O
an -X- _ O
interaction -X- _ O
mechanism -X- _ O
to -X- _ O
support -X- _ O
information -X- _ O
sharing -X- _ O
between -X- _ O
boundary -X- _ O
detection -X- _ O
and -X- _ O
type -X- _ O
prediction -X- _ O
, -X- _ O
enhancing -X- _ O
the -X- _ O
performance -X- _ O
for -X- _ O
the -X- _ O
NER -X- _ B-TaskName
task -X- _ O
. -X- _ O

Baseline -X- _ O
methods -X- _ O

Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O

• -X- _ O
Fukuda -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
( -X- _ O
CoFEE -X- _ B-MethodName
) -X- _ O
, -X- _ O
which -X- _ O
refer -X- _ O
to -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
word -X- _ O
embeddings -X- _ O
for -X- _ O
known -X- _ O
words -X- _ O
with -X- _ O
similar -X- _ O
surfaces -X- _ O
to -X- _ O
target -X- _ O
OOV -X- _ O
words -X- _ O
. -X- _ O

• -X- _ O
Nie -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
( -X- _ O
SA -X- _ B-MethodName
- -X- _ I-MethodName
NER -X- _ I-MethodName
) -X- _ O
, -X- _ O
which -X- _ O
utilize -X- _ O
semantic -X- _ O
enhancement -X- _ O
methods -X- _ O
to -X- _ O
reduce -X- _ O
the -X- _ O
negative -X- _ O
impact -X- _ O
of -X- _ O
data -X- _ O
sparsity -X- _ O
problems -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
the -X- _ O
method -X- _ O
obtains -X- _ O
the -X- _ O
augmented -X- _ O
semantic -X- _ O
information -X- _ O
from -X- _ O
a -X- _ O
largescale -X- _ O
corpus -X- _ O
, -X- _ O
and -X- _ O
proposes -X- _ O
an -X- _ O
attentive -X- _ O
semantic -X- _ O
augmentation -X- _ O
module -X- _ O
and -X- _ O
a -X- _ O
gate -X- _ O
module -X- _ O
to -X- _ O
encode -X- _ O
and -X- _ O
aggregate -X- _ O
such -X- _ O
information -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O

To -X- _ O
verify -X- _ O
the -X- _ O
universality -X- _ O
of -X- _ O
our -X- _ O
method -X- _ O
, -X- _ O
we -X- _ O
measured -X- _ O
its -X- _ O
performance -X- _ O
on -X- _ O
various -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
Bert -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
Roberta -X- _ B-MethodName
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
Albert -X- _ B-MethodName
( -X- _ O
Lan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

Implementation -X- _ O
Details -X- _ O

Bert -X- _ B-MethodName
- -X- _ O
large -X- _ O
released -X- _ O
by -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
is -X- _ O
selected -X- _ O
as -X- _ O
our -X- _ O
base -X- _ O
encoder -X- _ O
. -X- _ O
The -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
is -X- _ O
set -X- _ O
to -X- _ O
5e-5 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
the -X- _ O
dropout -X- _ B-HyperparameterName
is -X- _ O
set -X- _ O
to -X- _ O
0.2 -X- _ B-HyperparameterValue
. -X- _ O
The -X- _ O
output -X- _ B-HyperparameterName
dim -X- _ I-HyperparameterName
of -X- _ O
the -X- _ O
information -X- _ O
bottleneck -X- _ O
layer -X- _ O
is -X- _ O
50 -X- _ B-HyperparameterValue
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
make -X- _ O
a -X- _ O
trade -X- _ O
- -X- _ O
off -X- _ O
for -X- _ O
the -X- _ O
performance -X- _ O
and -X- _ O
efficiency -X- _ O
, -X- _ O
on -X- _ O
the -X- _ O
one -X- _ O
hand -X- _ O
, -X- _ O
we -X- _ O
truncate -X- _ O
the -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
sentence -X- _ O
whose -X- _ O
tokens -X- _ O
exceeds -X- _ O
128 -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
we -X- _ O
count -X- _ O
the -X- _ O
length -X- _ O
distribution -X- _ O
of -X- _ O
entity -X- _ O
length -X- _ O
in -X- _ O
different -X- _ O
datasets -X- _ O
, -X- _ O
and -X- _ O
finally -X- _ O
choose -X- _ O
4 -X- _ B-HyperparameterValue
as -X- _ O
the -X- _ O
maximum -X- _ B-HyperparameterName
enumerated -X- _ I-HyperparameterName
entity -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
. -X- _ O
The -X- _ O
values -X- _ O
of -X- _ O
β -X- _ B-HyperparameterName
and -X- _ O
γ -X- _ B-HyperparameterName
differ -X- _ O
for -X- _ O
different -X- _ O
datasets -X- _ O
. -X- _ O
Empirically -X- _ O
, -X- _ O
1e-5 -X- _ B-HyperparameterValue
for -X- _ O
β -X- _ B-HyperparameterName
and -X- _ O
0.01 -X- _ B-HyperparameterValue
for -X- _ O
γ -X- _ B-HyperparameterName
can -X- _ O
get -X- _ O
promised -X- _ O
results -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
in -X- _ O
an -X- _ O
NVIDIA -X- _ O
GeForce -X- _ O
RTX -X- _ O
2080Ti -X- _ O
GPU -X- _ O
. -X- _ O
Checkpoints -X- _ O
with -X- _ O
top-3 -X- _ O
performance -X- _ O
are -X- _ O
finally -X- _ O
evaluated -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
to -X- _ O
report -X- _ O
averaged -X- _ O
results -X- _ O
. -X- _ O

Main -X- _ O
Results -X- _ O

We -X- _ O
demonstrate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
MINER -X- _ B-MethodName
against -X- _ O
other -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
models -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
table -X- _ O
3 -X- _ O
, -X- _ O
we -X- _ O
conducted -X- _ O
the -X- _ O
following -X- _ O
comparison -X- _ O
and -X- _ O
analysis -X- _ O
: -X- _ O

1 -X- _ O
) -X- _ O
Our -X- _ O
baseline -X- _ O
model -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
SpanNER -X- _ B-MethodName
, -X- _ O
does -X- _ O
an -X- _ O
excellent -X- _ O
job -X- _ O
of -X- _ O
predicting -X- _ O
OOV -X- _ O
entities -X- _ O
. -X- _ O
Compared -X- _ O
with -X- _ O
sequence -X- _ O
labeling -X- _ O
, -X- _ O
the -X- _ O
span -X- _ O
classification -X- _ O
could -X- _ O
model -X- _ O
the -X- _ O
relation -X- _ O
of -X- _ O
entity -X- _ O
tokens -X- _ O
directly -X- _ O
; -X- _ O
2 -X- _ O
) -X- _ O
The -X- _ O
performance -X- _ O
of -X- _ O
SpanNER -X- _ B-MethodName
is -X- _ O
further -X- _ O
boosted -X- _ O
with -X- _ O
our -X- _ O
proposed -X- _ O
approach -X- _ O
, -X- _ O
which -X- _ O
proved -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
method -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
table -X- _ O
3 -X- _ O
, -X- _ O
MINER -X- _ B-MethodName
almost -X- _ O
outperforms -X- _ O
all -X- _ O
other -X- _ O
SOTA -X- _ O
methods -X- _ O
without -X- _ O
any -X- _ O
external -X- _ O
resource -X- _ O
; -X- _ O
3 -X- _ O
) -X- _ O
Compared -X- _ O
with -X- _ O
Typos -X- _ O
data -X- _ O
transformation -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
more -X- _ O
difficult -X- _ O
for -X- _ O
models -X- _ O
to -X- _ O
predict -X- _ O
OOV -X- _ O
words -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
are -X- _ O
obtained -X- _ O
by -X- _ O
testing -X- _ O
MINER -X- _ B-MethodName
( -X- _ O
Bert -X- _ B-MethodName
large -X- _ O
) -X- _ O
on -X- _ O
TwitterNER -X- _ B-DatasetName
. -X- _ O
We -X- _ O
fix -X- _ O
β -X- _ B-HyperparameterName
= -X- _ O
1e03 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
the -X- _ O
orange -X- _ O
line -X- _ O
is -X- _ O
f1 -X- _ B-MetricName
score -X- _ O
when -X- _ O
γ -X- _ B-HyperparameterName
= -X- _ O
0 -X- _ B-HyperparameterValue
. -X- _ O
The -X- _ O
results -X- _ O
are -X- _ O
obtained -X- _ O
by -X- _ O
testing -X- _ O
MINER -X- _ B-MethodName
( -X- _ O
Bert -X- _ B-MethodName
large -X- _ O
) -X- _ O
on -X- _ O
TwitterNER -X- _ B-DatasetName
. -X- _ O
We -X- _ O
fix -X- _ O
γ -X- _ B-HyperparameterName
= -X- _ O
1e04 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
the -X- _ O
orange -X- _ O
line -X- _ O
is -X- _ O
f1 -X- _ B-MetricName
score -X- _ O
when -X- _ O
β -X- _ B-HyperparameterName
= -X- _ O
0 -X- _ B-HyperparameterValue
. -X- _ O

To -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
model -X- _ O
, -X- _ O
typos -X- _ O
word -X- _ O
may -X- _ O
not -X- _ O
appear -X- _ O
in -X- _ O
training -X- _ O
set -X- _ O
, -X- _ O
but -X- _ O
they -X- _ O
share -X- _ O
most -X- _ O
subwords -X- _ O
with -X- _ O
the -X- _ O
original -X- _ O
token -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
the -X- _ O
subword -X- _ O
of -X- _ O
OOV -X- _ O
entity -X- _ O
may -X- _ O
be -X- _ O
rare -X- _ O
; -X- _ O
4 -X- _ O
) -X- _ O
It -X- _ O
seems -X- _ O
that -X- _ O
the -X- _ O
traditional -X- _ O
information -X- _ O
bottleneck -X- _ O
will -X- _ O
not -X- _ O
significantly -X- _ O
improve -X- _ O
the -X- _ O
OOV -X- _ B-TaskName
prediction -X- _ I-TaskName
ability -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O
We -X- _ O
argue -X- _ O
that -X- _ O
the -X- _ O
traditional -X- _ O
information -X- _ O
bottlenecks -X- _ O
will -X- _ O
indiscriminately -X- _ O
compress -X- _ O
the -X- _ O
information -X- _ O
in -X- _ O
the -X- _ O
representation -X- _ O
, -X- _ O
leading -X- _ O
to -X- _ O
underfitting -X- _ O
; -X- _ O
5 -X- _ O
) -X- _ O
Our -X- _ O
model -X- _ O
has -X- _ O
significantly -X- _ O
improved -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
entity -X- _ O
perturbed -X- _ O
methods -X- _ O
of -X- _ O
typos -X- _ O
and -X- _ O
OOV -X- _ O
, -X- _ O
demonstrating -X- _ O
that -X- _ O
MI -X- _ O
improve -X- _ O
the -X- _ O
robustness -X- _ O
substantially -X- _ O
in -X- _ O
the -X- _ O
face -X- _ O
of -X- _ O
noise -X- _ O
; -X- _ O
6 -X- _ O
) -X- _ O
It -X- _ O
is -X- _ O
clear -X- _ O
that -X- _ O
our -X- _ O
proposed -X- _ O
method -X- _ O
is -X- _ O
universal -X- _ O
and -X- _ O
can -X- _ O
further -X- _ O
improve -X- _ O
OOV -X- _ B-TaskName
prediction -X- _ I-TaskName
performance -X- _ O
for -X- _ O
different -X- _ O
embedding -X- _ O
models -X- _ O
, -X- _ O
as -X- _ O
we -X- _ O
get -X- _ O
improvements -X- _ O
on -X- _ O
Bert -X- _ B-MethodName
, -X- _ O
Roberta -X- _ B-MethodName
, -X- _ O
and -X- _ O
Albert -X- _ B-MethodName
stably -X- _ O
. -X- _ O

Ablation -X- _ O
Study -X- _ O

We -X- _ O
also -X- _ O
perform -X- _ O
ablation -X- _ O
studies -X- _ O
to -X- _ O
validate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
each -X- _ O
part -X- _ O
in -X- _ O
MINER -X- _ B-MethodName
. -X- _ O
demonstrates -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
different -X- _ O
settings -X- _ O
for -X- _ O
the -X- _ O
proposed -X- _ O
training -X- _ O
strategy -X- _ O
equipped -X- _ O
with -X- _ O
BERT -X- _ B-MethodName
. -X- _ O

After -X- _ O
only -X- _ O
adding -X- _ O
the -X- _ O
L -X- _ O
gi -X- _ O
loss -X- _ O
to -X- _ O
enhance -X- _ O
context -X- _ O
and -X- _ O
entity -X- _ O
surface -X- _ O
form -X- _ O
information -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
results -X- _ O
are -X- _ O
better -X- _ O
than -X- _ O
the -X- _ O
original -X- _ O
PLMs -X- _ B-MethodName
. -X- _ O
A -X- _ O
similar -X- _ O
phenomenon -X- _ O
occurs -X- _ O
in -X- _ O
L -X- _ O
si -X- _ O
, -X- _ O
too -X- _ O
. -X- _ O
It -X- _ O
reflects -X- _ O
that -X- _ O
both -X- _ O
L -X- _ O
gi -X- _ O
and -X- _ O
L -X- _ O
si -X- _ O
are -X- _ O
beneficial -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
generalizing -X- _ O
ability -X- _ O
on -X- _ O
OOV -X- _ B-TaskName
entities -X- _ I-TaskName
recognition -X- _ I-TaskName
. -X- _ O
Moreover -X- _ O
, -X- _ O
the -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
three -X- _ O
datasets -X- _ O
are -X- _ O
significantly -X- _ O
improved -X- _ O
by -X- _ O
adding -X- _ O
both -X- _ O
L -X- _ O
gi -X- _ O
and -X- _ O
L -X- _ O
si -X- _ O
learning -X- _ O
objectives -X- _ O
. -X- _ O
It -X- _ O
means -X- _ O
L -X- _ O
gi -X- _ O
and -X- _ O
L -X- _ O
si -X- _ O
can -X- _ O
boost -X- _ O
each -X- _ O
over -X- _ O
, -X- _ O
which -X- _ O
proves -X- _ O
that -X- _ O
our -X- _ O
method -X- _ O
enhances -X- _ O
representation -X- _ O
via -X- _ O
deep -X- _ O
understanding -X- _ O
of -X- _ O
context -X- _ O
and -X- _ O
entity -X- _ O
surface -X- _ O
forms -X- _ O
and -X- _ O
discourages -X- _ O
representation -X- _ O
from -X- _ O
rote -X- _ O
memorizing -X- _ O
entity -X- _ O
names -X- _ O
or -X- _ O
exploiting -X- _ O
biased -X- _ O
cues -X- _ O
in -X- _ O
data -X- _ O
. -X- _ O

Sensitivity -X- _ O
Analysis -X- _ O
of -X- _ O
β -X- _ B-HyperparameterName
and -X- _ O
γ -X- _ B-HyperparameterName

To -X- _ O
show -X- _ O
the -X- _ O
different -X- _ O
influence -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
training -X- _ O
objectives -X- _ O
L -X- _ O
gi -X- _ O
and -X- _ O
L -X- _ O
si -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
sensitivity -X- _ O
analysis -X- _ O
of -X- _ O
the -X- _ O
coefficient -X- _ O
β -X- _ B-HyperparameterName
and -X- _ O
γ -X- _ B-HyperparameterName
. -X- _ O
Figure -X- _ O
2 -X- _ O
shows -X- _ O
the -X- _ O
performance -X- _ O
change -X- _ O
under -X- _ O
different -X- _ O
settings -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
coefficients -X- _ O
. -X- _ O
The -X- _ O
yellow -X- _ O
line -X- _ O
denotes -X- _ O
ablation -X- _ O
results -X- _ O
without -X- _ O
the -X- _ O
corresponding -X- _ O
loss -X- _ O
functions -X- _ O
( -X- _ O
with -X- _ O
β=0 -X- _ B-HyperparameterName
or -X- _ O
γ=0 -X- _ B-HyperparameterName
) -X- _ O
. -X- _ O
From -X- _ O
Figure -X- _ O
2 -X- _ O
we -X- _ O
can -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
performance -X- _ O
is -X- _ O
significantly -X- _ O
enhanced -X- _ O
with -X- _ O
a -X- _ O
small -X- _ O
rate -X- _ O
of -X- _ O
β -X- _ B-HyperparameterName
or -X- _ O
γ -X- _ B-HyperparameterName
, -X- _ O
where -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
is -X- _ O
achieved -X- _ O
when -X- _ O
β=1e-3 -X- _ B-HyperparameterName
and -X- _ O
γ=1e-4 -X- _ B-HyperparameterName
, -X- _ O
respectively -X- _ O
. -X- _ O
It -X- _ O
probes -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
training -X- _ O
objectives -X- _ O
that -X- _ O
enhances -X- _ O
representation -X- _ O
via -X- _ O
deep -X- _ O
understanding -X- _ O
of -X- _ O
context -X- _ O
and -X- _ O
entity -X- _ O
surface -X- _ O
forms -X- _ O
and -X- _ O
discourages -X- _ O
representation -X- _ O
from -X- _ O
rote -X- _ O
memorizing -X- _ O
entity -X- _ O
names -X- _ O
or -X- _ O
exploiting -X- _ O
biased -X- _ O
cues -X- _ O
in -X- _ O
data -X- _ O
. -X- _ O
As -X- _ O
the -X- _ O
coefficient -X- _ O
rate -X- _ O
increases -X- _ O
continuously -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
shows -X- _ O
a -X- _ O
declining -X- _ O
trend -X- _ O
, -X- _ O
which -X- _ O
means -X- _ O
the -X- _ O
over -X- _ O
- -X- _ O
constraint -X- _ O
of -X- _ O
L -X- _ O
gi -X- _ O
or -X- _ O
L -X- _ O
si -X- _ O
will -X- _ O
hurt -X- _ O
the -X- _ O
generalizing -X- _ O
ability -X- _ O
of -X- _ O
predicting -X- _ O
the -X- _ O
OOV -X- _ O
entities -X- _ O
. -X- _ O

Interpretable -X- _ O
Analysis -X- _ O

The -X- _ O
above -X- _ O
experiments -X- _ O
show -X- _ O
the -X- _ O
promising -X- _ O
performance -X- _ O
of -X- _ O
MINER -X- _ B-MethodName
on -X- _ O
predicting -X- _ O
the -X- _ O
unseen -X- _ O
entities -X- _ O
. -X- _ O
To -X- _ O
further -X- _ O
investigate -X- _ O
which -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
sentence -X- _ O
MINER -X- _ B-MethodName
focuses -X- _ O
on -X- _ O
, -X- _ O
we -X- _ O
visualize -X- _ O
the -X- _ O
attention -X- _ O
weights -X- _ O
over -X- _ O
entities -X- _ O
and -X- _ O
contexts -X- _ O
. -X- _ O
We -X- _ O
demonstrate -X- _ O
an -X- _ O
example -X- _ O
in -X- _ O
Figure -X- _ O
4 -X- _ O
, -X- _ O
where -X- _ O
is -X- _ O
selected -X- _ O
from -X- _ O
TwitterNER -X- _ B-DatasetName
. -X- _ O
The -X- _ O
attention -X- _ O
score -X- _ O
is -X- _ O
calculated -X- _ O
by -X- _ O
averaging -X- _ O
the -X- _ O
attention -X- _ O
weight -X- _ O
of -X- _ O
the -X- _ O
0th -X- _ O
layer -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
. -X- _ O
Take -X- _ O
the -X- _ O
attention -X- _ O
weights -X- _ O
of -X- _ O
the -X- _ O
entity -X- _ O
" -X- _ O
State -X- _ O
Street -X- _ O
" -X- _ O
as -X- _ O
an -X- _ O
example -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
obvious -X- _ O
that -X- _ O
baseline -X- _ O
model -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
SpanNER -X- _ B-MethodName
, -X- _ O
focus -X- _ O
on -X- _ O
entity -X- _ O
words -X- _ O
themselves -X- _ O
. -X- _ O
While -X- _ O
the -X- _ O
scores -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
are -X- _ O
more -X- _ O
average -X- _ O
, -X- _ O
it -X- _ O
means -X- _ O
that -X- _ O
our -X- _ O
method -X- _ O
concerns -X- _ O
more -X- _ O
context -X- _ O
information -X- _ O
. -X- _ O

6 -X- _ O
Related -X- _ O
Work -X- _ O

External -X- _ O
Knowledge -X- _ O

This -X- _ O
group -X- _ O
of -X- _ O
methods -X- _ O
makes -X- _ O
it -X- _ O
easier -X- _ O
to -X- _ O
predict -X- _ O
OOV -X- _ O
entities -X- _ O
using -X- _ O
external -X- _ O
knowledge -X- _ O
. -X- _ O
Zhang -X- _ O
and -X- _ O
Yang -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
utilize -X- _ O
a -X- _ O
dictionary -X- _ O
to -X- _ O
list -X- _ O
numerous -X- _ O
entity -X- _ O
mentions -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
possible -X- _ O
to -X- _ O
get -X- _ O
stronger -X- _ O
" -X- _ O
lookup -X- _ O
" -X- _ O
models -X- _ O
by -X- _ O
integrating -X- _ O
dictionary -X- _ O
information -X- _ O
, -X- _ O
but -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
guarantee -X- _ O
that -X- _ O
entities -X- _ O
outside -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
and -X- _ O
vocabulary -X- _ O
will -X- _ O
be -X- _ O
correctly -X- _ O
identified -X- _ O
. -X- _ O
To -X- _ O
diminish -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
dependency -X- _ O
on -X- _ O
OOV -X- _ O
embedding -X- _ O
, -X- _ O
introduce -X- _ O
partof -X- _ O
- -X- _ O
speech -X- _ O
tags -X- _ O
. -X- _ O
External -X- _ O
resources -X- _ O
are -X- _ O
not -X- _ O
always -X- _ O
available -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
limitation -X- _ O
of -X- _ O
this -X- _ O
strategy -X- _ O
. -X- _ O

OOV -X- _ O
word -X- _ O
Embedding -X- _ O

The -X- _ O
OOV -X- _ O
problem -X- _ O
can -X- _ O
be -X- _ O
alleviated -X- _ O
by -X- _ O
improving -X- _ O
the -X- _ O
OOV -X- _ O
word -X- _ O
embedding -X- _ O
. -X- _ O
The -X- _ O
character -X- _ O
ngram -X- _ O
of -X- _ O
each -X- _ O
word -X- _ O
is -X- _ O
used -X- _ O
by -X- _ O
Bojanowski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
to -X- _ O
represent -X- _ O
the -X- _ O
OOV -X- _ O
word -X- _ O
embedding -X- _ O
. -X- _ O
Pinter -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
captures -X- _ O
morphological -X- _ O
features -X- _ O
using -X- _ O
character -X- _ O
- -X- _ O
level -X- _ O
RNN -X- _ O
. -X- _ O
Another -X- _ O
technique -X- _ O
is -X- _ O
to -X- _ O
first -X- _ O
match -X- _ O
the -X- _ O
OOV -X- _ O
words -X- _ O
with -X- _ O
the -X- _ O
words -X- _ O
that -X- _ O
have -X- _ O
been -X- _ O
seen -X- _ O
in -X- _ O
training -X- _ O
, -X- _ O
then -X- _ O
replace -X- _ O
the -X- _ O
OOV -X- _ O
words -X- _ O
' -X- _ O
embedding -X- _ O
with -X- _ O
the -X- _ O
seen -X- _ O
words -X- _ O
' -X- _ O
embedding -X- _ O
. -X- _ O
Peng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
trains -X- _ O
a -X- _ O
student -X- _ O
network -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
closest -X- _ O
word -X- _ O
representation -X- _ O
to -X- _ O
the -X- _ O
OOV -X- _ O
term -X- _ O
. -X- _ O
Fukuda -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
referring -X- _ O
to -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
word -X- _ O
embeddings -X- _ O
for -X- _ O
known -X- _ O
words -X- _ O
with -X- _ O
similar -X- _ O
surfaces -X- _ O
to -X- _ O
target -X- _ O
OOV -X- _ O
words -X- _ O
. -X- _ O
This -X- _ O
kind -X- _ O
of -X- _ O
method -X- _ O
is -X- _ O
learning -X- _ O
a -X- _ O
static -X- _ O
OOV -X- _ O
embedding -X- _ O
representation -X- _ O
, -X- _ O
and -X- _ O
does -X- _ O
not -X- _ O
directly -X- _ O
utilize -X- _ O
the -X- _ O
context -X- _ O
. -X- _ O

Contextualized -X- _ O
Embedding -X- _ O

Contextual -X- _ O
information -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
enhance -X- _ O
the -X- _ O
representation -X- _ O
of -X- _ O
OOV -X- _ O
words -X- _ O
in -X- _ O
this -X- _ O
strategy -X- _ O
. -X- _ O
( -X- _ O
Hu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
formulate -X- _ O
the -X- _ O
OOV -X- _ O
problem -X- _ O
as -X- _ O
a -X- _ O
Kshot -X- _ O
regression -X- _ O
problem -X- _ O
and -X- _ O
learns -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
OOV -X- _ O
embedding -X- _ O
by -X- _ O
aggregating -X- _ O
only -X- _ O
K -X- _ O
contexts -X- _ O
and -X- _ O
morphological -X- _ O
features -X- _ O
. -X- _ O
Pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
contextualized -X- _ O
word -X- _ O
embeddings -X- _ O
via -X- _ O
pretraining -X- _ O
on -X- _ O
large -X- _ O
background -X- _ O
corpora -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
contextualized -X- _ O
word -X- _ O
embeddings -X- _ O
can -X- _ O
be -X- _ O
provided -X- _ O
by -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
on -X- _ O
large -X- _ O
background -X- _ O
corpora -X- _ O
( -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Yan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
shows -X- _ O
that -X- _ O
BERT -X- _ B-MethodName
is -X- _ O
not -X- _ O
always -X- _ O
better -X- _ O
at -X- _ O
capturing -X- _ O
context -X- _ O
as -X- _ O
compared -X- _ O
to -X- _ O
Gloe -X- _ O
- -X- _ O
based -X- _ O
BiLSTM -X- _ O
- -X- _ O
CRFs -X- _ O
. -X- _ O

Their -X- _ O
higher -X- _ O
performance -X- _ O
could -X- _ O
be -X- _ O
the -X- _ O
result -X- _ O
of -X- _ O
learning -X- _ O
the -X- _ O
subword -X- _ O
structure -X- _ O
better -X- _ O
. -X- _ O

Conclusion -X- _ O

Based -X- _ O
on -X- _ O
the -X- _ O
recent -X- _ O
studies -X- _ O
of -X- _ O
NER -X- _ B-TaskName
, -X- _ O
we -X- _ O
analyze -X- _ O
how -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
OOV -X- _ B-TaskName
entity -X- _ I-TaskName
recognition -X- _ I-TaskName
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
and -X- _ O
flexible -X- _ O
learning -X- _ O
framework -X- _ O
-MINER -X- _ B-MethodName
, -X- _ O
to -X- _ O
tackle -X- _ O
OOV -X- _ B-TaskName
entities -X- _ I-TaskName
recognition -X- _ I-TaskName
issue -X- _ O
from -X- _ O
an -X- _ O
information -X- _ O
- -X- _ O
theoretic -X- _ O
perspective -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
one -X- _ O
hand -X- _ O
, -X- _ O
this -X- _ O
method -X- _ O
can -X- _ O
enhance -X- _ O
the -X- _ O
context -X- _ O
information -X- _ O
of -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
encoder -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
it -X- _ O
can -X- _ O
safely -X- _ O
eliminate -X- _ O
task -X- _ O
- -X- _ O
irrelevant -X- _ O
nuisances -X- _ O
and -X- _ O
prevents -X- _ O
the -X- _ O
model -X- _ O
from -X- _ O
rote -X- _ O
memorizing -X- _ O
the -X- _ O
entities -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
the -X- _ O
proposed -X- _ O
approach -X- _ O
contains -X- _ O
two -X- _ O
mutual -X- _ O
information -X- _ O
based -X- _ O
training -X- _ O
objectives -X- _ O
: -X- _ O
generalizing -X- _ O
information -X- _ O
maximization -X- _ O
, -X- _ O
and -X- _ O
superfluous -X- _ O
information -X- _ O
minimization -X- _ O
. -X- _ O
Experiments -X- _ O
on -X- _ O
various -X- _ O
datasets -X- _ O
demonstrate -X- _ O
that -X- _ O
MINER -X- _ B-MethodName
achieves -X- _ O
much -X- _ O
better -X- _ O
performance -X- _ O
in -X- _ O
predicting -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
vocabulary -X- _ O
entities -X- _ O
. -X- _ O

Acknowledgements -X- _ O

The -X- _ O
authors -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
thank -X- _ O
the -X- _ O
anonymous -X- _ O
reviewers -X- _ O
for -X- _ O
their -X- _ O
helpful -X- _ O
comments -X- _ O
, -X- _ O
Ting -X- _ O
Wu -X- _ O
and -X- _ O
Yiding -X- _ O
Tan -X- _ O
for -X- _ O
their -X- _ O
early -X- _ O
contribution -X- _ O
. -X- _ O
This -X- _ O
work -X- _ O
was -X- _ O
partially -X- _ O
funded -X- _ O
by -X- _ O
China -X- _ O
National -X- _ O
Key -X- _ O
RD -X- _ O
Program -X- _ O
( -X- _ O
No -X- _ O
. -X- _ O
2018YFB1005104 -X- _ O
) -X- _ O
, -X- _ O
National -X- _ O
Natural -X- _ O
Science -X- _ O
Foundation -X- _ O
of -X- _ O
China -X- _ O
( -X- _ O
No -X- _ O
. -X- _ O
62076069 -X- _ O
, -X- _ O
61976056 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
research -X- _ O
was -X- _ O
sponsored -X- _ O
by -X- _ O
Hikvision -X- _ O
Cooperation -X- _ O
Fund -X- _ O
, -X- _ O
Beijing -X- _ O
Academy -X- _ O
of -X- _ O
Artificial -X- _ O
Intelligence -X- _ O
( -X- _ O
BAAI -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
CAAI -X- _ O
- -X- _ O
Huawei -X- _ O
MindSpore -X- _ O
Open -X- _ O
Fund -X- _ O
. -X- _ O

A -X- _ O
Appendix -X- _ O

This -X- _ O
section -X- _ O
provides -X- _ O
the -X- _ O
proof -X- _ O
of -X- _ O
generalizing -X- _ O
information -X- _ O
maximization -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
8 -X- _ O
) -X- _ O
. -X- _ O
Consider -X- _ O
x -X- _ O
1 -X- _ O
and -X- _ O
x -X- _ O
2 -X- _ O
are -X- _ O
two -X- _ O
contrastive -X- _ O
samples -X- _ O
of -X- _ O
similar -X- _ O
context -X- _ O
, -X- _ O
and -X- _ O
contains -X- _ O
different -X- _ O
entity -X- _ O
mentions -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
entity -X- _ O
category -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
s -X- _ O
1 -X- _ O
and -X- _ O
s -X- _ O
2 -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O

B -X- _ O
Appendix -X- _ O

This -X- _ O
section -X- _ O
provides -X- _ O
the -X- _ O
proof -X- _ O
of -X- _ O
superfluous -X- _ O
information -X- _ O
minimization -X- _ O
, -X- _ O
i.e. -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
9 -X- _ O
) -X- _ O
. -X- _ O

