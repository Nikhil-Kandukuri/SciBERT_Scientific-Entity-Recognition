-DOCSTART- -X- O
How -X- _ O
Gender -X- _ O
Debiasing -X- _ O
Affects -X- _ O
Internal -X- _ O
Model -X- _ O
Representations -X- _ O
, -X- _ O
and -X- _ O
Why -X- _ O
It -X- _ O
Matters -X- _ O

Common -X- _ O
studies -X- _ O
of -X- _ O
gender -X- _ O
bias -X- _ O
in -X- _ O
NLP -X- _ O
focus -X- _ O
either -X- _ O
on -X- _ O
extrinsic -X- _ O
bias -X- _ O
measured -X- _ O
by -X- _ O
model -X- _ O
performance -X- _ O
on -X- _ O
a -X- _ O
downstream -X- _ O
task -X- _ O
or -X- _ O
on -X- _ O
intrinsic -X- _ O
bias -X- _ O
found -X- _ O
in -X- _ O
models -X- _ O
' -X- _ O
internal -X- _ O
representations -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
relationship -X- _ O
between -X- _ O
extrinsic -X- _ O
and -X- _ O
intrinsic -X- _ O
bias -X- _ O
is -X- _ O
relatively -X- _ O
unknown -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
illuminate -X- _ O
this -X- _ O
relationship -X- _ O
by -X- _ O
measuring -X- _ O
both -X- _ O
quantities -X- _ O
together -X- _ O
: -X- _ O
we -X- _ O
debias -X- _ O
a -X- _ O
model -X- _ O
during -X- _ O
downstream -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
, -X- _ O
which -X- _ O
reduces -X- _ O
extrinsic -X- _ O
bias -X- _ O
, -X- _ O
and -X- _ O
measure -X- _ O
the -X- _ O
effect -X- _ O
on -X- _ O
intrinsic -X- _ O
bias -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
operationalized -X- _ O
as -X- _ O
bias -X- _ O
extractability -X- _ O
with -X- _ O
information -X- _ O
- -X- _ O
theoretic -X- _ O
probing -X- _ O
. -X- _ O
Through -X- _ O
experiments -X- _ O
on -X- _ O
two -X- _ O
tasks -X- _ O
and -X- _ O
multiple -X- _ O
bias -X- _ O
metrics -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
intrinsic -X- _ O
bias -X- _ O
metric -X- _ O
is -X- _ O
a -X- _ O
better -X- _ O
indicator -X- _ O
of -X- _ O
debiasing -X- _ O
than -X- _ O
( -X- _ O
a -X- _ O
contextual -X- _ O
adaptation -X- _ O
of -X- _ O
) -X- _ O
the -X- _ O
standard -X- _ O
WEAT -X- _ O
metric -X- _ O
, -X- _ O
and -X- _ O
can -X- _ O
also -X- _ O
expose -X- _ O
cases -X- _ O
of -X- _ O
superficial -X- _ O
debiasing -X- _ O
. -X- _ O
Our -X- _ O
framework -X- _ O
provides -X- _ O
a -X- _ O
comprehensive -X- _ O
perspective -X- _ O
on -X- _ O
bias -X- _ O
in -X- _ O
NLP -X- _ O
models -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
applied -X- _ O
to -X- _ O
deploy -X- _ O
NLP -X- _ O
systems -X- _ O
in -X- _ O
a -X- _ O
more -X- _ O
informed -X- _ O
manner -X- _ O
. -X- _ O
1 -X- _ O
* -X- _ O
Supported -X- _ O
by -X- _ O
the -X- _ O
Viterbi -X- _ O
Fellowship -X- _ O
in -X- _ O
the -X- _ O
Center -X- _ O
for -X- _ O
Computer -X- _ O
Engineering -X- _ O
at -X- _ O
the -X- _ O
Technion -X- _ O
. -X- _ O

Introduction -X- _ O

Efforts -X- _ O
to -X- _ O
identify -X- _ O
and -X- _ O
mitigate -X- _ O
gender -X- _ O
bias -X- _ O
in -X- _ O
Natural -X- _ O
Language -X- _ O
Processing -X- _ O
( -X- _ O
NLP -X- _ O
) -X- _ O
systems -X- _ O
typically -X- _ O
target -X- _ O
one -X- _ O
of -X- _ O
two -X- _ O
notions -X- _ O
of -X- _ O
bias -X- _ O
. -X- _ O
Extrinsic -X- _ O
evaluation -X- _ O
methods -X- _ O
and -X- _ O
debiasing -X- _ O
techniques -X- _ O
focus -X- _ O
on -X- _ O
the -X- _ O
bias -X- _ O
reflected -X- _ O
in -X- _ O
a -X- _ O
downstream -X- _ O
task -X- _ O
Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
while -X- _ O
intrinsic -X- _ O
methods -X- _ O
focus -X- _ O
on -X- _ O
a -X- _ O
model -X- _ O
's -X- _ O
internal -X- _ O
representations -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
word -X- _ O
or -X- _ O
sentence -X- _ O
embedding -X- _ O
geometry -X- _ O
( -X- _ O
Caliskan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Bolukbasi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Guo -X- _ O
and -X- _ O
Caliskan -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Despite -X- _ O
an -X- _ O
abundance -X- _ O
of -X- _ O
evidence -X- _ O
pointing -X- _ O
towards -X- _ O
gender -X- _ O
bias -X- _ O
in -X- _ O
pretrained -X- _ O
language -X- _ O
models -X- _ O
( -X- _ O
LMs -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
extent -X- _ O
of -X- _ O
harm -X- _ O
caused -X- _ O
by -X- _ O
these -X- _ O
biases -X- _ O
is -X- _ O
not -X- _ O
clear -X- _ O
when -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
reflected -X- _ O
in -X- _ O
a -X- _ O
specific -X- _ O
downstream -X- _ O
task -X- _ O
( -X- _ O
Barocas -X- _ O
Figure -X- _ O
1 -X- _ O
: -X- _ O
Our -X- _ O
proposed -X- _ O
framework -X- _ O
. -X- _ O
Black -X- _ O
arrows -X- _ O
mark -X- _ O
forward -X- _ O
passes -X- _ O
, -X- _ O
red -X- _ O
arrows -X- _ O
mark -X- _ O
things -X- _ O
we -X- _ O
measure -X- _ O
. -X- _ O
We -X- _ O
first -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
train -X- _ O
a -X- _ O
model -X- _ O
on -X- _ O
a -X- _ O
downstream -X- _ O
task -X- _ O
, -X- _ O
then -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
train -X- _ O
another -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
same -X- _ O
task -X- _ O
using -X- _ O
a -X- _ O
debiased -X- _ O
dataset -X- _ O
, -X- _ O
and -X- _ O
finally -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
measure -X- _ O
intrinsic -X- _ O
bias -X- _ O
in -X- _ O
both -X- _ O
models -X- _ O
and -X- _ O
compare -X- _ O
. -X- _ O
Kate -X- _ O
Crawford -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Blodgett -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Bommasani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
word -X- _ O
embedding -X- _ O
proximity -X- _ O
of -X- _ O
" -X- _ O
doctor -X- _ O
" -X- _ O
to -X- _ O
" -X- _ O
man -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
nurse -X- _ O
" -X- _ O
to -X- _ O
" -X- _ O
woman -X- _ O
" -X- _ O
is -X- _ O
intuitively -X- _ O
normatively -X- _ O
wrong -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
clear -X- _ O
when -X- _ O
such -X- _ O
phenomena -X- _ O
would -X- _ O
lead -X- _ O
to -X- _ O
downstream -X- _ O
predictions -X- _ O
manifesting -X- _ O
in -X- _ O
social -X- _ O
biases -X- _ O
. -X- _ O
Recently -X- _ O
, -X- _ O
Goldfarb -X- _ O
- -X- _ O
Tarrant -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
have -X- _ O
shown -X- _ O
that -X- _ O
debiasing -X- _ O
static -X- _ O
embeddings -X- _ O
intrinsically -X- _ O
is -X- _ O
not -X- _ O
correlated -X- _ O
with -X- _ O
extrinsic -X- _ O
gender -X- _ O
bias -X- _ O
measures -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
nature -X- _ O
of -X- _ O
the -X- _ O
reverse -X- _ O
relationship -X- _ O
is -X- _ O
unknown -X- _ O
: -X- _ O
how -X- _ O
are -X- _ O
extrinsic -X- _ O
interventions -X- _ O
reflected -X- _ O
in -X- _ O
intrinsic -X- _ O
representations -X- _ O
? -X- _ O
Furthermore -X- _ O
, -X- _ O
Gonen -X- _ O
and -X- _ O
Goldberg -X- _ O
( -X- _ O
2019a -X- _ O
) -X- _ O
demonstrated -X- _ O
that -X- _ O
a -X- _ O
number -X- _ O
of -X- _ O
intrinsic -X- _ O
debiasing -X- _ O
methods -X- _ O
applied -X- _ O
to -X- _ O
static -X- _ O
embeddings -X- _ O
only -X- _ O
partially -X- _ O
remove -X- _ O
the -X- _ O
bias -X- _ O
and -X- _ O
that -X- _ O
most -X- _ O
of -X- _ O
it -X- _ O
is -X- _ O
still -X- _ O
hidden -X- _ O
within -X- _ O
the -X- _ O
embed -X- _ O
- -X- _ O
ding -X- _ O
. -X- _ O
Complementing -X- _ O
their -X- _ O
view -X- _ O
, -X- _ O
we -X- _ O
examine -X- _ O
extrinsic -X- _ O
debiasing -X- _ O
methods -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
demonstrate -X- _ O
the -X- _ O
possible -X- _ O
harm -X- _ O
this -X- _ O
could -X- _ O
cause -X- _ O
. -X- _ O
Contrary -X- _ O
to -X- _ O
their -X- _ O
conclusion -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
claim -X- _ O
that -X- _ O
these -X- _ O
debiasing -X- _ O
methods -X- _ O
should -X- _ O
not -X- _ O
be -X- _ O
trusted -X- _ O
, -X- _ O
as -X- _ O
long -X- _ O
as -X- _ O
they -X- _ O
are -X- _ O
utilized -X- _ O
with -X- _ O
care -X- _ O
. -X- _ O

Our -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
gain -X- _ O
a -X- _ O
better -X- _ O
understanding -X- _ O
of -X- _ O
the -X- _ O
relationship -X- _ O
between -X- _ O
a -X- _ O
model -X- _ O
's -X- _ O
internal -X- _ O
representations -X- _ O
and -X- _ O
its -X- _ O
extrinsic -X- _ O
gender -X- _ O
bias -X- _ O
by -X- _ O
examining -X- _ O
the -X- _ O
effects -X- _ O
of -X- _ O
various -X- _ O
debiasing -X- _ O
methods -X- _ O
on -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
representations -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
models -X- _ O
with -X- _ O
and -X- _ O
without -X- _ O
gender -X- _ O
debiasing -X- _ O
strategies -X- _ O
, -X- _ O
evaluate -X- _ O
their -X- _ O
external -X- _ O
bias -X- _ O
using -X- _ O
various -X- _ O
bias -X- _ O
metrics -X- _ O
, -X- _ O
and -X- _ O
measure -X- _ O
intrinsic -X- _ O
bias -X- _ O
in -X- _ O
the -X- _ O
representations -X- _ O
. -X- _ O
We -X- _ O
operationalize -X- _ O
intrinsic -X- _ O
bias -X- _ O
via -X- _ O
two -X- _ O
metrics -X- _ O
: -X- _ O
First -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
CEAT -X- _ B-MetricName
( -X- _ O
Guo -X- _ O
and -X- _ O
Caliskan -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
contextual -X- _ O
adaptation -X- _ O
of -X- _ O
the -X- _ O
widely -X- _ O
used -X- _ O
intrinsic -X- _ O
bias -X- _ O
metric -X- _ O
WEAT -X- _ O
( -X- _ O
Caliskan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
Second -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
use -X- _ O
an -X- _ O
information -X- _ O
- -X- _ O
theoretic -X- _ O
probe -X- _ O
to -X- _ O
quantify -X- _ O
the -X- _ O
degree -X- _ O
to -X- _ O
which -X- _ O
gender -X- _ O
can -X- _ O
be -X- _ O
extracted -X- _ O
from -X- _ O
the -X- _ O
internal -X- _ O
model -X- _ O
representations -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
examine -X- _ O
how -X- _ O
these -X- _ O
intrinsic -X- _ O
metrics -X- _ O
correlate -X- _ O
with -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
extrinsic -X- _ O
bias -X- _ O
metrics -X- _ O
that -X- _ O
we -X- _ O
measure -X- _ O
on -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
downstream -X- _ O
performance -X- _ O
. -X- _ O
Our -X- _ O
approach -X- _ O
is -X- _ O
visualised -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
. -X- _ O

We -X- _ O
perform -X- _ O
extensive -X- _ O
experiments -X- _ O
on -X- _ O
two -X- _ O
downstream -X- _ O
tasks -X- _ O
( -X- _ O
occupation -X- _ B-TaskName
prediction -X- _ I-TaskName
and -X- _ O
coreference -X- _ B-TaskName
resolution -X- _ I-TaskName
) -X- _ O
; -X- _ O
several -X- _ O
debiasing -X- _ O
strategies -X- _ O
that -X- _ O
involve -X- _ O
alterations -X- _ O
to -X- _ O
the -X- _ O
training -X- _ O
dataset -X- _ O
( -X- _ O
such -X- _ O
as -X- _ O
removing -X- _ O
names -X- _ O
and -X- _ O
gender -X- _ O
indicators -X- _ O
, -X- _ O
or -X- _ O
balancing -X- _ O
the -X- _ O
data -X- _ O
by -X- _ O
oversampling -X- _ O
or -X- _ O
downsampling -X- _ O
) -X- _ O
; -X- _ O
and -X- _ O
a -X- _ O
multitude -X- _ O
of -X- _ O
extrinsic -X- _ O
bias -X- _ O
metrics -X- _ O
. -X- _ O
Our -X- _ O
analysis -X- _ O
reveals -X- _ O
new -X- _ O
insights -X- _ O
into -X- _ O
the -X- _ O
way -X- _ O
language -X- _ O
models -X- _ O
encode -X- _ O
and -X- _ O
use -X- _ O
information -X- _ O
on -X- _ O
gender -X- _ O
: -X- _ O

• -X- _ O
The -X- _ O
effect -X- _ O
of -X- _ O
debiasing -X- _ O
on -X- _ O
internal -X- _ O
representations -X- _ O
is -X- _ O
reflected -X- _ O
in -X- _ O
gender -X- _ O
extractability -X- _ O
, -X- _ O
while -X- _ O
not -X- _ O
always -X- _ O
in -X- _ O
CEAT -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
gender -X- _ O
extractability -X- _ O
is -X- _ O
a -X- _ O
more -X- _ O
reliable -X- _ O
indicator -X- _ O
of -X- _ O
gender -X- _ O
bias -X- _ O
in -X- _ O
NLP -X- _ O
models -X- _ O
. -X- _ O

• -X- _ O
In -X- _ O
cases -X- _ O
of -X- _ O
high -X- _ O
gender -X- _ O
extractability -X- _ O
but -X- _ O
low -X- _ O
extrinsic -X- _ O
bias -X- _ O
metrics -X- _ O
, -X- _ O
the -X- _ O
debiasing -X- _ O
is -X- _ O
superficial -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
internal -X- _ O
representations -X- _ O
are -X- _ O
a -X- _ O
good -X- _ O
indicator -X- _ O
for -X- _ O
this -X- _ O
: -X- _ O
The -X- _ O
bias -X- _ O
is -X- _ O
still -X- _ O
present -X- _ O
in -X- _ O
internal -X- _ O
representations -X- _ O
and -X- _ O
can -X- _ O
be -X- _ O
restored -X- _ O
by -X- _ O
retraining -X- _ O
the -X- _ O
classification -X- _ O
layer -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
our -X- _ O
proposed -X- _ O
measuring -X- _ O
method -X- _ O
can -X- _ O
help -X- _ O
in -X- _ O
detecting -X- _ O
such -X- _ O
cases -X- _ O
before -X- _ O
deploying -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O

• -X- _ O
The -X- _ O
two -X- _ O
tasks -X- _ O
show -X- _ O
different -X- _ O
patterns -X- _ O
of -X- _ O
correlation -X- _ O
between -X- _ O
intrinsic -X- _ O
and -X- _ O
extrinsic -X- _ O
bias -X- _ O
. -X- _ O

The -X- _ O
coreference -X- _ B-TaskName
task -X- _ O
exhibits -X- _ O
a -X- _ O
high -X- _ O
correlation -X- _ O
. -X- _ O
The -X- _ O
occupation -X- _ B-TaskName
prediction -X- _ I-TaskName
task -X- _ O
exhibits -X- _ O
a -X- _ O
lower -X- _ O
correlation -X- _ O
, -X- _ O
but -X- _ O
it -X- _ O
increases -X- _ O
after -X- _ O
retraining -X- _ O
( -X- _ O
a -X- _ O
case -X- _ O
of -X- _ O
superficial -X- _ O
debiasing -X- _ O
) -X- _ O
. -X- _ O
Gender -X- _ O
extractability -X- _ O
shows -X- _ O
higher -X- _ O
correlations -X- _ O
with -X- _ O
extrinsic -X- _ O
metrics -X- _ O
than -X- _ O
CEAT -X- _ O
, -X- _ O
increasing -X- _ O
the -X- _ O
confidence -X- _ O
in -X- _ O
this -X- _ O
metric -X- _ O
as -X- _ O
a -X- _ O
reliable -X- _ O
measure -X- _ O
for -X- _ O
gender -X- _ O
bias -X- _ O
in -X- _ O
NLP -X- _ O
models -X- _ O
. -X- _ O

Methodology -X- _ O

In -X- _ O
this -X- _ O
study -X- _ O
, -X- _ O
we -X- _ O
investigate -X- _ O
the -X- _ O
relationship -X- _ O
between -X- _ O
extrinsic -X- _ O
bias -X- _ O
metrics -X- _ O
of -X- _ O
a -X- _ O
task -X- _ O
and -X- _ O
a -X- _ O
model -X- _ O
's -X- _ O
internal -X- _ O
representations -X- _ O
, -X- _ O
under -X- _ O
various -X- _ O
debiasing -X- _ O
conditions -X- _ O
, -X- _ O
for -X- _ O
two -X- _ O
datasets -X- _ O
in -X- _ O
English -X- _ O
. -X- _ O
We -X- _ O
perform -X- _ O
extrinsic -X- _ O
debiasing -X- _ O
, -X- _ O
evaluate -X- _ O
various -X- _ O
extrinsic -X- _ O
and -X- _ O
intrinsic -X- _ O
bias -X- _ O
metrics -X- _ O
before -X- _ O
and -X- _ O
after -X- _ O
debiasing -X- _ O
, -X- _ O
and -X- _ O
examine -X- _ O
correlations -X- _ O
. -X- _ O

Dataset -X- _ O
. -X- _ O
Let -X- _ O
D -X- _ O
= -X- _ O
{ -X- _ O
X -X- _ O
, -X- _ O
Y -X- _ O
, -X- _ O
Z -X- _ O
} -X- _ O
be -X- _ O
a -X- _ O
dataset -X- _ O
consisting -X- _ O
of -X- _ O
input -X- _ O
data -X- _ O
X -X- _ O
, -X- _ O
labels -X- _ O
Y -X- _ O
and -X- _ O
protected -X- _ O
attributes -X- _ O
Z. -X- _ O
2 -X- _ O
This -X- _ O
work -X- _ O
focuses -X- _ O
on -X- _ O
gender -X- _ O
as -X- _ O
the -X- _ O
protected -X- _ O
attribute -X- _ O
z. -X- _ O
In -X- _ O
all -X- _ O
definitions -X- _ O
, -X- _ O
F -X- _ O
and -X- _ O
M -X- _ O
indicate -X- _ O
female -X- _ O
and -X- _ O
male -X- _ O
gender -X- _ O
, -X- _ O
respectively -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
value -X- _ O
of -X- _ O
the -X- _ O
protected -X- _ O
attribute -X- _ O
z -X- _ O
. -X- _ O

Trained -X- _ O
Model -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
is -X- _ O
optimized -X- _ O
to -X- _ O
solve -X- _ O
the -X- _ O
downstream -X- _ O
task -X- _ O
posed -X- _ O
by -X- _ O
the -X- _ O
dataset -X- _ O
. -X- _ O
It -X- _ O
can -X- _ O
be -X- _ O
formalized -X- _ O
as -X- _ O
f -X- _ O
• -X- _ O
g -X- _ O
: -X- _ O
X -X- _ O
→ -X- _ O
R -X- _ O
|Y| -X- _ O
, -X- _ O
where -X- _ O
g -X- _ O
( -X- _ O
• -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
feature -X- _ O
extractor -X- _ O
, -X- _ O
implemented -X- _ O
by -X- _ O
a -X- _ O
language -X- _ O
model -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
RoBERTa -X- _ B-MethodName
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
f -X- _ O
( -X- _ O
• -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
classification -X- _ O
function -X- _ O
, -X- _ O
and -X- _ O
Y -X- _ O
is -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
the -X- _ O
possible -X- _ O
labels -X- _ O
for -X- _ O
the -X- _ O
task -X- _ O
. -X- _ O

Bias -X- _ O
Metrics -X- _ O

Each -X- _ O
bias -X- _ O
evaluation -X- _ O
method -X- _ O
described -X- _ O
in -X- _ O
the -X- _ O
literature -X- _ O
can -X- _ O
be -X- _ O
categorized -X- _ O
as -X- _ O
extrinsic -X- _ O
or -X- _ O
intrinsic -X- _ O
. -X- _ O
In -X- _ O
all -X- _ O
definitions -X- _ O
, -X- _ O
r -X- _ O
indicates -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
output -X- _ O
probabilities -X- _ O
. -X- _ O

Extrinsic -X- _ O
Metrics -X- _ O

Extrinsic -X- _ O
methods -X- _ O
involve -X- _ O
measuring -X- _ O
the -X- _ O
bias -X- _ O
of -X- _ O
a -X- _ O
model -X- _ O
solving -X- _ O
a -X- _ O
downstream -X- _ O
problem -X- _ O
. -X- _ O
The -X- _ O
extrinsic -X- _ O
metric -X- _ O
is -X- _ O
a -X- _ O
function -X- _ O
: -X- _ O

E -X- _ O
( -X- _ O
X -X- _ O
, -X- _ O
Y -X- _ O
, -X- _ O
R -X- _ O
, -X- _ O
Z -X- _ O
) -X- _ O
∈ -X- _ O
R -X- _ O

The -X- _ O
output -X- _ O
represents -X- _ O
the -X- _ O
quantity -X- _ O
of -X- _ O
bias -X- _ O
measured -X- _ O
; -X- _ O
the -X- _ O
further -X- _ O
from -X- _ O
0 -X- _ O
the -X- _ O
number -X- _ O
is -X- _ O
, -X- _ O
the -X- _ O
larger -X- _ O
the -X- _ O
bias -X- _ O
is -X- _ O
. -X- _ O
Our -X- _ O
analysis -X- _ O
comprises -X- _ O
a -X- _ O
wide -X- _ O
range -X- _ O
of -X- _ O
extrinsic -X- _ O
metrics -X- _ O
, -X- _ O
including -X- _ O
some -X- _ O
that -X- _ O
have -X- _ O
been -X- _ O
measured -X- _ O
in -X- _ O
the -X- _ O
past -X- _ O
on -X- _ O
the -X- _ O
analyzed -X- _ O
tasks -X- _ O
( -X- _ O
Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Ravfogel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Goldfarb -X- _ O
- -X- _ O
Tarrant -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
and -X- _ O
some -X- _ O
that -X- _ O
have -X- _ O
never -X- _ O
been -X- _ O
measured -X- _ O
before -X- _ O
, -X- _ O
and -X- _ O
shows -X- _ O
our -X- _ O
results -X- _ O
apply -X- _ O
to -X- _ O
many -X- _ O
of -X- _ O
them -X- _ O
. -X- _ O
For -X- _ O
illustration -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
consider -X- _ O
occupation -X- _ O
prediction -X- _ O
, -X- _ O
a -X- _ O
common -X- _ O
task -X- _ O
in -X- _ O
research -X- _ O
on -X- _ O
gender -X- _ O
bias -X- _ O
Ravfogel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
. -X- _ O
The -X- _ O
input -X- _ O
x -X- _ O
is -X- _ O
a -X- _ O
biography -X- _ O
and -X- _ O
the -X- _ O
prediction -X- _ O
y -X- _ O
is -X- _ O
the -X- _ O
profession -X- _ O
of -X- _ O
the -X- _ O
person -X- _ O
described -X- _ O
in -X- _ O
it -X- _ O
. -X- _ O
The -X- _ O
protected -X- _ O
attribute -X- _ O
z -X- _ O
is -X- _ O
the -X- _ O
gender -X- _ O
of -X- _ O
that -X- _ O
person -X- _ O
. -X- _ O

Performance -X- _ O
gap -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
the -X- _ O
difference -X- _ O
in -X- _ O
performance -X- _ O
metric -X- _ O
for -X- _ O
two -X- _ O
different -X- _ O
groups -X- _ O
, -X- _ O
for -X- _ O
instance -X- _ O
two -X- _ O
groups -X- _ O
of -X- _ O
binary -X- _ O
genders -X- _ O
, -X- _ O
or -X- _ O
a -X- _ O
group -X- _ O
of -X- _ O
pro -X- _ O
- -X- _ O
stereotypical -X- _ O
and -X- _ O
a -X- _ O
group -X- _ O
of -X- _ O
anti -X- _ O
- -X- _ O
stereotypical -X- _ O
examples -X- _ O
. -X- _ O
We -X- _ O
measure -X- _ O
the -X- _ O
following -X- _ O
metrics -X- _ O
: -X- _ O
True -X- _ B-MetricName
Positive -X- _ I-MetricName
Rate -X- _ I-MetricName
( -X- _ O
TPR -X- _ B-MetricName
) -X- _ O
, -X- _ O
False -X- _ B-MetricName
Positive -X- _ I-MetricName
Rate -X- _ I-MetricName
( -X- _ O
FPR -X- _ B-MetricName
) -X- _ O
, -X- _ O
and -X- _ O
Precision -X- _ B-MetricName
. -X- _ O
In -X- _ O
occupation -X- _ B-TaskName
prediction -X- _ I-TaskName
, -X- _ O
for -X- _ O
instance -X- _ O
, -X- _ O
the -X- _ O
TPR -X- _ B-MetricName
gap -X- _ O
for -X- _ O
each -X- _ O
profession -X- _ O
y -X- _ O
expresses -X- _ O
the -X- _ O
difference -X- _ O
in -X- _ O
the -X- _ O
percentage -X- _ O
of -X- _ O
women -X- _ O
and -X- _ O
men -X- _ O
whose -X- _ O
profession -X- _ O
is -X- _ O
y -X- _ O
and -X- _ O
are -X- _ O
correctly -X- _ O
classified -X- _ O
as -X- _ O
such -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
measure -X- _ O
F1 -X- _ O
of -X- _ O
three -X- _ O
standard -X- _ O
clustering -X- _ O
metrics -X- _ O
for -X- _ O
coreference -X- _ O
resolution -X- _ O
. -X- _ O
Each -X- _ O
such -X- _ O
performance -X- _ O
gap -X- _ O
captures -X- _ O
a -X- _ O
different -X- _ O
facet -X- _ O
of -X- _ O
gender -X- _ O
bias -X- _ O
, -X- _ O
and -X- _ O
one -X- _ O
might -X- _ O
be -X- _ O
more -X- _ O
interested -X- _ O
in -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
metrics -X- _ O
depending -X- _ O
on -X- _ O
the -X- _ O
application -X- _ O
. -X- _ O
We -X- _ O
compute -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
performance -X- _ O
gap -X- _ O
metrics -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
the -X- _ O
sum -X- _ B-MetricName
of -X- _ I-MetricName
absolute -X- _ I-MetricName
gap -X- _ I-MetricName
values -X- _ O
over -X- _ O
all -X- _ O
classes -X- _ O
; -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
the -X- _ O
Pearson -X- _ B-MetricName
correlation -X- _ I-MetricName
between -X- _ O
the -X- _ O
performance -X- _ O
gap -X- _ O
for -X- _ O
a -X- _ O
class -X- _ O
and -X- _ O
the -X- _ O
percentage -X- _ O
of -X- _ O
women -X- _ O
in -X- _ O
that -X- _ O
class -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
if -X- _ O
y -X- _ O
is -X- _ O
a -X- _ O
profession -X- _ O
, -X- _ O
we -X- _ O
measure -X- _ O
the -X- _ O
correlation -X- _ O
between -X- _ O
performance -X- _ O
gaps -X- _ O
and -X- _ O
percentages -X- _ O
of -X- _ O
women -X- _ O
in -X- _ O
each -X- _ O
profession -X- _ O
. -X- _ O
3 -X- _ O
The -X- _ O
two -X- _ O
metrics -X- _ O
are -X- _ O
closely -X- _ O
related -X- _ O
but -X- _ O
answer -X- _ O
slightly -X- _ O
different -X- _ O
questions -X- _ O
: -X- _ O
the -X- _ O
sum -X- _ O
quantifies -X- _ O
how -X- _ O
a -X- _ O
model -X- _ O
behaves -X- _ O
differently -X- _ O
on -X- _ O
different -X- _ O
genders -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
correlation -X- _ O
shows -X- _ O
the -X- _ O
relation -X- _ O
of -X- _ O
model -X- _ O
behaviour -X- _ O
to -X- _ O
social -X- _ O
biases -X- _ O
( -X- _ O
in -X- _ O
the -X- _ O
world -X- _ O
or -X- _ O
the -X- _ O
data -X- _ O
) -X- _ O
without -X- _ O
regard -X- _ O
to -X- _ O
actual -X- _ O
gap -X- _ O
size -X- _ O
. -X- _ O

Statistical -X- _ O
metrics -X- _ O
. -X- _ O
For -X- _ O
breadth -X- _ O
of -X- _ O
analysis -X- _ O
, -X- _ O
we -X- _ O
examine -X- _ O
three -X- _ O
additional -X- _ O
statistical -X- _ O
metrics -X- _ O
( -X- _ O
Barocas -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
correspond -X- _ O
to -X- _ O
different -X- _ O
notions -X- _ O
of -X- _ O
bias -X- _ O
. -X- _ O
All -X- _ O
three -X- _ O
are -X- _ O
measured -X- _ O
as -X- _ O
differences -X- _ O
( -X- _ O
d -X- _ O
) -X- _ O
between -X- _ O
two -X- _ O
probability -X- _ O
distributions -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
then -X- _ O
obtain -X- _ O
a -X- _ O
single -X- _ O
bias -X- _ O
quantity -X- _ O
per -X- _ O
metric -X- _ O
by -X- _ O
summing -X- _ O
all -X- _ O
computed -X- _ O
distances -X- _ O
. -X- _ O

• -X- _ O
Independence -X- _ B-MetricName
: -X- _ O
d -X- _ O
P -X- _ O
( -X- _ O
r|z -X- _ O
= -X- _ O
z -X- _ O
) -X- _ O
, -X- _ O
P -X- _ O
( -X- _ O
r -X- _ O
) -X- _ O
∀z -X- _ O
∈ -X- _ O
{ -X- _ O
F -X- _ O
, -X- _ O
M -X- _ O
} -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
we -X- _ O
measure -X- _ O
the -X- _ O
difference -X- _ O
between -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
model -X- _ O
's -X- _ O
predictions -X- _ O
on -X- _ O
women -X- _ O
and -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
all -X- _ O
predictions -X- _ O
. -X- _ O
Independence -X- _ O
is -X- _ O
stronger -X- _ O
as -X- _ O
the -X- _ O
prediction -X- _ O
r -X- _ O
is -X- _ O
less -X- _ O
correlated -X- _ O
with -X- _ O
the -X- _ O
protected -X- _ O
attribute -X- _ O
z. -X- _ O
It -X- _ O
is -X- _ O
measured -X- _ O
with -X- _ O
no -X- _ O
relation -X- _ O
to -X- _ O
the -X- _ O
gold -X- _ O
labels -X- _ O
. -X- _ O

• -X- _ O
Separation -X- _ B-MetricName
: -X- _ O
d -X- _ O
P -X- _ O
( -X- _ O
r|y -X- _ O
= -X- _ O
y -X- _ O
, -X- _ O
z -X- _ O
= -X- _ O
z -X- _ O
) -X- _ O
, -X- _ O
P -X- _ O
( -X- _ O
r|y -X- _ O
= -X- _ O
y -X- _ O
) -X- _ O
∀y -X- _ O
∈ -X- _ O
Y -X- _ O
, -X- _ O
z -X- _ O
∈ -X- _ O
{ -X- _ O
F -X- _ O
, -X- _ O
M -X- _ O
} -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
we -X- _ O
measure -X- _ O
the -X- _ O
difference -X- _ O
between -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
a -X- _ O
model -X- _ O
's -X- _ O
predictions -X- _ O
on -X- _ O
women -X- _ O
who -X- _ O
are -X- _ O
teachers -X- _ O
and -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
predictions -X- _ O
on -X- _ O
all -X- _ O
teachers -X- _ O
. -X- _ O
It -X- _ O
encapsulates -X- _ O
the -X- _ O
TPR -X- _ O
and -X- _ O
FPR -X- _ O
gaps -X- _ O
discussed -X- _ O
previously -X- _ O
, -X- _ O
and -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
as -X- _ O
a -X- _ O
more -X- _ O
general -X- _ O
metric -X- _ O
. -X- _ O

• -X- _ O
Sufficiency -X- _ B-MetricName
: -X- _ O
d -X- _ O
P -X- _ O
( -X- _ O
y|r -X- _ O
= -X- _ O
r -X- _ O
, -X- _ O
z -X- _ O
= -X- _ O
z -X- _ O
) -X- _ O
, -X- _ O
P -X- _ O
( -X- _ O
y|r -X- _ O
= -X- _ O
r -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
we -X- _ O
measure -X- _ O
the -X- _ O
difference -X- _ O
between -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
gold -X- _ O
labels -X- _ O
on -X- _ O
women -X- _ O
classified -X- _ O
as -X- _ O
teachers -X- _ O
by -X- _ O
the -X- _ O
model -X- _ O
and -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
gold -X- _ O
labels -X- _ O
on -X- _ O
all -X- _ O
individuals -X- _ O
classified -X- _ O
as -X- _ O
teachers -X- _ O
by -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O
Sufficiency -X- _ O
relates -X- _ O
to -X- _ O
the -X- _ O
concept -X- _ O
of -X- _ O
calibration -X- _ O
in -X- _ O
classification -X- _ O
. -X- _ O
A -X- _ O
difference -X- _ O
in -X- _ O
the -X- _ O
classifier -X- _ O
's -X- _ O
scores -X- _ O
for -X- _ O
men -X- _ O
and -X- _ O
for -X- _ O
women -X- _ O
indicates -X- _ O
that -X- _ O
it -X- _ O
might -X- _ O
be -X- _ O
penalizing -X- _ O
or -X- _ O
over -X- _ O
- -X- _ O
promoting -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
genders -X- _ O
. -X- _ O

Intrinsic -X- _ O
Metrics -X- _ O

Intrinsic -X- _ O
methods -X- _ O
are -X- _ O
applied -X- _ O
to -X- _ O
the -X- _ O
representation -X- _ O
obtained -X- _ O
from -X- _ O
the -X- _ O
feature -X- _ O
extractor -X- _ O
. -X- _ O
These -X- _ O
methods -X- _ O
are -X- _ O
independent -X- _ O
of -X- _ O
any -X- _ O
downstream -X- _ O
task -X- _ O
. -X- _ O
The -X- _ O
intrinsic -X- _ O
metric -X- _ O
is -X- _ O
a -X- _ O
function -X- _ O
: -X- _ O

I -X- _ O
( -X- _ O
g -X- _ O
( -X- _ O
X -X- _ O
) -X- _ O
, -X- _ O
Z -X- _ O
) -X- _ O
∈ -X- _ O
R -X- _ O
Compression -X- _ B-MetricName
. -X- _ O

Our -X- _ O
main -X- _ O
intrinsic -X- _ O
metric -X- _ O
is -X- _ O
the -X- _ O
compression -X- _ B-MetricName
of -X- _ O
gender -X- _ O
information -X- _ O
evaluated -X- _ O
by -X- _ O
a -X- _ O
minimum -X- _ O
description -X- _ O
length -X- _ O
( -X- _ O
MDL -X- _ O
) -X- _ O
probing -X- _ O
classifier -X- _ O
( -X- _ O
Voita -X- _ O
and -X- _ O
Titov -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
trained -X- _ O
to -X- _ O
predict -X- _ O
gender -X- _ O
from -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
representations -X- _ O
. -X- _ O
Probing -X- _ O
classifiers -X- _ O
are -X- _ O
widely -X- _ O
used -X- _ O
for -X- _ O
predicting -X- _ O
various -X- _ O
properties -X- _ O
of -X- _ O
interest -X- _ O
from -X- _ O
frozen -X- _ O
model -X- _ O
representations -X- _ O
( -X- _ O
Belinkov -X- _ O
and -X- _ O
Glass -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
MDL -X- _ O
probes -X- _ O
were -X- _ O
proposed -X- _ O
because -X- _ O
a -X- _ O
probe -X- _ O
's -X- _ O
accuracy -X- _ O
may -X- _ O
be -X- _ O
misleading -X- _ O
due -X- _ O
to -X- _ O
memorization -X- _ O
and -X- _ O
other -X- _ O
issues -X- _ O
( -X- _ O
Hewitt -X- _ O
and -X- _ O
Liang -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Belinkov -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
MDL -X- _ O
online -X- _ O
code -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
probe -X- _ O
is -X- _ O
trained -X- _ O
in -X- _ O
timesteps -X- _ O
, -X- _ O
on -X- _ O
increasing -X- _ O
subsets -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
, -X- _ O
then -X- _ O
evaluated -X- _ O
against -X- _ O
the -X- _ O
rest -X- _ O
of -X- _ O
it -X- _ O
. -X- _ O
Higher -X- _ O
compression -X- _ O
indicates -X- _ O
greater -X- _ O
gender -X- _ O
extractability -X- _ O
. -X- _ O

CEAT -X- _ B-MetricName
. -X- _ O
We -X- _ O
also -X- _ O
measure -X- _ O
CEAT -X- _ B-MetricName
( -X- _ O
Guo -X- _ O
and -X- _ O
Caliskan -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
contextualized -X- _ O
version -X- _ O
of -X- _ O
WEAT -X- _ O
( -X- _ O
Caliskan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
widely -X- _ O
used -X- _ O
bias -X- _ O
metric -X- _ O
for -X- _ O
static -X- _ O
word -X- _ O
embeddings -X- _ O
. -X- _ O
WEAT -X- _ O
defines -X- _ O
sets -X- _ O
X -X- _ O
and -X- _ O
Y -X- _ O
of -X- _ O
target -X- _ O
words -X- _ O
, -X- _ O
and -X- _ O
sets -X- _ O
A -X- _ O
and -X- _ O
B -X- _ O
of -X- _ O
attribute -X- _ O
words -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
A -X- _ O
and -X- _ O
B -X- _ O
contain -X- _ O
males -X- _ O
and -X- _ O
females -X- _ O
names -X- _ O
, -X- _ O
while -X- _ O
X -X- _ O
and -X- _ O
Y -X- _ O
contain -X- _ O
career -X- _ O
and -X- _ O
family -X- _ O
related -X- _ O
words -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
The -X- _ O
bias -X- _ O
is -X- _ O
operationalized -X- _ O
as -X- _ O
the -X- _ O
geometric -X- _ O
proximity -X- _ O
between -X- _ O
the -X- _ O
target -X- _ O
and -X- _ O
attribute -X- _ O
word -X- _ O
embeddings -X- _ O
, -X- _ O
and -X- _ O
is -X- _ O
quantified -X- _ O
in -X- _ O
CEAT -X- _ B-MetricName
by -X- _ O
the -X- _ O
Combined -X- _ O
Effect -X- _ O
Size -X- _ O
( -X- _ O
CES -X- _ O
) -X- _ O
and -X- _ O
a -X- _ O
p -X- _ O
- -X- _ O
value -X- _ O
for -X- _ O
the -X- _ O
null -X- _ O
hypothesis -X- _ O
of -X- _ O
having -X- _ O
no -X- _ O
biased -X- _ O
associations -X- _ O
. -X- _ O
For -X- _ O
more -X- _ O
information -X- _ O
on -X- _ O
CEAT -X- _ B-MetricName
refer -X- _ O
to -X- _ O
Appendix -X- _ O
A.4.3 -X- _ O
. -X- _ O

Debiasing -X- _ O
Techniques -X- _ O

We -X- _ O
debias -X- _ O
models -X- _ O
by -X- _ O
modifying -X- _ O
the -X- _ O
downstream -X- _ O
task -X- _ O
's -X- _ O
training -X- _ O
data -X- _ O
before -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
. -X- _ O
Scrubbing -X- _ O
( -X- _ O
De -X- _ O
- -X- _ O
Arteaga -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
removes -X- _ O
first -X- _ O
names -X- _ O
and -X- _ O
gender -X- _ O
- -X- _ O
specific -X- _ O
terms -X- _ O
( -X- _ O
" -X- _ O
he -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
she -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
husband -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
wife -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
Mr -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
Mrs -X- _ O
" -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
) -X- _ O
. -X- _ O
Balancing -X- _ O
subsamples -X- _ O
or -X- _ O
oversamples -X- _ O
examples -X- _ O
such -X- _ O
that -X- _ O
each -X- _ O
gender -X- _ O
is -X- _ O
equally -X- _ O
represented -X- _ O
in -X- _ O
the -X- _ O
resulting -X- _ O
dataset -X- _ O
w.r.t -X- _ O
each -X- _ O
label -X- _ O
. -X- _ O
Anonymization -X- _ O
( -X- _ O
Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
removes -X- _ O
named -X- _ O
entities -X- _ O
. -X- _ O
Counterfactual -X- _ O
Augmentation -X- _ O
( -X- _ O
Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
involves -X- _ O
replacing -X- _ O
male -X- _ O
entities -X- _ O
in -X- _ O
an -X- _ O
example -X- _ O
with -X- _ O
female -X- _ O
entities -X- _ O
, -X- _ O
and -X- _ O
adding -X- _ O
the -X- _ O
modified -X- _ O
example -X- _ O
to -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
. -X- _ O
As -X- _ O
some -X- _ O
of -X- _ O
these -X- _ O
are -X- _ O
dataset -X- _ O
/ -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
, -X- _ O
we -X- _ O
give -X- _ O
more -X- _ O
details -X- _ O
in -X- _ O
the -X- _ O
following -X- _ O
section -X- _ O
. -X- _ O

Experiments -X- _ O

In -X- _ O
each -X- _ O
experiment -X- _ O
, -X- _ O
we -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
a -X- _ O
model -X- _ O
for -X- _ O
a -X- _ O
downstream -X- _ O
task -X- _ O
. -X- _ O
For -X- _ O
training -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
either -X- _ O
the -X- _ O
original -X- _ O
dataset -X- _ O
or -X- _ O
a -X- _ O
dataset -X- _ O
debiased -X- _ O
with -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
methods -X- _ O
from -X- _ O
Section -X- _ O
2.2 -X- _ O
. -X- _ O
Figure -X- _ O
2 -X- _ O
presents -X- _ O
examples -X- _ O
of -X- _ O
debiasing -X- _ O
methods -X- _ O
for -X- _ O
the -X- _ O
two -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O
We -X- _ O
measure -X- _ O
two -X- _ O
intrinsic -X- _ O
metrics -X- _ O
by -X- _ O
probing -X- _ O
that -X- _ O
model -X- _ O
's -X- _ O
inner -X- _ O
representations -X- _ O
for -X- _ O
gender -X- _ O
extractability -X- _ O
( -X- _ O
as -X- _ O
measured -X- _ O
by -X- _ O
MDL -X- _ O
) -X- _ O
and -X- _ O
by -X- _ O
CEAT -X- _ O
, -X- _ O
and -X- _ O
test -X- _ O
various -X- _ O
extrinsic -X- _ O
metrics -X- _ O
. -X- _ O
The -X- _ O
relation -X- _ O
between -X- _ O
one -X- _ O
intrinsic -X- _ O
and -X- _ O
one -X- _ O
extrinsic -X- _ O
metric -X- _ O
becomes -X- _ O
one -X- _ O
data -X- _ O
point -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
repeat -X- _ O
over -X- _ O
many -X- _ O
random -X- _ O
seeds -X- _ O
( -X- _ O
for -X- _ O
both -X- _ O
the -X- _ O
model -X- _ O
and -X- _ O
the -X- _ O
probe -X- _ O
) -X- _ O
. -X- _ O
Further -X- _ O
implementation -X- _ O
details -X- _ O
are -X- _ O
in -X- _ O
appendix -X- _ O
A -X- _ O
. -X- _ O

Occupation -X- _ B-TaskName
Prediction -X- _ I-TaskName

The -X- _ O
task -X- _ O
of -X- _ O
occupation -X- _ B-TaskName
prediction -X- _ I-TaskName
is -X- _ O
to -X- _ O
predict -X- _ O
a -X- _ O
person -X- _ O
's -X- _ O
occupations -X- _ O
( -X- _ O
from -X- _ O
a -X- _ O
closed -X- _ O
set -X- _ O
) -X- _ O
, -X- _ O
based -X- _ O
on -X- _ O
their -X- _ O
biography -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
Bias -X- _ O
in -X- _ O
Bios -X- _ O
dataset -X- _ O
. -X- _ O
Regardless -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
method -X- _ O
, -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
is -X- _ O
subsampled -X- _ O
such -X- _ O
that -X- _ O
each -X- _ O
profession -X- _ O
has -X- _ O
equal -X- _ O
gender -X- _ O
representation -X- _ O
. -X- _ O

Britney -X- _ O
currently -X- _ O
works -X- _ O
on -X- _ O
CNN -X- _ O
's -X- _ O
newest -X- _ O
primetime -X- _ O
show -X- _ O
. -X- _ O
She -X- _ O
has -X- _ O
also -X- _ O
written -X- _ O
for -X- _ O
the -X- _ O
New -X- _ O
York -X- _ O
Times -X- _ O
. -X- _ O

_ -X- _ O
currently -X- _ O
works -X- _ O
on -X- _ O
CNN -X- _ O
's -X- _ O
newest -X- _ O
primetime -X- _ O
show -X- _ O
. -X- _ O
_ -X- _ O
has -X- _ O
also -X- _ O
written -X- _ O
for -X- _ O
the -X- _ O
New -X- _ O
York -X- _ O
Times -X- _ O
. -X- _ O

Scrubbing -X- _ O

My -X- _ O
sister -X- _ O
is -X- _ O
taking -X- _ O
a -X- _ O
painting -X- _ O
class -X- _ O
this -X- _ O
summer -X- _ O
, -X- _ O
so -X- _ O
she -X- _ O
has -X- _ O
been -X- _ O
sharing -X- _ O
the -X- _ O
latest -X- _ O
lesson -X- _ O
with -X- _ O
me -X- _ O
. -X- _ O

My -X- _ O
brother -X- _ O
is -X- _ O
taking -X- _ O
a -X- _ O
painting -X- _ O
class -X- _ O
this -X- _ O
summer -X- _ O
, -X- _ O
so -X- _ O
he -X- _ O
has -X- _ O
been -X- _ O
sharing -X- _ O
the -X- _ O
latest -X- _ O
lesson -X- _ O
with -X- _ O
me -X- _ O
. -X- _ O

Counterfactual -X- _ O
augmentation -X- _ O
Occupation -X- _ O
Classification -X- _ O
Coreference -X- _ B-TaskName
Resolution -X- _ I-TaskName
Original -X- _ O
dataset -X- _ O

Original -X- _ O
dataset -X- _ O
Model -X- _ O
. -X- _ O
Our -X- _ O
main -X- _ O
model -X- _ O
is -X- _ O
a -X- _ O
RoBERTa -X- _ B-MethodName
model -X- _ O
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
topped -X- _ O
with -X- _ O
a -X- _ O
linear -X- _ O
classifier -X- _ O
, -X- _ O
which -X- _ O
receives -X- _ O
the -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
token -X- _ O
embedding -X- _ O
as -X- _ O
input -X- _ O
and -X- _ O
generates -X- _ O
a -X- _ O
probability -X- _ O
distribution -X- _ O
over -X- _ O
the -X- _ O
professions -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
we -X- _ O
experiment -X- _ O
with -X- _ O
training -X- _ O
a -X- _ O
baseline -X- _ O
classifier -X- _ O
layer -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
a -X- _ O
frozen -X- _ O
, -X- _ O
non -X- _ O
- -X- _ O
finetuned -X- _ O
RoBERTa -X- _ B-MethodName
. -X- _ O
We -X- _ O
also -X- _ O
replicate -X- _ O
our -X- _ O
RoBERTa -X- _ B-MethodName
experiments -X- _ O
with -X- _ O
a -X- _ O
DeBERTa -X- _ B-MethodName
model -X- _ O
( -X- _ O
He -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
to -X- _ O
verify -X- _ O
that -X- _ O
our -X- _ O
results -X- _ O
are -X- _ O
are -X- _ O
not -X- _ O
model -X- _ O
specific -X- _ O
and -X- _ O
hold -X- _ O
more -X- _ O
broadly -X- _ O
. -X- _ O

Debiasing -X- _ O
Techniques -X- _ O
. -X- _ O
Following -X- _ O
De -X- _ O
- -X- _ O
Arteaga -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
we -X- _ O
experiment -X- _ O
with -X- _ O
scrubbing -X- _ O
the -X- _ O
training -X- _ O
dataset -X- _ O
. -X- _ O
Figure -X- _ O
2 -X- _ O
shows -X- _ O
an -X- _ O
example -X- _ O
biography -X- _ O
snippet -X- _ O
and -X- _ O
its -X- _ O
scrubbed -X- _ O
version -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
conduct -X- _ O
balancing -X- _ O
( -X- _ O
per -X- _ O
profession -X- _ O
, -X- _ O
subsampling -X- _ O
and -X- _ O
oversampling -X- _ O
to -X- _ O
ensure -X- _ O
an -X- _ O
equal -X- _ O
number -X- _ O
of -X- _ O
males -X- _ O
and -X- _ O
females -X- _ O
per -X- _ O
profession -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
has -X- _ O
not -X- _ O
previously -X- _ O
been -X- _ O
used -X- _ O
on -X- _ O
this -X- _ O
dataset -X- _ O
and -X- _ O
task -X- _ O
. -X- _ O

Metrics -X- _ O
. -X- _ O
We -X- _ O
measure -X- _ O
all -X- _ O
bias -X- _ O
metrics -X- _ O
from -X- _ O
Section -X- _ O
2.1 -X- _ O
except -X- _ O
for -X- _ O
F1 -X- _ O
. -X- _ O

Probing -X- _ O
. -X- _ O
The -X- _ O
probing -X- _ O
dataset -X- _ O
for -X- _ O
this -X- _ O
task -X- _ O
is -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
gender -X- _ O
label -X- _ O
of -X- _ O
a -X- _ O
single -X- _ O
biography -X- _ O
is -X- _ O
the -X- _ O
gender -X- _ O
of -X- _ O
the -X- _ O
person -X- _ O
described -X- _ O
in -X- _ O
it -X- _ O
. -X- _ O
We -X- _ O
probe -X- _ O
the -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
token -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
biography -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
to -X- _ O
the -X- _ O
models -X- _ O
described -X- _ O
above -X- _ O
, -X- _ O
we -X- _ O
measure -X- _ O
baseline -X- _ O
extractability -X- _ O
of -X- _ O
gender -X- _ O
information -X- _ O
from -X- _ O
a -X- _ O
randomly -X- _ O
initialized -X- _ O
RoBERTa -X- _ B-MethodName
model -X- _ O
. -X- _ O

Coreference -X- _ O
Resolution -X- _ O

The -X- _ O
task -X- _ O
of -X- _ O
coreference -X- _ B-TaskName
resolution -X- _ I-TaskName
is -X- _ O
to -X- _ O
find -X- _ O
all -X- _ O
textual -X- _ O
expressions -X- _ O
referring -X- _ O
to -X- _ O
the -X- _ O
same -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
entities -X- _ O
. -X- _ O
We -X- _ O
train -X- _ O
on -X- _ O
Ontonotes -X- _ O
5.0 -X- _ O
( -X- _ O
Weischedel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
and -X- _ O
test -X- _ O
on -X- _ O
the -X- _ O
Winobias -X- _ O
challenge -X- _ O
dataset -X- _ O
( -X- _ O
Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
Winobias -X- _ O
consists -X- _ O
of -X- _ O
sentence -X- _ O
pairs -X- _ O
, -X- _ O
pro -X- _ O
- -X- _ O
and -X- _ O
anti -X- _ O
- -X- _ O
stereotypical -X- _ O
variants -X- _ O
, -X- _ O
with -X- _ O
individuals -X- _ O
referred -X- _ O
to -X- _ O
by -X- _ O
their -X- _ O
profession -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
" -X- _ O
The -X- _ O
physician -X- _ O
hired -X- _ O
the -X- _ O
secretary -X- _ O
be- -X- _ O
cause -X- _ O
he -X- _ O
/ -X- _ O
she -X- _ O
was -X- _ O
busy -X- _ O
. -X- _ O
" -X- _ O
is -X- _ O
pro -X- _ O
/ -X- _ O
anti -X- _ O
- -X- _ O
stereotypical -X- _ O
, -X- _ O
based -X- _ O
on -X- _ O
US -X- _ O
labor -X- _ O
statistics -X- _ O
. -X- _ O
4 -X- _ O
A -X- _ O
coreference -X- _ O
system -X- _ O
is -X- _ O
measured -X- _ O
by -X- _ O
the -X- _ O
performance -X- _ O
gap -X- _ O
between -X- _ O
the -X- _ O
pro -X- _ O
- -X- _ O
and -X- _ O
anti -X- _ O
- -X- _ O
stereotypical -X- _ O
subsets -X- _ O
. -X- _ O

Model -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
model -X- _ O
presented -X- _ O
in -X- _ O
Lee -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018a -X- _ O
) -X- _ O
with -X- _ O
RoBERTa -X- _ B-MethodName
as -X- _ O
a -X- _ O
feature -X- _ O
extractor -X- _ O
. -X- _ O

Debiasing -X- _ O
Techniques -X- _ O
. -X- _ O
Following -X- _ O
Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
anonymization -X- _ O
( -X- _ O
denoted -X- _ O
as -X- _ O
Anon -X- _ O
) -X- _ O
and -X- _ O
counterfactual -X- _ O
augmentation -X- _ O
( -X- _ O
CA -X- _ O
) -X- _ O
on -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
. -X- _ O
These -X- _ O
techniques -X- _ O
were -X- _ O
used -X- _ O
jointly -X- _ O
in -X- _ O
previous -X- _ O
work -X- _ O
; -X- _ O
we -X- _ O
examine -X- _ O
each -X- _ O
individually -X- _ O
as -X- _ O
well -X- _ O
. -X- _ O

Metrics -X- _ O
. -X- _ O
Following -X- _ O
Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
measure -X- _ O
the -X- _ O
F1 -X- _ O
difference -X- _ O
between -X- _ O
anti -X- _ O
- -X- _ O
and -X- _ O
prostereotypical -X- _ O
examples -X- _ O
. -X- _ O
5 -X- _ O
We -X- _ O
also -X- _ O
interpret -X- _ O
the -X- _ O
task -X- _ O
as -X- _ O
a -X- _ O
classification -X- _ O
problem -X- _ O
, -X- _ O
and -X- _ O
measure -X- _ O
all -X- _ O
metrics -X- _ O
from -X- _ O
Section -X- _ O
2.1 -X- _ O
. -X- _ O
For -X- _ O
more -X- _ O
details -X- _ O
refer -X- _ O
to -X- _ O
Appendix -X- _ O
A.4.2 -X- _ O
. -X- _ O

Probing -X- _ O
. -X- _ O
We -X- _ O
probe -X- _ O
the -X- _ O
representation -X- _ O
of -X- _ O
a -X- _ O
profession -X- _ O
word -X- _ O
as -X- _ O
extracted -X- _ O
from -X- _ O
Winobias -X- _ O
sentences -X- _ O
, -X- _ O

Results -X- _ O

Tables -X- _ O
1a -X- _ O
and -X- _ O
1b -X- _ O
present -X- _ O
intrinsic -X- _ O
and -X- _ O
extrinsic -X- _ O
metrics -X- _ O
for -X- _ O
RoBERTa -X- _ B-MethodName
models -X- _ O
on -X- _ O
the -X- _ O
occupation -X- _ O
prediction -X- _ O
and -X- _ O
coreference -X- _ O
resolution -X- _ O
tasks -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
We -X- _ O
present -X- _ O
a -X- _ O
representative -X- _ O
subset -X- _ O
of -X- _ O
the -X- _ O
measured -X- _ O
metrics -X- _ O
that -X- _ O
demonstrate -X- _ O
the -X- _ O
observed -X- _ O
phenomena -X- _ O
; -X- _ O
full -X- _ O
results -X- _ O
are -X- _ O
found -X- _ O
in -X- _ O
Appendix -X- _ O
B. -X- _ O
The -X- _ O
DeBERTa -X- _ B-MethodName
model -X- _ O
results -X- _ O
are -X- _ O
consistent -X- _ O
with -X- _ O
the -X- _ O
RoBERTa -X- _ B-MethodName
model -X- _ O
trends -X- _ O
. -X- _ O

Compression -X- _ O
Reflects -X- _ O
Debiasing -X- _ O
Effects -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
the -X- _ O
tables -X- _ O
, -X- _ O
compression -X- _ O
captures -X- _ O
differences -X- _ O
in -X- _ O
models -X- _ O
that -X- _ O
were -X- _ O
debiased -X- _ O
differently -X- _ O
. -X- _ O
CEAT -X- _ B-MetricName
, -X- _ O
however -X- _ O
, -X- _ O
can -X- _ O
not -X- _ O
differentiate -X- _ O
between -X- _ O
occupation -X- _ O
prediction -X- _ O
models -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
in -X- _ O
occupation -X- _ O
prediction -X- _ O
( -X- _ O
Table -X- _ O
1a -X- _ O
) -X- _ O
the -X- _ O
compression -X- _ O
rate -X- _ O
varies -X- _ O
significantly -X- _ O
between -X- _ O
a -X- _ O
non -X- _ O
- -X- _ O
debiased -X- _ O
and -X- _ O
a -X- _ O
debiased -X- _ O
model -X- _ O
via -X- _ O
scrubbing -X- _ O
and -X- _ O
oversampling -X- _ O
, -X- _ O
while -X- _ O
CEAT -X- _ B-MetricName
detects -X- _ O
no -X- _ O
difference -X- _ O
between -X- _ O
the -X- _ O
models -X- _ O
. -X- _ O
In -X- _ O
coreference -X- _ O
resolution -X- _ O
( -X- _ O
Table -X- _ O
1b -X- _ O
) -X- _ O
, -X- _ O
both -X- _ O
compression -X- _ O
and -X- _ O
CEAT -X- _ B-MetricName
are -X- _ O
able -X- _ O
to -X- _ O
identify -X- _ O
differences -X- _ O
between -X- _ O
the -X- _ O
non -X- _ O
- -X- _ O
debiased -X- _ O
model -X- _ O
and -X- _ O
the -X- _ O
others -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
CA -X- _ O
, -X- _ O
which -X- _ O
has -X- _ O
both -X- _ O
a -X- _ O
lower -X- _ O
compression -X- _ O
and -X- _ O
CEAT -X- _ B-MetricName
effect -X- _ O
. -X- _ O
But -X- _ O
the -X- _ O
CEAT -X- _ B-MetricName
effect -X- _ O
sizes -X- _ O
are -X- _ O
small -X- _ O
( -X- _ O
below -X- _ O
0.5 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
implies -X- _ O
no -X- _ O
bias -X- _ O
, -X- _ O
in -X- _ O
contrast -X- _ O
to -X- _ O
the -X- _ O
extrinsic -X- _ O
metrics -X- _ O
. -X- _ O

High -X- _ O
Gender -X- _ O
Extractability -X- _ O
Implies -X- _ O
Superficial -X- _ O
Debiasing -X- _ O

Extrinsic -X- _ O
and -X- _ O
intrinsic -X- _ O
effects -X- _ O
of -X- _ O
debiasing -X- _ O
. -X- _ O
In -X- _ O
occupation -X- _ O
classification -X- _ O
( -X- _ O
1a -X- _ O
and -X- _ O
1b -X- _ O
also -X- _ O
compare -X- _ O
extrinsic -X- _ O
metrics -X- _ O
before -X- _ O
and -X- _ O
after -X- _ O
retraining -X- _ O
. -X- _ O
All -X- _ O
models -X- _ O
show -X- _ O
bias -X- _ O
restoration -X- _ O
, -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
classification -X- _ O
layer -X- _ O
being -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
biased -X- _ O
dataset -X- _ O
. -X- _ O
6 -X- _ O
The -X- _ O
amount -X- _ O
of -X- _ O
bias -X- _ O
restored -X- _ O
varies -X- _ O
between -X- _ O
models -X- _ O
in -X- _ O
a -X- _ O
way -X- _ O
that -X- _ O
is -X- _ O
predictable -X- _ O
by -X- _ O
the -X- _ O
compression -X- _ B-MetricName
metric -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
occupation -X- _ B-TaskName
prediction -X- _ I-TaskName
task -X- _ O
, -X- _ O
comparing -X- _ O
Before -X- _ O
and -X- _ O
After -X- _ O
numbers -X- _ O
in -X- _ O
Table -X- _ O
1a -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
using -X- _ O
a -X- _ O
scrubbed -X- _ O
dataset -X- _ O
- -X- _ O
which -X- _ O
has -X- _ O
the -X- _ O
lowest -X- _ O
compression -X- _ O
rate -X- _ O
- -X- _ O
displays -X- _ O
the -X- _ O
least -X- _ O
bias -X- _ O
restoration -X- _ O
, -X- _ O
confirming -X- _ O
that -X- _ O
the -X- _ O
LM -X- _ O
absorbed -X- _ O
the -X- _ O
process -X- _ O
of -X- _ O
debiasing -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
subsampled -X- _ O
data -X- _ O
has -X- _ O
higher -X- _ O
extrinsic -X- _ O
bias -X- _ O
after -X- _ O
retraining -X- _ O
. -X- _ O
Hence -X- _ O
, -X- _ O
the -X- _ O
debiasing -X- _ O
was -X- _ O
primarily -X- _ O
cosmetic -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
representations -X- _ O
within -X- _ O
the -X- _ O
LM -X- _ O
were -X- _ O
not -X- _ O
debiased -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
oversampled -X- _ O
data -X- _ O
- -X- _ O
which -X- _ O
has -X- _ O
the -X- _ O
highest -X- _ O
compression -X- _ O
- -X- _ O
has -X- _ O
the -X- _ O
highest -X- _ O
extrinsic -X- _ O
bias -X- _ O
( -X- _ O
except -X- _ O
for -X- _ O
FPR -X- _ O
) -X- _ O
, -X- _ O
even -X- _ O
though -X- _ O
this -X- _ O
was -X- _ O
not -X- _ O
true -X- _ O
before -X- _ O
retraining -X- _ O
. -X- _ O

In -X- _ O
coreference -X- _ B-TaskName
resolution -X- _ I-TaskName
, -X- _ O
comparing -X- _ O
Before -X- _ O
and -X- _ O
After -X- _ O
numbers -X- _ O
in -X- _ O
Table -X- _ O
1b -X- _ O
, -X- _ O
models -X- _ O
with -X- _ O
the -X- _ O
least -X- _ O
extrinsic -X- _ O
bias -X- _ O
( -X- _ O
CA -X- _ O
and -X- _ O
CA+Anon -X- _ O
) -X- _ O
are -X- _ O
also -X- _ O
least -X- _ O
biased -X- _ O
after -X- _ O
retraining -X- _ O
. -X- _ O
Compression -X- _ B-MetricName
rate -X- _ O
predicted -X- _ O
this -X- _ O
; -X- _ O
these -X- _ O
models -X- _ O
also -X- _ O
had -X- _ O
lower -X- _ O
compression -X- _ B-MetricName
rates -X- _ O
than -X- _ O
non -X- _ O
- -X- _ O
debiased -X- _ O
models -X- _ O
. -X- _ O
Interestingly -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
with -X- _ O
an -X- _ O
anonymized -X- _ O
dataset -X- _ O
is -X- _ O
the -X- _ O
most -X- _ O
biased -X- _ O
after -X- _ O
retraining -X- _ O
, -X- _ O
consistent -X- _ O
with -X- _ O
its -X- _ O
high -X- _ O
compression -X- _ B-MetricName
rate -X- _ O
relative -X- _ O
to -X- _ O
the -X- _ O
other -X- _ O
models -X- _ O
. -X- _ O
As -X- _ O
with -X- _ O
subsampling -X- _ O
and -X- _ O
oversampling -X- _ O
in -X- _ O
occupation -X- _ B-TaskName
prediction -X- _ I-TaskName
, -X- _ O
anonymization -X- _ O
's -X- _ O
( -X- _ O
lack -X- _ O
of -X- _ O
) -X- _ O
effect -X- _ O
on -X- _ O
extrinsic -X- _ O
metrics -X- _ O
was -X- _ O
cosmetic -X- _ O
( -X- _ O
compare -X- _ O
None -X- _ O
and -X- _ O
Anon -X- _ O
in -X- _ O
Before -X- _ O
block -X- _ O
, -X- _ O
Table -X- _ O
1b -X- _ O
) -X- _ O
. -X- _ O
Anonymization -X- _ O
actually -X- _ O
had -X- _ O
a -X- _ O
biasing -X- _ O
effect -X- _ O
on -X- _ O
the -X- _ O
LM -X- _ O
, -X- _ O
which -X- _ O
was -X- _ O
realized -X- _ O
after -X- _ O
retraining -X- _ O
. -X- _ O

We -X- _ O
conclude -X- _ O
that -X- _ O
compression -X- _ B-MetricName
rate -X- _ O
is -X- _ O
a -X- _ O
useful -X- _ O
indicator -X- _ O
of -X- _ O
superficial -X- _ O
debiasing -X- _ O
, -X- _ O
and -X- _ O
can -X- _ O
potentially -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
verify -X- _ O
and -X- _ O
gain -X- _ O
confidence -X- _ O
in -X- _ O
attempts -X- _ O
to -X- _ O
debias -X- _ O
an -X- _ O
NLP -X- _ O
model -X- _ O
, -X- _ O
especially -X- _ O
when -X- _ O
there -X- _ O
is -X- _ O
little -X- _ O
or -X- _ O
no -X- _ O
testing -X- _ O
data -X- _ O
. -X- _ O
retraining -X- _ O
. -X- _ O
In -X- _ O
occupation -X- _ B-TaskName
prediction -X- _ I-TaskName
, -X- _ O
certain -X- _ O
extrinsic -X- _ O
metrics -X- _ O
have -X- _ O
a -X- _ O
weak -X- _ O
correlation -X- _ O
with -X- _ O
compression -X- _ O
rate -X- _ O
, -X- _ O
while -X- _ O
others -X- _ O
do -X- _ O
not -X- _ O
. -X- _ O
Except -X- _ O
one -X- _ O
metric -X- _ O
( -X- _ O
FPR -X- _ B-MetricName
gap -X- _ O
sum -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
compression -X- _ O
rate -X- _ O
and -X- _ O
the -X- _ O
extrinsic -X- _ O
metric -X- _ O
correlate -X- _ O
more -X- _ O
after -X- _ O
retraining -X- _ O
. -X- _ O
Figure -X- _ O
3 -X- _ O
illustrates -X- _ O
this -X- _ O
for -X- _ O
TPR -X- _ B-MetricName
- -X- _ O
gap -X- _ O
( -X- _ O
Pearson -X- _ B-MetricName
) -X- _ O
. -X- _ O
The -X- _ O
increase -X- _ O
is -X- _ O
due -X- _ O
to -X- _ O
superficial -X- _ O
debiasing -X- _ O
, -X- _ O
especially -X- _ O
by -X- _ O
subsampling -X- _ O
data -X- _ O
, -X- _ O
which -X- _ O
prior -X- _ O
to -X- _ O
retraining -X- _ O
had -X- _ O
low -X- _ O
extrinsic -X- _ O
metrics -X- _ O
and -X- _ O
relatively -X- _ O
high -X- _ O
intrinsic -X- _ O
metrics -X- _ O
. -X- _ O
This -X- _ O
shows -X- _ O
that -X- _ O
correlation -X- _ O
between -X- _ O
extrinsic -X- _ O
metrics -X- _ O
and -X- _ O
compression -X- _ O
rate -X- _ O
for -X- _ O
certain -X- _ O
metrics -X- _ O
is -X- _ O
stronger -X- _ O
than -X- _ O
it -X- _ O
appeared -X- _ O
before -X- _ O
retraining -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
unsurprising -X- _ O
that -X- _ O
CEAT -X- _ B-MetricName
does -X- _ O
not -X- _ O
correlate -X- _ O
with -X- _ O
any -X- _ O
extrinsic -X- _ O
metrics -X- _ O
, -X- _ O
since -X- _ O
CEAT -X- _ B-MetricName
could -X- _ O
not -X- _ O
distinguish -X- _ O
between -X- _ O
different -X- _ O
models -X- _ O
. -X- _ O

Correlation -X- _ O
between -X- _ O
Extrinsic -X- _ O
and -X- _ O
Intrinsic -X- _ O
Metrics -X- _ O

Coreference -X- _ B-TaskName
resolution -X- _ I-TaskName
shows -X- _ O
stronger -X- _ O
correlations -X- _ O
between -X- _ O
compression -X- _ O
rate -X- _ O
and -X- _ O
extrinsic -X- _ O
met -X- _ O
- -X- _ O
rics -X- _ O
, -X- _ O
but -X- _ O
low -X- _ O
correlations -X- _ O
between -X- _ O
Pearson -X- _ B-MetricName
metrics -X- _ O
. -X- _ O
We -X- _ O
further -X- _ O
discuss -X- _ O
cases -X- _ O
of -X- _ O
no -X- _ O
correlation -X- _ O
in -X- _ O
appendix -X- _ O
D. -X- _ O
Correlations -X- _ O
decrease -X- _ O
after -X- _ O
retraining -X- _ O
, -X- _ O
but -X- _ O
metrics -X- _ O
that -X- _ O
were -X- _ O
highly -X- _ O
correlated -X- _ O
remain -X- _ O
so -X- _ O
( -X- _ O
> -X- _ O
0.7 -X- _ O
after -X- _ O
retraining -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
correlations -X- _ O
are -X- _ O
visualized -X- _ O
for -X- _ O
F1 -X- _ O
difference -X- _ O
metrics -X- _ O
in -X- _ O
Figure -X- _ O
4 -X- _ O
. -X- _ O
CEAT -X- _ B-MetricName
and -X- _ O
extrinsic -X- _ O
metrics -X- _ O
correlate -X- _ O
much -X- _ O
less -X- _ O
than -X- _ O
compression -X- _ O
rate -X- _ O
( -X- _ O
Table -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O
Our -X- _ O
results -X- _ O
are -X- _ O
in -X- _ O
line -X- _ O
with -X- _ O
those -X- _ O
of -X- _ O
Goldfarb -X- _ O
- -X- _ O
Tarrant -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
who -X- _ O
found -X- _ O
a -X- _ O
lack -X- _ O
of -X- _ O
correlation -X- _ O
between -X- _ O
extrinsic -X- _ O
metrics -X- _ O
and -X- _ O
WEAT -X- _ O
, -X- _ O
the -X- _ O
static -X- _ O
- -X- _ O
embedded -X- _ O
version -X- _ O
of -X- _ O
CEAT -X- _ B-MetricName
. -X- _ O

Given -X- _ O
that -X- _ O
recent -X- _ O
work -X- _ O
( -X- _ O
Goldfarb -X- _ O
- -X- _ O
Tarrant -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Cao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
questions -X- _ O
the -X- _ O
validity -X- _ O
of -X- _ O
intrinsic -X- _ O
metrics -X- _ O
as -X- _ O
a -X- _ O
reliable -X- _ O
indicator -X- _ O
for -X- _ O
gender -X- _ O
bias -X- _ O
, -X- _ O
the -X- _ O
compression -X- _ B-MetricName
rate -X- _ O
provides -X- _ O
a -X- _ O
reliable -X- _ O
alternative -X- _ O
to -X- _ O
current -X- _ O
intrinsic -X- _ O
metrics -X- _ O
, -X- _ O
by -X- _ O
offering -X- _ O
correlation -X- _ O
to -X- _ O
many -X- _ O
extrinsic -X- _ O
bias -X- _ O
metrics -X- _ O
. -X- _ O

Related -X- _ O
Work -X- _ O

There -X- _ O
are -X- _ O
few -X- _ O
studies -X- _ O
that -X- _ O
examine -X- _ O
both -X- _ O
intrinsic -X- _ O
and -X- _ O
extrinsic -X- _ O
metrics -X- _ O
. -X- _ O
Previous -X- _ O
work -X- _ O
by -X- _ O
Goldfarb -X- _ O
- -X- _ O
Tarrant -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
showed -X- _ O
that -X- _ O
debiasing -X- _ O
static -X- _ O
embeddings -X- _ O
intrinsically -X- _ O
is -X- _ O
not -X- _ O
correlated -X- _ O
with -X- _ O
extrinsic -X- _ O
bias -X- _ O
, -X- _ O
challenging -X- _ O
the -X- _ O
assumption -X- _ O
that -X- _ O
intrinsic -X- _ O
metrics -X- _ O
are -X- _ O
predictive -X- _ O
of -X- _ O
bias -X- _ O
. -X- _ O
We -X- _ O
examine -X- _ O
the -X- _ O
other -X- _ O
direction -X- _ O
, -X- _ O
exploring -X- _ O
how -X- _ O
extrinsic -X- _ O
debiasing -X- _ O
affects -X- _ O
intrinsic -X- _ O
metrics -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
extend -X- _ O
beyond -X- _ O
their -X- _ O
work -X- _ O
to -X- _ O
contextualized -X- _ O
embeddings -X- _ O
, -X- _ O
a -X- _ O
wider -X- _ O
range -X- _ O
of -X- _ O
extrinsic -X- _ O
metrics -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
new -X- _ O
, -X- _ O
more -X- _ O
effective -X- _ O
intrinsic -X- _ O
metric -X- _ O
based -X- _ O
on -X- _ O
information -X- _ O
- -X- _ O
theoretic -X- _ O
probing -X- _ O
. -X- _ O
A -X- _ O
contemporary -X- _ O
work -X- _ O
by -X- _ O
Cao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
measured -X- _ O
the -X- _ O
correlations -X- _ O
between -X- _ O
intrinsic -X- _ O
and -X- _ O
extrinsic -X- _ O
metrics -X- _ O
in -X- _ O
contextualized -X- _ O
settings -X- _ O
across -X- _ O
different -X- _ O
language -X- _ O
models -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
our -X- _ O
work -X- _ O
examines -X- _ O
the -X- _ O
correlations -X- _ O
across -X- _ O
different -X- _ O
versions -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
language -X- _ O
model -X- _ O
by -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
it -X- _ O
using -X- _ O
various -X- _ O
debiasing -X- _ O
techniques -X- _ O
. -X- _ O
Studies -X- _ O
that -X- _ O
inspect -X- _ O
extrinsic -X- _ O
metrics -X- _ O
include -X- _ O
either -X- _ O
a -X- _ O
challenge -X- _ O
dataset -X- _ O
curated -X- _ O
to -X- _ O
expose -X- _ O
differences -X- _ O
in -X- _ O
model -X- _ O
behavior -X- _ O
by -X- _ O
gender -X- _ O
, -X- _ O
or -X- _ O
a -X- _ O
test -X- _ O
dataset -X- _ O
labelled -X- _ O
by -X- _ O
gender -X- _ O
. -X- _ O
Among -X- _ O
these -X- _ O
datasets -X- _ O
are -X- _ O
Winobias -X- _ O
( -X- _ O
Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
Winogender -X- _ O
( -X- _ O
Rudinger -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
and -X- _ O
GAP -X- _ O
( -X- _ O
Webster -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
for -X- _ O
coreference -X- _ O
resolution -X- _ O
, -X- _ O
WinoMT -X- _ O
( -X- _ O
Stanovsky -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
for -X- _ O
machine -X- _ O
translation -X- _ O
, -X- _ O
EEC -X- _ O
( -X- _ O
Kiritchenko -X- _ O
and -X- _ O
Mohammad -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
for -X- _ O
sentiment -X- _ O
analysis -X- _ O
, -X- _ O
BOLD -X- _ O
( -X- _ O
Dhamala -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
for -X- _ O
language -X- _ O
generation -X- _ O
, -X- _ O
gendered -X- _ O
NLI -X- _ O
( -X- _ O
Sharma -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
for -X- _ O
natural -X- _ O
language -X- _ O
inference -X- _ O
and -X- _ O
Bias -X- _ O
in -X- _ O
Bios -X- _ O
for -X- _ O
occupation -X- _ O
prediction -X- _ O
. -X- _ O

Studies -X- _ O
that -X- _ O
measure -X- _ O
gender -X- _ O
bias -X- _ O
intrinsically -X- _ O
in -X- _ O
static -X- _ O
word -X- _ O
or -X- _ O
sentence -X- _ O
embeddings -X- _ O
measure -X- _ O
characteristics -X- _ O
of -X- _ O
the -X- _ O
geometry -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
prox -X- _ O
- -X- _ O
imity -X- _ O
between -X- _ O
female -X- _ O
- -X- _ O
and -X- _ O
male -X- _ O
- -X- _ O
related -X- _ O
words -X- _ O
to -X- _ O
stereotypical -X- _ O
words -X- _ O
, -X- _ O
or -X- _ O
how -X- _ O
embeddings -X- _ O
cluster -X- _ O
or -X- _ O
relate -X- _ O
to -X- _ O
a -X- _ O
gender -X- _ O
subspace -X- _ O
( -X- _ O
Bolukbasi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Caliskan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Gonen -X- _ O
and -X- _ O
Goldberg -X- _ O
, -X- _ O
2019b -X- _ O
; -X- _ O
Ethayarajh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
metrics -X- _ O
and -X- _ O
debiasing -X- _ O
methods -X- _ O
for -X- _ O
static -X- _ O
embeddings -X- _ O
do -X- _ O
not -X- _ O
apply -X- _ O
directly -X- _ O
to -X- _ O
contextualized -X- _ O
ones -X- _ O
. -X- _ O
Several -X- _ O
studies -X- _ O
use -X- _ O
sentence -X- _ O
templates -X- _ O
to -X- _ O
adapt -X- _ O
to -X- _ O
contextual -X- _ O
embeddings -X- _ O
( -X- _ O
May -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Kurita -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Tan -X- _ O
and -X- _ O
Celis -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
templated -X- _ O
approach -X- _ O
is -X- _ O
difficult -X- _ O
to -X- _ O
scale -X- _ O
, -X- _ O
and -X- _ O
lacks -X- _ O
the -X- _ O
range -X- _ O
of -X- _ O
representations -X- _ O
that -X- _ O
a -X- _ O
contextual -X- _ O
embedding -X- _ O
offers -X- _ O
. -X- _ O
Other -X- _ O
work -X- _ O
extracts -X- _ O
embedding -X- _ O
representations -X- _ O
of -X- _ O
words -X- _ O
from -X- _ O
natural -X- _ O
corpora -X- _ O
( -X- _ O
Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Guo -X- _ O
and -X- _ O
Caliskan -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Basta -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
These -X- _ O
studies -X- _ O
often -X- _ O
adapt -X- _ O
the -X- _ O
WEAT -X- _ O
method -X- _ O
( -X- _ O
Caliskan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
measures -X- _ O
embedding -X- _ O
geometry -X- _ O
. -X- _ O
None -X- _ O
measure -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
the -X- _ O
presumably -X- _ O
found -X- _ O
" -X- _ O
bias -X- _ O
" -X- _ O
on -X- _ O
a -X- _ O
downstream -X- _ O
task -X- _ O
. -X- _ O

There -X- _ O
is -X- _ O
a -X- _ O
growing -X- _ O
conversation -X- _ O
in -X- _ O
the -X- _ O
field -X- _ O
( -X- _ O
Barocas -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Kate -X- _ O
Crawford -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Blodgett -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Bommasani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
about -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
articulating -X- _ O
the -X- _ O
harms -X- _ O
of -X- _ O
measured -X- _ O
bias -X- _ O
. -X- _ O
In -X- _ O
general -X- _ O
, -X- _ O
extrinsic -X- _ O
metrics -X- _ O
have -X- _ O
clear -X- _ O
, -X- _ O
interpretable -X- _ O
impacts -X- _ O
for -X- _ O
which -X- _ O
harm -X- _ O
can -X- _ O
be -X- _ O
defined -X- _ O
. -X- _ O
Intrinsic -X- _ O
metrics -X- _ O
have -X- _ O
an -X- _ O
unclear -X- _ O
effect -X- _ O
. -X- _ O
Without -X- _ O
evidence -X- _ O
from -X- _ O
a -X- _ O
concrete -X- _ O
downstream -X- _ O
task -X- _ O
, -X- _ O
a -X- _ O
found -X- _ O
intrinsic -X- _ O
bias -X- _ O
is -X- _ O
only -X- _ O
theoretically -X- _ O
harmful -X- _ O
. -X- _ O
Our -X- _ O
work -X- _ O
is -X- _ O
a -X- _ O
step -X- _ O
towards -X- _ O
understanding -X- _ O
whether -X- _ O
intrinsic -X- _ O
metrics -X- _ O
provide -X- _ O
valuable -X- _ O
insights -X- _ O
about -X- _ O
bias -X- _ O
in -X- _ O
a -X- _ O
model -X- _ O
. -X- _ O

Discussion -X- _ O
and -X- _ O
Conclusions -X- _ O

This -X- _ O
study -X- _ O
examined -X- _ O
whether -X- _ O
bias -X- _ O
in -X- _ O
internal -X- _ O
representations -X- _ O
is -X- _ O
related -X- _ O
to -X- _ O
extrinsic -X- _ O
bias -X- _ O
. -X- _ O
We -X- _ O
designed -X- _ O
a -X- _ O
new -X- _ O
framework -X- _ O
in -X- _ O
which -X- _ O
we -X- _ O
debias -X- _ O
a -X- _ O
model -X- _ O
on -X- _ O
a -X- _ O
downstream -X- _ O
task -X- _ O
, -X- _ O
and -X- _ O
measure -X- _ O
its -X- _ O
intrinsic -X- _ O
bias -X- _ O
. -X- _ O
We -X- _ O
found -X- _ O
that -X- _ O
gender -X- _ O
extractability -X- _ O
from -X- _ O
internal -X- _ O
representations -X- _ O
, -X- _ O
measured -X- _ O
by -X- _ O
compression -X- _ O
rate -X- _ O
via -X- _ O
MDL -X- _ O
probing -X- _ O
, -X- _ O
reflects -X- _ O
bias -X- _ O
in -X- _ O
a -X- _ O
model -X- _ O
. -X- _ O
Compression -X- _ O
was -X- _ O
much -X- _ O
more -X- _ O
reliable -X- _ O
than -X- _ O
an -X- _ O
alternative -X- _ O
intrinsic -X- _ O
metric -X- _ O
for -X- _ O
contextualised -X- _ O
representations -X- _ O
, -X- _ O
CEAT -X- _ B-MetricName
. -X- _ O
Compression -X- _ B-MetricName
correlated -X- _ O
well -X- _ O
- -X- _ O
to -X- _ O
varying -X- _ O
degrees -X- _ O
- -X- _ O
with -X- _ O
many -X- _ O
extrinsic -X- _ O
metrics -X- _ O
. -X- _ O
We -X- _ O
thus -X- _ O
encourage -X- _ O
NLP -X- _ O
practitioners -X- _ O
to -X- _ O
use -X- _ O
compression -X- _ O
as -X- _ O
an -X- _ O
intrinsic -X- _ O
indicator -X- _ O
for -X- _ O
gender -X- _ O
bias -X- _ O
in -X- _ O
NLP -X- _ O
models -X- _ O
. -X- _ O
When -X- _ O
comparing -X- _ O
two -X- _ O
alternative -X- _ O
models -X- _ O
, -X- _ O
a -X- _ O
lower -X- _ O
compression -X- _ B-MetricName
rate -X- _ O
provides -X- _ O
confidence -X- _ O
in -X- _ O
a -X- _ O
model -X- _ O
's -X- _ O
superiority -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
gender -X- _ O
bias -X- _ O
. -X- _ O
The -X- _ O
relative -X- _ O
success -X- _ O
of -X- _ O
compression -X- _ B-MetricName
over -X- _ O
CEAT -X- _ B-MetricName
may -X- _ O
be -X- _ O
because -X- _ O
the -X- _ O
compression -X- _ B-MetricName
rate -X- _ O
was -X- _ O
calculated -X- _ O
on -X- _ O
the -X- _ O
same -X- _ O
dataset -X- _ O
as -X- _ O
the -X- _ O
extrinsic -X- _ O
metrics -X- _ O
, -X- _ O
whereas -X- _ O
CEAT -X- _ B-MetricName
was -X- _ O
measured -X- _ O
on -X- _ O
a -X- _ O
different -X- _ O
dataset -X- _ O
not -X- _ O
necessarily -X- _ O
aligned -X- _ O
with -X- _ O
a -X- _ O
specific -X- _ O
downstream -X- _ O
task -X- _ O
. -X- _ O
The -X- _ O
use -X- _ O
of -X- _ O
a -X- _ O
non -X- _ O
- -X- _ O
task -X- _ O
- -X- _ O
aligned -X- _ O
dataset -X- _ O
is -X- _ O
a -X- _ O
common -X- _ O
strategy -X- _ O
among -X- _ O
other -X- _ O
intrinsic -X- _ O
metrics -X- _ O
( -X- _ O
May -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Kurita -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Basta -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Another -X- _ O
possible -X- _ O
explanation -X- _ O
is -X- _ O
that -X- _ O
compression -X- _ B-MetricName
rate -X- _ O
measures -X- _ O
a -X- _ O
more -X- _ O
focused -X- _ O
concept -X- _ O
, -X- _ O
namely -X- _ O
the -X- _ O
gender -X- _ O
information -X- _ O
within -X- _ O
the -X- _ O
internal -X- _ O
representations -X- _ O
. -X- _ O
CEAT -X- _ B-MetricName
measures -X- _ O
proximity -X- _ O
among -X- _ O
embeddings -X- _ O
of -X- _ O
general -X- _ O
terms -X- _ O
that -X- _ O
may -X- _ O
include -X- _ O
other -X- _ O
social -X- _ O
contexts -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
directly -X- _ O
relate -X- _ O
to -X- _ O
gender -X- _ O
( -X- _ O
e.g. -X- _ O
a -X- _ O
female -X- _ O
term -X- _ O
like -X- _ O
' -X- _ O
lady -X- _ O
' -X- _ O
or -X- _ O
' -X- _ O
Sarah -X- _ O
' -X- _ O
contains -X- _ O
information -X- _ O
about -X- _ O
not -X- _ O
just -X- _ O
gender -X- _ O
but -X- _ O
class -X- _ O
, -X- _ O
culture -X- _ O
, -X- _ O
formality -X- _ O
, -X- _ O
etc -X- _ O
, -X- _ O
and -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
hard -X- _ O
to -X- _ O
isolate -X- _ O
just -X- _ O
one -X- _ O
of -X- _ O
these -X- _ O
from -X- _ O
the -X- _ O
rest -X- _ O
) -X- _ O
. -X- _ O

Our -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
when -X- _ O
a -X- _ O
debiasing -X- _ O
method -X- _ O
reduces -X- _ O
extrinsic -X- _ O
metrics -X- _ O
but -X- _ O
not -X- _ O
compression -X- _ B-MetricName
, -X- _ O
it -X- _ O
indicates -X- _ O
that -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
remains -X- _ O
biased -X- _ O
. -X- _ O
When -X- _ O
such -X- _ O
superficial -X- _ O
debiasing -X- _ O
occurs -X- _ O
, -X- _ O
the -X- _ O
debiased -X- _ O
language -X- _ O
model -X- _ O
may -X- _ O
be -X- _ O
reapplied -X- _ O
to -X- _ O
another -X- _ O
task -X- _ O
, -X- _ O
as -X- _ O
in -X- _ O
Jin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
unexpected -X- _ O
biases -X- _ O
and -X- _ O
nullifying -X- _ O
the -X- _ O
supposed -X- _ O
debiasing -X- _ O
. -X- _ O
Our -X- _ O
findings -X- _ O
suggest -X- _ O
that -X- _ O
practitioners -X- _ O
of -X- _ O
NLP -X- _ O
should -X- _ O
take -X- _ O
special -X- _ O
care -X- _ O
when -X- _ O
adopting -X- _ O
previously -X- _ O
debiased -X- _ O
models -X- _ O
and -X- _ O
inspect -X- _ O
them -X- _ O
carefully -X- _ O
, -X- _ O
perhaps -X- _ O
using -X- _ O
our -X- _ O
framework -X- _ O
. -X- _ O
Our -X- _ O
results -X- _ O
differ -X- _ O
from -X- _ O
those -X- _ O
of -X- _ O
Mendelson -X- _ O
and -X- _ O
Belinkov -X- _ O
( -X- _ O
2021a -X- _ O
) -X- _ O
, -X- _ O
who -X- _ O
found -X- _ O
that -X- _ O
the -X- _ O
debiasing -X- _ O
increases -X- _ O
bias -X- _ O
extractability -X- _ O
as -X- _ O
measured -X- _ O
by -X- _ O
compression -X- _ B-MetricName
rate -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
they -X- _ O
studied -X- _ O
different -X- _ O
, -X- _ O
non -X- _ O
- -X- _ O
social -X- _ O
biases -X- _ O
, -X- _ O
that -X- _ O
arise -X- _ O
from -X- _ O
spurious -X- _ O
or -X- _ O
unintended -X- _ O
correlations -X- _ O
in -X- _ O
training -X- _ O
datasets -X- _ O
( -X- _ O
often -X- _ O
called -X- _ O
dataset -X- _ O
biases -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
case -X- _ O
, -X- _ O
some -X- _ O
debiasing -X- _ O
strategies -X- _ O
increase -X- _ O
intrinsic -X- _ O
bias -X- _ O
while -X- _ O
others -X- _ O
decrease -X- _ O
it -X- _ O
. -X- _ O
Future -X- _ O
work -X- _ O
could -X- _ O
investigate -X- _ O
why -X- _ O
debiasing -X- _ O
affects -X- _ O
extractability -X- _ O
differently -X- _ O
for -X- _ O
these -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
biases -X- _ O
. -X- _ O

Our -X- _ O
work -X- _ O
also -X- _ O
highlighted -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
the -X- _ O
classification -X- _ B-HyperparameterName
layer -X- _ I-HyperparameterName
. -X- _ O
Using -X- _ O
a -X- _ O
debiased -X- _ O
objective -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
a -X- _ O
balanced -X- _ O
dataset -X- _ O
, -X- _ O
the -X- _ O
classification -X- _ B-HyperparameterName
layer -X- _ I-HyperparameterName
can -X- _ O
provide -X- _ O
significant -X- _ O
debiasing -X- _ O
. -X- _ O
This -X- _ O
holds -X- _ O
even -X- _ O
if -X- _ O
the -X- _ O
internal -X- _ O
representations -X- _ O
are -X- _ O
biased -X- _ O
and -X- _ O
the -X- _ O
classifier -X- _ O
is -X- _ O
a -X- _ O
single -X- _ O
linear -X- _ O
layer -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
the -X- _ O
occupation -X- _ O
prediction -X- _ O
task -X- _ O
. -X- _ O
Bias -X- _ O
stems -X- _ O
in -X- _ O
part -X- _ O
from -X- _ O
internal -X- _ O
LM -X- _ O
bias -X- _ O
and -X- _ O
in -X- _ O
part -X- _ O
from -X- _ O
classification -X- _ O
bias -X- _ O
. -X- _ O
Practitioners -X- _ O
should -X- _ O
focus -X- _ O
their -X- _ O
efforts -X- _ O
on -X- _ O
both -X- _ O
parts -X- _ O
when -X- _ O
attempting -X- _ O
to -X- _ O
debias -X- _ O
a -X- _ O
model -X- _ O
. -X- _ O

We -X- _ O
used -X- _ O
a -X- _ O
broader -X- _ O
set -X- _ O
of -X- _ O
extrinsic -X- _ O
metrics -X- _ O
than -X- _ O
is -X- _ O
typically -X- _ O
used -X- _ O
, -X- _ O
and -X- _ O
found -X- _ O
that -X- _ O
the -X- _ O
bias -X- _ O
metrics -X- _ O
behaved -X- _ O
differently -X- _ O
: -X- _ O
some -X- _ O
decreased -X- _ O
more -X- _ O
than -X- _ O
others -X- _ O
after -X- _ O
debiasing -X- _ O
, -X- _ O
and -X- _ O
they -X- _ O
correlated -X- _ O
differently -X- _ O
with -X- _ O
compression -X- _ O
rate -X- _ O
. -X- _ O
Debiasing -X- _ O
efforts -X- _ O
may -X- _ O
not -X- _ O
be -X- _ O
fully -X- _ O
understood -X- _ O
by -X- _ O
testing -X- _ O
only -X- _ O
a -X- _ O
few -X- _ O
extrinsic -X- _ O
metrics -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
compression -X- _ B-MetricName
as -X- _ O
an -X- _ O
intrinsic -X- _ O
bias -X- _ O
metric -X- _ O
can -X- _ O
indicate -X- _ O
meaningful -X- _ O
debiasing -X- _ O
of -X- _ O
internal -X- _ O
model -X- _ O
representations -X- _ O
even -X- _ O
when -X- _ O
not -X- _ O
all -X- _ O
metrics -X- _ O
are -X- _ O
easily -X- _ O
measurable -X- _ O
, -X- _ O
since -X- _ O
it -X- _ O
correlates -X- _ O
well -X- _ O
with -X- _ O
many -X- _ O
extrinsic -X- _ O
metrics -X- _ O
. -X- _ O

A -X- _ O
major -X- _ O
limitation -X- _ O
of -X- _ O
this -X- _ O
study -X- _ O
is -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
gender -X- _ O
as -X- _ O
a -X- _ O
binary -X- _ O
variable -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
trans -X- _ O
- -X- _ O
exclusive -X- _ O
. -X- _ O
Cao -X- _ O
and -X- _ O
Daumé -X- _ O
III -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
made -X- _ O
the -X- _ O
first -X- _ O
steps -X- _ O
towards -X- _ O
inclusive -X- _ O
gender -X- _ O
bias -X- _ O
evaluation -X- _ O
in -X- _ O
NLP -X- _ O
, -X- _ O
revealing -X- _ O
that -X- _ O
coreference -X- _ B-TaskName
systems -X- _ O
fail -X- _ O
on -X- _ O
genderinclusive -X- _ O
text -X- _ O
. -X- _ O
Further -X- _ O
work -X- _ O
is -X- _ O
required -X- _ O
to -X- _ O
adjust -X- _ O
our -X- _ O
framework -X- _ O
to -X- _ O
non -X- _ O
- -X- _ O
binary -X- _ O
genders -X- _ O
, -X- _ O
potentially -X- _ O
revealing -X- _ O
insights -X- _ O
about -X- _ O
the -X- _ O
poor -X- _ O
performance -X- _ O
of -X- _ O
NLP -X- _ O
systems -X- _ O
in -X- _ O
that -X- _ O
area -X- _ O
. -X- _ O

A -X- _ O
Implementation -X- _ O
Details -X- _ O

We -X- _ O
used -X- _ O
RoBERTa -X- _ B-MethodName
in -X- _ O
all -X- _ O
models -X- _ O
( -X- _ O
base -X- _ O
size -X- _ O
, -X- _ O
120 -X- _ O
M -X- _ O
parameters -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
following -X- _ O
random -X- _ B-HyperparameterName
seeds -X- _ I-HyperparameterName
in -X- _ O
all -X- _ O
repeated -X- _ O
experiments -X- _ O
: -X- _ O
0 -X- _ B-HyperparameterValue
, -X- _ O
5,11,26,42,46,50,63,83,90 -X- _ B-HyperparameterValue
. -X- _ O
Our -X- _ O
code -X- _ O
was -X- _ O
implemented -X- _ O
mainly -X- _ O
using -X- _ O
the -X- _ O
Python -X- _ O
libraries -X- _ O
Pytorch -X- _ O
( -X- _ O
Paszke -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
Transformers -X- _ O
( -X- _ O
Wolf -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
Sklearn -X- _ O
( -X- _ O
Pedregosa -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
experiments -X- _ O
were -X- _ O
logged -X- _ O
using -X- _ O
Wandb -X- _ O
( -X- _ O
Biewald -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

A.1 -X- _ O
Occupation -X- _ B-TaskName
Classification -X- _ I-TaskName

We -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
a -X- _ O
RoBERTa -X- _ B-MethodName
- -X- _ O
base -X- _ O
model -X- _ O
with -X- _ O
a -X- _ O
linear -X- _ B-HyperparameterName
classification -X- _ I-HyperparameterName
layer -X- _ I-HyperparameterName
on -X- _ O
top -X- _ O
. -X- _ O
Training -X- _ O
was -X- _ O
done -X- _ O
for -X- _ O
10 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
at -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
5e-5 -X- _ B-HyperparameterValue
, -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
64 -X- _ B-HyperparameterValue
. -X- _ O
The -X- _ O
input -X- _ O
to -X- _ O
RoBERTa -X- _ B-MethodName
was -X- _ O
the -X- _ O
biography -X- _ O
tokens -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
limited -X- _ O
to -X- _ O
the -X- _ O
first -X- _ O
128 -X- _ O
tokens -X- _ O
. -X- _ O
The -X- _ O
resulting -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
token -X- _ O
embedding -X- _ O
is -X- _ O
fed -X- _ O
to -X- _ O
the -X- _ O
classifier -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
occupation -X- _ O
. -X- _ O
The -X- _ O
probing -X- _ O
task -X- _ O
involves -X- _ O
using -X- _ O
the -X- _ O
same -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
token -X- _ O
and -X- _ O
training -X- _ O
the -X- _ O
probing -X- _ O
classifier -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
gender -X- _ O
of -X- _ O
the -X- _ O
person -X- _ O
in -X- _ O
the -X- _ O
biography -X- _ O
. -X- _ O
The -X- _ O
experiments -X- _ O
without -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
included -X- _ O
either -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
or -X- _ O
a -X- _ O
previously -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
RoBERTa -X- _ B-MethodName
. -X- _ O
We -X- _ O
first -X- _ O
extracted -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
RoBERTa -X- _ B-MethodName
's -X- _ O
embeddings -X- _ O
of -X- _ O
tokens -X- _ O
from -X- _ O
the -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
and -X- _ O
then -X- _ O
trained -X- _ O
a -X- _ O
linear -X- _ O
classifier -X- _ O
on -X- _ O
them -X- _ O
. -X- _ O
The -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
was -X- _ O
0.001 -X- _ B-HyperparameterValue
and -X- _ O
the -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
was -X- _ O
64 -X- _ B-HyperparameterValue
. -X- _ O
We -X- _ O
trained -X- _ O
the -X- _ O
classification -X- _ B-HyperparameterName
layer -X- _ I-HyperparameterName
with -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
RoBERTa -X- _ B-MethodName
on -X- _ O
300 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
, -X- _ O
but -X- _ O
with -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
RoBERTa -X- _ B-MethodName
, -X- _ O
10 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
were -X- _ O
sufficient -X- _ O
. -X- _ O
For -X- _ O
all -X- _ O
training -X- _ O
processes -X- _ O
, -X- _ O
the -X- _ O
epoch -X- _ B-HyperparameterName
with -X- _ O
the -X- _ O
greatest -X- _ O
validation -X- _ O
accuracy -X- _ O
was -X- _ O
saved -X- _ O
. -X- _ O
Finetuning -X- _ O
took -X- _ O
7 -X- _ O
hours -X- _ O
on -X- _ O
a -X- _ O
GeForce -X- _ O
RTX -X- _ O
2080 -X- _ O
Ti -X- _ O
GPU -X- _ O
. -X- _ O
Bias -X- _ O
in -X- _ O
Bios -X- _ B-DatasetName
contains -X- _ O
almost -X- _ O
400k -X- _ O
biographies -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
obtain -X- _ O
validation -X- _ O
( -X- _ O
10 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
) -X- _ O
and -X- _ O
test -X- _ O
set -X- _ O
( -X- _ O
25 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
) -X- _ O
by -X- _ O
splitting -X- _ O
with -X- _ O
Scikit -X- _ O
- -X- _ O
learn -X- _ O
's -X- _ O
( -X- _ O
Pedregosa -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
test_train_split -X- _ B-HyperparameterName
with -X- _ O
our -X- _ O
random -X- _ B-HyperparameterName
seeds -X- _ I-HyperparameterName
. -X- _ O

A.2 -X- _ O
Coreference -X- _ B-TaskName
Resolution -X- _ I-TaskName

We -X- _ O
use -X- _ O
the -X- _ O
implementation -X- _ O
of -X- _ O
Xu -X- _ O
and -X- _ O
Choi -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
model -X- _ O
that -X- _ O
was -X- _ O
introduced -X- _ O
by -X- _ O
Lee -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018b -X- _ O
) -X- _ O
and -X- _ O
has -X- _ O
been -X- _ O
adopted -X- _ O
by -X- _ O
many -X- _ O
coreference -X- _ O
resolution -X- _ O
models -X- _ O
. -X- _ O
Coreference -X- _ B-TaskName
resolution -X- _ I-TaskName
is -X- _ O
the -X- _ O
process -X- _ O
of -X- _ O
clustering -X- _ O
different -X- _ O
mentions -X- _ O
in -X- _ O
a -X- _ O
text -X- _ O
that -X- _ O
refer -X- _ O
to -X- _ O
the -X- _ O
same -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
entities -X- _ O
. -X- _ O
The -X- _ O
task -X- _ O
is -X- _ O
solved -X- _ O
by -X- _ O
detecting -X- _ O
mentions -X- _ O
through -X- _ O
text -X- _ O
spans -X- _ O
and -X- _ O
then -X- _ O
predicting -X- _ O
for -X- _ O
each -X- _ O
pair -X- _ O
of -X- _ O
spans -X- _ O
if -X- _ O
they -X- _ O
represent -X- _ O
the -X- _ O
same -X- _ O
entity -X- _ O
. -X- _ O
The -X- _ O
span -X- _ O
representations -X- _ O
were -X- _ O
extracted -X- _ O
with -X- _ O
a -X- _ O
RoBERTa -X- _ B-MethodName
model -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
throughout -X- _ O
the -X- _ O
training -X- _ O
process -X- _ O
, -X- _ O
except -X- _ O
in -X- _ O
the -X- _ O
retraining -X- _ O
experiment -X- _ O
. -X- _ O
Fine -X- _ O
- -X- _ O
tuning -X- _ O
took -X- _ O
3 -X- _ O
hours -X- _ O
on -X- _ O
an -X- _ O
NVIDIA -X- _ O
RTX -X- _ O
A6000 -X- _ O
GPU -X- _ O
. -X- _ O
Ontonotes -X- _ B-DatasetName
5.0 -X- _ O
has -X- _ O
625k -X- _ O
sentences -X- _ O
and -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
standard -X- _ O
validation -X- _ B-HyperparameterName
and -X- _ I-HyperparameterName
test -X- _ I-HyperparameterName
splits -X- _ I-HyperparameterName
. -X- _ O

A.3 -X- _ O
Probing -X- _ O
Classifier -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
MDL -X- _ O
probe -X- _ O
( -X- _ O
Voita -X- _ O
and -X- _ O
Titov -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
implementation -X- _ O
by -X- _ O
Mendelson -X- _ O
and -X- _ O
Belinkov -X- _ O
( -X- _ O
2021b -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
all -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
linear -X- _ O
probe -X- _ O
and -X- _ O
train -X- _ O
it -X- _ O
with -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
16 -X- _ B-HyperparameterValue
and -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
1e-3 -X- _ B-HyperparameterValue
. -X- _ O
The -X- _ O
timestamps -X- _ O
used -X- _ O
, -X- _ O
meaning -X- _ O
the -X- _ O
accumulating -X- _ O
fractions -X- _ O
of -X- _ O
data -X- _ O
that -X- _ O
the -X- _ O
probe -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
, -X- _ O
are -X- _ O
2.0 -X- _ O
% -X- _ O
, -X- _ O
3.0 -X- _ O
% -X- _ O
, -X- _ O
4.4 -X- _ O
% -X- _ O
, -X- _ O
6.5 -X- _ O
% -X- _ O
, -X- _ O
9.5 -X- _ O
% -X- _ O
, -X- _ O
14.0 -X- _ O
% -X- _ O
, -X- _ O
21.0 -X- _ O
% -X- _ O
, -X- _ O
31.0 -X- _ O
% -X- _ O
, -X- _ O
45.7 -X- _ O
% -X- _ O
, -X- _ O
67.6 -X- _ O
% -X- _ O
, -X- _ O
100 -X- _ O
% -X- _ O
. -X- _ O

A.4 -X- _ O
Metrics -X- _ O

A.4.1 -X- _ O
Fairness -X- _ O
- -X- _ O
Based -X- _ O
Metrics -X- _ O
Implementation -X- _ O

All -X- _ O
three -X- _ O
statistical -X- _ O
fairness -X- _ O
metrics -X- _ O
measure -X- _ O
the -X- _ O
difference -X- _ O
between -X- _ O
two -X- _ O
probability -X- _ O
distributions -X- _ O
, -X- _ O
where -X- _ O
this -X- _ O
difference -X- _ O
describes -X- _ O
a -X- _ O
notion -X- _ O
of -X- _ O
bias -X- _ O
. -X- _ O
We -X- _ O
calculate -X- _ O
Independence -X- _ B-MetricName
and -X- _ O
Separation -X- _ B-MetricName
via -X- _ O
Kullback -X- _ O
- -X- _ O
Leibler -X- _ O
( -X- _ O
KL -X- _ O
) -X- _ O
divergence -X- _ O
, -X- _ O
using -X- _ O
the -X- _ O
Al -X- _ O
- -X- _ O
lenNLP -X- _ O
implementation -X- _ O
( -X- _ O
https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
github.com -X- _ O
/ -X- _ O
allenai -X- _ O
/ -X- _ O
allennlp -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
calculate -X- _ O
Sufficiency -X- _ B-MetricName
via -X- _ O
Wasserstein -X- _ O
distance -X- _ O
instead -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
motivated -X- _ O
by -X- _ O
Kwegyir -X- _ O
- -X- _ O
Aggrey -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
case -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
not -X- _ O
use -X- _ O
KL -X- _ O
divergence -X- _ O
, -X- _ O
since -X- _ O
there -X- _ O
are -X- _ O
some -X- _ O
classes -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
occur -X- _ O
in -X- _ O
model -X- _ O
predictions -X- _ O
for -X- _ O
both -X- _ O
male -X- _ O
and -X- _ O
female -X- _ O
genders -X- _ O
. -X- _ O
This -X- _ O
causes -X- _ O
the -X- _ O
probability -X- _ O
distributions -X- _ O
to -X- _ O
not -X- _ O
have -X- _ O
the -X- _ O
same -X- _ O
support -X- _ O
, -X- _ O
and -X- _ O
KL -X- _ O
divergence -X- _ O
is -X- _ O
unbounded -X- _ O
. -X- _ O
Wasserstein -X- _ O
distance -X- _ O
lacks -X- _ O
the -X- _ O
requirement -X- _ O
for -X- _ O
equal -X- _ O
support -X- _ O
. -X- _ O

A.4.2 -X- _ O
Classification -X- _ O
Metrics -X- _ O
Interpretation -X- _ O
in -X- _ O
Winobias -X- _ O

Winobias -X- _ B-DatasetName
datasets -X- _ O
contain -X- _ O
pairs -X- _ O
of -X- _ O
stereotypical -X- _ O
and -X- _ O
anti -X- _ O
- -X- _ O
stereotypical -X- _ O
sentences -X- _ O
. -X- _ O
The -X- _ O
stereotypes -X- _ O
are -X- _ O
derived -X- _ O
from -X- _ O
the -X- _ O
US -X- _ O
labor -X- _ O
statistics -X- _ O
( -X- _ O
for -X- _ O
instance -X- _ O
, -X- _ O
a -X- _ O
profession -X- _ O
with -X- _ O
a -X- _ O
majority -X- _ O
of -X- _ O
males -X- _ O
is -X- _ O
stereotypically -X- _ O
male -X- _ O
) -X- _ O
. -X- _ O
Since -X- _ O
coreference -X- _ O
resolution -X- _ O
is -X- _ O
viewed -X- _ O
as -X- _ O
a -X- _ O
clustering -X- _ O
problem -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
usually -X- _ O
measured -X- _ O
via -X- _ O
clustering -X- _ O
evaluation -X- _ O
metrics -X- _ O
. -X- _ O
Coreference -X- _ B-TaskName
resolution -X- _ I-TaskName
is -X- _ O
commonly -X- _ O
measured -X- _ O
as -X- _ O
the -X- _ O
average -X- _ O
F1 -X- _ O
score -X- _ O
of -X- _ O
these -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
same -X- _ O
is -X- _ O
true -X- _ O
for -X- _ O
Winobias -X- _ B-DatasetName
. -X- _ O
Nevertheless -X- _ O
, -X- _ O
coreference -X- _ B-TaskName
resolution -X- _ I-TaskName
is -X- _ O
accomplished -X- _ O
by -X- _ O
making -X- _ O
a -X- _ O
prediction -X- _ O
for -X- _ O
each -X- _ O
pair -X- _ O
of -X- _ O
mentions -X- _ O
, -X- _ O
so -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
as -X- _ O
a -X- _ O
classification -X- _ O
task -X- _ O
. -X- _ O
Winobias -X- _ B-DatasetName
can -X- _ O
be -X- _ O
viewed -X- _ O
as -X- _ O
a -X- _ O
simpler -X- _ O
task -X- _ O
than -X- _ O
general -X- _ O
coreference -X- _ O
resolution -X- _ O
, -X- _ O
as -X- _ O
it -X- _ O
contains -X- _ O
exactly -X- _ O
two -X- _ O
mentions -X- _ O
of -X- _ O
professions -X- _ O
and -X- _ O
one -X- _ O
pronoun -X- _ O
, -X- _ O
which -X- _ O
refers -X- _ O
to -X- _ O
exactly -X- _ O
one -X- _ O
profession -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
reframe -X- _ O
it -X- _ O
as -X- _ O
a -X- _ O
classification -X- _ O
problem -X- _ O
. -X- _ O
In -X- _ O
a -X- _ O
Winobias -X- _ B-DatasetName
sentence -X- _ O
with -X- _ O
two -X- _ O
professions -X- _ O
x -X- _ O
and -X- _ O
y -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
a -X- _ O
pronoun -X- _ O
p -X- _ O
, -X- _ O
where -X- _ O
p -X- _ O
is -X- _ O
referring -X- _ O
to -X- _ O
x -X- _ O
, -X- _ O
a -X- _ O
true -X- _ O
positive -X- _ O
would -X- _ O
be -X- _ O
to -X- _ O
cluster -X- _ O
x -X- _ O
and -X- _ O
p -X- _ O
together -X- _ O
, -X- _ O
while -X- _ O
a -X- _ O
false -X- _ O
positive -X- _ O
would -X- _ O
be -X- _ O
to -X- _ O
cluster -X- _ O
y -X- _ O
and -X- _ O
p -X- _ O
together -X- _ O
. -X- _ O
Our -X- _ O
classification -X- _ O
metrics -X- _ O
are -X- _ O
derived -X- _ O
based -X- _ O
on -X- _ O
these -X- _ O
definitions -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
the -X- _ O
TPR -X- _ B-MetricName
gap -X- _ O
for -X- _ O
profession -X- _ O
" -X- _ O
teacher -X- _ O
" -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
stereotypical -X- _ O
female -X- _ O
occupation -X- _ O
, -X- _ O
is -X- _ O
the -X- _ O
TPR -X- _ B-MetricName
rate -X- _ O
on -X- _ O
pro -X- _ O
- -X- _ O
stereotypical -X- _ O
sentences -X- _ O
( -X- _ O
with -X- _ O
a -X- _ O
female -X- _ O
pronoun -X- _ O
) -X- _ O
minus -X- _ O
the -X- _ O
TPR -X- _ B-MetricName
rate -X- _ O
on -X- _ O
anti -X- _ O
- -X- _ O
stereotypical -X- _ O
sentences -X- _ O
( -X- _ O
with -X- _ O
a -X- _ O
male -X- _ O
pronoun -X- _ O
) -X- _ O
. -X- _ O

A.4.3 -X- _ O
CEAT -X- _ B-MetricName

The -X- _ O
Word -X- _ O
Embedding -X- _ O
Association -X- _ O
Test -X- _ O
( -X- _ O
WEAT -X- _ O
) -X- _ O
developed -X- _ O
by -X- _ O
( -X- _ O
Caliskan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
method -X- _ O
for -X- _ O
evaluating -X- _ O
bias -X- _ O
in -X- _ O
static -X- _ O
word -X- _ O
embeddings -X- _ O
. -X- _ O
The -X- _ O
test -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
given -X- _ O
two -X- _ O
sets -X- _ O
of -X- _ O
target -X- _ O
words -X- _ O
X -X- _ O
, -X- _ O
Y -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
' -X- _ O
executive -X- _ O
' -X- _ O
, -X- _ O
' -X- _ O
management -X- _ O
' -X- _ O
, -X- _ O
' -X- _ O
professional -X- _ O
' -X- _ O
and -X- _ O
' -X- _ O
home -X- _ O
' -X- _ O
, -X- _ O
' -X- _ O
parents -X- _ O
' -X- _ O
, -X- _ O
' -X- _ O
children -X- _ O
' -X- _ O
) -X- _ O
and -X- _ O
two -X- _ O
sets -X- _ O
of -X- _ O
attribute -X- _ O
words -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
male -X- _ O
names -X- _ O
and -X- _ O
female -X- _ O
names -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
using -X- _ O
⃗ -X- _ O
w -X- _ O
to -X- _ O
represent -X- _ O
the -X- _ O
word -X- _ O
embedding -X- _ O
for -X- _ O
word -X- _ O
w -X- _ O
, -X- _ O
the -X- _ O
effect -X- _ O
size -X- _ O
is -X- _ O
: -X- _ O
In -X- _ O
essence -X- _ O
, -X- _ O
the -X- _ O
effect -X- _ O
size -X- _ O
measures -X- _ O
how -X- _ O
different -X- _ O
are -X- _ O
the -X- _ O
distances -X- _ O
between -X- _ O
the -X- _ O
embedding -X- _ O
vectors -X- _ O
of -X- _ O
each -X- _ O
target -X- _ O
group -X- _ O
and -X- _ O
the -X- _ O
attribute -X- _ O
groups -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
if -X- _ O
s -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
A -X- _ O
, -X- _ O
B -X- _ O
) -X- _ O
> -X- _ O
0 -X- _ O
, -X- _ O
⃗ -X- _ O

x -X- _ O
is -X- _ O
more -X- _ O
similar -X- _ O
to -X- _ O
attribute -X- _ O
words -X- _ O
B -X- _ O
and -X- _ O
vice -X- _ O
versa -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
a -X- _ O
larger -X- _ O
effect -X- _ O
size -X- _ O
is -X- _ O
observed -X- _ O
if -X- _ O
target -X- _ O
words -X- _ O
X -X- _ O
are -X- _ O
more -X- _ O
similar -X- _ O
to -X- _ O
attribute -X- _ O
words -X- _ O
A -X- _ O
and -X- _ O
target -X- _ O
words -X- _ O
Y -X- _ O
are -X- _ O
more -X- _ O
similar -X- _ O
to -X- _ O
attribute -X- _ O
words -X- _ O
B. -X- _ O
|ES| -X- _ O
> -X- _ O
0.5 -X- _ O
and -X- _ O
|ES| -X- _ O
> -X- _ O
0.8 -X- _ O
are -X- _ O
considered -X- _ O
medium -X- _ O
and -X- _ O
large -X- _ O
effect -X- _ O
sizes -X- _ O
, -X- _ O
respectively -X- _ O
( -X- _ O
Rice -X- _ O
and -X- _ O
Harris -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
null -X- _ O
hypothesis -X- _ O
holds -X- _ O
that -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
difference -X- _ O
between -X- _ O
the -X- _ O
two -X- _ O
sets -X- _ O
of -X- _ O
target -X- _ O
words -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
their -X- _ O
relative -X- _ O
similarity -X- _ O
to -X- _ O
the -X- _ O
two -X- _ O
sets -X- _ O
of -X- _ O
attribute -X- _ O
words -X- _ O
, -X- _ O
indicating -X- _ O
that -X- _ O
there -X- _ O
are -X- _ O
no -X- _ O
biased -X- _ O
associations -X- _ O
. -X- _ O
Statistical -X- _ O
significance -X- _ B-MetricName
is -X- _ O
defined -X- _ O
by -X- _ O
the -X- _ O
p -X- _ O
- -X- _ O
value -X- _ O
of -X- _ O
WEAT -X- _ O
, -X- _ O
which -X- _ O
reflects -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
observing -X- _ O
the -X- _ O
effect -X- _ O
size -X- _ O
under -X- _ O
the -X- _ O
null -X- _ O
hypothesis -X- _ O
. -X- _ O

Since -X- _ O
a -X- _ O
word -X- _ O
can -X- _ O
take -X- _ O
on -X- _ O
a -X- _ O
great -X- _ O
variety -X- _ O
of -X- _ O
vector -X- _ O
representations -X- _ O
in -X- _ O
a -X- _ O
contextual -X- _ O
setting -X- _ O
, -X- _ O
ES -X- _ O
varies -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
sentences -X- _ O
used -X- _ O
to -X- _ O
extract -X- _ O
word -X- _ O
representation -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
to -X- _ O
adopt -X- _ O
WEAT -X- _ O
to -X- _ O
contextualized -X- _ O
representations -X- _ O
, -X- _ O
the -X- _ O
Combined -X- _ O
Effect -X- _ O
Size -X- _ O
( -X- _ O
CES -X- _ O
) -X- _ O
( -X- _ O
Guo -X- _ O
and -X- _ O
Caliskan -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
is -X- _ O
derived -X- _ O
as -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
WEAT -X- _ O
effect -X- _ O
sizes -X- _ O
over -X- _ O
many -X- _ O
possible -X- _ O
contextual -X- _ O
word -X- _ O
representations -X- _ O
: -X- _ O

CES -X- _ O
( -X- _ O
X -X- _ O
, -X- _ O
Y -X- _ O
, -X- _ O
A -X- _ O
, -X- _ O
B -X- _ O
) -X- _ O
= -X- _ O
N -X- _ O
i=1 -X- _ O
v -X- _ O
i -X- _ O
ES -X- _ O
i -X- _ O
N -X- _ O
i=1 -X- _ O
v -X- _ O
i -X- _ O

where -X- _ O
ES -X- _ O
i -X- _ O
denotes -X- _ O
the -X- _ O
WEAT -X- _ O
effect -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
i'th -X- _ O
choice -X- _ O
of -X- _ O
word -X- _ O
representations -X- _ O
from -X- _ O
a -X- _ O
large -X- _ O
corpus -X- _ O
, -X- _ O
and -X- _ O
v -X- _ O
i -X- _ O
is -X- _ O
the -X- _ O
inverse -X- _ O
of -X- _ O
the -X- _ O
sum -X- _ O
of -X- _ O
in -X- _ O
- -X- _ O
sample -X- _ O
variance -X- _ O
V -X- _ O
i -X- _ O
and -X- _ O
between -X- _ O
- -X- _ O
sample -X- _ O
variance -X- _ O
in -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
random -X- _ O
- -X- _ O
effects -X- _ O
. -X- _ O
As -X- _ O
in -X- _ O
Guo -X- _ O
and -X- _ O
Caliskan -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
representation -X- _ O
for -X- _ O
each -X- _ O
word -X- _ O
is -X- _ O
derived -X- _ O
from -X- _ O
10,000 -X- _ O
random -X- _ O
sentences -X- _ O
extracted -X- _ O
from -X- _ O
a -X- _ O
corpus -X- _ O
of -X- _ O
Reddit -X- _ O
comments -X- _ O
. -X- _ O

The -X- _ O
combined -X- _ O
effect -X- _ O
size -X- _ O
of -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
models -X- _ O
is -X- _ O
examined -X- _ O
on -X- _ O
WEAT -X- _ B-DatasetName
stimulus -X- _ I-DatasetName
6 -X- _ I-DatasetName
, -X- _ O
which -X- _ O
contains -X- _ O
target -X- _ O
words -X- _ O
of -X- _ O
career -X- _ O
/ -X- _ O
family -X- _ O
and -X- _ O
attribute -X- _ O
words -X- _ O
of -X- _ O
male -X- _ O
/ -X- _ O
female -X- _ O
names -X- _ O
. -X- _ O
This -X- _ O
was -X- _ O
the -X- _ O
only -X- _ O
one -X- _ O
that -X- _ O
detected -X- _ O
bias -X- _ O
on -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
RoBERTa -X- _ B-MethodName
( -X- _ O
CES -X- _ B-MetricName
close -X- _ O
to -X- _ O
0.5 -X- _ B-MetricValue
and -X- _ O
p -X- _ O
< -X- _ O
0.05 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
points -X- _ O
that -X- _ O
we -X- _ O
kept -X- _ O
in -X- _ O
our -X- _ O
analysis -X- _ O
are -X- _ O
those -X- _ O
where -X- _ O
p -X- _ O
< -X- _ O
0.05 -X- _ O
, -X- _ O
which -X- _ O
make -X- _ O
up -X- _ O
90 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
points -X- _ O
in -X- _ O
occupation -X- _ O
prediction -X- _ O
and -X- _ O
95 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
points -X- _ O
in -X- _ O
coreference -X- _ B-TaskName
resolution -X- _ I-TaskName
. -X- _ O

B -X- _ O
Full -X- _ O
Results -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
we -X- _ O
provide -X- _ O
the -X- _ O
full -X- _ O
results -X- _ O
of -X- _ O
a -X- _ O
RoBERTa -X- _ B-MethodName
model -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
downstream -X- _ O
task -X- _ O
. -X- _ O

Table -X- _ O
3 -X- _ O
presents -X- _ O
results -X- _ O
for -X- _ O
the -X- _ O
occupation -X- _ B-TaskName
prediction -X- _ I-TaskName
task -X- _ O
after -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
, -X- _ O
Table -X- _ O
4 -X- _ O
presents -X- _ O
the -X- _ O
retrained -X- _ O
model -X- _ O
results -X- _ O
. -X- _ O

Figure -X- _ O
5 -X- _ O
illustrates -X- _ O
the -X- _ O
correlations -X- _ O
between -X- _ O
extrinsic -X- _ O
metrics -X- _ O
and -X- _ O
compression -X- _ O
rate -X- _ O
before -X- _ O
and -X- _ O
after -X- _ O
retraining -X- _ O
. -X- _ O

Table -X- _ O
5 -X- _ O
presents -X- _ O
the -X- _ O
complete -X- _ O
results -X- _ O
for -X- _ O
the -X- _ O
occupation -X- _ O
prediction -X- _ O
task -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
trained -X- _ O
without -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
, -X- _ O
meaning -X- _ O
that -X- _ O
the -X- _ O
RoBERTa -X- _ B-MethodName
model -X- _ O
is -X- _ O
the -X- _ O
pretrained -X- _ O
version -X- _ O
from -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
only -X- _ O
the -X- _ O
classification -X- _ O
layer -X- _ O
was -X- _ O
updated -X- _ O
. -X- _ O
Subsampling -X- _ O
the -X- _ O
dataset -X- _ O
has -X- _ O
significant -X- _ O
debiasing -X- _ O
effects -X- _ O
, -X- _ O
which -X- _ O
suggests -X- _ O
that -X- _ O
this -X- _ O
debiasing -X- _ O
method -X- _ O
can -X- _ O
achieve -X- _ O
low -X- _ O
extrinsic -X- _ O
bias -X- _ O
even -X- _ O
when -X- _ O
internal -X- _ O
bias -X- _ O
exists -X- _ O
. -X- _ O
The -X- _ O
Pearson -X- _ B-MetricName
correlation -X- _ I-MetricName
on -X- _ O
precision -X- _ O
exhibits -X- _ O
a -X- _ O
different -X- _ O
behavior -X- _ O
. -X- _ O
It -X- _ O
makes -X- _ O
sense -X- _ O
nonetheless -X- _ O
: -X- _ O
precision -X- _ O
is -X- _ O
computed -X- _ O
as -X- _ O
T -X- _ O
P -X- _ O
\ -X- _ O
( -X- _ O
T -X- _ O
P -X- _ O
+ -X- _ O
F -X- _ O
P -X- _ O
) -X- _ O
. -X- _ O
A -X- _ O
biased -X- _ O
model -X- _ O
will -X- _ O
assign -X- _ O
more -X- _ O
examples -X- _ O
of -X- _ O
a -X- _ O
specific -X- _ O
profession -X- _ O
to -X- _ O
a -X- _ O
specific -X- _ O
gender -X- _ O
( -X- _ O
which -X- _ O
aligns -X- _ O
with -X- _ O
the -X- _ O
percentage -X- _ O
of -X- _ O
biographies -X- _ O
of -X- _ O
this -X- _ O
profession -X- _ O
with -X- _ O
this -X- _ O
gender -X- _ O
on -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
) -X- _ O
, -X- _ O
increasing -X- _ O
both -X- _ O
T -X- _ O
P -X- _ O
and -X- _ O
F -X- _ O
P -X- _ O
and -X- _ O
decreasing -X- _ O
precision -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
coreference -X- _ O
resolution -X- _ O
task -X- _ O
align -X- _ O
with -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
occupation -X- _ O
prediction -X- _ O
. -X- _ O

Table -X- _ O
6 -X- _ O
presents -X- _ O
the -X- _ O
results -X- _ O
using -X- _ O
a -X- _ O
DeBERTa -X- _ B-MethodName
model -X- _ O
( -X- _ O
He -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
for -X- _ O
the -X- _ O
occupation -X- _ B-TaskName
classification -X- _ I-TaskName
task -X- _ O
. -X- _ O
The -X- _ O
trends -X- _ O
are -X- _ O
similar -X- _ O
to -X- _ O
those -X- _ O
of -X- _ O
RoBERTa -X- _ B-MethodName
, -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
metrics -X- _ O
showing -X- _ O
an -X- _ O
increase -X- _ O
, -X- _ O
no -X- _ O
change -X- _ O
, -X- _ O
or -X- _ O
decrease -X- _ O
in -X- _ O
correlation -X- _ O
after -X- _ O
re -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
suggesting -X- _ O
a -X- _ O
general -X- _ O
trend -X- _ O
in -X- _ O
the -X- _ O
behavior -X- _ O
of -X- _ O
these -X- _ O
metrics -X- _ O
in -X- _ O
relation -X- _ O
to -X- _ O
internal -X- _ O
model -X- _ O
representations -X- _ O
. -X- _ O

Table -X- _ O
7 -X- _ O
displays -X- _ O
the -X- _ O
results -X- _ O
on -X- _ O
a -X- _ O
finetuned -X- _ O
model -X- _ O
for -X- _ O
the -X- _ O
coreference -X- _ O
resolution -X- _ O
task -X- _ O
and -X- _ O
Table -X- _ O
8 -X- _ O
displays -X- _ O
the -X- _ O
retraining -X- _ O
results -X- _ O
. -X- _ O

Figure -X- _ O
6 -X- _ O
shows -X- _ O
the -X- _ O
correlations -X- _ O
between -X- _ O
compression -X- _ B-MetricName
rate -X- _ O
and -X- _ O
extrinsic -X- _ O
metrics -X- _ O
before -X- _ O
and -X- _ O
after -X- _ O
the -X- _ O
retraining -X- _ O
. -X- _ O
C -X- _ O
Why -X- _ O
is -X- _ O
scrubbing -X- _ O
not -X- _ O
as -X- _ O
effective -X- _ O
as -X- _ O
subsampling -X- _ O
? -X- _ O

The -X- _ O
debiasing -X- _ O
method -X- _ O
of -X- _ O
subsampling -X- _ O
significantly -X- _ O
reduced -X- _ O
external -X- _ O
biases -X- _ O
in -X- _ O
the -X- _ O
occupation -X- _ O
prediction -X- _ O
task -X- _ O
. -X- _ O
Although -X- _ O
compression -X- _ B-MetricName
rates -X- _ O
show -X- _ O
that -X- _ O
scrubbing -X- _ O
reduced -X- _ O
more -X- _ O
gender -X- _ O
information -X- _ O
, -X- _ O
subsampling -X- _ O
outperforms -X- _ O
it -X- _ O
as -X- _ O
a -X- _ O
debiasing -X- _ O
method -X- _ O
. -X- _ O
We -X- _ O
find -X- _ O
that -X- _ O
in -X- _ O
spite -X- _ O
of -X- _ O
the -X- _ O
scrubbing -X- _ O
, -X- _ O
a -X- _ O
probe -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
correctly -X- _ O
identify -X- _ O
the -X- _ O
gender -X- _ O
from -X- _ O
an -X- _ O
internal -X- _ O
representation -X- _ O
with -X- _ O
68.8 -X- _ B-MetricValue
% -X- _ I-MetricValue
accuracy -X- _ B-MetricName
compared -X- _ O
to -X- _ O
90.7 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
the -X- _ O
original -X- _ O
, -X- _ O
non -X- _ O
- -X- _ O
scrubbed -X- _ O
data -X- _ O
. -X- _ O
This -X- _ O
means -X- _ O
that -X- _ O
although -X- _ O
the -X- _ O
scrubbing -X- _ O
process -X- _ O
reduces -X- _ O
extrinsic -X- _ O
bias -X- _ O
significantly -X- _ O
, -X- _ O
gender -X- _ O
information -X- _ O
is -X- _ O
still -X- _ O
embedded -X- _ O
in -X- _ O
the -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
token -X- _ O
embeddings -X- _ O
. -X- _ O

To -X- _ O
investigate -X- _ O
the -X- _ O
source -X- _ O
of -X- _ O
gender -X- _ O
information -X- _ O
after -X- _ O
scrubbing -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
logistic -X- _ B-MethodName
regression -X- _ I-MethodName
( -X- _ O
LR -X- _ B-MethodName
) -X- _ O
model -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
gender -X- _ O
from -X- _ O
the -X- _ O
Bag -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
Words -X- _ O
of -X- _ O
the -X- _ O
scrubbed -X- _ O
biographies -X- _ O
. -X- _ O
We -X- _ O
perform -X- _ O
an -X- _ O
iterative -X- _ O
process -X- _ O
for -X- _ O
automatic -X- _ O
extra -X- _ O
scrubbing -X- _ O
: -X- _ O
in -X- _ O
each -X- _ O
iteration -X- _ O
we -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
train -X- _ O
a -X- _ O
LR -X- _ O
model -X- _ O
for -X- _ O
gender -X- _ O
prediction -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
scrub -X- _ O
the -X- _ O
n -X- _ O
most -X- _ O
significant -X- _ O
words -X- _ O
for -X- _ O
each -X- _ O
gender -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
LR -X- _ O
weights -X- _ O
. -X- _ O
The -X- _ O
most -X- _ O
relevant -X- _ O
words -X- _ O
among -X- _ O
5 -X- _ O
seeds -X- _ O
of -X- _ O
training -X- _ O
with -X- _ O
n=10 -X- _ O
words -X- _ O
scrubbed -X- _ O
per -X- _ O
iteration -X- _ O
are -X- _ O
displayed -X- _ O
in -X- _ O
Table -X- _ O
9 -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
learns -X- _ O
indirect -X- _ O
correlations -X- _ O
to -X- _ O
gender -X- _ O
in -X- _ O
the -X- _ O
absence -X- _ O
of -X- _ O
explicit -X- _ O
gendered -X- _ O
words -X- _ O
. -X- _ O
Because -X- _ O
the -X- _ O
significant -X- _ O
words -X- _ O
are -X- _ O
related -X- _ O
to -X- _ O
male -X- _ O
- -X- _ O
or -X- _ O
femaledominated -X- _ O
professions -X- _ O
, -X- _ O
we -X- _ O
conducted -X- _ O
the -X- _ O
process -X- _ O
on -X- _ O
a -X- _ O
specific -X- _ O
profession -X- _ O
. -X- _ O
Table -X- _ O
10 -X- _ O
presents -X- _ O
the -X- _ O
most -X- _ O
significant -X- _ O
words -X- _ O
for -X- _ O
biographies -X- _ O
of -X- _ O
nurses -X- _ O
. -X- _ O
There -X- _ O
are -X- _ O
differences -X- _ O
in -X- _ O
wording -X- _ O
even -X- _ O
between -X- _ O
females -X- _ O
and -X- _ O
males -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
profession -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
of -X- _ O
this -X- _ O
study -X- _ O
are -X- _ O
in -X- _ O
line -X- _ O
with -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
other -X- _ O
studies -X- _ O
that -X- _ O
have -X- _ O
been -X- _ O
conducted -X- _ O
on -X- _ O
the -X- _ O
way -X- _ O
biographies -X- _ O
are -X- _ O
written -X- _ O
for -X- _ O
men -X- _ O
and -X- _ O
women -X- _ O
( -X- _ O
Wagner -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Sun -X- _ O
and -X- _ O
Peng -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

Subsampling -X- _ O
is -X- _ O
therefore -X- _ O
more -X- _ O
effective -X- _ O
even -X- _ O
when -X- _ O
gender -X- _ O
information -X- _ O
is -X- _ O
present -X- _ O
since -X- _ O
it -X- _ O
prevents -X- _ O
the -X- _ O
model -X- _ O
from -X- _ O
learning -X- _ O
correlations -X- _ O
between -X- _ O
gender -X- _ O
information -X- _ O
and -X- _ O
a -X- _ O
profession -X- _ O
whereas -X- _ O
scrubbing -X- _ O
only -X- _ O
attempts -X- _ O
to -X- _ O
remove -X- _ O
gender -X- _ O
indicators -X- _ O
without -X- _ O
removing -X- _ O
correlations -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
possible -X- _ O
that -X- _ O
oversampling -X- _ O
is -X- _ O
less -X- _ O
effective -X- _ O
for -X- _ O
debiasing -X- _ O
since -X- _ O
seeing -X- _ O
more -X- _ O
non -X- _ O
- -X- _ O
unique -X- _ O
examples -X- _ O
an -X- _ O
unrepresented -X- _ O
group -X- _ O
encourages -X- _ O
learning -X- _ O
correlations -X- _ O
. -X- _ O

D -X- _ O
A -X- _ O
closer -X- _ O
look -X- _ O
into -X- _ O
no -X- _ O
- -X- _ O
correlation -X- _ O
cases -X- _ O
D.1 -X- _ O
Occupation -X- _ B-TaskName
Prediction -X- _ I-TaskName

Although -X- _ O
compression -X- _ B-MetricName
has -X- _ O
the -X- _ O
ability -X- _ O
to -X- _ O
identify -X- _ O
bias -X- _ O
in -X- _ O
most -X- _ O
cases -X- _ O
, -X- _ O
some -X- _ O
metrics -X- _ O
still -X- _ O
show -X- _ O
little -X- _ O
or -X- _ O
no -X- _ O
correlation -X- _ O
with -X- _ O
compression -X- _ O
rate -X- _ O
. -X- _ O
These -X- _ O
results -X- _ O
suggest -X- _ O
that -X- _ O
gender -X- _ O
information -X- _ O
comprises -X- _ O
only -X- _ O
one -X- _ O
facet -X- _ O
of -X- _ O
embedded -X- _ O
bias -X- _ O
in -X- _ O
the -X- _ O
representations -X- _ O
. -X- _ O
Other -X- _ O
factors -X- _ O
that -X- _ O
may -X- _ O
influence -X- _ O
these -X- _ O
metrics -X- _ O
are -X- _ O
not -X- _ O
considered -X- _ O
or -X- _ O
measured -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
connection -X- _ O
between -X- _ O
a -X- _ O
name -X- _ O
and -X- _ O
a -X- _ O
profession -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
as -X- _ O
can -X- _ O
be -X- _ O
see -X- _ O
in -X- _ O
Tables -X- _ O
3 -X- _ O
and -X- _ O
4 -X- _ O
, -X- _ O
LMs -X- _ O
finetuned -X- _ O
on -X- _ O
subsampled -X- _ O
data -X- _ O
have -X- _ O
the -X- _ O
largest -X- _ O
FPR -X- _ B-MetricName
gaps -X- _ O
after -X- _ O
retraining -X- _ O
, -X- _ O
despite -X- _ O
being -X- _ O
the -X- _ O
least -X- _ O
biased -X- _ O
before -X- _ O
retraining -X- _ O
, -X- _ O
while -X- _ O
those -X- _ O
finetuned -X- _ O
on -X- _ O
oversampled -X- _ O
data -X- _ O
have -X- _ O
the -X- _ O
next -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
lowest -X- _ O
FPR -X- _ B-MetricName
gaps -X- _ O
after -X- _ O
retraining -X- _ O
. -X- _ O
The -X- _ O
information -X- _ O
encoded -X- _ O
in -X- _ O
the -X- _ O
internal -X- _ O
representations -X- _ O
may -X- _ O
have -X- _ O
been -X- _ O
encoded -X- _ O
in -X- _ O
a -X- _ O
manner -X- _ O
that -X- _ O
allowed -X- _ O
the -X- _ O
classification -X- _ O
layer -X- _ O
to -X- _ O
exhibit -X- _ O
a -X- _ O
smaller -X- _ O
FPR -X- _ B-MetricName
gap -X- _ O
when -X- _ O
trained -X- _ O
on -X- _ O
a -X- _ O
balanced -X- _ O
dataset -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
when -X- _ O
the -X- _ O
classification -X- _ O
Figure -X- _ O
7 -X- _ O
: -X- _ O
Occupation -X- _ O
prediction -X- _ O
: -X- _ O
Before -X- _ O
( -X- _ O
left -X- _ O
) -X- _ O
and -X- _ O
after -X- _ O
( -X- _ O
right -X- _ O
) -X- _ O
plots -X- _ O
of -X- _ O
compression -X- _ O
rate -X- _ O
versus -X- _ O
Pearson -X- _ B-MetricName
metrics -X- _ O
as -X- _ O
computed -X- _ O
from -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
statistics -X- _ O
( -X- _ O
as -X- _ O
opposed -X- _ O
to -X- _ O
statistics -X- _ O
derived -X- _ O
from -X- _ O
the -X- _ O
training -X- _ O
dataset -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
shows -X- _ O
the -X- _ O
unrealiability -X- _ O
of -X- _ O
using -X- _ O
real -X- _ O
world -X- _ O
statistics -X- _ O
to -X- _ O
draw -X- _ O
conclusions -X- _ O
, -X- _ O
as -X- _ O
they -X- _ O
may -X- _ O
not -X- _ O
be -X- _ O
reflected -X- _ O
in -X- _ O
the -X- _ O
data -X- _ O
. -X- _ O

Acknowledgements -X- _ O

This -X- _ O
research -X- _ O
was -X- _ O
supported -X- _ O
by -X- _ O
the -X- _ O
ISRAEL -X- _ O
SCI -X- _ O
- -X- _ O
ENCE -X- _ O
FOUNDATION -X- _ O
( -X- _ O
grant -X- _ O
No -X- _ O
. -X- _ O
448 -X- _ O
/ -X- _ O
20 -X- _ O
) -X- _ O
and -X- _ O
by -X- _ O
an -X- _ O
Azrieli -X- _ O
Foundation -X- _ O
Early -X- _ O
Career -X- _ O
Faculty -X- _ O
Fellowship -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
thank -X- _ O
Kate -X- _ O
McCurdy -X- _ O
and -X- _ O
Andreas -X- _ O
Grivas -X- _ O
for -X- _ O
comments -X- _ O
on -X- _ O
early -X- _ O
drafts -X- _ O
, -X- _ O
the -X- _ O
members -X- _ O
of -X- _ O
the -X- _ O
Technion -X- _ O
CS -X- _ O
NLP -X- _ O
group -X- _ O
for -X- _ O
their -X- _ O
valuable -X- _ O
feedback -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
anonymous -X- _ O
reviewers -X- _ O
for -X- _ O
their -X- _ O
useful -X- _ O
suggestions -X- _ O
. -X- _ O

Debiasing -X- _ O
Strategy -X- _ O

Metric -X- _ O

None -X- _ O
Oversampling -X- _ O
Subsampling -X- _ O
Scrubbing -X- _ O
Compression -X- _ B-MetricName
4.121 -X- _ O
± -X- _ O
1.238 -X- _ O
8.522 -X- _ O
* -X- _ O
± -X- _ O
2.354 -X- _ O
3.568 -X- _ O
± -X- _ O
1.516 -X- _ O
1.699 -X- _ O
* -X- _ O
± -X- _ O
0.138 -X- _ O
Accuracy -X- _ B-MetricName
0.861 -X- _ O
± -X- _ O
0.005 -X- _ O
0.852 -X- _ O
* -X- _ O
± -X- _ O
0.004 -X- _ O
0.861 -X- _ O
± -X- _ O
0.003 -X- _ O
0.851 -X- _ O
* -X- _ O
± -X- _ O
0.003 -X- _ O
TPR -X- _ B-MetricName
gap -X- _ O
( -X- _ O
P -X- _ O
) -X- _ O
0.763 -X- _ O
± -X- _ O
0.071 -X- _ O
0.729 -X- _ O
± -X- _ O
0.067 -X- _ O
0.319 -X- _ O
* -X- _ O
± -X- _ O
0.114 -X- _ O
0.704 -X- _ O
* -X- _ O
± -X- _ O
0.068 -X- _ O
TPR -X- _ O
gap -X- _ O
( -X- _ O
S -X- _ O
) -X- _ O
2.391 -X- _ O
± -X- _ O
0.257 -X- _ O
2.145 -X- _ O
* -X- _ O
± -X- _ O
0.220 -X- _ O
1.598 -X- _ O
* -X- _ O
± -X- _ O
0.273 -X- _ O
2.019 -X- _ O
* -X- _ O
± -X- _ O
0.262 -X- _ O
FPR -X- _ B-MetricName
gap -X- _ O
( -X- _ O
P -X- _ O
) -X- _ O
0.591 -X- _ O
± -X- _ O
0.052 -X- _ O
0.491 -X- _ O
* -X- _ O
± -X- _ O
0.059 -X- _ O
0.087 -X- _ O
* -X- _ O
± -X- _ O
0.094 -X- _ O
0.552 -X- _ O
± -X- _ O
0.063 -X- _ O
FPR -X- _ B-MetricName
gap -X- _ O
( -X- _ O
S -X- _ O
) -X- _ O
0.075 -X- _ O
± -X- _ O
0.010 -X- _ O
0.085 -X- _ O
* -X- _ O
± -X- _ O
0.011 -X- _ O
0.030 -X- _ O
* -X- _ O
± -X- _ O
0.006 -X- _ O
0.057 -X- _ O
* -X- _ O
± -X- _ O
0.007 -X- _ O
Precision -X- _ B-MetricName
gap -X- _ O
( -X- _ O
P -X- _ O
) -X- _ O

-0.880 -X- _ O
± -X- _ O
0.031 -X- _ O
-0.855 -X- _ O
± -X- _ O
0.115 -X- _ O
-0.299 -X- _ O
* -X- _ O
± -X- _ O
0.215 -X- _ O
-0.815 -X- _ O
* -X- _ O
± -X- _ O
0.040 -X- _ O
Precision -X- _ B-MetricName
gap -X- _ O
( -X- _ O
S -X- _ O
) -X- _ O

3.621 -X- _ O
± -X- _ O
0.337 -X- _ O
3.401 -X- _ O
± -X- _ O
0.667 -X- _ O
1.549 -X- _ O
* -X- _ O
± -X- _ O
0.229 -X- _ O
2.590 -X- _ O
* -X- _ O
± -X- _ O
0.279 -X- _ O
Independence -X- _ B-MetricName
gap -X- _ O
( -X- _ O
S -X- _ O
) -X- _ O
0.009 -X- _ O
± -X- _ O
0.002 -X- _ O
0.008 -X- _ O
± -X- _ O
0.002 -X- _ O
0.001 -X- _ O
* -X- _ O
± -X- _ O
0.000 -X- _ O
0.005 -X- _ O
* -X- _ O
± -X- _ O
0.001 -X- _ O
Separation -X- _ B-MetricName
gap -X- _ O
( -X- _ O
S -X- _ O
) -X- _ O
0.327 -X- _ O
± -X- _ O
0.051 -X- _ O
0.305 -X- _ O
± -X- _ O
0.030 -X- _ O
0.204 -X- _ O
* -X- _ O
± -X- _ O
0.032 -X- _ O
0.296 -X- _ O
± -X- _ O
0.053 -X- _ O
Sufficiency -X- _ B-MetricName
gap -X- _ O
( -X- _ O
S -X- _ O
) -X- _ O
9.451 -X- _ O
± -X- _ O
1.945 -X- _ O
8.324 -X- _ O
* -X- _ O
± -X- _ O
1.537 -X- _ O
1.218 -X- _ O
* -X- _ O
± -X- _ O
0.330 -X- _ O
4.930 -X- _ O
* -X- _ O
± -X- _ O
0.927 -X- _ O
layer -X- _ O
was -X- _ O
retrained -X- _ O
on -X- _ O
biased -X- _ O
training -X- _ O
data -X- _ O
, -X- _ O
it -X- _ O
used -X- _ O
the -X- _ O
same -X- _ O
features -X- _ O
to -X- _ O
make -X- _ O
biased -X- _ O
predictions -X- _ O
. -X- _ O

D.2 -X- _ O
Coreference -X- _ B-TaskName
Resolution -X- _ I-TaskName

The -X- _ O
cases -X- _ O
where -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
correlation -X- _ O
between -X- _ O
our -X- _ O
intrinsic -X- _ O
metric -X- _ O
and -X- _ O
an -X- _ O
extrinsic -X- _ O
metric -X- _ O
are -X- _ O
the -X- _ O
cases -X- _ O
where -X- _ O
the -X- _ O
metric -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
Pearson -X- _ B-MetricName
correlation -X- _ O
. -X- _ O
Unlike -X- _ O
occupation -X- _ B-TaskName
prediction -X- _ I-TaskName
, -X- _ O
coreference -X- _ B-TaskName
resolution -X- _ I-TaskName
seems -X- _ O
to -X- _ O
exhibit -X- _ O
no -X- _ O
correlation -X- _ O
between -X- _ O
those -X- _ O
metrics -X- _ O
and -X- _ O
compression -X- _ B-MetricName
rate -X- _ O
. -X- _ O
These -X- _ O
metrics -X- _ O
are -X- _ O
computed -X- _ O
as -X- _ O
the -X- _ O
Pearson -X- _ B-MetricName
correlation -X- _ O
between -X- _ O
a -X- _ O
performance -X- _ O
gap -X- _ O
for -X- _ O
a -X- _ O
specific -X- _ O
profession -X- _ O
and -X- _ O
the -X- _ O
percentage -X- _ O
of -X- _ O
women -X- _ O
in -X- _ O
that -X- _ O
profession -X- _ O
, -X- _ O
however -X- _ O
the -X- _ O
percentages -X- _ O
are -X- _ O
computed -X- _ O
differently -X- _ O
in -X- _ O
each -X- _ O
task -X- _ O
: -X- _ O
in -X- _ O
occupation -X- _ B-TaskName
prediction -X- _ I-TaskName
, -X- _ O
the -X- _ O
percentages -X- _ O
are -X- _ O
computed -X- _ O
from -X- _ O
the -X- _ O
train -X- _ O
set -X- _ O
, -X- _ O
focusing -X- _ O
on -X- _ O
the -X- _ O
representation -X- _ O
each -X- _ O
gender -X- _ O
has -X- _ O
in -X- _ O
the -X- _ O
data -X- _ O
. -X- _ O
In -X- _ O
Winobias -X- _ B-DatasetName
, -X- _ O
the -X- _ O
percentages -X- _ O
are -X- _ O
taken -X- _ O
from -X- _ O
the -X- _ O
US -X- _ O
labor -X- _ O
statistics -X- _ O
, -X- _ O
and -X- _ O
are -X- _ O
unrelated -X- _ O
to -X- _ O
the -X- _ O
training -X- _ O
dataset -X- _ O
statistics -X- _ O
. -X- _ O
We -X- _ O
note -X- _ O
that -X- _ O
the -X- _ O
two -X- _ O
statistics -X- _ O
can -X- _ O
be -X- _ O
different -X- _ O
-the -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
representation -X- _ O
of -X- _ O
women -X- _ O
in -X- _ O
a -X- _ O
profession -X- _ O
does -X- _ O
not -X- _ O
have -X- _ O
to -X- _ O
be -X- _ O
equal -X- _ O
to -X- _ O
their -X- _ O
representation -X- _ O
in -X- _ O
written -X- _ O
text -X- _ O
( -X- _ O
Suresh -X- _ O
and -X- _ O
Guttag -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
thus -X- _ O
decided -X- _ O
to -X- _ O
test -X- _ O
what -X- _ O
happens -X- _ O
if -X- _ O
we -X- _ O
change -X- _ O
the -X- _ O
statistics -X- _ O
used -X- _ O
in -X- _ O
Winobias -X- _ B-DatasetName
to -X- _ O
dataset -X- _ O
statistics -X- _ O
, -X- _ O
but -X- _ O
Ontonotes -X- _ B-DatasetName
5.0 -X- _ O
has -X- _ O
very -X- _ O
little -X- _ O
representation -X- _ O
to -X- _ O
each -X- _ O
profession -X- _ O
and -X- _ O
the -X- _ O
statistics -X- _ O
extracted -X- _ O
from -X- _ O
it -X- _ O
would -X- _ O
not -X- _ O
be -X- _ O
reliable -X- _ O
. -X- _ O
We -X- _ O
thus -X- _ O
took -X- _ O
a -X- _ O
different -X- _ O
approach -X- _ O
and -X- _ O
computed -X- _ O
the -X- _ O
Pearson -X- _ B-MetricName
correlations -X- _ O
for -X- _ O
occupation -X- _ B-TaskName
prediction -X- _ I-TaskName
with -X- _ O
real -X- _ O
world -X- _ O
statistics -X- _ O
instead -X- _ O
of -X- _ O
dataset -X- _ O
statistics -X- _ O
. -X- _ O
To -X- _ O
do -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
mapped -X- _ O
the -X- _ O
professions -X- _ O
appearing -X- _ O
in -X- _ O
this -X- _ O
dataset -X- _ O
to -X- _ O
professions -X- _ O
from -X- _ O
the -X- _ O
US -X- _ O
labor -X- _ O
statistics -X- _ O
, -X- _ O
and -X- _ O
dropped -X- _ O
those -X- _ O
who -X- _ O
could -X- _ O
no -X- _ O
be -X- _ O
mapped -X- _ O
( -X- _ O
6 -X- _ O
out -X- _ O
of -X- _ O
29 -X- _ O
of -X- _ O
the -X- _ O
professions -X- _ O
which -X- _ O
is -X- _ O
21.4 -X- _ O
% -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
repeated -X- _ O
all -X- _ O
experiments -X- _ O
on -X- _ O
the -X- _ O
Pearson -X- _ B-MetricName
metrics -X- _ O
using -X- _ O
these -X- _ O
statistics -X- _ O
. -X- _ O
Figure -X- _ O
7 -X- _ O
shows -X- _ O
the -X- _ O
results -X- _ O
. -X- _ O
Correlations -X- _ O
are -X- _ O
very -X- _ O
different -X- _ O
when -X- _ O
computed -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
statistics -X- _ O
. -X- _ O
TPR -X- _ B-MetricName
- -X- _ O
gap -X- _ O
has -X- _ O
no -X- _ O
correlation -X- _ O
at -X- _ O
all -X- _ O
although -X- _ O
it -X- _ O
had -X- _ O
with -X- _ O
training -X- _ O
data -X- _ O
statistics -X- _ O
, -X- _ O
the -X- _ O
correlation -X- _ O
for -X- _ O
FPR -X- _ B-MetricName
- -X- _ O
gap -X- _ O
after -X- _ O
retraining -X- _ O
exists -X- _ O
but -X- _ O
is -X- _ O
negative -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
correlation -X- _ O
with -X- _ O
precision -X- _ B-MetricName
- -X- _ O
gap -X- _ O
does -X- _ O
not -X- _ O
exist -X- _ O
after -X- _ O
retraining -X- _ O
. -X- _ O
We -X- _ O
thus -X- _ O
conclude -X- _ O
that -X- _ O
the -X- _ O
Pearson -X- _ B-MetricName
metrics -X- _ O
are -X- _ O
less -X- _ O
reliable -X- _ O
as -X- _ O
they -X- _ O
are -X- _ O
heavily -X- _ O
dependent -X- _ O
on -X- _ O
the -X- _ O
statistics -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
which -X- _ O
they -X- _ O
are -X- _ O
calculated -X- _ O
. -X- _ O

