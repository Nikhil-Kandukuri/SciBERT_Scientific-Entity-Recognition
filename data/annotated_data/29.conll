-DOCSTART- -X- O
Early -X- _ B-TaskName
exit -X- _ I-TaskName
mechanism -X- _ O
aims -X- _ O
to -X- _ O
accelerate -X- _ O
the -X- _ O
inference -X- _ O
speed -X- _ O
of -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
. -X- _ O
The -X- _ O
essential -X- _ O
idea -X- _ O
is -X- _ O
to -X- _ O
exit -X- _ O
early -X- _ O
without -X- _ O
passing -X- _ O
through -X- _ O
all -X- _ O
the -X- _ O
inference -X- _ O
layers -X- _ O
at -X- _ O
the -X- _ O
inference -X- _ O
stage -X- _ O
. -X- _ O
To -X- _ O
make -X- _ O
accurate -X- _ O
predictions -X- _ O
for -X- _ O
downstream -X- _ O
tasks -X- _ O
, -X- _ O
the -X- _ O
hierarchical -X- _ O
linguistic -X- _ O
information -X- _ O
embedded -X- _ O
in -X- _ O
all -X- _ O
layers -X- _ O
should -X- _ O
be -X- _ O
jointly -X- _ O
considered -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
much -X- _ O
of -X- _ O
the -X- _ O
research -X- _ O
up -X- _ O
to -X- _ O
now -X- _ O
has -X- _ O
been -X- _ O
limited -X- _ O
to -X- _ O
use -X- _ O
local -X- _ O
representations -X- _ O
of -X- _ O
the -X- _ O
exit -X- _ O
layer -X- _ O
. -X- _ O
Such -X- _ O
treatment -X- _ O
inevitably -X- _ O
loses -X- _ O
information -X- _ O
of -X- _ O
the -X- _ O
unused -X- _ O
past -X- _ O
layers -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
high -X- _ O
- -X- _ O
level -X- _ O
features -X- _ O
embedded -X- _ O
in -X- _ O
future -X- _ O
layers -X- _ O
, -X- _ O
leading -X- _ O
to -X- _ O
sub -X- _ O
- -X- _ O
optimal -X- _ O
performance -X- _ O
. -X- _ O
To -X- _ O
address -X- _ O
this -X- _ O
issue -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
Past -X- _ O
- -X- _ O
Future -X- _ O
method -X- _ O
to -X- _ O
make -X- _ O
comprehensive -X- _ O
predictions -X- _ O
from -X- _ O
a -X- _ O
global -X- _ O
perspective -X- _ O
. -X- _ O
We -X- _ O
first -X- _ O
take -X- _ O
into -X- _ O
consideration -X- _ O
all -X- _ O
the -X- _ O
linguistic -X- _ O
information -X- _ O
embedded -X- _ O
in -X- _ O
the -X- _ O
past -X- _ O
layers -X- _ O
and -X- _ O
further -X- _ O
engage -X- _ O
the -X- _ O
future -X- _ O
information -X- _ O
which -X- _ O
is -X- _ O
originally -X- _ O
inaccessible -X- _ O
for -X- _ O
predictions -X- _ O
. -X- _ O
Extensive -X- _ O
experiments -X- _ O
demonstrate -X- _ O
that -X- _ O
our -X- _ O
method -X- _ O
outperforms -X- _ O
previous -X- _ O
early -X- _ B-TaskName
exit -X- _ I-TaskName
methods -X- _ O
by -X- _ O
a -X- _ O
large -X- _ O
margin -X- _ O
, -X- _ O
yielding -X- _ O
better -X- _ O
and -X- _ O
robust -X- _ O
performance -X- _ O
1 -X- _ O
. -X- _ O

Introduction -X- _ O

Pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
( -X- _ O
PLMs -X- _ O
) -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
RoBERTa -X- _ B-MethodName
and -X- _ O
XLNet -X- _ B-MethodName
( -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
have -X- _ O
obtained -X- _ O
remarkable -X- _ O
success -X- _ O
in -X- _ O
a -X- _ O
wide -X- _ O
range -X- _ O
of -X- _ O
NLP -X- _ O
tasks -X- _ O
. -X- _ O
Despite -X- _ O
their -X- _ O
impressive -X- _ O
performance -X- _ O
, -X- _ O
PLMs -X- _ O
are -X- _ O
usually -X- _ O
associated -X- _ O
with -X- _ O
large -X- _ O
memory -X- _ O
requirement -X- _ O
and -X- _ O
high -X- _ O
computational -X- _ O
cost -X- _ O
. -X- _ O
Such -X- _ O
drawbacks -X- _ O
slow -X- _ O
down -X- _ O
the -X- _ O
inference -X- _ O
and -X- _ O
further -X- _ O
encumber -X- _ O
the -X- _ O
application -X- _ O
of -X- _ O
PLMs -X- _ O
in -X- _ O
the -X- _ O
scenarios -X- _ O
where -X- _ O
inference -X- _ O
time -X- _ O
and -X- _ O
computation -X- _ O
budget -X- _ O
are -X- _ O
restricted -X- _ O
. -X- _ O

To -X- _ O
address -X- _ O
this -X- _ O
issue -X- _ O
, -X- _ O
a -X- _ O
growing -X- _ O
number -X- _ O
of -X- _ O
studies -X- _ O
focusing -X- _ O
on -X- _ O
improving -X- _ O
model -X- _ O
efficiency -X- _ O
have -X- _ O
emerged -X- _ O
recently -X- _ O
. -X- _ O
Particularly -X- _ O
, -X- _ O
Kaya -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
point -X- _ O
out -X- _ O
that -X- _ O
the -X- _ O
current -X- _ O
over -X- _ O
- -X- _ O
parameterized -X- _ O
models -X- _ O
conduct -X- _ O
excessive -X- _ O
computation -X- _ O
for -X- _ O
simple -X- _ O
instances -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
actually -X- _ O
undesirable -X- _ O
and -X- _ O
computationally -X- _ O
wasteful -X- _ O
. -X- _ O
In -X- _ O
light -X- _ O
of -X- _ O
this -X- _ O
observation -X- _ O
, -X- _ O
an -X- _ O
increasing -X- _ O
amount -X- _ O
of -X- _ O
work -X- _ O
seeks -X- _ O
various -X- _ O
early -X- _ O
exit -X- _ O
methods -X- _ O
, -X- _ O
of -X- _ O
which -X- _ O
the -X- _ O
basic -X- _ O
idea -X- _ O
is -X- _ O
to -X- _ O
exit -X- _ O
early -X- _ O
without -X- _ O
passing -X- _ O
through -X- _ O
the -X- _ O
entire -X- _ O
model -X- _ O
during -X- _ O
inference -X- _ O
. -X- _ O
Concretely -X- _ O
, -X- _ O
for -X- _ O
NLP -X- _ O
tasks -X- _ O
, -X- _ O
they -X- _ O
couple -X- _ O
branch -X- _ O
classifiers -X- _ O
with -X- _ O
each -X- _ O
layer -X- _ O
of -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
and -X- _ O
stop -X- _ O
forward -X- _ O
propagation -X- _ O
at -X- _ O
an -X- _ O
intermediate -X- _ O
layer -X- _ O
. -X- _ O
Then -X- _ O
the -X- _ O
current -X- _ O
branch -X- _ O
classifier -X- _ O
makes -X- _ O
a -X- _ O
prediction -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
token -X- _ O
that -X- _ O
is -X- _ O
used -X- _ O
as -X- _ O
the -X- _ O
aggregated -X- _ O
sequence -X- _ O
representation -X- _ O
for -X- _ O
classification -X- _ O
tasks -X- _ O
and -X- _ O
is -X- _ O
referred -X- _ O
to -X- _ O
as -X- _ O
the -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
layer -X- _ O
in -X- _ O
this -X- _ O
work -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
existing -X- _ O
work -X- _ O
on -X- _ O
early -X- _ O
exit -X- _ O
has -X- _ O
two -X- _ O
major -X- _ O
drawbacks -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
existing -X- _ O
work -X- _ O
( -X- _ O
Xin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
uses -X- _ O
only -X- _ O
local -X- _ O
states -X- _ O
in -X- _ O
the -X- _ O
early -X- _ O
exit -X- _ O
framework -X- _ O
. -X- _ O
They -X- _ O
inevitably -X- _ O
lose -X- _ O
valuable -X- _ O
features -X- _ O
that -X- _ O
are -X- _ O
captured -X- _ O
by -X- _ O
passed -X- _ O
layers -X- _ O
but -X- _ O
are -X- _ O
ignored -X- _ O
for -X- _ O
prediction -X- _ O
, -X- _ O
leading -X- _ O
to -X- _ O
less -X- _ O
reliable -X- _ O
prediction -X- _ O
results -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
these -X- _ O
methods -X- _ O
abandon -X- _ O
the -X- _ O
potentially -X- _ O
useful -X- _ O
features -X- _ O
captured -X- _ O
by -X- _ O
the -X- _ O
future -X- _ O
layers -X- _ O
that -X- _ O
have -X- _ O
not -X- _ O
been -X- _ O
passed -X- _ O
, -X- _ O
which -X- _ O
may -X- _ O
hurt -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
instances -X- _ O
requiring -X- _ O
high -X- _ O
- -X- _ O
level -X- _ O
features -X- _ O
embedded -X- _ O
in -X- _ O
the -X- _ O
deep -X- _ O
layers -X- _ O
. -X- _ O
Consequently -X- _ O
, -X- _ O
their -X- _ O
performance -X- _ O
dramatically -X- _ O
declines -X- _ O
when -X- _ O
the -X- _ O
inference -X- _ O
exits -X- _ O
earlier -X- _ O
for -X- _ O
a -X- _ O
higher -X- _ O
speed -X- _ O
- -X- _ O
up -X- _ O
ratio -X- _ O
. -X- _ O

These -X- _ O
two -X- _ O
major -X- _ O
drawbacks -X- _ O
hinder -X- _ O
the -X- _ O
progress -X- _ O
of -X- _ O
early -X- _ O
exit -X- _ O
research -X- _ O
and -X- _ O
motivate -X- _ O
us -X- _ O
to -X- _ O
develop -X- _ O
a -X- _ O
new -X- _ O
mechanism -X- _ O
using -X- _ O
the -X- _ O
hierarchical -X- _ O
linguistic -X- _ O
information -X- _ O
embedded -X- _ O
in -X- _ O
all -X- _ O
layers -X- _ O
( -X- _ O
Jawahar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
from -X- _ O
a -X- _ O
global -X- _ O
perspective -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
up -X- _ O
to -X- _ O
now -X- _ O
, -X- _ O
a -X- _ O
global -X- _ O
early -X- _ O
exit -X- _ O
mechanism -X- _ O
remains -X- _ O
a -X- _ O
under -X- _ O
- -X- _ O
explored -X- _ O
challenging -X- _ O
problem -X- _ O
. -X- _ O
We -X- _ O
extend -X- _ O
the -X- _ O
existing -X- _ O
methods -X- _ O
to -X- _ O
their -X- _ O
corresponding -X- _ O
global -X- _ O
versions -X- _ O
and -X- _ O
find -X- _ O
that -X- _ O
naive -X- _ O
global -X- _ O
strategies -X- _ O
only -X- _ O
result -X- _ O
in -X- _ O
poor -X- _ O
performance -X- _ O
. -X- _ O
Meanwhile -X- _ O
, -X- _ O
the -X- _ O
future -X- _ O
states -X- _ O
are -X- _ O
originally -X- _ O
inaccessible -X- _ O
in -X- _ O
the -X- _ O
early -X- _ O
exit -X- _ O
framework -X- _ O
, -X- _ O
which -X- _ O
also -X- _ O
remains -X- _ O
a -X- _ O
bottleneck -X- _ O
for -X- _ O
a -X- _ O
global -X- _ O
prediction -X- _ O
considering -X- _ O
both -X- _ O
past -X- _ O
and -X- _ O
future -X- _ O
states -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
focus -X- _ O
on -X- _ O
the -X- _ O
aforementioned -X- _ O
problems -X- _ O
and -X- _ O
first -X- _ O
put -X- _ O
into -X- _ O
practice -X- _ O
a -X- _ O
global -X- _ O
Past -X- _ O
- -X- _ O
Future -X- _ O
early -X- _ B-TaskName
exit -X- _ I-TaskName
mechanism -X- _ O
. -X- _ O
The -X- _ O
term -X- _ O
global -X- _ O
is -X- _ O
two -X- _ O
- -X- _ O
fold -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
instead -X- _ O
of -X- _ O
using -X- _ O
one -X- _ O
or -X- _ O
several -X- _ O
local -X- _ O
state -X- _ O
( -X- _ O
s -X- _ O
) -X- _ O
for -X- _ O
prediction -X- _ O
in -X- _ O
previous -X- _ O
work -X- _ O
, -X- _ O
all -X- _ O
the -X- _ O
available -X- _ O
past -X- _ O
states -X- _ O
are -X- _ O
effectively -X- _ O
incorporated -X- _ O
in -X- _ O
our -X- _ O
method -X- _ O
; -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
furthermore -X- _ O
, -X- _ O
to -X- _ O
grasp -X- _ O
the -X- _ O
features -X- _ O
embedded -X- _ O
in -X- _ O
the -X- _ O
deep -X- _ O
layers -X- _ O
, -X- _ O
the -X- _ O
originally -X- _ O
inaccessible -X- _ O
future -X- _ O
states -X- _ O
are -X- _ O
approximated -X- _ O
by -X- _ O
imitation -X- _ O
learning -X- _ O
and -X- _ O
are -X- _ O
also -X- _ O
engaged -X- _ O
for -X- _ O
prediction -X- _ O
. -X- _ O
The -X- _ O
comparison -X- _ O
of -X- _ O
the -X- _ O
previous -X- _ O
method -X- _ O
and -X- _ O
our -X- _ O
method -X- _ O
is -X- _ O
illustrated -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
. -X- _ O
By -X- _ O
combining -X- _ O
both -X- _ O
past -X- _ O
and -X- _ O
future -X- _ O
states -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
make -X- _ O
more -X- _ O
accurate -X- _ O
predictions -X- _ O
for -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O

Extensive -X- _ O
experiments -X- _ O
reveal -X- _ O
that -X- _ O
the -X- _ O
proposal -X- _ O
significantly -X- _ O
outperforms -X- _ O
previous -X- _ O
early -X- _ O
exit -X- _ O
methods -X- _ O
. -X- _ O
Particularly -X- _ O
, -X- _ O
it -X- _ O
surpasses -X- _ O
the -X- _ O
previous -X- _ O
methods -X- _ O
by -X- _ O
a -X- _ O
large -X- _ O
margin -X- _ O
when -X- _ O
the -X- _ O
speed -X- _ O
- -X- _ O
up -X- _ O
ratio -X- _ O
is -X- _ O
relatively -X- _ O
high -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
extensive -X- _ O
experiments -X- _ O
with -X- _ O
different -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
as -X- _ O
backbones -X- _ O
demonstrate -X- _ O
consistent -X- _ O
improvement -X- _ O
over -X- _ O
the -X- _ O
baseline -X- _ O
methods -X- _ O
, -X- _ O
which -X- _ O
verifies -X- _ O
the -X- _ O
generality -X- _ O
of -X- _ O
our -X- _ O
method -X- _ O
. -X- _ O

To -X- _ O
summarize -X- _ O
, -X- _ O
our -X- _ O
contributions -X- _ O
are -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

• -X- _ O
We -X- _ O
propose -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
global -X- _ O
strategies -X- _ O
which -X- _ O
effectively -X- _ O
incorporate -X- _ O
all -X- _ O
available -X- _ O
states -X- _ O
and -X- _ O
they -X- _ O
achieve -X- _ O
better -X- _ O
performance -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
existing -X- _ O
naive -X- _ O
global -X- _ O
strategies -X- _ O
. -X- _ O

• -X- _ O
Our -X- _ O
early -X- _ B-TaskName
exit -X- _ I-TaskName
method -X- _ O
first -X- _ O
utilizes -X- _ O
the -X- _ O
future -X- _ O
states -X- _ O
which -X- _ O
are -X- _ O
originally -X- _ O
inaccessible -X- _ O
at -X- _ O
the -X- _ O
inference -X- _ O
stage -X- _ O
, -X- _ O
enabling -X- _ O
more -X- _ O
comprehensive -X- _ O
global -X- _ O
predictions -X- _ O
. -X- _ O

• -X- _ O
Experiments -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
proposal -X- _ O
achieves -X- _ O
better -X- _ O
performance -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
previous -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
early -X- _ B-TaskName
exit -X- _ I-TaskName
methods -X- _ O
. -X- _ O

Related -X- _ O
Work -X- _ O

Large -X- _ O
- -X- _ O
scale -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
Transformer -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
architecture -X- _ O
demonstrate -X- _ O
superior -X- _ O
performance -X- _ O
in -X- _ O
various -X- _ O
NLP -X- _ O
tasks -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
impressive -X- _ O
performance -X- _ O
is -X- _ O
on -X- _ O
the -X- _ O
basis -X- _ O
of -X- _ O
massive -X- _ O
parameters -X- _ O
, -X- _ O
leading -X- _ O
to -X- _ O
large -X- _ O
memory -X- _ O
requirement -X- _ O
and -X- _ O
computational -X- _ O
cost -X- _ O
during -X- _ O
inference -X- _ O
. -X- _ O
To -X- _ O
overcome -X- _ O
this -X- _ O
bottleneck -X- _ O
, -X- _ O
increasing -X- _ O
studies -X- _ O
work -X- _ O
on -X- _ O
improving -X- _ O
the -X- _ O
efficiency -X- _ O
of -X- _ O
overparameterized -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
. -X- _ O
Knowledge -X- _ O
distillation -X- _ O
( -X- _ O
Hinton -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Turc -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Jiao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
compacts -X- _ O
the -X- _ O
model -X- _ O
architecture -X- _ O
to -X- _ O
obtain -X- _ O
a -X- _ O
smaller -X- _ O
model -X- _ O
that -X- _ O
remains -X- _ O
static -X- _ O
for -X- _ O
all -X- _ O
instances -X- _ O
at -X- _ O
the -X- _ O
inference -X- _ O
stage -X- _ O
. -X- _ O
Sanh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
focus -X- _ O
on -X- _ O
reducing -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
layers -X- _ O
since -X- _ O
their -X- _ O
investigation -X- _ O
reveals -X- _ O
variations -X- _ O
on -X- _ O
hidden -X- _ O
size -X- _ O
dimension -X- _ O
have -X- _ O
a -X- _ O
smaller -X- _ O
impact -X- _ O
on -X- _ O
computation -X- _ O
efficiency -X- _ O
. -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
learn -X- _ O
from -X- _ O
multiple -X- _ O
intermediate -X- _ O
layers -X- _ O
of -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
for -X- _ O
incremental -X- _ O
knowledge -X- _ O
extraction -X- _ O
instead -X- _ O
of -X- _ O
only -X- _ O
learning -X- _ O
from -X- _ O
the -X- _ O
last -X- _ O
hidden -X- _ O
representations -X- _ O
. -X- _ O
Further -X- _ O
, -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
design -X- _ O
elaborate -X- _ O
techniques -X- _ O
to -X- _ O
drive -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
to -X- _ O
mimic -X- _ O
the -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
module -X- _ O
of -X- _ O
teacher -X- _ O
models -X- _ O
. -X- _ O
compress -X- _ O
model -X- _ O
by -X- _ O
progressive -X- _ O
module -X- _ O
replacing -X- _ O
, -X- _ O
showing -X- _ O
a -X- _ O
new -X- _ O
perspective -X- _ O
of -X- _ O
model -X- _ O
compression -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
these -X- _ O
static -X- _ O
model -X- _ O
compression -X- _ O
methods -X- _ O
treat -X- _ O
the -X- _ O
instances -X- _ O
requiring -X- _ O
different -X- _ O
computational -X- _ O
cost -X- _ O
without -X- _ O
distinction -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
they -X- _ O
have -X- _ O
to -X- _ O
distill -X- _ O
a -X- _ O
model -X- _ O
from -X- _ O
scratch -X- _ O
to -X- _ O
meet -X- _ O
the -X- _ O
varying -X- _ O
speed -X- _ O
- -X- _ O
up -X- _ O
ratio -X- _ O
requirements -X- _ O
. -X- _ O

To -X- _ O
meet -X- _ O
different -X- _ O
constraints -X- _ O
for -X- _ O
acceleration -X- _ O
, -X- _ O
another -X- _ O
line -X- _ O
of -X- _ O
work -X- _ O
studies -X- _ O
instance -X- _ O
- -X- _ O
adaptive -X- _ O
methods -X- _ O
to -X- _ O
adjust -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
executed -X- _ O
layers -X- _ O
for -X- _ O
different -X- _ O
instances -X- _ O
. -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020b -X- _ O
) -X- _ O
select -X- _ O
models -X- _ O
in -X- _ O
different -X- _ O
sizes -X- _ O
depending -X- _ O
on -X- _ O
the -X- _ O
difficulty -X- _ O
of -X- _ O
input -X- _ O
instance -X- _ O
. -X- _ O
Besides -X- _ O
, -X- _ O
early -X- _ O
exit -X- _ O
is -X- _ O
a -X- _ O
practical -X- _ O
method -X- _ O
to -X- _ O
adaptively -X- _ O
accelerate -X- _ O
inference -X- _ O
and -X- _ O
is -X- _ O
first -X- _ O
proposed -X- _ O
for -X- _ O
computer -X- _ O
vision -X- _ O
tasks -X- _ O
( -X- _ O
Kaya -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Teerapittayanon -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
Elbayad -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
; -X- _ O
Xin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
; -X- _ O
Schwartz -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
follow -X- _ O
the -X- _ O
essential -X- _ O
idea -X- _ O
and -X- _ O
leverage -X- _ O
the -X- _ O
method -X- _ O
in -X- _ O
NLP -X- _ O
tasks -X- _ O
. -X- _ O
To -X- _ O
prevent -X- _ O
the -X- _ O
error -X- _ O
from -X- _ O
one -X- _ O
single -X- _ O
classifier -X- _ O
, -X- _ O
make -X- _ O
the -X- _ O
model -X- _ O
stop -X- _ O
inference -X- _ O
when -X- _ O
a -X- _ O
cross -X- _ O
- -X- _ O
layer -X- _ O
consistent -X- _ O
prediction -X- _ O
is -X- _ O
achieved -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
researches -X- _ O
on -X- _ O
the -X- _ O
subject -X- _ O
has -X- _ O
been -X- _ O
mostly -X- _ O
restricted -X- _ O
to -X- _ O
only -X- _ O
use -X- _ O
the -X- _ O
local -X- _ O
states -X- _ O
around -X- _ O
the -X- _ O
exit -X- _ O
layer -X- _ O
. -X- _ O

Method -X- _ O

We -X- _ O
first -X- _ O
introduce -X- _ O
the -X- _ O
strategies -X- _ O
to -X- _ O
incorporate -X- _ O
multiple -X- _ O
states -X- _ O
and -X- _ O
the -X- _ O
imitation -X- _ O
learning -X- _ O
method -X- _ O
for -X- _ O
generating -X- _ O
approximations -X- _ O
of -X- _ O
future -X- _ O
states -X- _ O
. -X- _ O
Then -X- _ O
we -X- _ O
introduce -X- _ O
the -X- _ O
merging -X- _ O
gate -X- _ O
to -X- _ O
adaptively -X- _ O
fuse -X- _ O
past -X- _ O
and -X- _ O
future -X- _ O
states -X- _ O
. -X- _ O
At -X- _ O
last -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
the -X- _ O
training -X- _ O
process -X- _ O
and -X- _ O
the -X- _ O
exit -X- _ O
condition -X- _ O
during -X- _ O
inference -X- _ O
. -X- _ O

Incorporation -X- _ O
of -X- _ O
Past -X- _ O
States -X- _ O

Existing -X- _ O
work -X- _ O
( -X- _ O
Xin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
focuses -X- _ O
on -X- _ O
making -X- _ O
exit -X- _ O
decision -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
single -X- _ O
branch -X- _ O
classifier -X- _ O
. -X- _ O
The -X- _ O
consequent -X- _ O
unreliable -X- _ O
result -X- _ O
motivates -X- _ O
the -X- _ O
recent -X- _ O
advance -X- _ O
that -X- _ O
uses -X- _ O
consecutive -X- _ O
states -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
accuracy -X- _ O
and -X- _ O
robustness -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
prediction -X- _ O
is -X- _ O
still -X- _ O
limited -X- _ O
to -X- _ O
use -X- _ O
several -X- _ O
local -X- _ O
states -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
we -X- _ O
investigate -X- _ O
how -X- _ O
to -X- _ O
incorporate -X- _ O
all -X- _ O
the -X- _ O
past -X- _ O
states -X- _ O
from -X- _ O
a -X- _ O
global -X- _ O
perspective -X- _ O
. -X- _ O
The -X- _ O
existing -X- _ O
strategy -X- _ O
using -X- _ O
consecutive -X- _ O
consistent -X- _ O
prediction -X- _ O
labels -X- _ O
can -X- _ O
be -X- _ O
easily -X- _ O
extended -X- _ O
to -X- _ O
a -X- _ O
global -X- _ O
version -X- _ O
that -X- _ O
counts -X- _ O
the -X- _ O
majority -X- _ O
of -X- _ O
the -X- _ O
predicted -X- _ O
labels -X- _ O
which -X- _ O
is -X- _ O
regarded -X- _ O
as -X- _ O
a -X- _ O
voting -X- _ O
strategy -X- _ O
. -X- _ O
Another -X- _ O
alternative -X- _ O
is -X- _ O
the -X- _ O
commonly -X- _ O
- -X- _ O
used -X- _ O
ensemble -X- _ O
strategy -X- _ O
that -X- _ O
averages -X- _ O
the -X- _ O
output -X- _ O
probabilities -X- _ O
for -X- _ O
prediction -X- _ O
. -X- _ O
Besides -X- _ O
these -X- _ O
naive -X- _ O
solutions -X- _ O
, -X- _ O
we -X- _ O
explore -X- _ O
the -X- _ O
following -X- _ O
strategies -X- _ O
to -X- _ O
integrate -X- _ O
multiple -X- _ O
states -X- _ O
into -X- _ O
a -X- _ O
single -X- _ O
one -X- _ O
: -X- _ O

• -X- _ O
Max -X- _ O
- -X- _ O
Pooling -X- _ O
: -X- _ O
The -X- _ O
max -X- _ O
- -X- _ O
pooling -X- _ O
operation -X- _ O
is -X- _ O
performed -X- _ O
on -X- _ O
all -X- _ O
available -X- _ O
states -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
the -X- _ O
integrated -X- _ O
state -X- _ O
. -X- _ O

• -X- _ O
Avg -X- _ O
- -X- _ O
Pooling -X- _ O
: -X- _ O
The -X- _ O
average -X- _ O
- -X- _ O
pooling -X- _ O
operation -X- _ O
is -X- _ O
performed -X- _ O
on -X- _ O
all -X- _ O
available -X- _ O
states -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
the -X- _ O
integrated -X- _ O
state -X- _ O
. -X- _ O

• -X- _ O
Attn -X- _ O
- -X- _ O
Pooling -X- _ O
: -X- _ O
The -X- _ O
attentive -X- _ O
- -X- _ O
pooling -X- _ O
takes -X- _ O
the -X- _ O
weighted -X- _ O
summation -X- _ O
of -X- _ O
all -X- _ O
available -X- _ O
states -X- _ O
as -X- _ O
the -X- _ O
integrated -X- _ O
state -X- _ O
. -X- _ O
The -X- _ O
attention -X- _ O
weights -X- _ O
are -X- _ O
computed -X- _ O
with -X- _ O
the -X- _ O
last -X- _ O
state -X- _ O
as -X- _ O
the -X- _ O
query -X- _ O
. -X- _ O

• -X- _ O
Concatenation -X- _ O
: -X- _ O
All -X- _ O
available -X- _ O
states -X- _ O
are -X- _ O
concatenated -X- _ O
and -X- _ O
then -X- _ O
fed -X- _ O
into -X- _ O
a -X- _ O
linear -X- _ O
transformation -X- _ O
layer -X- _ O
to -X- _ O
obtain -X- _ O
the -X- _ O
compressed -X- _ O
state -X- _ O
. -X- _ O

• -X- _ O
Sequential -X- _ O
Neural -X- _ O
Network -X- _ O
: -X- _ O
All -X- _ O
available -X- _ O
states -X- _ O
are -X- _ O
sequentially -X- _ O
fed -X- _ O
into -X- _ O
an -X- _ O
LSTM -X- _ O
and -X- _ O
the -X- _ O
hidden -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
last -X- _ O
time -X- _ O
- -X- _ O
step -X- _ O
is -X- _ O
regarded -X- _ O
as -X- _ O
the -X- _ O
integrated -X- _ O
state -X- _ O
. -X- _ O

Formally -X- _ O
, -X- _ O
the -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
layer -X- _ O
is -X- _ O
denoted -X- _ O
as -X- _ O
s -X- _ O
i -X- _ O
. -X- _ O
When -X- _ O
forward -X- _ O
propagation -X- _ O
proceeds -X- _ O
to -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
intermediate -X- _ O
layer -X- _ O
, -X- _ O
all -X- _ O
the -X- _ O
past -X- _ O
states -X- _ O
s -X- _ O
1 -X- _ O
: -X- _ O
i -X- _ O
are -X- _ O
incorporated -X- _ O
into -X- _ O
a -X- _ O
global -X- _ O
past -X- _ O
state -X- _ O
s -X- _ O
p -X- _ O
: -X- _ O

s -X- _ O
p -X- _ O
= -X- _ O
G -X- _ O
( -X- _ O
s -X- _ O
1 -X- _ O
: -X- _ O
i -X- _ O
) -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O

where -X- _ O
G -X- _ O
( -X- _ O
• -X- _ O
) -X- _ O
refers -X- _ O
to -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
state -X- _ O
incorporation -X- _ O
strategies -X- _ O
. -X- _ O

Imitation -X- _ O
of -X- _ O
Future -X- _ O
States -X- _ O

Existing -X- _ O
work -X- _ O
for -X- _ O
early -X- _ B-TaskName
exit -X- _ I-TaskName
stops -X- _ O
inference -X- _ O
at -X- _ O
an -X- _ O
intermediate -X- _ O
layer -X- _ O
and -X- _ O
ignores -X- _ O
the -X- _ O
underlying -X- _ O
valuable -X- _ O
features -X- _ O
captured -X- _ O
by -X- _ O
the -X- _ O
future -X- _ O
layers -X- _ O
. -X- _ O
Such -X- _ O
treatment -X- _ O
is -X- _ O
partly -X- _ O
rationalized -X- _ O
by -X- _ O
the -X- _ O
recent -X- _ O
claim -X- _ O
( -X- _ O
Kaya -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
that -X- _ O
shallow -X- _ O
layers -X- _ O
are -X- _ O
adequate -X- _ O
to -X- _ O
make -X- _ O
a -X- _ O
correct -X- _ O
prediction -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
Jawahar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
reveal -X- _ O
that -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
capture -X- _ O
a -X- _ O
hierarchy -X- _ O
of -X- _ O
linguistic -X- _ O
information -X- _ O
from -X- _ O
the -X- _ O
lower -X- _ O
to -X- _ O
the -X- _ O
upper -X- _ O
layers -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
the -X- _ O
lower -X- _ O
layers -X- _ O
learn -X- _ O
the -X- _ O
surface -X- _ O
or -X- _ O
syntactic -X- _ O
features -X- _ O
while -X- _ O
the -X- _ O
upper -X- _ O
layers -X- _ O
capture -X- _ O
high -X- _ O
- -X- _ O
level -X- _ O
information -X- _ O
like -X- _ O
the -X- _ O
semantic -X- _ O
features -X- _ O
. -X- _ O
We -X- _ O
hypothesize -X- _ O
that -X- _ O
some -X- _ O
instances -X- _ O
not -X- _ O
only -X- _ O
rely -X- _ O
on -X- _ O
syntactic -X- _ O
features -X- _ O
but -X- _ O
also -X- _ O
require -X- _ O
semantic -X- _ O
features -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
actually -X- _ O
undesirable -X- _ O
to -X- _ O
only -X- _ O
consider -X- _ O
features -X- _ O
captured -X- _ O
by -X- _ O
shallow -X- _ O
layers -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
take -X- _ O
advantage -X- _ O
of -X- _ O
both -X- _ O
past -X- _ O
and -X- _ O
future -X- _ O
states -X- _ O
. -X- _ O
Normally -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
directly -X- _ O
fetch -X- _ O
the -X- _ O
past -X- _ O
states -X- _ O
, -X- _ O
while -X- _ O
using -X- _ O
future -X- _ O
information -X- _ O
is -X- _ O
intractable -X- _ O
how -X- _ O
since -X- _ O
the -X- _ O
future -X- _ O
states -X- _ O
are -X- _ O
inaccessible -X- _ O
before -X- _ O
passing -X- _ O
through -X- _ O
the -X- _ O
future -X- _ O
layers -X- _ O
. -X- _ O
To -X- _ O
bridge -X- _ O
this -X- _ O
gap -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
simple -X- _ O
method -X- _ O
to -X- _ O
approximate -X- _ O
the -X- _ O
future -X- _ O
states -X- _ O
in -X- _ O
light -X- _ O
of -X- _ O
imitation -X- _ O
learning -X- _ O
( -X- _ O
Ross -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011 -X- _ O
; -X- _ O
Nguyen -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Ho -X- _ O
and -X- _ O
Ermon -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
couple -X- _ O
each -X- _ O
layer -X- _ O
with -X- _ O
an -X- _ O
imitation -X- _ O
learner -X- _ O
. -X- _ O
During -X- _ O
training -X- _ O
, -X- _ O
the -X- _ O
imitation -X- _ O
learner -X- _ O
is -X- _ O
encouraged -X- _ O
to -X- _ O
mimic -X- _ O
the -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
real -X- _ O
state -X- _ O
of -X- _ O
that -X- _ O
layer -X- _ O
. -X- _ O
Through -X- _ O
this -X- _ O
layer -X- _ O
- -X- _ O
wise -X- _ O
imitation -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
obtain -X- _ O
approximations -X- _ O
of -X- _ O
the -X- _ O
future -X- _ O
states -X- _ O
with -X- _ O
minimum -X- _ O
cost -X- _ O
. -X- _ O
The -X- _ O
illustration -X- _ O
of -X- _ O
the -X- _ O
future -X- _ O
imitation -X- _ O
learning -X- _ O
during -X- _ O
inference -X- _ O
is -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
. -X- _ O

To -X- _ O
be -X- _ O
precise -X- _ O
, -X- _ O
we -X- _ O
intend -X- _ O
to -X- _ O
obtain -X- _ O
a -X- _ O
state -X- _ O
approximation -X- _ O
of -X- _ O
the -X- _ O
j -X- _ O
- -X- _ O
th -X- _ O
layer -X- _ O
if -X- _ O
the -X- _ O
forward -X- _ O
pass -X- _ O
exits -X- _ O
at -X- _ O
the -X- _ O
intermediate -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
layer -X- _ O
for -X- _ O
any -X- _ O
j -X- _ O
> -X- _ O
i. -X- _ O
During -X- _ O
training -X- _ O
, -X- _ O
we -X- _ O
pass -X- _ O
through -X- _ O
the -X- _ O
entire -X- _ O
n -X- _ O
- -X- _ O
layer -X- _ O
model -X- _ O
but -X- _ O
we -X- _ O
simulate -X- _ O
the -X- _ O
situation -X- _ O
that -X- _ O
the -X- _ O
forward -X- _ O
pass -X- _ O
ends -X- _ O
up -X- _ O
at -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
layer -X- _ O
for -X- _ O
any -X- _ O
i -X- _ O
< -X- _ O
n. -X- _ O
The -X- _ O
j -X- _ O
- -X- _ O
th -X- _ O
learner -X- _ O
corresponding -X- _ O
to -X- _ O
the -X- _ O
j -X- _ O
- -X- _ O
th -X- _ O
layer -X- _ O
takes -X- _ O
s -X- _ O
i -X- _ O
as -X- _ O
input -X- _ O
and -X- _ O
outputs -X- _ O
an -X- _ O
approximationŝ -X- _ O
i -X- _ O
j -X- _ O
of -X- _ O
the -X- _ O
real -X- _ O
state -X- _ O
s -X- _ O
j -X- _ O
. -X- _ O
Then -X- _ O
s -X- _ O
j -X- _ O
serves -X- _ O
as -X- _ O
a -X- _ O
teacher -X- _ O
to -X- _ O
guide -X- _ O
the -X- _ O
jth -X- _ O
imitation -X- _ O
learner -X- _ O
. -X- _ O
We -X- _ O
adopt -X- _ O
cosine -X- _ O
similarity -X- _ O
as -X- _ O
the -X- _ O
distance -X- _ O
measurement -X- _ O
and -X- _ O
penalize -X- _ O
the -X- _ O
discrepancy -X- _ O
between -X- _ O
the -X- _ O
real -X- _ O
state -X- _ O
s -X- _ O
j -X- _ O
and -X- _ O
the -X- _ O
learned -X- _ O
statê -X- _ O
s -X- _ O
i -X- _ O
j -X- _ O
. -X- _ O
Let -X- _ O
L -X- _ O
i -X- _ O
cos -X- _ O
denotes -X- _ O
the -X- _ O
imitation -X- _ O
loss -X- _ O
of -X- _ O
the -X- _ O
situation -X- _ O
that -X- _ O
the -X- _ O
forward -X- _ O
pass -X- _ O
exits -X- _ O
at -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
layer -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
computed -X- _ O
as -X- _ O
the -X- _ O
average -X- _ O
of -X- _ O
the -X- _ O
similarity -X- _ O
loss -X- _ O
for -X- _ O
any -X- _ O
j -X- _ O
> -X- _ O
i. -X- _ O
Since -X- _ O
the -X- _ O
exit -X- _ O
layer -X- _ O
i -X- _ O
can -X- _ O
be -X- _ O
any -X- _ O
number -X- _ O
between -X- _ O
2 -X- _ O
to -X- _ O
n -X- _ O
during -X- _ O
inference -X- _ O
, -X- _ O
we -X- _ O
go -X- _ O
through -X- _ O
all -X- _ O
possible -X- _ O
number -X- _ O
i -X- _ O
and -X- _ O
average -X- _ O
the -X- _ O
corresponding -X- _ O
L -X- _ O
i -X- _ O
cos -X- _ O
, -X- _ O
resulting -X- _ O
the -X- _ O
overall -X- _ O
loss -X- _ O
L -X- _ O
cos -X- _ O
: -X- _ O

s -X- _ O
i -X- _ O
j -X- _ O
= -X- _ O
Learner -X- _ O
j -X- _ O
( -X- _ O
s -X- _ O
i -X- _ O
) -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
l -X- _ O
i -X- _ O
, -X- _ O
j -X- _ O
cos -X- _ O
( -X- _ O
s -X- _ O
j -X- _ O
, -X- _ O
ŝ -X- _ O
i -X- _ O
j -X- _ O
) -X- _ O
= -X- _ O
1 -X- _ O
−ŝ -X- _ O
i -X- _ O
j -X- _ O
• -X- _ O
s -X- _ O
j -X- _ O
ŝ -X- _ O
i -X- _ O
j -X- _ O
s -X- _ O
j -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
L -X- _ O
i -X- _ O
cos -X- _ O
= -X- _ O
1 -X- _ O
n -X- _ O
− -X- _ O
i -X- _ O
n -X- _ O
j -X- _ O
= -X- _ O
i+1 -X- _ O
l -X- _ O
i -X- _ O
, -X- _ O
j -X- _ O
cos -X- _ O
( -X- _ O
s -X- _ O
j -X- _ O
, -X- _ O
ŝ -X- _ O
i -X- _ O
j -X- _ O
) -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
L -X- _ O
cos -X- _ O
= -X- _ O
1 -X- _ O
n -X- _ O
− -X- _ O
1 -X- _ O
n -X- _ O
i=2 -X- _ O
L -X- _ O
i -X- _ O
cos -X- _ O
( -X- _ O
5 -X- _ O
) -X- _ O

where -X- _ O
• -X- _ O
denotes -X- _ O
the -X- _ O
L -X- _ O
2 -X- _ O
norm -X- _ O
. -X- _ O
Learner -X- _ O
j -X- _ O
( -X- _ O
• -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
simple -X- _ O
feed -X- _ O
- -X- _ O
forward -X- _ O
layer -X- _ O
with -X- _ O
learnable -X- _ O
parameters -X- _ O
W -X- _ O
i -X- _ O
and -X- _ O
b -X- _ O
i -X- _ O
. -X- _ O

During -X- _ O
training -X- _ O
, -X- _ O
the -X- _ O
forward -X- _ O
propagation -X- _ O
is -X- _ O
computed -X- _ O
on -X- _ O
all -X- _ O
layers -X- _ O
and -X- _ O
all -X- _ O
imitation -X- _ O
learners -X- _ O
are -X- _ O
encouraged -X- _ O
to -X- _ O
generate -X- _ O
representations -X- _ O
close -X- _ O
to -X- _ O
the -X- _ O
real -X- _ O
states -X- _ O
. -X- _ O
During -X- _ O
inference -X- _ O
, -X- _ O
the -X- _ O
forward -X- _ O
propagation -X- _ O
proceeds -X- _ O
to -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
intermediate -X- _ O
layer -X- _ O
and -X- _ O
the -X- _ O
subsequent -X- _ O
imitation -X- _ O
learners -X- _ O
take -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
real -X- _ O
state -X- _ O
as -X- _ O
input -X- _ O
to -X- _ O
generate -X- _ O
the -X- _ O
approximations -X- _ O
of -X- _ O
future -X- _ O
states -X- _ O
. -X- _ O
Then -X- _ O
the -X- _ O
approximations -X- _ O
are -X- _ O
incorporated -X- _ O
into -X- _ O
a -X- _ O
comprehensive -X- _ O
future -X- _ O
state -X- _ O
s -X- _ O
f -X- _ O
with -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
global -X- _ O
strategies -X- _ O
introduced -X- _ O
before -X- _ O
: -X- _ O

s -X- _ O
f -X- _ O
= -X- _ O
G -X- _ O
( -X- _ O
ŝ -X- _ O
i -X- _ O
i+1 -X- _ O
: -X- _ O
n -X- _ O
) -X- _ O
( -X- _ O
6 -X- _ O
) -X- _ O

whereŝ -X- _ O
i -X- _ O
i+1 -X- _ O
: -X- _ O
n -X- _ O
denotes -X- _ O
the -X- _ O
approximations -X- _ O
of -X- _ O
the -X- _ O
states -X- _ O
from -X- _ O
the -X- _ O
( -X- _ O
i+1 -X- _ O
) -X- _ O
-th -X- _ O
layer -X- _ O
to -X- _ O
the -X- _ O
n -X- _ O
- -X- _ O
th -X- _ O
layer -X- _ O
. -X- _ O

Adaptive -X- _ O
Merging -X- _ O
Gate -X- _ O

We -X- _ O
then -X- _ O
explore -X- _ O
how -X- _ O
to -X- _ O
adaptively -X- _ O
merge -X- _ O
the -X- _ O
past -X- _ O
information -X- _ O
and -X- _ O
future -X- _ O
information -X- _ O
. -X- _ O
Intuitively -X- _ O
, -X- _ O
the -X- _ O
past -X- _ O
state -X- _ O
s -X- _ O
p -X- _ O
and -X- _ O
the -X- _ O
future -X- _ O
state -X- _ O
s -X- _ O
f -X- _ O
are -X- _ O
of -X- _ O
different -X- _ O
importance -X- _ O
since -X- _ O
the -X- _ O
authentic -X- _ O
past -X- _ O
states -X- _ O
are -X- _ O
more -X- _ O
reliable -X- _ O
than -X- _ O
our -X- _ O
imitated -X- _ O
future -X- _ O
states -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
different -X- _ O
instances -X- _ O
depend -X- _ O
differently -X- _ O
on -X- _ O
high -X- _ O
- -X- _ O
level -X- _ O
features -X- _ O
learned -X- _ O
by -X- _ O
future -X- _ O
layers -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
indispensable -X- _ O
to -X- _ O
develop -X- _ O
an -X- _ O
adaptive -X- _ O
method -X- _ O
to -X- _ O
automatically -X- _ O
combine -X- _ O
the -X- _ O
past -X- _ O
state -X- _ O
s -X- _ O
p -X- _ O
and -X- _ O
the -X- _ O
future -X- _ O
state -X- _ O
s -X- _ O
f -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
design -X- _ O
an -X- _ O
adaptive -X- _ O
merging -X- _ O
gate -X- _ O
to -X- _ O
automatically -X- _ O
fuse -X- _ O
the -X- _ O
past -X- _ O
state -X- _ O
s -X- _ O
p -X- _ O
and -X- _ O
the -X- _ O
future -X- _ O
state -X- _ O
s -X- _ O
f -X- _ O
. -X- _ O
As -X- _ O
the -X- _ O
forward -X- _ O
propagation -X- _ O
proceeds -X- _ O
to -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
layer -X- _ O
, -X- _ O
we -X- _ O
compute -X- _ O
the -X- _ O
reliability -X- _ O
of -X- _ O
the -X- _ O
past -X- _ O
state -X- _ O
s -X- _ O
p -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
final -X- _ O
merged -X- _ O
representation -X- _ O
is -X- _ O
a -X- _ O
trade -X- _ O
- -X- _ O
off -X- _ O
between -X- _ O
these -X- _ O
two -X- _ O
states -X- _ O
: -X- _ O

α -X- _ O
= -X- _ O
sigmoid -X- _ O
( -X- _ O
FFN -X- _ O
( -X- _ O
s -X- _ O
p -X- _ O
) -X- _ O
) -X- _ O
( -X- _ O
7 -X- _ O
) -X- _ O

z -X- _ O
i -X- _ O
= -X- _ O
αs -X- _ O
p -X- _ O
+ -X- _ O
( -X- _ O
1 -X- _ O
− -X- _ O
α -X- _ O
) -X- _ O
s -X- _ O
f -X- _ O
( -X- _ O
8 -X- _ O
) -X- _ O

During -X- _ O
training -X- _ O
, -X- _ O
each -X- _ O
layer -X- _ O
can -X- _ O
generate -X- _ O
the -X- _ O
approximated -X- _ O
states -X- _ O
of -X- _ O
future -X- _ O
and -X- _ O
obtain -X- _ O
a -X- _ O
merged -X- _ O
final -X- _ O
state -X- _ O
which -X- _ O
is -X- _ O
used -X- _ O
for -X- _ O
prediction -X- _ O
. -X- _ O
Then -X- _ O
the -X- _ O
model -X- _ O
will -X- _ O
be -X- _ O
updated -X- _ O
with -X- _ O
the -X- _ O
layer -X- _ O
- -X- _ O
wise -X- _ O
crossentropy -X- _ O
loss -X- _ O
against -X- _ O
the -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
label -X- _ O
y. -X- _ O
The -X- _ O
merging -X- _ O
gate -X- _ O
adaptively -X- _ O
learns -X- _ O
to -X- _ O
adjust -X- _ O
the -X- _ O
balance -X- _ O
under -X- _ O
the -X- _ O
supervision -X- _ O
signal -X- _ O
given -X- _ O
by -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
labels -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
layer -X- _ O
- -X- _ O
wise -X- _ O
optimization -X- _ O
objectives -X- _ O
, -X- _ O
the -X- _ O
shallow -X- _ O
layers -X- _ O
will -X- _ O
be -X- _ O
updated -X- _ O
more -X- _ O
frequently -X- _ O
since -X- _ O
they -X- _ O
receive -X- _ O
more -X- _ O
updating -X- _ O
signals -X- _ O
from -X- _ O
higher -X- _ O
layers -X- _ O
. -X- _ O
To -X- _ O
address -X- _ O
this -X- _ O
issue -X- _ O
, -X- _ O
we -X- _ O
heuristically -X- _ O
re -X- _ O
- -X- _ O
weight -X- _ O
the -X- _ O
cross -X- _ O
entropy -X- _ O
loss -X- _ O
of -X- _ O
each -X- _ O
layer -X- _ O
depending -X- _ O
on -X- _ O
its -X- _ O
depth -X- _ O
i -X- _ O
and -X- _ O
get -X- _ O
its -X- _ O
weight -X- _ O
w -X- _ O
i -X- _ O
. -X- _ O
The -X- _ O
updating -X- _ O
procedure -X- _ O
is -X- _ O
formalized -X- _ O
as -X- _ O
: -X- _ O

w -X- _ O
i -X- _ O
= -X- _ O
i -X- _ O
n -X- _ O
j=1 -X- _ O
j -X- _ O
( -X- _ O
9 -X- _ O
) -X- _ O
p -X- _ O
i -X- _ O
= -X- _ O
softmax -X- _ O
( -X- _ O
z -X- _ O
i -X- _ O
) -X- _ O
( -X- _ O
10 -X- _ O
) -X- _ O

L -X- _ O
i -X- _ O
ce -X- _ O
= -X- _ O
− -X- _ O
l∈labels -X- _ O
y -X- _ O
( -X- _ O
l -X- _ O
) -X- _ O
log -X- _ O
( -X- _ O
p -X- _ O
i -X- _ O
( -X- _ O
l -X- _ O
) -X- _ O
) -X- _ O
( -X- _ O
11 -X- _ O
) -X- _ O

L -X- _ O
ce -X- _ O
= -X- _ O
n -X- _ O
i=1 -X- _ O
w -X- _ O
i -X- _ O
L -X- _ O
i -X- _ O
ce -X- _ O
( -X- _ O
12 -X- _ O
) -X- _ O

The -X- _ O
overall -X- _ O
loss -X- _ B-HyperparameterName
is -X- _ O
computed -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

L -X- _ O
= -X- _ O
L -X- _ O
ce -X- _ O
+ -X- _ O
L -X- _ O
cos -X- _ O
( -X- _ O
13 -X- _ O
) -X- _ O

Fine -X- _ O
- -X- _ O
tuning -X- _ O
and -X- _ O
Inference -X- _ O

Here -X- _ O
we -X- _ O
introduce -X- _ O
the -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
technique -X- _ O
and -X- _ O
the -X- _ O
exit -X- _ O
condition -X- _ O
at -X- _ O
the -X- _ O
inference -X- _ O
stage -X- _ O
. -X- _ O

Fine -X- _ O
- -X- _ O
tuning -X- _ O
The -X- _ O
representations -X- _ O
learned -X- _ O
by -X- _ O
shallow -X- _ O
layers -X- _ O
have -X- _ O
a -X- _ O
big -X- _ O
impact -X- _ O
on -X- _ O
performance -X- _ O
in -X- _ O
the -X- _ O
early -X- _ O
exit -X- _ O
framework -X- _ O
since -X- _ O
the -X- _ O
prediction -X- _ O
largely -X- _ O
depends -X- _ O
on -X- _ O
the -X- _ O
states -X- _ O
of -X- _ O
shallow -X- _ O
layers -X- _ O
. -X- _ O
Most -X- _ O
existing -X- _ O
work -X- _ O
updates -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
layers -X- _ O
at -X- _ O
each -X- _ O
step -X- _ O
during -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
to -X- _ O
adapt -X- _ O
to -X- _ O
the -X- _ O
data -X- _ O
of -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
we -X- _ O
argue -X- _ O
that -X- _ O
such -X- _ O
an -X- _ O
aggressive -X- _ O
updating -X- _ O
strategy -X- _ O
may -X- _ O
undermine -X- _ O
the -X- _ O
well -X- _ O
- -X- _ O
generalized -X- _ O
features -X- _ O
learned -X- _ O
in -X- _ O
the -X- _ O
pretraining -X- _ O
stage -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
try -X- _ O
to -X- _ O
balance -X- _ O
the -X- _ O
requirements -X- _ O
of -X- _ O
maintaining -X- _ O
features -X- _ O
learned -X- _ O
in -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
and -X- _ O
adapting -X- _ O
to -X- _ O
data -X- _ O
at -X- _ O
the -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
stage -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
the -X- _ O
parameters -X- _ O
of -X- _ O
a -X- _ O
layer -X- _ O
will -X- _ O
be -X- _ O
frozen -X- _ O
with -X- _ O
a -X- _ O
probability -X- _ O
p -X- _ O
and -X- _ O
the -X- _ O
probability -X- _ O
p -X- _ O
linearly -X- _ O
decreases -X- _ O
from -X- _ O
the -X- _ O
first -X- _ O
layer -X- _ O
to -X- _ O
the -X- _ O
L -X- _ O
- -X- _ O
th -X- _ O
layer -X- _ O
in -X- _ O
a -X- _ O
range -X- _ O
of -X- _ O
1 -X- _ O
to -X- _ O
0 -X- _ O
. -X- _ O

Inference -X- _ O
Following -X- _ O
Xin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
quantify -X- _ O
the -X- _ O
prediction -X- _ O
confidence -X- _ O
e -X- _ O
with -X- _ O
the -X- _ O
entropy -X- _ O
of -X- _ O
the -X- _ O
output -X- _ O
distribution -X- _ O
p -X- _ O
i -X- _ O
of -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
layer -X- _ O
: -X- _ O

e -X- _ O
( -X- _ O
p -X- _ O
i -X- _ O
) -X- _ O
= -X- _ O
Entropy -X- _ O
( -X- _ O
p -X- _ O
i -X- _ O
) -X- _ O
( -X- _ O
14 -X- _ O
) -X- _ O

The -X- _ O
inference -X- _ O
stops -X- _ O
once -X- _ O
the -X- _ O
confidence -X- _ O
e -X- _ O
( -X- _ O
p -X- _ O
i -X- _ O
) -X- _ O
is -X- _ O
lower -X- _ O
than -X- _ O
a -X- _ O
predefined -X- _ O
threshold -X- _ B-HyperparameterName
τ -X- _ B-HyperparameterName
. -X- _ O
The -X- _ O
hyperparameter -X- _ O
τ -X- _ B-HyperparameterName
is -X- _ O
adjusted -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
required -X- _ O
speed -X- _ O
- -X- _ O
up -X- _ O
ratios -X- _ O
. -X- _ O
If -X- _ O
the -X- _ O
exit -X- _ O
condition -X- _ O
is -X- _ O
never -X- _ O
reached -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
degrades -X- _ O
into -X- _ O
the -X- _ O
common -X- _ O
case -X- _ O
of -X- _ O
inference -X- _ O
that -X- _ O
the -X- _ O
complete -X- _ O
forward -X- _ O
propagation -X- _ O
is -X- _ O
accomplished -X- _ O
. -X- _ O

Experiments -X- _ O

Experimental -X- _ O
Setup -X- _ O

Experimental -X- _ O
Settings -X- _ O
Following -X- _ O
previous -X- _ O
work -X- _ O
( -X- _ O
Xin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
our -X- _ O
proposed -X- _ O
method -X- _ O
on -X- _ O
six -X- _ O
classification -X- _ O
datasets -X- _ O
from -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
benchmark -X- _ O
: -X- _ O
SST-2 -X- _ B-DatasetName
, -X- _ O
MRPC -X- _ B-DatasetName
, -X- _ O
QNLI -X- _ B-DatasetName
, -X- _ O
RTE -X- _ B-DatasetName
, -X- _ O
QQP -X- _ B-DatasetName
, -X- _ O
and -X- _ O
MNLI -X- _ B-DatasetName
. -X- _ O
We -X- _ O
perform -X- _ O
a -X- _ O
grid -X- _ O
search -X- _ O
over -X- _ O
the -X- _ O
sets -X- _ O
of -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
as -X- _ O
{ -X- _ O
1e-5 -X- _ B-HyperparameterValue
, -X- _ O
2e-5 -X- _ B-HyperparameterValue
, -X- _ O
3e-5 -X- _ B-HyperparameterValue
, -X- _ O
5e-5 -X- _ B-HyperparameterValue
} -X- _ O
, -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
as -X- _ O
{ -X- _ O
16 -X- _ B-HyperparameterValue
, -X- _ O
32 -X- _ B-HyperparameterValue
, -X- _ O
128 -X- _ B-HyperparameterValue
} -X- _ O
and -X- _ O
number -X- _ O
of -X- _ O
frozen -X- _ B-HyperparameterName
layers -X- _ I-HyperparameterName
during -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
as -X- _ O
{ -X- _ O
0,1,2,3 -X- _ B-HyperparameterValue
} -X- _ O
. -X- _ O
The -X- _ O
maximum -X- _ O
sequence -X- _ B-HyperparameterName
length -X- _ I-HyperparameterName
is -X- _ O
fixed -X- _ O
to -X- _ O
128 -X- _ B-HyperparameterValue
. -X- _ O
We -X- _ O
employ -X- _ O
a -X- _ O
linear -X- _ O
decay -X- _ O
learning -X- _ O
rate -X- _ O
scheduler -X- _ O
and -X- _ O
the -X- _ O
AdamW -X- _ O
optimizer -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
concatenation -X- _ O
strategy -X- _ O
to -X- _ O
incorporate -X- _ O
all -X- _ O
available -X- _ O
states -X- _ O
for -X- _ O
its -X- _ O
best -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
dev -X- _ O
set -X- _ O
. -X- _ O

Speed -X- _ O
Measurement -X- _ O
Since -X- _ O
the -X- _ O
measurement -X- _ O
of -X- _ O
runtime -X- _ O
might -X- _ O
not -X- _ O
be -X- _ O
stable -X- _ O
, -X- _ O
following -X- _ O
Xin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
; -X- _ O
, -X- _ O
we -X- _ O
manually -X- _ O
adjust -X- _ O
the -X- _ O
exit -X- _ O
threshold -X- _ O
τ -X- _ B-HyperparameterName
and -X- _ O
calculate -X- _ O
the -X- _ O
speed -X- _ O
- -X- _ O
up -X- _ O
ratio -X- _ O
by -X- _ O
comparing -X- _ O
the -X- _ O
actually -X- _ O
executed -X- _ O
layers -X- _ O
in -X- _ O
forward -X- _ O
propagation -X- _ O
and -X- _ O
the -X- _ O
required -X- _ O
complete -X- _ O
layers -X- _ O
. -X- _ O
For -X- _ O
a -X- _ O
n -X- _ O
- -X- _ O
layer -X- _ B-HyperparameterName
model -X- _ O
, -X- _ O
the -X- _ O
speed -X- _ O
- -X- _ O
up -X- _ O
ratio -X- _ O
is -X- _ O
: -X- _ O

speed -X- _ O
- -X- _ O
up -X- _ O
ratio -X- _ O
= -X- _ O
n -X- _ O
i=1 -X- _ O
n -X- _ O
* -X- _ O
m -X- _ O
i -X- _ O
n -X- _ O
i=1 -X- _ O
i -X- _ O
* -X- _ O
m -X- _ O
i -X- _ O
( -X- _ O
15 -X- _ O
) -X- _ O

where -X- _ O
m -X- _ O
i -X- _ O
is -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
examples -X- _ O
that -X- _ O
exit -X- _ O
at -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
layer -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O

Baselines -X- _ O

The -X- _ O
proposed -X- _ O
method -X- _ O
can -X- _ O
be -X- _ O
practical -X- _ O
for -X- _ O
a -X- _ O
range -X- _ O
of -X- _ O
existing -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
. -X- _ O
Without -X- _ O
losing -X- _ O
generality -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
experiments -X- _ O
with -X- _ O
several -X- _ O
well -X- _ O
- -X- _ O
known -X- _ O
PLMs -X- _ O
as -X- _ O
backbones -X- _ O
, -X- _ O
namely -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
RoBERTa -X- _ B-MethodName
, -X- _ O
and -X- _ O
ALBERT -X- _ B-MethodName
( -X- _ O
Lan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Both -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
RoBERTa -X- _ B-MethodName
suffer -X- _ O
from -X- _ O
the -X- _ O
problem -X- _ O
of -X- _ O
over -X- _ O
- -X- _ O
parameterization -X- _ O
. -X- _ O
ALBERT -X- _ B-MethodName
largely -X- _ O
alleviates -X- _ O
this -X- _ O
problem -X- _ O
and -X- _ O
is -X- _ O
very -X- _ O
efficient -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
model -X- _ O
size -X- _ O
, -X- _ O
the -X- _ O
results -X- _ O
on -X- _ O
which -X- _ O
verify -X- _ O
the -X- _ O
effectiveness -X- _ O
on -X- _ O
such -X- _ O
parameter -X- _ O
- -X- _ O
efficient -X- _ O
models -X- _ O
. -X- _ O
We -X- _ O
mainly -X- _ O
compare -X- _ O
our -X- _ O
method -X- _ O
with -X- _ O
other -X- _ O
methods -X- _ O
targeting -X- _ O
on -X- _ O
reducing -X- _ O
the -X- _ O
depth -X- _ O
of -X- _ O
models -X- _ O
, -X- _ O
including -X- _ O
the -X- _ O
recent -X- _ O
early -X- _ O
exit -X- _ O
methods -X- _ O
and -X- _ O
the -X- _ O
method -X- _ O
directly -X- _ O
reducing -X- _ O
model -X- _ O
depth -X- _ O
to -X- _ O
m -X- _ O
layers -X- _ B-HyperparameterName
which -X- _ O
is -X- _ O
denoted -X- _ O
as -X- _ O
( -X- _ B-MethodName
AL -X- _ I-MethodName
) -X- _ I-MethodName
BERT -X- _ I-MethodName
- -X- _ I-MethodName
mL -X- _ I-MethodName
. -X- _ O

Overall -X- _ O
Comparison -X- _ O

We -X- _ O
compare -X- _ O
our -X- _ O
model -X- _ O
performance -X- _ O
with -X- _ O
the -X- _ O
baseline -X- _ O
methods -X- _ O
when -X- _ O
different -X- _ O
backbone -X- _ O
models -X- _ O
are -X- _ O
adopted -X- _ O
and -X- _ O
show -X- _ O
the -X- _ O
result -X- _ O
in -X- _ O
method -X- _ O
maintains -X- _ O
a -X- _ O
comparable -X- _ O
result -X- _ O
with -X- _ O
the -X- _ O
original -X- _ O
models -X- _ O
on -X- _ O
most -X- _ O
datasets -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
notice -X- _ O
that -X- _ O
directly -X- _ O
reducing -X- _ O
layers -X- _ O
performs -X- _ O
well -X- _ O
and -X- _ O
serves -X- _ O
as -X- _ O
a -X- _ O
strong -X- _ O
baseline -X- _ O
. -X- _ O
Nevertheless -X- _ O
, -X- _ O
our -X- _ O
proposal -X- _ O
significantly -X- _ O
outperforms -X- _ O
such -X- _ O
a -X- _ O
method -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
other -X- _ O
two -X- _ O
early -X- _ B-TaskName
exit -X- _ I-TaskName
methods -X- _ O
. -X- _ O

We -X- _ O
then -X- _ O
adopt -X- _ O
a -X- _ O
more -X- _ O
aggressive -X- _ O
3.00× -X- _ O
speedup -X- _ O
ratio -X- _ O
to -X- _ O
verify -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
method -X- _ O
. -X- _ O
According -X- _ O
to -X- _ O
Table -X- _ O
2 -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
PABEE -X- _ B-MethodName
and -X- _ O
DeeBERT -X- _ B-MethodName
deteriorates -X- _ O
badly -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
exhibits -X- _ O
more -X- _ O
robust -X- _ O
and -X- _ O
stable -X- _ O
performance -X- _ O
, -X- _ O
showing -X- _ O
its -X- _ O
superiority -X- _ O
over -X- _ O
previous -X- _ O
early -X- _ O
exit -X- _ O
methods -X- _ O
. -X- _ O
Particularly -X- _ O
, -X- _ O
ALBERT -X- _ B-MethodName
is -X- _ O
already -X- _ O
very -X- _ O
efficient -X- _ O
in -X- _ O
model -X- _ O
size -X- _ O
owing -X- _ O
to -X- _ O
its -X- _ O
layer -X- _ O
- -X- _ O
sharing -X- _ O
mechanism -X- _ O
. -X- _ O
Results -X- _ O
shown -X- _ O
in -X- _ O
the -X- _ O
bottom -X- _ O
of -X- _ O
Table -X- _ O
2 -X- _ O
suggest -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
can -X- _ O
obtain -X- _ O
a -X- _ O
good -X- _ O
result -X- _ O
with -X- _ O
minimum -X- _ O
performance -X- _ O
loss -X- _ O
on -X- _ O
such -X- _ O
a -X- _ O
parameterefficient -X- _ O
model -X- _ O
. -X- _ O
The -X- _ O
success -X- _ O
of -X- _ O
our -X- _ O
proposal -X- _ O
might -X- _ O
be -X- _ O
attributed -X- _ O
to -X- _ O
the -X- _ O
global -X- _ O
perspective -X- _ O
for -X- _ O
prediction -X- _ O
. -X- _ O
DeeBERT -X- _ B-MethodName
makes -X- _ O
prediction -X- _ O
with -X- _ O
the -X- _ O
help -X- _ O
of -X- _ O
the -X- _ O
state -X- _ O
of -X- _ O
a -X- _ O
single -X- _ O
branch -X- _ O
classifier -X- _ O
, -X- _ O
leading -X- _ O
to -X- _ O
less -X- _ O
reliable -X- _ O
results -X- _ O
. -X- _ O
Although -X- _ O
PABEE -X- _ B-MethodName
employs -X- _ O
cross -X- _ O
- -X- _ O
layer -X- _ O
prediction -X- _ O
to -X- _ O
prevent -X- _ O
error -X- _ O
from -X- _ O
one -X- _ O
single -X- _ O
classifier -X- _ O
, -X- _ O
they -X- _ O
ignore -X- _ O
much -X- _ O
available -X- _ O
information -X- _ O
of -X- _ O
past -X- _ O
states -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
high -X- _ O
- -X- _ O
level -X- _ O
semantic -X- _ O
features -X- _ O
captured -X- _ O
by -X- _ O
future -X- _ O
layers -X- _ O
. -X- _ O
Different -X- _ O
from -X- _ O
those -X- _ O
methods -X- _ O
, -X- _ O
our -X- _ O
method -X- _ O
jointly -X- _ O
takes -X- _ O
into -X- _ O
consideration -X- _ O
the -X- _ O
hierarchical -X- _ O
linguistic -X- _ O
information -X- _ O
embedded -X- _ O
in -X- _ O
all -X- _ O
layers -X- _ O
and -X- _ O
thus -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
produce -X- _ O
more -X- _ O
accurate -X- _ O
results -X- _ O
. -X- _ O

Performance -X- _ O
- -X- _ O
Efficiency -X- _ O
Trade -X- _ O
- -X- _ O
Off -X- _ O

To -X- _ O
further -X- _ O
verify -X- _ O
the -X- _ O
robustness -X- _ O
and -X- _ O
efficiency -X- _ O
of -X- _ O
our -X- _ O
method -X- _ O
, -X- _ O
we -X- _ O
visualize -X- _ O
the -X- _ O
performanceefficiency -X- _ O
trade -X- _ O
- -X- _ O
off -X- _ O
curves -X- _ O
in -X- _ O
Figure -X- _ O
3 -X- _ O
on -X- _ O
a -X- _ O
representative -X- _ O
subset -X- _ O
of -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
dev -X- _ O
set -X- _ O
. -X- _ O
The -X- _ O
backbone -X- _ O
model -X- _ O
is -X- _ O
BERT -X- _ B-MethodName
. -X- _ O
Please -X- _ O
refer -X- _ O
to -X- _ O
the -X- _ O
Appendix -X- _ O
A -X- _ O
for -X- _ O
results -X- _ O
of -X- _ O
RoBERTa -X- _ B-MethodName
and -X- _ O
ALBERT -X- _ B-MethodName
. -X- _ O
As -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
from -X- _ O
Figure -X- _ O
3 -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
previous -X- _ O
stateof -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
early -X- _ O
exit -X- _ O
methods -X- _ O
drops -X- _ O
dramatically -X- _ O
when -X- _ O
the -X- _ O
speed -X- _ O
- -X- _ O
up -X- _ O
ratio -X- _ O
increases -X- _ O
, -X- _ O
which -X- _ O
limits -X- _ O
their -X- _ O
practicality -X- _ O
for -X- _ O
higher -X- _ O
acceleration -X- _ O
requirements -X- _ O
. -X- _ O
By -X- _ O
comparison -X- _ O
, -X- _ O
our -X- _ O
method -X- _ O
demonstrates -X- _ O
more -X- _ O
tolerance -X- _ O
of -X- _ O
speed -X- _ O
- -X- _ O
up -X- _ O
ratio -X- _ O
. -X- _ O
It -X- _ O
significantly -X- _ O
improves -X- _ O
performance -X- _ O
compared -X- _ O
to -X- _ O
previous -X- _ O
bestperforming -X- _ O
early -X- _ O
exit -X- _ O
models -X- _ O
under -X- _ O
the -X- _ O
same -X- _ O
speedup -X- _ O
ratio -X- _ O
, -X- _ O
especially -X- _ O
in -X- _ O
the -X- _ O
case -X- _ O
that -X- _ O
the -X- _ O
speed -X- _ O
- -X- _ O
up -X- _ O
ratio -X- _ O
is -X- _ O
high -X- _ O
, -X- _ O
indicating -X- _ O
that -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
applied -X- _ O
in -X- _ O
a -X- _ O
wider -X- _ O
range -X- _ O
of -X- _ O
acceleration -X- _ O
scenarios -X- _ O
. -X- _ O

Analysis -X- _ O

Effect -X- _ O
of -X- _ O
Global -X- _ O
Strategies -X- _ O

The -X- _ O
results -X- _ O
of -X- _ O
different -X- _ O
global -X- _ O
strategies -X- _ O
on -X- _ O
a -X- _ O
representative -X- _ O
subset -X- _ O
of -X- _ O
GLUE -X- _ B-DatasetName
dev -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
. -X- _ O
The -X- _ O
naive -X- _ O
global -X- _ O
strategies -X- _ O
including -X- _ O
voting -X- _ O
and -X- _ O
ensemble -X- _ O
perform -X- _ O
poorly -X- _ O
, -X- _ O
which -X- _ O
demonstrates -X- _ O
that -X- _ O
existing -X- _ O
global -X- _ O
strategies -X- _ O
can -X- _ O
only -X- _ O
achieve -X- _ O
suboptimal -X- _ O
performance -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
we -X- _ O
design -X- _ O
simple -X- _ O
yet -X- _ O
effective -X- _ O
global -X- _ O
strategies -X- _ O
to -X- _ O
incorporate -X- _ O
past -X- _ O
states -X- _ O
which -X- _ O
bring -X- _ O
significant -X- _ O
improvement -X- _ O
compared -X- _ O
to -X- _ O
baselines -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
we -X- _ O
empirically -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
concatenation -X- _ O
strategy -X- _ O
works -X- _ O
best -X- _ O
from -X- _ O
an -X- _ O
overall -X- _ O
point -X- _ O
of -X- _ O
view -X- _ O
. -X- _ O
We -X- _ O
assume -X- _ O
that -X- _ O
such -X- _ O
a -X- _ O
strategy -X- _ O
allows -X- _ O
interaction -X- _ O
among -X- _ O
different -X- _ O
states -X- _ O
, -X- _ O
yielding -X- _ O
better -X- _ O
performance -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
the -X- _ O
merging -X- _ O
gate -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Appendix -X- _ O
B -X- _ O
. -X- _ O

Analysis -X- _ O
of -X- _ O
Future -X- _ O
Information -X- _ O

To -X- _ O
assess -X- _ O
whether -X- _ O
and -X- _ O
how -X- _ O
future -X- _ O
information -X- _ O
contributes -X- _ O
to -X- _ O
the -X- _ O
prediction -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
evaluate -X- _ O
the -X- _ O
Global -X- _ O
Future -X- _ O
version -X- _ O
of -X- _ O
our -X- _ O
early -X- _ O
exit -X- _ O
method -X- _ O
where -X- _ O
all -X- _ O
the -X- _ O
approximations -X- _ O
of -X- _ O
futures -X- _ O
states -X- _ O
are -X- _ O
incorporated -X- _ O
through -X- _ O
the -X- _ O
concatenation -X- _ O
strategy -X- _ O
. -X- _ O
Effect -X- _ O
of -X- _ O
future -X- _ O
information -X- _ O
is -X- _ O
backed -X- _ O
with -X- _ O
the -X- _ O
results -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
Global -X- _ O
Future -X- _ O
mechanism -X- _ O
brings -X- _ O
improvement -X- _ O
on -X- _ O
most -X- _ O
datasets -X- _ O
for -X- _ O
both -X- _ O
2× -X- _ O
speed -X- _ O
- -X- _ O
up -X- _ O
ratio -X- _ O
and -X- _ O
3× -X- _ O
speedup -X- _ O
ratio -X- _ O
, -X- _ O
which -X- _ O
confirms -X- _ O
that -X- _ O
the -X- _ O
approximations -X- _ O
of -X- _ O
future -X- _ O
states -X- _ O
help -X- _ O
enhance -X- _ O
the -X- _ O
model -X- _ O
ability -X- _ O
in -X- _ O
prediction -X- _ O
. -X- _ O
Beyond -X- _ O
that -X- _ O
, -X- _ O
the -X- _ O
future -X- _ O
states -X- _ O
can -X- _ O
be -X- _ O
especially -X- _ O
advantageous -X- _ O
for -X- _ O
the -X- _ O
models -X- _ O
with -X- _ O
a -X- _ O
higher -X- _ O
speed -X- _ O
- -X- _ O
up -X- _ O
ratio -X- _ O
. -X- _ O
Recall -X- _ O
that -X- _ O
approximations -X- _ O
of -X- _ O
future -X- _ O
states -X- _ O
complement -X- _ O
the -X- _ O
high -X- _ O
- -X- _ O
level -X- _ O
semantic -X- _ O
information -X- _ O
and -X- _ O
the -X- _ O
exit -X- _ O
at -X- _ O
shallow -X- _ O
layers -X- _ O
loses -X- _ O
more -X- _ O
semantic -X- _ O
information -X- _ O
in -X- _ O
comparison -X- _ O
with -X- _ O
the -X- _ O
exit -X- _ O
at -X- _ O
deep -X- _ O
layers -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
the -X- _ O
benefit -X- _ O
of -X- _ O
future -X- _ O
information -X- _ O
is -X- _ O
more -X- _ O
significant -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
exit -X- _ O
at -X- _ O
shallow -X- _ O
layers -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
validated -X- _ O
by -X- _ O
the -X- _ O
larger -X- _ O
improvement -X- _ O
gap -X- _ O
with -X- _ O
a -X- _ O
3× -X- _ O
speed -X- _ O
- -X- _ O
up -X- _ O
ratio -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
investigate -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
future -X- _ O
information -X- _ O
on -X- _ O
exit -X- _ O
time -X- _ O
. -X- _ O
Figure -X- _ O
4 -X- _ O
demonstrates -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
exit -X- _ O
layers -X- _ O
with -X- _ O
and -X- _ O
without -X- _ O
future -X- _ O
information -X- _ O
. -X- _ O
When -X- _ O
future -X- _ O
information -X- _ O
is -X- _ O
engaged -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
proportion -X- _ O
of -X- _ O
exit -X- _ O
at -X- _ O
shallow -X- _ O
layers -X- _ O
increases -X- _ O
. -X- _ O
The -X- _ O
observation -X- _ O
conforms -X- _ O
with -X- _ O
our -X- _ O
intuition -X- _ O
: -X- _ O
with -X- _ O
the -X- _ O
approximations -X- _ O
of -X- _ O
future -X- _ O
states -X- _ O
supplemented -X- _ O
for -X- _ O
prediction -X- _ O
, -X- _ O
the -X- _ O
merged -X- _ O
state -X- _ O
at -X- _ O
a -X- _ O
shallow -X- _ O
layer -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
make -X- _ O
a -X- _ O
confident -X- _ O
and -X- _ O
correct -X- _ O
prediction -X- _ O
. -X- _ O
Thus -X- _ O
the -X- _ O
exit -X- _ O
time -X- _ O
is -X- _ O
earlier -X- _ O
compared -X- _ O
to -X- _ O
situations -X- _ O
without -X- _ O
future -X- _ O
states -X- _ O
, -X- _ O
result- -X- _ O
ing -X- _ O
in -X- _ O
a -X- _ O
higher -X- _ O
speed -X- _ O
- -X- _ O
up -X- _ O
ratio -X- _ O
. -X- _ O
To -X- _ O
be -X- _ O
more -X- _ O
specific -X- _ O
, -X- _ O
for -X- _ O
MRPC -X- _ B-DatasetName
, -X- _ O
the -X- _ O
speed -X- _ B-MetricName
- -X- _ I-MetricName
up -X- _ I-MetricName
ratios -X- _ I-MetricName
with -X- _ O
and -X- _ O
without -X- _ O
future -X- _ O
states -X- _ O
are -X- _ O
1.69 -X- _ B-MetricValue
and -X- _ O
1.99 -X- _ B-MetricValue
, -X- _ O
and -X- _ O
are -X- _ O
1.92 -X- _ B-MetricValue
and -X- _ O
2.04 -X- _ B-MetricValue
for -X- _ O
MNLI -X- _ B-DatasetName
, -X- _ O
respectively -X- _ O
. -X- _ O
Meanwhile -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
a -X- _ O
performance -X- _ O
boost -X- _ O
with -X- _ O
future -X- _ O
states -X- _ O
involved -X- _ O
. -X- _ O
It -X- _ O
confirms -X- _ O
our -X- _ O
assumption -X- _ O
that -X- _ O
the -X- _ O
high -X- _ O
- -X- _ O
level -X- _ O
semantic -X- _ O
features -X- _ O
embedded -X- _ O
in -X- _ O
future -X- _ O
states -X- _ O
help -X- _ O
improve -X- _ O
performance -X- _ O
in -X- _ O
early -X- _ B-TaskName
exit -X- _ I-TaskName
framework -X- _ O
. -X- _ O

Comparison -X- _ O
with -X- _ O
Distillation -X- _ O
Methods -X- _ O

As -X- _ O
an -X- _ O
alternative -X- _ O
method -X- _ O
to -X- _ O
accelerate -X- _ O
inference -X- _ O
, -X- _ O
knowledge -X- _ O
distillation -X- _ O
also -X- _ O
exhibits -X- _ O
promising -X- _ O
performance -X- _ O
for -X- _ O
NLP -X- _ O
tasks -X- _ O
. -X- _ O
We -X- _ O
provide -X- _ O
comparison -X- _ O
with -X- _ O
typical -X- _ O
knowledge -X- _ O
distillation -X- _ O
methods -X- _ O
in -X- _ O
Table -X- _ O
5 -X- _ O
. -X- _ O
Existing -X- _ O
model -X- _ O
TinyBERT -X- _ B-MethodName
( -X- _ O
Jiao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
exerts -X- _ O
multiple -X- _ O
elaborate -X- _ O
strategies -X- _ O
to -X- _ O
achieve -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
results -X- _ O
, -X- _ O
including -X- _ O
the -X- _ O
expensive -X- _ O
general -X- _ O
distillation -X- _ O
process -X- _ O
and -X- _ O
a -X- _ O
vast -X- _ O
amount -X- _ O
of -X- _ O
augmented -X- _ O
data -X- _ O
for -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
. -X- _ O
We -X- _ O
remove -X- _ O
these -X- _ O
two -X- _ O
techniques -X- _ O
to -X- _ O
exclude -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
extra -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
Under -X- _ O
the -X- _ O
same -X- _ O
settings -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
our -X- _ O
method -X- _ O
outperforms -X- _ O
the -X- _ O
distillation -X- _ O
methods -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
speed -X- _ O
- -X- _ O
up -X- _ O
ratio -X- _ O
. -X- _ O

In -X- _ O
general -X- _ O
, -X- _ O
early -X- _ O
exit -X- _ O
and -X- _ O
distillation -X- _ O
methods -X- _ O
improve -X- _ O
inference -X- _ O
efficiency -X- _ O
from -X- _ O
different -X- _ O
perspec- -X- _ O
tives -X- _ O
. -X- _ O
The -X- _ O
distillation -X- _ O
methods -X- _ O
are -X- _ O
more -X- _ O
efficient -X- _ O
in -X- _ O
saving -X- _ O
memory -X- _ O
usage -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
downside -X- _ O
is -X- _ O
that -X- _ O
such -X- _ O
static -X- _ O
methods -X- _ O
suffer -X- _ O
from -X- _ O
high -X- _ O
computation -X- _ O
cost -X- _ O
to -X- _ O
adapt -X- _ O
to -X- _ O
different -X- _ O
speed -X- _ O
- -X- _ O
up -X- _ O
ratios -X- _ O
. -X- _ O
A -X- _ O
new -X- _ O
student -X- _ O
model -X- _ O
has -X- _ O
to -X- _ O
be -X- _ O
trained -X- _ O
from -X- _ O
scratch -X- _ O
if -X- _ O
the -X- _ O
speedup -X- _ O
requirement -X- _ O
changes -X- _ O
. -X- _ O
By -X- _ O
contrast -X- _ O
, -X- _ O
dynamic -X- _ O
methods -X- _ O
are -X- _ O
more -X- _ O
flexible -X- _ O
to -X- _ O
meet -X- _ O
different -X- _ O
acceleration -X- _ O
requirements -X- _ O
. -X- _ O
Concretely -X- _ O
, -X- _ O
simple -X- _ O
instances -X- _ O
will -X- _ O
be -X- _ O
processed -X- _ O
by -X- _ O
passing -X- _ O
through -X- _ O
fewer -X- _ O
layers -X- _ O
and -X- _ O
complex -X- _ O
instances -X- _ O
may -X- _ O
require -X- _ O
more -X- _ O
layers -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
the -X- _ O
speed -X- _ O
- -X- _ O
up -X- _ O
ratio -X- _ O
can -X- _ O
be -X- _ O
easily -X- _ O
adjusted -X- _ O
depending -X- _ O
on -X- _ O
the -X- _ O
acceleration -X- _ O
requests -X- _ O
. -X- _ O
Nevertheless -X- _ O
, -X- _ O
early -X- _ B-TaskName
exit -X- _ I-TaskName
and -X- _ O
distillation -X- _ O
accelerate -X- _ O
inference -X- _ O
from -X- _ O
different -X- _ O
perspectives -X- _ O
and -X- _ O
these -X- _ O
two -X- _ O
kinds -X- _ O
of -X- _ O
techniques -X- _ O
can -X- _ O
be -X- _ O
integrated -X- _ O
to -X- _ O
further -X- _ O
compress -X- _ O
the -X- _ O
model -X- _ O
size -X- _ O
and -X- _ O
accelerate -X- _ O
the -X- _ O
inference -X- _ O
time -X- _ O
. -X- _ O

Conclusions -X- _ O

We -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
Past -X- _ O
- -X- _ O
Future -X- _ O
early -X- _ B-TaskName
exit -X- _ I-TaskName
method -X- _ O
from -X- _ O
a -X- _ O
global -X- _ O
perspective -X- _ O
. -X- _ O
Unlike -X- _ O
previous -X- _ O
work -X- _ O
using -X- _ O
only -X- _ O
local -X- _ O
states -X- _ O
for -X- _ O
prediction -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
employs -X- _ O
all -X- _ O
available -X- _ O
past -X- _ O
states -X- _ O
for -X- _ O
prediction -X- _ O
and -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
approach -X- _ O
to -X- _ O
engage -X- _ O
the -X- _ O
future -X- _ O
states -X- _ O
which -X- _ O
are -X- _ O
originally -X- _ O
inaccessible -X- _ O
for -X- _ O
prediction -X- _ O
. -X- _ O
Experiments -X- _ O
illustrate -X- _ O
that -X- _ O
our -X- _ O
method -X- _ O
achieves -X- _ O
significant -X- _ O
improvement -X- _ O
over -X- _ O
baseline -X- _ O
methods -X- _ O
with -X- _ O
different -X- _ O
models -X- _ O
as -X- _ O
backbones -X- _ O
, -X- _ O
suggesting -X- _ O
the -X- _ O
superiority -X- _ O
of -X- _ O
our -X- _ O
early -X- _ B-TaskName
exit -X- _ I-TaskName
method -X- _ O
. -X- _ O

Acknowledgements -X- _ O

We -X- _ O
thank -X- _ O
all -X- _ O
the -X- _ O
anonymous -X- _ O
reviewers -X- _ O
for -X- _ O
their -X- _ O
constructive -X- _ O
comments -X- _ O
. -X- _ O
This -X- _ O
work -X- _ O
is -X- _ O
partly -X- _ O
supported -X- _ O
by -X- _ O
National -X- _ O
Key -X- _ O
R -X- _ O
& -X- _ O
D -X- _ O
Program -X- _ O
of -X- _ O
China -X- _ O
No -X- _ O
. -X- _ O
2019YFC1521200 -X- _ O
and -X- _ O
Beijing -X- _ O
Academy -X- _ O
of -X- _ O
Artificial -X- _ O
Intelligence -X- _ O
( -X- _ O
BAAI -X- _ O
) -X- _ O
. -X- _ O
Xu -X- _ O
Sun -X- _ O
is -X- _ O
the -X- _ O
corresponding -X- _ O
author -X- _ O
. -X- _ O

A -X- _ O
More -X- _ O
Performance -X- _ O
- -X- _ O
Efficiency -X- _ O

Trade -X- _ O
- -X- _ O
Off -X- _ O
Curves -X- _ O

Performance -X- _ O
- -X- _ O
efficiency -X- _ O
curves -X- _ O
with -X- _ O
RoBERTa -X- _ B-MethodName
and -X- _ O
ALBERT -X- _ B-MethodName
as -X- _ O
backbones -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
5 -X- _ O
and -X- _ O
Figure -X- _ O
6 -X- _ O
respectively -X- _ O
. -X- _ O
Similar -X- _ O
to -X- _ O
the -X- _ O
observation -X- _ O
with -X- _ O
BERT -X- _ B-MethodName
as -X- _ O
backbone -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
Dee -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
and -X- _ O
PABEE -X- _ B-MethodName
becomes -X- _ O
progressively -X- _ O
worse -X- _ O
as -X- _ O
the -X- _ O
speed -X- _ O
- -X- _ O
up -X- _ O
ratio -X- _ O
increases -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
our -X- _ O
past -X- _ O
- -X- _ O
future -X- _ O
early -X- _ O
exit -X- _ O
method -X- _ O
shows -X- _ O
more -X- _ O
robust -X- _ O
results -X- _ O
. -X- _ O
We -X- _ O
conduct -X- _ O
ablation -X- _ O
study -X- _ O
to -X- _ O
show -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
the -X- _ O
merging -X- _ O
gate -X- _ O
and -X- _ O
report -X- _ O
the -X- _ O
result -X- _ O
in -X- _ O
Table -X- _ O
6 -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
see -X- _ O
that -X- _ O
the -X- _ O
performance -X- _ O
drops -X- _ O
when -X- _ O
we -X- _ O
remove -X- _ O
the -X- _ O
merging -X- _ O
gate -X- _ O
from -X- _ O
our -X- _ O
model -X- _ O
, -X- _ O
suggesting -X- _ O
that -X- _ O
the -X- _ O
merging -X- _ O
gate -X- _ O
plays -X- _ O
an -X- _ O
important -X- _ O
role -X- _ O
in -X- _ O
keeping -X- _ O
the -X- _ O
balance -X- _ O
between -X- _ O
past -X- _ O
information -X- _ O
and -X- _ O
future -X- _ O
information -X- _ O
. -X- _ O

