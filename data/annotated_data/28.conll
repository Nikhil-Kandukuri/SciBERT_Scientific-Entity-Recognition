-DOCSTART- -X- O
Static -X- _ O
Embeddings -X- _ O
as -X- _ O
Efficient -X- _ O
Knowledge -X- _ O
Bases -X- _ O
? -X- _ O

Recent -X- _ O
research -X- _ O
investigates -X- _ O
factual -X- _ O
knowledge -X- _ O
stored -X- _ O
in -X- _ O
large -X- _ O
pretrained -X- _ B-MethodName
language -X- _ I-MethodName
models -X- _ I-MethodName
( -X- _ O
PLMs -X- _ B-MethodName
) -X- _ O
. -X- _ O
Instead -X- _ O
of -X- _ O
structural -X- _ O
knowledge -X- _ B-TaskName
base -X- _ I-TaskName
( -X- _ O
KB -X- _ B-TaskName
) -X- _ O
queries -X- _ B-TaskName
, -X- _ O
masked -X- _ O
sentences -X- _ O
such -X- _ O
as -X- _ O
" -X- _ O
Paris -X- _ O
is -X- _ O
the -X- _ O
capital -X- _ O
of -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
" -X- _ O
are -X- _ O
used -X- _ O
as -X- _ O
probes -X- _ O
. -X- _ O
The -X- _ O
good -X- _ O
performance -X- _ O
on -X- _ O
this -X- _ O
analysis -X- _ O
task -X- _ O
has -X- _ O
been -X- _ O
interpreted -X- _ O
as -X- _ O
PLMs -X- _ B-MethodName
becoming -X- _ O
potential -X- _ O
repositories -X- _ O
of -X- _ O
factual -X- _ O
knowledge -X- _ O
. -X- _ O
In -X- _ O
experiments -X- _ O
across -X- _ O
ten -X- _ O
linguistically -X- _ O
diverse -X- _ O
languages -X- _ O
, -X- _ O
we -X- _ O
study -X- _ O
knowledge -X- _ O
contained -X- _ O
in -X- _ O
static -X- _ O
embeddings -X- _ O
. -X- _ O
We -X- _ O
show -X- _ O
that -X- _ O
, -X- _ O
when -X- _ O
restricting -X- _ O
the -X- _ O
output -X- _ O
space -X- _ O
to -X- _ O
a -X- _ O
candidate -X- _ O
set -X- _ O
, -X- _ O
simple -X- _ O
nearest -X- _ O
neighbor -X- _ O
matching -X- _ O
using -X- _ O
static -X- _ O
embeddings -X- _ O
performs -X- _ O
better -X- _ O
than -X- _ O
PLMs -X- _ B-MethodName
. -X- _ O
E.g. -X- _ O
, -X- _ O
static -X- _ O
embeddings -X- _ O
perform -X- _ O
1.6 -X- _ B-MetricValue
% -X- _ I-MetricValue
points -X- _ O
better -X- _ O
than -X- _ O
BERT -X- _ B-MethodName
while -X- _ O
just -X- _ O
using -X- _ O
0.3 -X- _ B-MetricValue
% -X- _ I-MetricValue
of -X- _ O
energy -X- _ O
for -X- _ O
training -X- _ O
. -X- _ O
One -X- _ O
important -X- _ O
factor -X- _ O
in -X- _ O
their -X- _ O
good -X- _ O
comparative -X- _ O
performance -X- _ O
is -X- _ O
that -X- _ O
static -X- _ O
embeddings -X- _ O
are -X- _ O
standardly -X- _ O
learned -X- _ O
for -X- _ O
a -X- _ O
large -X- _ O
vocabulary -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
exploits -X- _ O
its -X- _ O
more -X- _ O
sophisticated -X- _ O
, -X- _ O
but -X- _ O
expensive -X- _ O
ability -X- _ O
to -X- _ O
compose -X- _ O
meaningful -X- _ O
representations -X- _ O
from -X- _ O
a -X- _ O
much -X- _ O
smaller -X- _ O
subword -X- _ O
vocabulary -X- _ O
. -X- _ O

Introduction -X- _ O

Pretrained -X- _ O
language -X- _ O
models -X- _ O
( -X- _ O
PLMs -X- _ O
) -X- _ O
( -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Howard -X- _ O
and -X- _ O
Ruder -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
can -X- _ O
be -X- _ O
finetuned -X- _ O
to -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
( -X- _ O
NLP -X- _ O
) -X- _ O
tasks -X- _ O
and -X- _ O
then -X- _ O
generally -X- _ O
yield -X- _ O
high -X- _ O
performance -X- _ O
. -X- _ O
Increasingly -X- _ O
, -X- _ O
these -X- _ O
models -X- _ O
and -X- _ O
their -X- _ O
generative -X- _ O
variants -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
GPT -X- _ O
, -X- _ O
Brown -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
are -X- _ O
used -X- _ O
to -X- _ O
solve -X- _ O
tasks -X- _ O
by -X- _ O
simple -X- _ O
text -X- _ O
generation -X- _ O
, -X- _ O
without -X- _ O
any -X- _ O
finetuning -X- _ O
. -X- _ O
This -X- _ O
motivated -X- _ O
research -X- _ O
on -X- _ O
how -X- _ O
much -X- _ O
knowledge -X- _ O
is -X- _ O
contained -X- _ O
in -X- _ O
PLMs -X- _ O
: -X- _ O
Petroni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
used -X- _ O
models -X- _ O
pretrained -X- _ O
with -X- _ O
a -X- _ O
masked -X- _ O
language -X- _ O
objective -X- _ O
to -X- _ O
answer -X- _ O
clozestyle -X- _ O
templates -X- _ O
such -X- _ O
as -X- _ O
: -X- _ O

( -X- _ O
Ex1 -X- _ O
) -X- _ O
Paris -X- _ O
is -X- _ O
the -X- _ O
capital -X- _ O
of -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
. -X- _ O

Using -X- _ O
this -X- _ O
methodology -X- _ O
, -X- _ O
Petroni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
showed -X- _ O
that -X- _ O
PLMs -X- _ O
capture -X- _ O
some -X- _ O
knowledge -X- _ O
implicitly -X- _ O
. -X- _ O
This -X- _ O
has -X- _ O
been -X- _ O
interpreted -X- _ O
as -X- _ O
suggesting -X- _ O
* -X- _ O
Equal -X- _ O
contribution -X- _ O
-random -X- _ O
order -X- _ O
. -X- _ O

Model -X- _ O

Vocabulary -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
mBERT -X- _ B-MethodName
use -X- _ O
their -X- _ O
subword -X- _ O
vocabularies -X- _ O
. -X- _ O

For -X- _ O
fastText -X- _ B-MethodName
, -X- _ O
we -X- _ O
use -X- _ O
BERT -X- _ B-MethodName
/ -X- _ O
mBERT -X- _ B-MethodName
's -X- _ O
vocabularies -X- _ O
and -X- _ O
newly -X- _ O
trained -X- _ O
wordpiece -X- _ O
vocabularies -X- _ O
on -X- _ O
Wikipedia -X- _ O
. -X- _ O

that -X- _ O
PLMs -X- _ O
are -X- _ O
promising -X- _ O
as -X- _ O
repositories -X- _ O
of -X- _ O
factual -X- _ O
knowledge -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
evidence -X- _ O
that -X- _ O
simple -X- _ O
static -X- _ O
embeddings -X- _ O
like -X- _ O
fastText -X- _ O
perform -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
PLMs -X- _ O
in -X- _ O
the -X- _ O
context -X- _ O
of -X- _ O
answering -X- _ O
knowledge -X- _ O
base -X- _ O
( -X- _ O
KB -X- _ O
) -X- _ O
queries -X- _ O
. -X- _ O
Answering -X- _ O
KB -X- _ B-TaskName
queries -X- _ I-TaskName
can -X- _ O
be -X- _ O
decomposed -X- _ O
into -X- _ O
two -X- _ O
subproblems -X- _ O
, -X- _ O
typing -X- _ B-TaskName
and -X- _ O
ranking -X- _ B-TaskName
. -X- _ O
Typing -X- _ B-TaskName
refers -X- _ O
to -X- _ O
the -X- _ O
problem -X- _ O
of -X- _ O
predicting -X- _ O
the -X- _ O
correct -X- _ O
type -X- _ O
of -X- _ O
the -X- _ O
answer -X- _ O
entity -X- _ O
; -X- _ O
e.g. -X- _ O
, -X- _ O
" -X- _ O
country -X- _ O
" -X- _ O
is -X- _ O
the -X- _ O
correct -X- _ O
type -X- _ O
for -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
in -X- _ O
( -X- _ O
Ex1 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
task -X- _ O
that -X- _ O
PLMs -X- _ O
seem -X- _ O
to -X- _ O
be -X- _ O
good -X- _ O
at -X- _ O
. -X- _ O
Ranking -X- _ B-TaskName
consists -X- _ O
of -X- _ O
finding -X- _ O
the -X- _ O
entity -X- _ O
of -X- _ O
the -X- _ O
correct -X- _ O
type -X- _ O
that -X- _ O
is -X- _ O
the -X- _ O
best -X- _ O
fit -X- _ O
( -X- _ O
" -X- _ O
France -X- _ O
" -X- _ O
in -X- _ O
( -X- _ O
Ex1 -X- _ O
) -X- _ O
) -X- _ O
. -X- _ O
By -X- _ O
restricting -X- _ O
the -X- _ O
output -X- _ O
space -X- _ O
to -X- _ O
the -X- _ O
correct -X- _ O
type -X- _ O
we -X- _ O
disentangle -X- _ O
the -X- _ O
two -X- _ O
subproblems -X- _ O
and -X- _ O
only -X- _ O
evaluate -X- _ O
ranking -X- _ O
. -X- _ O
We -X- _ O
do -X- _ O
this -X- _ O
for -X- _ O
three -X- _ O
reasons -X- _ O
. -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
Ranking -X- _ B-TaskName
is -X- _ O
the -X- _ O
knowledgeintensive -X- _ O
step -X- _ O
and -X- _ O
thus -X- _ O
the -X- _ O
key -X- _ O
research -X- _ O
question -X- _ O
. -X- _ O

( -X- _ O
ii -X- _ O
) -X- _ O
Typed -X- _ B-TaskName
querying -X- _ I-TaskName
reduces -X- _ O
PLMs -X- _ O
' -X- _ O
dependency -X- _ O
on -X- _ O
the -X- _ O
template -X- _ O
. -X- _ O
( -X- _ O
iii -X- _ O
) -X- _ O
It -X- _ O
allows -X- _ O
a -X- _ O
direct -X- _ O
comparison -X- _ O
between -X- _ O
static -X- _ O
word -X- _ O
embeddings -X- _ O
and -X- _ O
PLMs -X- _ O
. -X- _ O
Prior -X- _ O
work -X- _ O
has -X- _ O
adopted -X- _ O
a -X- _ O
similar -X- _ O
approach -X- _ O
( -X- _ O
Xiong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
. -X- _ O

For -X- _ O
a -X- _ O
PLM -X- _ O
like -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
ranking -X- _ B-TaskName
amounts -X- _ O
to -X- _ O
finding -X- _ O
the -X- _ O
entity -X- _ O
whose -X- _ O
embedding -X- _ O
is -X- _ O
most -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
output -X- _ O
embedding -X- _ O
for -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
. -X- _ O
For -X- _ O
static -X- _ O
embeddings -X- _ O
, -X- _ O
we -X- _ O
rank -X- _ B-TaskName
entities -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
entities -X- _ O
of -X- _ O
type -X- _ O
country -X- _ O
) -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
similarity -X- _ O
to -X- _ O
the -X- _ O
query -X- _ O
entity -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
" -X- _ O
Paris -X- _ O
" -X- _ O
in -X- _ O
( -X- _ O
Ex1 -X- _ O
) -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
experiments -X- _ O
across -X- _ O
ten -X- _ O
linguistically -X- _ O
diverse -X- _ O
languages -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
this -X- _ O
simple -X- _ O
nearest -X- _ O
neighbor -X- _ O
matching -X- _ O
with -X- _ O
fastText -X- _ B-MethodName
embeddings -X- _ O
performs -X- _ O
comparably -X- _ O
to -X- _ O
or -X- _ O
even -X- _ O
better -X- _ O
than -X- _ O
BERT -X- _ B-MethodName
. -X- _ O
For -X- _ O
example -X- _ O
for -X- _ O
English -X- _ O
, -X- _ O
fastText -X- _ B-MethodName
embeddings -X- _ O
perform -X- _ O
1.6 -X- _ B-MetricValue
% -X- _ I-MetricValue
points -X- _ O
better -X- _ O
than -X- _ O
BERT -X- _ O
( -X- _ O
41.2 -X- _ B-MetricValue
% -X- _ I-MetricValue
vs. -X- _ O
39.6 -X- _ B-MetricValue
% -X- _ I-MetricValue
, -X- _ O
see -X- _ O
Table -X- _ O
1 -X- _ O
, -X- _ O
column -X- _ O
" -X- _ O
LAMA -X- _ B-DatasetName
" -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
suggests -X- _ O
that -X- _ O
BERT -X- _ B-MethodName
's -X- _ O
core -X- _ O
mechanism -X- _ O
for -X- _ O
answering -X- _ O
factual -X- _ O
queries -X- _ O
is -X- _ O
not -X- _ O
more -X- _ O
effective -X- _ O
than -X- _ O
simple -X- _ O
nearest -X- _ O
neighbor -X- _ O
matching -X- _ O
using -X- _ O
fastText -X- _ B-MethodName
embeddings -X- _ O
. -X- _ O

We -X- _ O
believe -X- _ O
this -X- _ O
means -X- _ O
that -X- _ O
claims -X- _ O
that -X- _ O
PLMs -X- _ O
are -X- _ O
KBs -X- _ O
have -X- _ O
to -X- _ O
be -X- _ O
treated -X- _ O
with -X- _ O
caution -X- _ O
. -X- _ O
Advantages -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
are -X- _ O
that -X- _ O
it -X- _ O
composes -X- _ O
meaningful -X- _ O
representations -X- _ O
from -X- _ O
a -X- _ O
small -X- _ O
subword -X- _ O
vocabulary -X- _ O
and -X- _ O
handles -X- _ O
typing -X- _ O
implicitly -X- _ O
( -X- _ O
Petroni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
answering -X- _ O
queries -X- _ O
without -X- _ O
restricting -X- _ O
the -X- _ O
answer -X- _ O
space -X- _ O
to -X- _ O
a -X- _ O
list -X- _ O
of -X- _ O
candidates -X- _ O
is -X- _ O
hard -X- _ O
to -X- _ O
achieve -X- _ O
with -X- _ O
static -X- _ O
word -X- _ O
embeddings -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
static -X- _ O
embeddings -X- _ O
are -X- _ O
cheap -X- _ O
to -X- _ O
obtain -X- _ O
, -X- _ O
even -X- _ O
for -X- _ O
large -X- _ O
vocabulary -X- _ O
sizes -X- _ O
. -X- _ O
This -X- _ O
has -X- _ O
important -X- _ O
implications -X- _ O
for -X- _ O
green -X- _ O
NLP -X- _ O
. -X- _ O
PLMs -X- _ O
require -X- _ O
tremendous -X- _ O
computational -X- _ O
resources -X- _ O
, -X- _ O
whereas -X- _ O
static -X- _ O
embeddings -X- _ O
have -X- _ O
only -X- _ O
0.3 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
carbon -X- _ O
footprint -X- _ O
of -X- _ O
BERT -X- _ O
( -X- _ O
see -X- _ O
Table -X- _ O
4 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
argues -X- _ O
for -X- _ O
proponents -X- _ O
of -X- _ O
resourcehungry -X- _ O
deep -X- _ O
learning -X- _ O
models -X- _ O
to -X- _ O
try -X- _ O
harder -X- _ O
to -X- _ O
find -X- _ O
cheap -X- _ O
" -X- _ O
green -X- _ O
" -X- _ O
baselines -X- _ O
or -X- _ O
to -X- _ O
combine -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
both -X- _ O
worlds -X- _ O
( -X- _ O
cf -X- _ O
. -X- _ O
Poerner -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
summary -X- _ O
, -X- _ O
our -X- _ O
contributions -X- _ O
are -X- _ O
: -X- _ O

i -X- _ O
) -X- _ O

We -X- _ O
propose -X- _ O
an -X- _ O
experimental -X- _ O
setup -X- _ O
that -X- _ O
allows -X- _ O
a -X- _ O
direct -X- _ O
comparison -X- _ O
between -X- _ O
PLMs -X- _ O
and -X- _ O
static -X- _ O
word -X- _ O
embeddings -X- _ O
. -X- _ O
We -X- _ O
find -X- _ O
that -X- _ O
static -X- _ O
word -X- _ O
embeddings -X- _ O
show -X- _ O
performance -X- _ O
similar -X- _ O
to -X- _ O
BERT -X- _ B-MethodName
on -X- _ O
the -X- _ O
modified -X- _ O
LAMA -X- _ B-DatasetName
analysis -X- _ O
task -X- _ O
across -X- _ O
ten -X- _ O
languages -X- _ O
. -X- _ O

ii -X- _ O
) -X- _ O
We -X- _ O
provide -X- _ O
evidence -X- _ O
that -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
trade -X- _ O
- -X- _ O
off -X- _ O
between -X- _ O
composing -X- _ O
meaningful -X- _ O
representations -X- _ O
from -X- _ O
subwords -X- _ O
and -X- _ O
increasing -X- _ O
the -X- _ O
vocabulary -X- _ O
size -X- _ O
. -X- _ O
Storing -X- _ O
information -X- _ O
through -X- _ O
composition -X- _ O
in -X- _ O
a -X- _ O
network -X- _ O
seems -X- _ O
to -X- _ O
be -X- _ O
more -X- _ O
expensive -X- _ O
and -X- _ O
challenging -X- _ O
than -X- _ O
simply -X- _ O
increasing -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
atomic -X- _ O
representations -X- _ O
. -X- _ O

iii -X- _ O
) -X- _ O
Our -X- _ O
findings -X- _ O
may -X- _ O
point -X- _ O
to -X- _ O
a -X- _ O
general -X- _ O
problem -X- _ O
: -X- _ O
baselines -X- _ O
that -X- _ O
are -X- _ O
simpler -X- _ O
and -X- _ O
" -X- _ O
greener -X- _ O
" -X- _ O
are -X- _ O
not -X- _ O
given -X- _ O
enough -X- _ O
attention -X- _ O
in -X- _ O
deep -X- _ O
learning -X- _ O
. -X- _ O

Code -X- _ O
and -X- _ O
embeddings -X- _ O
are -X- _ O
available -X- _ O
online -X- _ O
. -X- _ O

Data -X- _ O

We -X- _ O
follow -X- _ O
the -X- _ O
LAMA -X- _ B-DatasetName
setup -X- _ O
introduced -X- _ O
by -X- _ O
Petroni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
More -X- _ O
specifically -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
data -X- _ O
from -X- _ O
TREx -X- _ B-DatasetName
( -X- _ O
Elsahar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
TREx -X- _ B-DatasetName
consists -X- _ O
of -X- _ O
triples -X- _ O
of -X- _ O
the -X- _ O
form -X- _ O
( -X- _ O
object -X- _ O
, -X- _ O
relation -X- _ O
, -X- _ O
subject -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
underlying -X- _ O
idea -X- _ O
of -X- _ O
LAMA -X- _ O
is -X- _ O
to -X- _ O
query -X- _ O
knowledge -X- _ O
from -X- _ O
PLMs -X- _ O
using -X- _ O
templates -X- _ O
without -X- _ O
any -X- _ O
finetuning -X- _ O
: -X- _ O
the -X- _ O
triple -X- _ O
( -X- _ O
Paris -X- _ O
, -X- _ O
capital -X- _ O
- -X- _ O
of -X- _ O
, -X- _ O
France -X- _ O
) -X- _ O
is -X- _ O
queried -X- _ O
with -X- _ O
the -X- _ O
template -X- _ O
" -X- _ O
Paris -X- _ O
is -X- _ O
the -X- _ O
capital -X- _ O
of -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
. -X- _ O
" -X- _ O
TREx -X- _ B-DatasetName
covers -X- _ O
41 -X- _ O
relations -X- _ O
. -X- _ O
Templates -X- _ O
for -X- _ O
each -X- _ O
relation -X- _ O
were -X- _ O
manually -X- _ O
created -X- _ O
by -X- _ O
Petroni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
LAMA -X- _ B-DatasetName
has -X- _ O
been -X- _ O
found -X- _ O
to -X- _ O
contain -X- _ O
many -X- _ O
" -X- _ O
easy -X- _ O
- -X- _ O
toguess -X- _ O
" -X- _ O
triples -X- _ O
; -X- _ O
e.g. -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
easy -X- _ O
to -X- _ O
guess -X- _ O
that -X- _ O
a -X- _ O
person -X- _ O
with -X- _ O
an -X- _ O
Italian -X- _ O
sounding -X- _ O
name -X- _ O
is -X- _ O
Italian -X- _ O
. -X- _ O
LAMA -X- _ B-DatasetName
- -X- _ I-DatasetName
UHN -X- _ I-DatasetName
is -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
triples -X- _ O
that -X- _ O
are -X- _ O
" -X- _ O
hard -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
guess -X- _ O
" -X- _ O
created -X- _ O
by -X- _ O
Poerner -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

Beyond -X- _ O
English -X- _ O
, -X- _ O
we -X- _ O
run -X- _ O
experiments -X- _ O
on -X- _ O
nine -X- _ O
additional -X- _ O
languages -X- _ O
using -X- _ O
mLAMA -X- _ B-DatasetName
, -X- _ O
a -X- _ O
multilingual -X- _ O
version -X- _ O
of -X- _ O
TREx -X- _ B-DatasetName
. -X- _ O
For -X- _ O
an -X- _ O
overview -X- _ O
of -X- _ O
languages -X- _ O
and -X- _ O
language -X- _ O
families -X- _ O
see -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O
For -X- _ O
training -X- _ O
static -X- _ O
embeddings -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
Wikipedia -X- _ O
dumps -X- _ O
from -X- _ O
October -X- _ O
2020 -X- _ O
. -X- _ O

Methods -X- _ O

We -X- _ O
describe -X- _ O
our -X- _ O
proposed -X- _ O
setup -X- _ O
, -X- _ O
which -X- _ O
allows -X- _ O
to -X- _ O
compare -X- _ O
PLMs -X- _ O
with -X- _ O
static -X- _ O
embeddings -X- _ O
. -X- _ O

PLMs -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
following -X- _ O
two -X- _ O
PLMs -X- _ O
: -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
BERT -X- _ B-MethodName
for -X- _ O
English -X- _ O
( -X- _ O
BERT -X- _ B-MethodName
- -X- _ O
base -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
cased -X- _ I-HyperparameterName
, -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
ii -X- _ O
) -X- _ O
mBERT -X- _ B-MethodName
for -X- _ O
all -X- _ O
ten -X- _ O
languages -X- _ O
( -X- _ O
the -X- _ O
multilingual -X- _ O
version -X- _ O
BERT -X- _ B-MethodName
- -X- _ O
base -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
multilingual -X- _ I-HyperparameterName
- -X- _ I-HyperparameterName
cased -X- _ I-HyperparameterName
) -X- _ O
. -X- _ O
Petroni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
use -X- _ O
templates -X- _ O
like -X- _ O
" -X- _ O
Paris -X- _ O
is -X- _ O
the -X- _ O
capital -X- _ O
of -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
" -X- _ O
and -X- _ O
give -X- _ O
arg -X- _ O
max -X- _ O
w∈V -X- _ O
p -X- _ O
( -X- _ O
w|t -X- _ O
) -X- _ O
as -X- _ O
answer -X- _ O
where -X- _ O
V -X- _ O
is -X- _ O
the -X- _ O
vocabulary -X- _ O
of -X- _ O
the -X- _ O
PLM -X- _ O
and -X- _ O
p -X- _ O
( -X- _ O
w|t -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
probability -X- _ O
that -X- _ O
word -X- _ O
w -X- _ O
gets -X- _ O
predicted -X- _ O
in -X- _ O
the -X- _ O
template -X- _ O
t -X- _ O
. -X- _ O

We -X- _ O
follow -X- _ O
the -X- _ O
same -X- _ O
setup -X- _ O
as -X- _ O
( -X- _ O
Kassner -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
120k -X- _ O
27.9 -X- _ O
25.2 -X- _ O
31.0 -X- _ O
24.2 -X- _ O
28.3 -X- _ O
22.4 -X- _ O
28.2 -X- _ O
28.0 -X- _ O
33.2 -X- _ O
250k -X- _ O
30.1 -X- _ O
30.3 -X- _ O
34.2 -X- _ O
28.8 -X- _ O
32.8 -X- _ O
24.9 -X- _ O
30.5 -X- _ O
31.6 -X- _ O
35.6 -X- _ O
500k -X- _ O
31.7 -X- _ O
32.5 -X- _ O
36.6 -X- _ O
30.9 -X- _ O
33.7 -X- _ O
27.0 -X- _ O
31.5 -X- _ O
31.8 -X- _ O
36.1 -X- _ O
1000k -X- _ O
31.3 -X- _ O
33.6 -X- _ O
36.5 -X- _ O
31.8 -X- _ O
33.9 -X- _ O
27.2 -X- _ O
29.8 -X- _ O
30.5 -X- _ O
36.6 -X- _ O
Table -X- _ O
3 -X- _ O
: -X- _ O
p1 -X- _ O
( -X- _ O
Strubell -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
our -X- _ O
server -X- _ O
's -X- _ O
peak -X- _ O
power -X- _ O
consumption -X- _ O
. -X- _ O
See -X- _ O
appendix -X- _ O
for -X- _ O
details -X- _ O
. -X- _ O

2021 -X- _ O
) -X- _ O
and -X- _ O
use -X- _ O
typed -X- _ B-TaskName
querying -X- _ I-TaskName
: -X- _ O
for -X- _ O
each -X- _ O
relation -X- _ O
, -X- _ O
we -X- _ O
create -X- _ O
a -X- _ O
candidate -X- _ O
set -X- _ O
C -X- _ O
and -X- _ O
then -X- _ O
predict -X- _ O
arg -X- _ O
max -X- _ O
c∈C -X- _ O
p -X- _ O
( -X- _ O
c|t -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
most -X- _ O
templates -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
only -X- _ O
one -X- _ O
valid -X- _ O
entity -X- _ O
type -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
country -X- _ O
for -X- _ O
( -X- _ O
Ex1 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
choose -X- _ O
as -X- _ O
C -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
objects -X- _ O
across -X- _ O
all -X- _ O
triples -X- _ O
for -X- _ O
a -X- _ O
single -X- _ O
relation -X- _ O
. -X- _ O
The -X- _ O
candidate -X- _ O
set -X- _ O
could -X- _ O
also -X- _ O
be -X- _ O
obtained -X- _ O
from -X- _ O
an -X- _ O
entity -X- _ O
typing -X- _ O
system -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
Yaghoobzadeh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
this -X- _ O
is -X- _ O
beyond -X- _ O
the -X- _ O
scope -X- _ O
of -X- _ O
this -X- _ O
paper -X- _ O
. -X- _ O
Variants -X- _ O
of -X- _ O
typed -X- _ O
prediction -X- _ O
have -X- _ O
been -X- _ O
used -X- _ O
before -X- _ O
( -X- _ O
Xiong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
accommodate -X- _ O
multi -X- _ O
- -X- _ O
token -X- _ O
objects -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
objects -X- _ O
that -X- _ O
are -X- _ O
not -X- _ O
contained -X- _ O
in -X- _ O
the -X- _ O
vocabulary -X- _ O
, -X- _ O
by -X- _ O
including -X- _ O
multiple -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
templates -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
compute -X- _ O
an -X- _ O
object -X- _ O
's -X- _ O
score -X- _ O
as -X- _ O
the -X- _ O
average -X- _ O
of -X- _ O
the -X- _ O
log -X- _ O
probabilities -X- _ O
for -X- _ O
its -X- _ O
individual -X- _ O
tokens -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
perform -X- _ O
any -X- _ O
finetuning -X- _ O
. -X- _ O

Vocabulary -X- _ O

The -X- _ O
vocabulary -X- _ O
V -X- _ O
of -X- _ O
the -X- _ O
wordpiece -X- _ O
tokenizer -X- _ O
is -X- _ O
of -X- _ O
central -X- _ O
importance -X- _ O
for -X- _ O
static -X- _ O
embeddings -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
PLMs -X- _ O
. -X- _ O
BERT -X- _ O
models -X- _ O
come -X- _ O
with -X- _ O
fixed -X- _ O
vocabularies -X- _ O
. -X- _ O
It -X- _ O
would -X- _ O
be -X- _ O
prohibitive -X- _ O
to -X- _ O
retrain -X- _ O
the -X- _ O
models -X- _ O
with -X- _ O
a -X- _ O
new -X- _ O
vocabulary -X- _ O
. -X- _ O
It -X- _ O
would -X- _ O
also -X- _ O
be -X- _ O
too -X- _ O
expensive -X- _ O
to -X- _ O
increase -X- _ O
the -X- _ O
vocabulary -X- _ O
by -X- _ O
a -X- _ O
large -X- _ O
factor -X- _ O
: -X- _ O
the -X- _ O
embedding -X- _ O
matrix -X- _ O
is -X- _ O
responsible -X- _ O
for -X- _ O
the -X- _ O
majority -X- _ O
of -X- _ O
the -X- _ O
memory -X- _ O
consumption -X- _ O
of -X- _ O
these -X- _ O
models -X- _ O
. -X- _ O

In -X- _ O
contrast -X- _ O
, -X- _ O
increasing -X- _ O
the -X- _ O
vocabulary -X- _ O
size -X- _ O
is -X- _ O
cheap -X- _ O
for -X- _ O
static -X- _ O
embeddings -X- _ O
. -X- _ O
We -X- _ O
thus -X- _ O
experiment -X- _ O
with -X- _ O
different -X- _ O
vocabulary -X- _ O
sizes -X- _ O
for -X- _ O
static -X- _ O
embeddings -X- _ O
. -X- _ O
To -X- _ O
this -X- _ O
end -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
new -X- _ O
vocabularies -X- _ O
for -X- _ O
each -X- _ O
language -X- _ O
on -X- _ O
Wikipedia -X- _ O
using -X- _ O
the -X- _ O
wordpiece -X- _ O
tokenizer -X- _ O
( -X- _ O
Schuster -X- _ O
and -X- _ O
Nakajima -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
. -X- _ O

Static -X- _ O
Embeddings -X- _ O

Using -X- _ O
either -X- _ O
newly -X- _ O
trained -X- _ O
vocabularies -X- _ O
or -X- _ O
existing -X- _ O
BERT -X- _ B-MethodName
vocabularies -X- _ O
, -X- _ O
we -X- _ O
tokenize -X- _ O
Wikipedia -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
train -X- _ O
fastText -X- _ B-MethodName
embeddings -X- _ O
( -X- _ O
Bojanowski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
with -X- _ O
default -X- _ O
parameters -X- _ O
( -X- _ O
http -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
fasttext.cc -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
consider -X- _ O
the -X- _ O
same -X- _ O
candidate -X- _ O
set -X- _ O
C -X- _ O
as -X- _ O
for -X- _ O
PLMs -X- _ O
. -X- _ O

Let -X- _ O
c -X- _ O
∈ -X- _ O
C -X- _ O
be -X- _ O
a -X- _ O
candidate -X- _ O
that -X- _ O
gets -X- _ O
split -X- _ O
into -X- _ O
tokens -X- _ O
t -X- _ O
1 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
t -X- _ O
k -X- _ O
by -X- _ O
the -X- _ O
wordpiece -X- _ O
tokenizer -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
assign -X- _ O
to -X- _ O
c -X- _ O
the -X- _ O
embedding -X- _ O
vector -X- _ O

e -X- _ O
c -X- _ O
= -X- _ O
1 -X- _ O
k -X- _ O
k -X- _ O
i=1 -X- _ O
e -X- _ O
t -X- _ O
i -X- _ O

where -X- _ O
e -X- _ O
t -X- _ O
i -X- _ O
is -X- _ O
the -X- _ O
fastText -X- _ B-MethodName
vector -X- _ O
for -X- _ O
token -X- _ O
t -X- _ O
i -X- _ O
. -X- _ O
We -X- _ O
compute -X- _ O
the -X- _ O
representations -X- _ O
for -X- _ O
a -X- _ O
query -X- _ O
q -X- _ O
analogously -X- _ O
. -X- _ O
For -X- _ O
a -X- _ O
query -X- _ O
q -X- _ O
( -X- _ O
the -X- _ O
subject -X- _ O
of -X- _ O
a -X- _ O
triple -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
then -X- _ O
compute -X- _ O
the -X- _ O
prediction -X- _ O
as -X- _ O
: -X- _ O

arg -X- _ O
max -X- _ O
c∈C -X- _ O
cosine -X- _ O
- -X- _ O
sim -X- _ O
( -X- _ O
ē -X- _ O
q -X- _ O
, -X- _ O
ē -X- _ O
c -X- _ O
) -X- _ O
, -X- _ O

i.e. -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
simple -X- _ O
nearest -X- _ O
neighbor -X- _ O
matching -X- _ O
. -X- _ O

Note -X- _ O
that -X- _ O
the -X- _ O
static -X- _ O
embedding -X- _ O
method -X- _ O
does -X- _ O
not -X- _ O
get -X- _ O
any -X- _ O
signal -X- _ O
about -X- _ O
the -X- _ O
relation -X- _ O
. -X- _ O
The -X- _ O
method -X- _ O
's -X- _ O
only -X- _ O
input -X- _ O
is -X- _ O
the -X- _ O
subject -X- _ O
of -X- _ O
a -X- _ O
triple -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
leave -X- _ O
incorporating -X- _ O
a -X- _ O
relation -X- _ O
vector -X- _ O
to -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O

Evaluation -X- _ O
Metric -X- _ O

We -X- _ O
compute -X- _ O
precision -X- _ O
at -X- _ O
one -X- _ O
for -X- _ O
each -X- _ O
relation -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
1 -X- _ O
/ -X- _ O
|T -X- _ O
| -X- _ O
t∈T -X- _ O
1 -X- _ O
{ -X- _ O
t -X- _ O
object -X- _ O
= -X- _ O
t -X- _ O
object -X- _ O
} -X- _ O
where -X- _ O
T -X- _ O
is -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
all -X- _ O
triples -X- _ O
andt -X- _ O
object -X- _ O
the -X- _ O
object -X- _ O
predicted -X- _ O
using -X- _ O
contextualized -X- _ O
/ -X- _ O
static -X- _ O
embeddings -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
T -X- _ O
is -X- _ O
different -X- _ O
for -X- _ O
each -X- _ O
language -X- _ O
. -X- _ O
Our -X- _ O
final -X- _ O
measure -X- _ O
( -X- _ O
p1 -X- _ O
) -X- _ O
is -X- _ O
then -X- _ O
the -X- _ O
precision -X- _ O
at -X- _ O
one -X- _ O
( -X- _ O
macro- -X- _ O
) -X- _ O
averaged -X- _ O
over -X- _ O
relations -X- _ O
. -X- _ O
As -X- _ O
a -X- _ O
consistency -X- _ O
check -X- _ O
we -X- _ O
provide -X- _ O
an -X- _ O
Oracle -X- _ O
baseline -X- _ O
: -X- _ O
it -X- _ O
always -X- _ O
predicts -X- _ O
the -X- _ O
most -X- _ O
frequent -X- _ O
object -X- _ O
across -X- _ O
triples -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
gold -X- _ O
candidate -X- _ O
sets -X- _ O
. -X- _ O

BERT -X- _ B-MethodName
vs. -X- _ O
fastText -X- _ B-MethodName

Results -X- _ O
for -X- _ O
English -X- _ O
are -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O
The -X- _ O
table -X- _ O
shows -X- _ O
that -X- _ O
when -X- _ O
increasing -X- _ O
the -X- _ O
vocabulary -X- _ O
size -X- _ O
, -X- _ O
static -X- _ O
embeddings -X- _ O
and -X- _ O
BERT -X- _ B-MethodName
exhibit -X- _ O
similar -X- _ O
performance -X- _ O
on -X- _ O
LAMA -X- _ B-DatasetName
. -X- _ O
The -X- _ O
Oracle -X- _ O
baseline -X- _ O
is -X- _ O
mostly -X- _ O
outperformed -X- _ O
. -X- _ O
Only -X- _ O
for -X- _ O
small -X- _ O
vocabulary -X- _ O
sizes -X- _ O
, -X- _ O
fast -X- _ B-MethodName
- -X- _ I-MethodName
Text -X- _ I-MethodName
is -X- _ O
worse -X- _ O
. -X- _ O
Performance -X- _ O
of -X- _ O
fastText -X- _ B-MethodName
increases -X- _ O
with -X- _ O
larger -X- _ O
vocabulary -X- _ O
sizes -X- _ O
and -X- _ O
with -X- _ O
a -X- _ O
vocabulary -X- _ O
size -X- _ O
of -X- _ O
1000k -X- _ O
we -X- _ O
observe -X- _ O
a -X- _ O
1.6 -X- _ O
% -X- _ O
absolute -X- _ O
performance -X- _ O
increase -X- _ O
of -X- _ O
fastText -X- _ B-MethodName
embeddings -X- _ O
compared -X- _ O
to -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
41.2 -X- _ O
% -X- _ O
vs. -X- _ O
39.6 -X- _ O
% -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
performance -X- _ O
gap -X- _ O
between -X- _ O
fastText -X- _ B-MethodName
and -X- _ O
BERT -X- _ B-MethodName
increases -X- _ O
to -X- _ O
2.7 -X- _ O
% -X- _ O
points -X- _ O
on -X- _ O
LAMA -X- _ B-DatasetName
- -X- _ I-DatasetName
UHN -X- _ I-DatasetName
, -X- _ O
indicating -X- _ O
that -X- _ O
fastText -X- _ B-MethodName
is -X- _ O
less -X- _ O
vulnerable -X- _ O
to -X- _ O
misleading -X- _ O
clues -X- _ O
about -X- _ O
the -X- _ O
subject -X- _ O
. -X- _ O

Only -X- _ O
providing -X- _ O
results -X- _ O
on -X- _ O
English -X- _ O
can -X- _ O
be -X- _ O
prone -X- _ O
to -X- _ O
unexpected -X- _ O
biases -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
we -X- _ O
verify -X- _ O
our -X- _ O
results -X- _ O
for -X- _ O
nine -X- _ O
additional -X- _ O
languages -X- _ O
. -X- _ O
Results -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
and -X- _ O
the -X- _ O
conclusions -X- _ O
are -X- _ O
similar -X- _ O
: -X- _ O
for -X- _ O
large -X- _ O
enough -X- _ O
vocabularies -X- _ O
, -X- _ O
static -X- _ O
embeddings -X- _ O
consistently -X- _ O
have -X- _ O
better -X- _ O
performance -X- _ O
. -X- _ O
For -X- _ O
languages -X- _ O
outside -X- _ O
the -X- _ O
Indo -X- _ O
- -X- _ O
European -X- _ O
family -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
gap -X- _ O
between -X- _ O
mBERT -X- _ B-MethodName
and -X- _ O
fastText -X- _ B-MethodName
is -X- _ O
much -X- _ O
larger -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
31.7 -X- _ O
vs. -X- _ O
17.2 -X- _ O
for -X- _ O
Arabic -X- _ O
) -X- _ O
and -X- _ O
mBERT -X- _ B-MethodName
is -X- _ O
sometimes -X- _ O
worse -X- _ O
than -X- _ O
the -X- _ O
Oracle -X- _ O
. -X- _ O

Our -X- _ O
fastText -X- _ B-MethodName
method -X- _ O
is -X- _ O
quite -X- _ O
primitive -X- _ O
: -X- _ O
it -X- _ O
is -X- _ O
a -X- _ O
type -X- _ O
- -X- _ O
restricted -X- _ O
search -X- _ O
for -X- _ O
entities -X- _ O
similar -X- _ O
to -X- _ O
what -X- _ O
is -X- _ O
most -X- _ O
prominent -X- _ O
in -X- _ O
the -X- _ O
context -X- _ O
( -X- _ O
whose -X- _ O
central -X- _ O
element -X- _ O
is -X- _ O
the -X- _ O
query -X- _ O
entity -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
" -X- _ O
Paris -X- _ O
" -X- _ O
in -X- _ O
( -X- _ O
Ex1 -X- _ O
) -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
fact -X- _ O
that -X- _ O
fastText -X- _ O
outperforms -X- _ O
BERT -X- _ B-MethodName
raises -X- _ O
the -X- _ O
question -X- _ O
: -X- _ O
Does -X- _ O
BERT -X- _ B-MethodName
simply -X- _ O
use -X- _ O
associations -X- _ O
between -X- _ O
entities -X- _ O
( -X- _ O
like -X- _ O
fastText -X- _ O
) -X- _ O
or -X- _ O
has -X- _ O
it -X- _ O
captured -X- _ O
factual -X- _ O
knowledge -X- _ O
beyond -X- _ O
this -X- _ O
? -X- _ O

BERT -X- _ B-MethodName
vs -X- _ O
fastText -X- _ B-MethodName
: -X- _ O
Diversity -X- _ O
of -X- _ O
Predictions -X- _ O

The -X- _ O
entropy -X- _ O
of -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
predicted -X- _ O
objects -X- _ O
is -X- _ O
6.5 -X- _ O
for -X- _ O
BERT -X- _ B-MethodName
vs. -X- _ O
7.3 -X- _ O
for -X- _ O
fastText -X- _ B-MethodName
. -X- _ O
So -X- _ O
BERT -X- _ B-MethodName
's -X- _ O
predictions -X- _ O
are -X- _ O
less -X- _ O
diverse -X- _ O
. -X- _ O
Of -X- _ O
151 -X- _ O
possible -X- _ O
objects -X- _ O
on -X- _ O
average -X- _ O
, -X- _ O
BERT -X- _ O
predicts -X- _ O
( -X- _ O
on -X- _ O
average -X- _ O
) -X- _ O
85 -X- _ O
, -X- _ O
fast -X- _ O
- -X- _ O
Text -X- _ O
119 -X- _ O
. -X- _ O
For -X- _ O
a -X- _ O
given -X- _ O
relation -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
's -X- _ O
prediction -X- _ O
tend -X- _ O
to -X- _ O
be -X- _ O
dominated -X- _ O
by -X- _ O
one -X- _ O
object -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
often -X- _ O
the -X- _ O
most -X- _ O
frequent -X- _ O
correct -X- _ O
object -X- _ O
-possibly -X- _ O
because -X- _ O
these -X- _ O
objects -X- _ O
are -X- _ O
frequent -X- _ O
in -X- _ O
Wikipedia -X- _ O
/ -X- _ O
Wikidata -X- _ O
. -X- _ O
When -X- _ O
filtering -X- _ O
out -X- _ O
triples -X- _ O
whose -X- _ O
correct -X- _ O
answer -X- _ O
is -X- _ O
the -X- _ O
most -X- _ O
frequent -X- _ O
object -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
's -X- _ O
performance -X- _ O
drops -X- _ O
to -X- _ O
35.7 -X- _ O
whereas -X- _ O
fastText -X- _ B-MethodName
's -X- _ O
increases -X- _ O
to -X- _ O
42.5 -X- _ O
. -X- _ O
See -X- _ O
Table -X- _ O
7 -X- _ O
in -X- _ O
the -X- _ O
appendix -X- _ O
for -X- _ O
full -X- _ O
results -X- _ O
on -X- _ O
diversity -X- _ O
. -X- _ O
We -X- _ O
leave -X- _ O
investigating -X- _ O
why -X- _ O
BERT -X- _ B-MethodName
has -X- _ O
these -X- _ O
narrower -X- _ O
object -X- _ O
preferences -X- _ O
for -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O

Contextualization -X- _ O
in -X- _ O
BERT -X- _ B-MethodName

BERT -X- _ B-MethodName
's -X- _ O
attention -X- _ O
mechanism -X- _ O
should -X- _ O
be -X- _ O
able -X- _ O
to -X- _ O
handle -X- _ O
long -X- _ O
subjects -X- _ O
-in -X- _ O
contrast -X- _ O
to -X- _ O
fastText -X- _ O
, -X- _ O
for -X- _ O
which -X- _ O
we -X- _ O
use -X- _ O
simple -X- _ O
averaging -X- _ O
. -X- _ O
Figure -X- _ O
1 -X- _ O
shows -X- _ O
that -X- _ O
fast -X- _ B-MethodName
- -X- _ I-MethodName
Text -X- _ I-MethodName
's -X- _ O
performance -X- _ O
indeed -X- _ O
drops -X- _ O
when -X- _ O
the -X- _ O
query -X- _ O
gets -X- _ O
tokenized -X- _ O
into -X- _ O
multiple -X- _ O
tokens -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
's -X- _ O
performance -X- _ O
remains -X- _ O
stable -X- _ O
. -X- _ O
We -X- _ O
conclude -X- _ O
that -X- _ O
token -X- _ O
averaging -X- _ O
harms -X- _ O
fastText -X- _ O
's -X- _ O
performance -X- _ O
and -X- _ O
that -X- _ O
the -X- _ O
attention -X- _ O
mechanism -X- _ O
in -X- _ O
BERT -X- _ B-MethodName
composes -X- _ O
meaningful -X- _ O
representations -X- _ O
from -X- _ O
subwords -X- _ O
. -X- _ O
We -X- _ O
try -X- _ O
to -X- _ O
induce -X- _ O
static -X- _ O
embeddings -X- _ O
from -X- _ O
BERT -X- _ B-MethodName
by -X- _ O
feeding -X- _ O
object -X- _ O
and -X- _ O
subject -X- _ O
surface -X- _ O
forms -X- _ O
to -X- _ O
BERT -X- _ B-MethodName
without -X- _ O
any -X- _ O
context -X- _ O
and -X- _ O
then -X- _ O
averaging -X- _ O
the -X- _ O
hidden -X- _ O
representations -X- _ O
for -X- _ O
each -X- _ O
layer -X- _ O
. -X- _ O
Figure -X- _ O
2 -X- _ O
analyzes -X- _ O
whether -X- _ O
a -X- _ O
nearest -X- _ O
neighbor -X- _ O
matching -X- _ O
over -X- _ O
this -X- _ O
static -X- _ O
embedding -X- _ O
space -X- _ O
extracted -X- _ O
from -X- _ O
BERT -X- _ B-MethodName
's -X- _ O
representations -X- _ O
is -X- _ O
effective -X- _ O
in -X- _ O
extracting -X- _ O
knowledge -X- _ O
from -X- _ O
it -X- _ O
. -X- _ O
We -X- _ O
find -X- _ O
that -X- _ O
performance -X- _ O
on -X- _ O
LAMA -X- _ B-DatasetName
is -X- _ O
significantly -X- _ O
lower -X- _ O
across -X- _ O
all -X- _ O
hidden -X- _ O
layers -X- _ O
with -X- _ O
the -X- _ O
first -X- _ O
two -X- _ O
layers -X- _ O
performing -X- _ O
best -X- _ O
. -X- _ O
That -X- _ O
simple -X- _ O
averaging -X- _ O
does -X- _ O
not -X- _ O
work -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
contextualization -X- _ O
indicates -X- _ O
that -X- _ O
BERT -X- _ B-MethodName
is -X- _ O
great -X- _ O
at -X- _ O
composing -X- _ O
meaningful -X- _ O
representations -X- _ O
through -X- _ O
attention -X- _ O
. -X- _ O
In -X- _ O
future -X- _ O
work -X- _ O
, -X- _ O
it -X- _ O
would -X- _ O
be -X- _ O
interesting -X- _ O
to -X- _ O
extract -X- _ O
better -X- _ O
static -X- _ O
representations -X- _ O
from -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
for -X- _ O
example -X- _ O
by -X- _ O
extracting -X- _ O
the -X- _ O
representations -X- _ O
of -X- _ O
entities -X- _ O
in -X- _ O
real -X- _ O
sentences -X- _ O
. -X- _ O
. -X- _ O
" -X- _ O
and -X- _ O
a -X- _ O
candidate -X- _ O
set -X- _ O
. -X- _ O
The -X- _ O
solid -X- _ O
lines -X- _ O
reflect -X- _ O
performance -X- _ O
of -X- _ O
nearest -X- _ O
neighbor -X- _ O
matching -X- _ O
with -X- _ O
cosine -X- _ O
similarity -X- _ O
when -X- _ O
inducing -X- _ O
a -X- _ O
static -X- _ O
embedding -X- _ O
space -X- _ O
from -X- _ O
the -X- _ O
representations -X- _ O
at -X- _ O
these -X- _ O
layers -X- _ O
. -X- _ O
This -X- _ O
shows -X- _ O
that -X- _ O
extracting -X- _ O
high -X- _ O
quality -X- _ O
static -X- _ O
embeddings -X- _ O
is -X- _ O
not -X- _ O
trivial -X- _ O
, -X- _ O
and -X- _ O
BERT -X- _ B-MethodName
's -X- _ O
contextualization -X- _ O
is -X- _ O
essential -X- _ O
for -X- _ O
getting -X- _ O
good -X- _ O
performance -X- _ O
. -X- _ O

Resource -X- _ O
Consumption -X- _ O

carbon -X- _ O
emissions -X- _ O
compared -X- _ O
to -X- _ O
BERT -X- _ B-MethodName
. -X- _ O
In -X- _ O
a -X- _ O
recent -X- _ O
study -X- _ O
, -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
showed -X- _ O
that -X- _ O
capturing -X- _ O
factual -X- _ O
knowledge -X- _ O
inside -X- _ O
PLMs -X- _ O
is -X- _ O
an -X- _ O
especially -X- _ O
resource -X- _ O
hungry -X- _ O
task -X- _ O
. -X- _ O
These -X- _ O
big -X- _ O
differences -X- _ O
demonstrate -X- _ O
that -X- _ O
fastText -X- _ O
, -X- _ O
in -X- _ O
addition -X- _ O
to -X- _ O
performing -X- _ O
better -X- _ O
than -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
is -X- _ O
the -X- _ O
environmentally -X- _ O
better -X- _ O
model -X- _ O
to -X- _ O
" -X- _ O
encode -X- _ O
knowledge -X- _ O
" -X- _ O
of -X- _ O
Wikipedia -X- _ O
in -X- _ O
an -X- _ O
unsupervised -X- _ O
fashion -X- _ O
. -X- _ O
This -X- _ O
calls -X- _ O
into -X- _ O
question -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
large -X- _ O
PLMs -X- _ O
as -X- _ O
knowledge -X- _ O
bases -X- _ O
, -X- _ O
particularly -X- _ O
in -X- _ O
light -X- _ O
of -X- _ O
the -X- _ O
recent -X- _ O
surge -X- _ O
of -X- _ O
knowledge -X- _ O
augmented -X- _ O
LMs -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
Guu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

5 -X- _ O
Related -X- _ O
Work -X- _ O
Petroni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
first -X- _ O
asked -X- _ O
: -X- _ O
can -X- _ O
PLMs -X- _ O
function -X- _ O
as -X- _ O
KBs -X- _ O
? -X- _ O
Subsequent -X- _ O
analysis -X- _ O
focused -X- _ O
on -X- _ O
different -X- _ O
aspects -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
negation -X- _ O
Ettinger -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
paraphrases -X- _ O
( -X- _ O
Elazar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
easy -X- _ O
to -X- _ O
guess -X- _ O
names -X- _ O
( -X- _ O
Poerner -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
finding -X- _ O
alternatives -X- _ O
to -X- _ O
a -X- _ O
cloze -X- _ O
- -X- _ O
style -X- _ O
approach -X- _ O
( -X- _ O
Bouraoui -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Heinzerling -X- _ O
and -X- _ O
Inui -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Jiang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
or -X- _ O
analyzing -X- _ O
different -X- _ O
model -X- _ O
sizes -X- _ O
( -X- _ O
Roberts -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

There -X- _ O
is -X- _ O
a -X- _ O
recent -X- _ O
surge -X- _ O
of -X- _ O
work -X- _ O
that -X- _ O
tries -X- _ O
to -X- _ O
improve -X- _ O
PLMs -X- _ O
' -X- _ O
ability -X- _ O
to -X- _ O
harvest -X- _ O
factual -X- _ O
knowledge -X- _ O
: -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
we -X- _ O
provide -X- _ O
evidence -X- _ O
that -X- _ O
BERT -X- _ B-MethodName
's -X- _ O
ability -X- _ O
to -X- _ O
answer -X- _ O
factual -X- _ O
queries -X- _ O
is -X- _ O
not -X- _ O
more -X- _ O
effective -X- _ O
than -X- _ O
capturing -X- _ O
" -X- _ O
knowledge -X- _ O
" -X- _ O
with -X- _ O
simple -X- _ O
traditional -X- _ O
static -X- _ O
embeddings -X- _ O
. -X- _ O
This -X- _ O
suggests -X- _ O
that -X- _ O
learning -X- _ O
associations -X- _ O
between -X- _ O
entities -X- _ O
and -X- _ O
typerestricted -X- _ O
similarity -X- _ O
search -X- _ O
over -X- _ O
these -X- _ O
associations -X- _ O
may -X- _ O
be -X- _ O
at -X- _ O
the -X- _ O
core -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
's -X- _ O
ability -X- _ O
to -X- _ O
answer -X- _ O
cloze -X- _ O
- -X- _ O
style -X- _ O
KB -X- _ B-TaskName
queries -X- _ I-TaskName
, -X- _ O
a -X- _ O
new -X- _ O
insight -X- _ O
into -X- _ O
BERT -X- _ B-MethodName
's -X- _ O
working -X- _ O
mechanism -X- _ O
. -X- _ O

Conclusion -X- _ O

We -X- _ O
have -X- _ O
shown -X- _ O
that -X- _ O
, -X- _ O
when -X- _ O
restricting -X- _ O
cloze -X- _ O
- -X- _ O
style -X- _ O
questions -X- _ O
to -X- _ O
a -X- _ O
candidate -X- _ O
set -X- _ O
, -X- _ O
static -X- _ O
word -X- _ O
embeddings -X- _ O
outperform -X- _ O
BERT -X- _ B-MethodName
. -X- _ O
To -X- _ O
explain -X- _ O
this -X- _ O
puzzling -X- _ O
superiority -X- _ O
of -X- _ O
a -X- _ O
much -X- _ O
simpler -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
put -X- _ O
forward -X- _ O
a -X- _ O
new -X- _ O
characterization -X- _ O
of -X- _ O
factual -X- _ O
knowledge -X- _ O
learned -X- _ O
by -X- _ O
BERT -X- _ B-MethodName
: -X- _ O
BERT -X- _ B-MethodName
seems -X- _ O
to -X- _ O
be -X- _ O
able -X- _ O
to -X- _ O
complete -X- _ O
cloze -X- _ O
- -X- _ O
style -X- _ O
queries -X- _ O
based -X- _ O
on -X- _ O
similarity -X- _ O
assessments -X- _ O
on -X- _ O
a -X- _ O
type -X- _ O
- -X- _ O
restricted -X- _ O
vocabulary -X- _ O
much -X- _ O
like -X- _ O
a -X- _ O
nearest -X- _ O
neighbor -X- _ O
search -X- _ O
for -X- _ O
static -X- _ O
embeddings -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
may -X- _ O
still -X- _ O
be -X- _ O
the -X- _ O
better -X- _ O
model -X- _ O
for -X- _ O
the -X- _ O
task -X- _ O
: -X- _ O
we -X- _ O
assume -X- _ O
perfect -X- _ O
typing -X- _ O
( -X- _ O
for -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
fastText -X- _ B-MethodName
) -X- _ O
and -X- _ O
only -X- _ O
evaluate -X- _ O
ranking -X- _ O
. -X- _ O
Typing -X- _ O
is -X- _ O
much -X- _ O
harder -X- _ O
with -X- _ O
static -X- _ O
embeddings -X- _ O
and -X- _ O
BERT -X- _ B-MethodName
has -X- _ O
been -X- _ O
shown -X- _ O
to -X- _ O
perform -X- _ O
well -X- _ O
at -X- _ O
guessing -X- _ O
the -X- _ O
expected -X- _ O
entity -X- _ O
type -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
template -X- _ O
. -X- _ O
BERT -X- _ B-MethodName
also -X- _ O
works -X- _ O
well -X- _ O
with -X- _ O
small -X- _ O
vocabularies -X- _ O
, -X- _ O
storing -X- _ O
most -X- _ O
of -X- _ O
its -X- _ O
" -X- _ O
knowledge -X- _ O
" -X- _ O
in -X- _ O
the -X- _ O
parameterization -X- _ O
of -X- _ O
subword -X- _ O
composition -X- _ O
. -X- _ O
Our -X- _ O
results -X- _ O
suggest -X- _ O
that -X- _ O
increasing -X- _ O
the -X- _ O
vocabulary -X- _ O
size -X- _ O
and -X- _ O
computing -X- _ O
more -X- _ O
atomic -X- _ O
entity -X- _ O
representations -X- _ O
with -X- _ O
fastText -X- _ B-MethodName
is -X- _ O
a -X- _ O
cheap -X- _ O
and -X- _ O
environmentally -X- _ O
friendly -X- _ O
method -X- _ O
of -X- _ O
storing -X- _ O
knowledge -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
learning -X- _ O
high -X- _ O
quality -X- _ O
composition -X- _ O
of -X- _ O
smaller -X- _ O
units -X- _ O
requires -X- _ O
many -X- _ O
more -X- _ O
resources -X- _ O
. -X- _ O

fastText -X- _ B-MethodName
is -X- _ O
a -X- _ O
simple -X- _ O
cheap -X- _ O
baseline -X- _ O
that -X- _ O
outperforms -X- _ O
BERT -X- _ B-MethodName
on -X- _ O
LAMA -X- _ B-DatasetName
, -X- _ O
but -X- _ O
was -X- _ O
not -X- _ O
considered -X- _ O
in -X- _ O
the -X- _ O
original -X- _ O
research -X- _ O
. -X- _ O
This -X- _ O
may -X- _ O
be -X- _ O
an -X- _ O
example -X- _ O
of -X- _ O
a -X- _ O
general -X- _ O
problem -X- _ O
: -X- _ O
" -X- _ O
green -X- _ O
" -X- _ O
baselines -X- _ O
are -X- _ O
often -X- _ O
ignored -X- _ O
, -X- _ O
but -X- _ O
should -X- _ O
be -X- _ O
considered -X- _ O
when -X- _ O
evaluating -X- _ O
resource -X- _ O
- -X- _ O
hungry -X- _ O
deep -X- _ O
learning -X- _ O
models -X- _ O
. -X- _ O
A -X- _ O
promising -X- _ O
way -X- _ O
forward -X- _ O
would -X- _ O
be -X- _ O
to -X- _ O
combine -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
both -X- _ O
worlds -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
by -X- _ O
building -X- _ O
on -X- _ O
work -X- _ O
that -X- _ O
incorporates -X- _ O
large -X- _ O
vocabularies -X- _ O
into -X- _ O
PLMs -X- _ O
after -X- _ O
pretraining -X- _ O
. -X- _ O

A -X- _ O
Resource -X- _ O
Consumption -X- _ O

We -X- _ O
follow -X- _ O
Strubell -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
for -X- _ O
our -X- _ O
computation -X- _ O
. -X- _ O
The -X- _ O
measured -X- _ O
peak -X- _ O
energy -X- _ O
consumption -X- _ O
of -X- _ O
our -X- _ O
CPU -X- _ O
- -X- _ O
server -X- _ O
was -X- _ O
618W. -X- _ O
Considering -X- _ O
the -X- _ O
power -X- _ O
usage -X- _ O
effectiveness -X- _ O
the -X- _ O
required -X- _ O
kWh -X- _ O
are -X- _ O
given -X- _ O
by -X- _ O
p -X- _ O
t -X- _ O
= -X- _ O
1.58 -X- _ O
• -X- _ O
t -X- _ O
• -X- _ O
618 -X- _ O
/ -X- _ O
1000 -X- _ O
. -X- _ O
Training -X- _ O
the -X- _ O
English -X- _ O
fast -X- _ O
- -X- _ O
Text -X- _ O
on -X- _ O
Wikipedia -X- _ O
took -X- _ O
around -X- _ O
5 -X- _ O
hours -X- _ O
. -X- _ O
Training -X- _ O
all -X- _ O
languages -X- _ O
took -X- _ O
20 -X- _ O
hours -X- _ O
. -X- _ O
The -X- _ O
estimated -X- _ O
CO -X- _ O
2 -X- _ O
e -X- _ O
can -X- _ O
then -X- _ O
be -X- _ O
computed -X- _ O
by -X- _ O
CO -X- _ O
2 -X- _ O
e -X- _ O
= -X- _ O
0.954 -X- _ O
• -X- _ O
p -X- _ O
t -X- _ O

B -X- _ O
Reproducibility -X- _ O
Information -X- _ O

For -X- _ O
computation -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
CPU -X- _ O
server -X- _ O
with -X- _ O
96 -X- _ O
CPU -X- _ O
cores -X- _ O
( -X- _ O
Intel -X- _ O
( -X- _ O
R -X- _ O
) -X- _ O
Xeon -X- _ O
( -X- _ O
R -X- _ O
) -X- _ O
Platinum -X- _ O
8160 -X- _ O
) -X- _ O
and -X- _ O
1024 -X- _ O
GB -X- _ O
RAM -X- _ O
. -X- _ O
For -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
mBERT -X- _ B-MethodName
inference -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
single -X- _ O
GeForce -X- _ O
GTX -X- _ O
1080Ti -X- _ O
GPU -X- _ O
. -X- _ O

Getting -X- _ O
the -X- _ O
object -X- _ O
predictions -X- _ O
for -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
fast -X- _ B-MethodName
- -X- _ I-MethodName
Text -X- _ I-MethodName
is -X- _ O
fast -X- _ O
and -X- _ O
takes -X- _ O
a -X- _ O
negligible -X- _ O
amount -X- _ O
of -X- _ O
time -X- _ O
. -X- _ O
Training -X- _ O
fastText -X- _ B-MethodName
embeddings -X- _ O
takes -X- _ O
between -X- _ O
1 -X- _ O
to -X- _ O
5 -X- _ O
hours -X- _ O
depending -X- _ O
on -X- _ O
Wikipedia -X- _ O
size -X- _ O
. -X- _ O

BERT -X- _ B-MethodName
has -X- _ O
around -X- _ O
110 -X- _ B-HyperparameterValue
M -X- _ I-HyperparameterValue
parameters -X- _ B-HyperparameterName
, -X- _ O
mBERT -X- _ B-HyperparameterName
around -X- _ O
178M. -X- _ B-HyperparameterValue
The -X- _ O
fastText -X- _ B-MethodName
embeddings -X- _ O
have -X- _ O
O -X- _ O
( -X- _ O
nd -X- _ O
) -X- _ O
parameters -X- _ O
where -X- _ O
n -X- _ O
is -X- _ O
the -X- _ O
vocabulary -X- _ O
size -X- _ O
and -X- _ O
d -X- _ O
is -X- _ O
the -X- _ O
embedding -X- _ B-HyperparameterName
dimension -X- _ I-HyperparameterName
. -X- _ O
We -X- _ O
use -X- _ O
d -X- _ O
= -X- _ O
300 -X- _ B-HyperparameterValue
. -X- _ O
Thus -X- _ O
, -X- _ O
for -X- _ O
most -X- _ O
vocabulary -X- _ O
sizes -X- _ O
, -X- _ O
fastText -X- _ B-MethodName
has -X- _ O
significantly -X- _ O
more -X- _ O
parameters -X- _ O
than -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
models -X- _ O
. -X- _ O
But -X- _ O
overall -X- _ O
they -X- _ O
are -X- _ O
cheaper -X- _ O
to -X- _ O
train -X- _ O
. -X- _ O

We -X- _ O
did -X- _ O
not -X- _ O
perform -X- _ O
any -X- _ O
hyperparameter -X- _ O
tuning -X- _ O
. -X- _ O
Table -X- _ O
6 -X- _ O
gives -X- _ O
an -X- _ O
overview -X- _ O
on -X- _ O
third -X- _ O
party -X- _ O
software -X- _ O
. -X- _ O
Table -X- _ O
5 -X- _ O
gives -X- _ O
an -X- _ O
overview -X- _ O
on -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
triples -X- _ O
in -X- _ O
the -X- _ O
dataset -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
no -X- _ O
training -X- _ O
set -X- _ O
is -X- _ O
required -X- _ O
, -X- _ O
as -X- _ O
all -X- _ O
methods -X- _ O
are -X- _ O
completely -X- _ O
unsupervised -X- _ O
. -X- _ O
Table -X- _ O
7 -X- _ O
: -X- _ O
Analysis -X- _ O
of -X- _ O
the -X- _ O
diversity -X- _ O
of -X- _ O
predictions -X- _ O
. -X- _ O
p1 -X- _ O
- -X- _ O
mf -X- _ O
is -X- _ O
the -X- _ O
p1 -X- _ O
when -X- _ O
excluding -X- _ O
triples -X- _ O
whose -X- _ O
correct -X- _ O
answer -X- _ O
is -X- _ O
the -X- _ O
most -X- _ O
frequent -X- _ O
object -X- _ O
. -X- _ O
entropy -X- _ O
is -X- _ O
the -X- _ O
entropy -X- _ O
of -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
predicted -X- _ O
objects -X- _ O
. -X- _ O
# -X- _ O
pred -X- _ O
. -X- _ O
denotes -X- _ O
the -X- _ O
average -X- _ O
number -X- _ O
of -X- _ O
distinct -X- _ O
objects -X- _ O
predicted -X- _ O
by -X- _ O
the -X- _ O
model -X- _ O
across -X- _ O
relations -X- _ O
. -X- _ O
The -X- _ O
average -X- _ O
number -X- _ O
of -X- _ O
unique -X- _ O
objects -X- _ O
in -X- _ O
the -X- _ O
candidate -X- _ O
set -X- _ O
across -X- _ O
relations -X- _ O
is -X- _ O
151 -X- _ O
. -X- _ O
fastText -X- _ B-MethodName
has -X- _ O
more -X- _ O
diverse -X- _ O
predictions -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
entropy -X- _ O
is -X- _ O
higher -X- _ O
and -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
predicted -X- _ O
objects -X- _ O
is -X- _ O
on -X- _ O
average -X- _ O
much -X- _ O
larger -X- _ O
. -X- _ O

C -X- _ O
Examples -X- _ O

D -X- _ O
Additional -X- _ O
Results -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
we -X- _ O
show -X- _ O
additional -X- _ O
results -X- _ O
. -X- _ O
Table -X- _ O
8 -X- _ O
shows -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
Table -X- _ O
1 -X- _ O
but -X- _ O
with -X- _ O
precision -X- _ O
at -X- _ O
five -X- _ O
. -X- _ O
Analogously -X- _ O
Table -X- _ O
9 -X- _ O
. -X- _ O
Table -X- _ O
10 -X- _ O
shows -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
Table -X- _ O
3 -X- _ O
but -X- _ O
for -X- _ O
LAMA -X- _ B-DatasetName
- -X- _ I-DatasetName
UHN -X- _ I-DatasetName
. -X- _ O
The -X- _ O
trends -X- _ O
and -X- _ O
key -X- _ O
insights -X- _ O
are -X- _ O
unchanged -X- _ O
. -X- _ O
Table -X- _ O
7 -X- _ O
analyses -X- _ O
the -X- _ O
diversity -X- _ O
of -X- _ O
predictions -X- _ O
by -X- _ O
the -X- _ O
different -X- _ O
models -X- _ O
. -X- _ O

