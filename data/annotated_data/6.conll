-DOCSTART- -X- O
On -X- _ O
Vision -X- _ O
Features -X- _ O
in -X- _ O
Multimodal -X- _ B-TaskName
Machine -X- _ I-TaskName
Translation -X- _ I-TaskName

Previous -X- _ O
work -X- _ O
on -X- _ O
multimodal -X- _ B-TaskName
machine -X- _ I-TaskName
translation -X- _ I-TaskName
( -X- _ O
MMT -X- _ B-TaskName
) -X- _ O
has -X- _ O
focused -X- _ O
on -X- _ O
the -X- _ O
way -X- _ O
of -X- _ O
incorporating -X- _ O
vision -X- _ O
features -X- _ O
into -X- _ O
translation -X- _ O
but -X- _ O
little -X- _ O
attention -X- _ O
is -X- _ O
on -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
vision -X- _ O
models -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
investigate -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
vision -X- _ O
models -X- _ O
on -X- _ O
MMT -X- _ B-TaskName
. -X- _ O
Given -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
Transformer -X- _ B-MethodName
is -X- _ O
becoming -X- _ O
popular -X- _ O
in -X- _ O
computer -X- _ O
vision -X- _ O
, -X- _ O
we -X- _ O
experiment -X- _ O
with -X- _ O
various -X- _ O
strong -X- _ O
models -X- _ O
( -X- _ O
such -X- _ O
as -X- _ O
Vision -X- _ B-MethodName
Transformer -X- _ I-MethodName
) -X- _ O
and -X- _ O
enhanced -X- _ O
features -X- _ O
( -X- _ O
such -X- _ O
as -X- _ O
object -X- _ O
- -X- _ O
detection -X- _ O
and -X- _ O
image -X- _ O
captioning -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
develop -X- _ O
a -X- _ O
selective -X- _ O
attention -X- _ O
model -X- _ O
to -X- _ O
study -X- _ O
the -X- _ O
patch -X- _ O
- -X- _ O
level -X- _ O
contribution -X- _ O
of -X- _ O
an -X- _ O
image -X- _ O
in -X- _ O
MMT -X- _ B-TaskName
. -X- _ O
On -X- _ O
detailed -X- _ O
probing -X- _ O
tasks -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
stronger -X- _ O
vision -X- _ O
models -X- _ O
are -X- _ O
helpful -X- _ O
for -X- _ O
learning -X- _ O
translation -X- _ O
from -X- _ O
the -X- _ O
visual -X- _ O
modality -X- _ O
. -X- _ O
Our -X- _ O
results -X- _ O
also -X- _ O
suggest -X- _ O
the -X- _ O
need -X- _ O
of -X- _ O
carefully -X- _ O
examining -X- _ O
MMT -X- _ B-TaskName
models -X- _ O
, -X- _ O
especially -X- _ O
when -X- _ O
current -X- _ O
benchmarks -X- _ O
are -X- _ O
small -X- _ O
- -X- _ O
scale -X- _ O
and -X- _ O
biased -X- _ O
. -X- _ O
Our -X- _ O
code -X- _ O
could -X- _ O
be -X- _ O
found -X- _ O
at -X- _ O
https -X- _ O
: -X- _ O

Introduction -X- _ O

Multimodal -X- _ B-TaskName
machine -X- _ I-TaskName
translation -X- _ I-TaskName
( -X- _ O
MMT -X- _ B-TaskName
) -X- _ O
has -X- _ O
emerged -X- _ O
as -X- _ O
an -X- _ O
active -X- _ O
field -X- _ O
of -X- _ O
research -X- _ O
which -X- _ O
marries -X- _ O
the -X- _ O
worlds -X- _ O
of -X- _ O
computer -X- _ O
vision -X- _ O
( -X- _ O
CV -X- _ O
) -X- _ O
and -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
( -X- _ O
NLP -X- _ O
) -X- _ O
. -X- _ O
Early -X- _ O
models -X- _ O
of -X- _ O
this -X- _ O
kind -X- _ O
produce -X- _ O
a -X- _ O
translation -X- _ O
given -X- _ O
the -X- _ O
fused -X- _ O
representation -X- _ O
of -X- _ O
both -X- _ O
the -X- _ O
visual -X- _ O
and -X- _ O
textual -X- _ O
inputs -X- _ O
( -X- _ O
Caglayan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Libovický -X- _ O
and -X- _ O
Helcl -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Calixto -X- _ O
and -X- _ O
Liu -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
As -X- _ O
expected -X- _ O
, -X- _ O
such -X- _ O
a -X- _ O
paradigm -X- _ O
achieves -X- _ O
promising -X- _ O
BLEU -X- _ B-MetricName
improvements -X- _ O
and -X- _ O
inspires -X- _ O
the -X- _ O
community -X- _ O
to -X- _ O
follow -X- _ O
up -X- _ O
. -X- _ O

But -X- _ O
soon -X- _ O
researchers -X- _ O
found -X- _ O
that -X- _ O
MMT -X- _ B-TaskName
systems -X- _ O
did -X- _ O
not -X- _ O
act -X- _ O
as -X- _ O
what -X- _ O
they -X- _ O
ordinarily -X- _ O
designed -X- _ O
: -X- _ O
the -X- _ O
visual -X- _ O
modality -X- _ O
contributes -X- _ O
to -X- _ O
translation -X- _ O
little -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
harmful -X- _ O
to -X- _ O
MMT -X- _ B-TaskName
systems -X- _ O
when -X- _ O
the -X- _ O
input -X- _ O
image -X- _ O
is -X- _ O
irrelevant -X- _ O
to -X- _ O
the -X- _ O
text -X- _ O
( -X- _ O
Grönroos -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Lala -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
or -X- _ O
even -X- _ O
when -X- _ O
the -X- _ O
vision -X- _ O
features -X- _ O
are -X- _ O
absent -X- _ O
( -X- _ O
Elliott -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
More -X- _ O
recently -X- _ O
, -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
have -X- _ O
pointed -X- _ O
out -X- _ O
that -X- _ O
the -X- _ O
* -X- _ O
Corresponding -X- _ O
author -X- _ O
. -X- _ O
use -X- _ O
of -X- _ O
the -X- _ O
visual -X- _ O
modality -X- _ O
is -X- _ O
a -X- _ O
way -X- _ O
of -X- _ O
regularization -X- _ O
for -X- _ O
training -X- _ O
but -X- _ O
not -X- _ O
a -X- _ O
complement -X- _ O
to -X- _ O
the -X- _ O
text -X- _ O
modality -X- _ O
. -X- _ O
As -X- _ O
another -X- _ O
response -X- _ O
to -X- _ O
the -X- _ O
analysis -X- _ O
of -X- _ O
MMT -X- _ B-TaskName
, -X- _ O
Caglayan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
investigate -X- _ O
how -X- _ O
the -X- _ O
vision -X- _ O
features -X- _ O
correlate -X- _ O
to -X- _ O
the -X- _ O
text -X- _ O
. -X- _ O
They -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
input -X- _ O
image -X- _ O
helps -X- _ O
translation -X- _ O
when -X- _ O
some -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
words -X- _ O
are -X- _ O
masked -X- _ O
. -X- _ O

Note -X- _ O
that -X- _ O
previous -X- _ O
work -X- _ O
has -X- _ O
for -X- _ O
the -X- _ O
most -X- _ O
part -X- _ O
focused -X- _ O
on -X- _ O
integrating -X- _ O
off -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
shelf -X- _ O
vision -X- _ O
models -X- _ O
( -X- _ O
such -X- _ O
as -X- _ O
ResNet-50 -X- _ O
) -X- _ O
into -X- _ O
MMT -X- _ B-TaskName
. -X- _ O
The -X- _ O
underlying -X- _ O
assumption -X- _ O
here -X- _ O
is -X- _ O
that -X- _ O
the -X- _ O
existing -X- _ O
vision -X- _ O
models -X- _ O
are -X- _ O
powerful -X- _ O
enough -X- _ O
to -X- _ O
encode -X- _ O
the -X- _ O
image -X- _ O
. -X- _ O
This -X- _ O
implicitly -X- _ O
ignores -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
vision -X- _ O
models -X- _ O
in -X- _ O
representing -X- _ O
images -X- _ O
. -X- _ O
But -X- _ O
computer -X- _ O
vision -X- _ O
is -X- _ O
facing -X- _ O
a -X- _ O
new -X- _ O
trend -X- _ O
by -X- _ O
moving -X- _ O
from -X- _ O
CNNs -X- _ O
to -X- _ O
Transformer -X- _ B-MethodName
as -X- _ O
the -X- _ O
backbone -X- _ O
model -X- _ O
( -X- _ O
Dosovitskiy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021b -X- _ O
; -X- _ O
Carion -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
A -X- _ O
natural -X- _ O
question -X- _ O
that -X- _ O
arises -X- _ O
is -X- _ O
: -X- _ O
how -X- _ O
will -X- _ O
MMT -X- _ B-TaskName
systems -X- _ O
behave -X- _ O
if -X- _ O
stronger -X- _ O
vision -X- _ O
models -X- _ O
are -X- _ O
adopted -X- _ O
? -X- _ O

In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
address -X- _ O
this -X- _ O
question -X- _ O
by -X- _ O
a -X- _ O
systematic -X- _ O
study -X- _ O
of -X- _ O
using -X- _ O
various -X- _ O
vision -X- _ O
models -X- _ O
in -X- _ O
MMT -X- _ B-TaskName
, -X- _ O
in -X- _ O
particular -X- _ O
using -X- _ O
the -X- _ O
most -X- _ O
successful -X- _ O
models -X- _ O
in -X- _ O
recent -X- _ O
studies -X- _ O
( -X- _ O
such -X- _ O
as -X- _ O
Vision -X- _ B-MethodName
Transformer -X- _ I-MethodName
, -X- _ O
or -X- _ O
ViT -X- _ B-MethodName
for -X- _ O
short -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
patch -X- _ O
method -X- _ O
used -X- _ O
in -X- _ O
Transformer -X- _ B-MethodName
- -X- _ O
based -X- _ O
vision -X- _ O
models -X- _ O
offers -X- _ O
an -X- _ O
opportunity -X- _ O
to -X- _ O
detail -X- _ O
the -X- _ O
patch -X- _ O
- -X- _ O
level -X- _ O
contribution -X- _ O
of -X- _ O
the -X- _ O
image -X- _ O
. -X- _ O
This -X- _ O
leads -X- _ O
us -X- _ O
to -X- _ O
develop -X- _ O
a -X- _ O
selective -X- _ O
attention -X- _ O
model -X- _ O
to -X- _ O
correlate -X- _ O
words -X- _ O
with -X- _ O
image -X- _ O
patches -X- _ O
. -X- _ O
Beyond -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
object -X- _ O
- -X- _ O
detection -X- _ O
and -X- _ O
image -X- _ O
captioning -X- _ O
features -X- _ O
into -X- _ O
MMT -X- _ B-TaskName
for -X- _ O
further -X- _ O
improvements -X- _ O
of -X- _ O
the -X- _ O
vision -X- _ O
models -X- _ O
( -X- _ O
Carion -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Fang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

Following -X- _ O
Caglayan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
's -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
design -X- _ O
more -X- _ O
detailed -X- _ O
probing -X- _ O
tasks -X- _ O
to -X- _ O
examine -X- _ O
to -X- _ O
what -X- _ O
degree -X- _ O
the -X- _ O
visual -X- _ O
modality -X- _ O
contributes -X- _ O
to -X- _ O
MMT -X- _ B-TaskName
. -X- _ O
We -X- _ O
run -X- _ O
an -X- _ O
extensive -X- _ O
set -X- _ O
of -X- _ O
experiments -X- _ O
on -X- _ O
En -X- _ B-TaskName
- -X- _ I-TaskName
De -X- _ I-TaskName
and -X- _ O
En -X- _ B-TaskName
- -X- _ I-TaskName
Fr -X- _ I-TaskName
MMT -X- _ B-TaskName
tasks -X- _ O
. -X- _ O
Our -X- _ O
findings -X- _ O
are -X- _ O

• -X- _ O
Stronger -X- _ O
vision -X- _ O
models -X- _ O
help -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
ViT -X- _ B-MethodName
can -X- _ O
beat -X- _ O
ResNet-50 -X- _ B-MethodName
on -X- _ O
the -X- _ O
probing -X- _ O
tasks -X- _ O
though -X- _ O
the -X- _ O
superiority -X- _ O
is -X- _ O
not -X- _ O
significant -X- _ O
on -X- _ O
standard -X- _ O
MMT -X- _ B-TaskName
data -X- _ O
. -X- _ O
Table -X- _ O
1 -X- _ O
: -X- _ O
An -X- _ O
example -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
probing -X- _ O
tasks -X- _ O
. -X- _ O
We -X- _ O
replace -X- _ O
the -X- _ O
masked -X- _ O
token -X- _ O
by -X- _ O
four -X- _ O
symbols -X- _ O
respectively -X- _ O
. -X- _ O

• -X- _ O
Automatic -X- _ O
evaluation -X- _ O
on -X- _ O
current -X- _ O
MMT -X- _ B-TaskName
tasks -X- _ O
might -X- _ O
not -X- _ O
be -X- _ O
a -X- _ O
good -X- _ O
indicator -X- _ O
for -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
MMT -X- _ B-TaskName
models -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
models -X- _ O
enhanced -X- _ O
with -X- _ O
object -X- _ O
- -X- _ O
detection -X- _ O
and -X- _ O
image -X- _ O
captioning -X- _ O
features -X- _ O
yield -X- _ O
good -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
on -X- _ O
the -X- _ O
original -X- _ O
MMT -X- _ B-TaskName
task -X- _ O
but -X- _ O
show -X- _ O
modest -X- _ O
or -X- _ O
no -X- _ O
contributions -X- _ O
on -X- _ O
the -X- _ O
probing -X- _ O
tasks -X- _ O
. -X- _ O

We -X- _ O
hope -X- _ O
that -X- _ O
the -X- _ O
results -X- _ O
here -X- _ O
can -X- _ O
inspire -X- _ O
more -X- _ O
research -X- _ O
on -X- _ O
exploring -X- _ O
better -X- _ O
vision -X- _ O
models -X- _ O
and -X- _ O
evaluation -X- _ O
methods -X- _ O
for -X- _ O
multimodal -X- _ O
NLP -X- _ O
. -X- _ O

Preliminary -X- _ O

We -X- _ O
start -X- _ O
with -X- _ O
a -X- _ O
description -X- _ O
of -X- _ O
the -X- _ O
probing -X- _ O
tasks -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
followed -X- _ O
by -X- _ O
a -X- _ O
design -X- _ O
of -X- _ O
vision -X- _ O
features -X- _ O
and -X- _ O
a -X- _ O
selective -X- _ O
attention -X- _ O
mechanism -X- _ O
for -X- _ O
introducing -X- _ O
ViT -X- _ B-MethodName
- -X- _ O
like -X- _ O
representations -X- _ O
into -X- _ O
MMT -X- _ B-TaskName
. -X- _ O

Insufficient -X- _ O
Text -X- _ O
Generation -X- _ O

To -X- _ O
know -X- _ O
how -X- _ O
an -X- _ O
image -X- _ O
contributes -X- _ O
to -X- _ O
translation -X- _ O
, -X- _ O
a -X- _ O
way -X- _ O
is -X- _ O
to -X- _ O
mask -X- _ O
some -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
words -X- _ O
( -X- _ O
call -X- _ O
this -X- _ O
insufficient -X- _ O
text -X- _ O
) -X- _ O
and -X- _ O
force -X- _ O
the -X- _ O
translation -X- _ O
model -X- _ O
to -X- _ O
learn -X- _ O
from -X- _ O
the -X- _ O
image -X- _ O
. -X- _ O
Following -X- _ O
the -X- _ O
previous -X- _ O
design -X- _ O
of -X- _ O
color -X- _ O
deprivation -X- _ O
and -X- _ O
entity -X- _ O
- -X- _ O
based -X- _ O
masking -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
detailed -X- _ O
probing -X- _ O
tasks -X- _ O
which -X- _ O
are -X- _ O
complementary -X- _ O
to -X- _ O
Caglayan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
's -X- _ O
work -X- _ O
. -X- _ O
In -X- _ O
preliminary -X- _ O
experiments -X- _ O
1 -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
" -X- _ O
color -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
character -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
noun -X- _ O
" -X- _ O
are -X- _ O
three -X- _ O
kinds -X- _ O
of -X- _ O
words -X- _ O
which -X- _ O
could -X- _ O
be -X- _ O
complemented -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
visual -X- _ O
modality -X- _ O
once -X- _ O
the -X- _ O
corresponding -X- _ O
texts -X- _ O
are -X- _ O
masked -X- _ O
. -X- _ O
The -X- _ O
following -X- _ O
probing -X- _ O
tasks -X- _ O
are -X- _ O
designed -X- _ O
accordingly -X- _ O
. -X- _ O

Color -X- _ O
- -X- _ O
based -X- _ O
Probing -X- _ O

In -X- _ O
training -X- _ O
, -X- _ O
all -X- _ O
source -X- _ O
words -X- _ O
referring -X- _ O
to -X- _ O
a -X- _ O
color -X- _ O
are -X- _ O
replaced -X- _ O
by -X- _ O
a -X- _ O
special -X- _ O
token -X- _ O
[ -X- _ O
Mask_C -X- _ O
] -X- _ O
. -X- _ O
There -X- _ O
are -X- _ O
8 -X- _ O
, -X- _ O
919 -X- _ O
sentences -X- _ O
involving -X- _ O
color -X- _ O
words -X- _ O
, -X- _ O
and -X- _ O
nearly -X- _ O
one -X- _ O
third -X- _ O
of -X- _ O
them -X- _ O
involve -X- _ O
more -X- _ O
than -X- _ O
one -X- _ O
color -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
worth -X- _ O
noting -X- _ O
that -X- _ O
each -X- _ O
color -X- _ O
may -X- _ O
have -X- _ O
two -X- _ O
or -X- _ O
more -X- _ O
translations -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
rich -X- _ O
morphology -X- _ O
in -X- _ O
German -X- _ O
and -X- _ O
French -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
English -X- _ O
" -X- _ O
green -X- _ O
" -X- _ O
can -X- _ O
be -X- _ O
translated -X- _ O
to -X- _ O
" -X- _ O
grün -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
grüne -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
grünes -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
grüner -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
grünen -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
grünem -X- _ O
" -X- _ O
in -X- _ O
German -X- _ O
. -X- _ O
We -X- _ O
design -X- _ O
two -X- _ O
criteria -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
accuracy -X- _ O
of -X- _ O
translation -X- _ O
. -X- _ O
The -X- _ O
first -X- _ O
criterion -X- _ O
is -X- _ O
strict -X- _ O
. -X- _ O
The -X- _ O
correct -X- _ O
translation -X- _ O
requires -X- _ O
generating -X- _ O
the -X- _ O
same -X- _ O
color -X- _ O
and -X- _ O
the -X- _ O
same -X- _ O
gender -X- _ O
as -X- _ O
in -X- _ O
reference -X- _ O
translations -X- _ O
. -X- _ O
The -X- _ O
second -X- _ O
criterion -X- _ O
is -X- _ O
relaxed -X- _ O
and -X- _ O
all -X- _ O
translations -X- _ O
expressing -X- _ O
the -X- _ O
same -X- _ O
color -X- _ O
are -X- _ O
correct -X- _ O
. -X- _ O

Character -X- _ O
- -X- _ O
based -X- _ O
Probing -X- _ O
For -X- _ O
character -X- _ O
words -X- _ O
, -X- _ O
we -X- _ O
choose -X- _ O
" -X- _ O
man -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
woman -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
people -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
men -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
girl -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
boy -X- _ O
" -X- _ O
. -X- _ O
More -X- _ O
than -X- _ O
60 -X- _ O
% -X- _ O
sentences -X- _ O
contain -X- _ O
character -X- _ O
words -X- _ O
in -X- _ O
our -X- _ O
training -X- _ O
data -X- _ O
, -X- _ O
so -X- _ O
they -X- _ O
are -X- _ O
reasonable -X- _ O
indicators -X- _ O
of -X- _ O
assessing -X- _ O
the -X- _ O
ability -X- _ O
to -X- _ O
infer -X- _ O
correct -X- _ O
translations -X- _ O
from -X- _ O
the -X- _ O
input -X- _ O
image -X- _ O
. -X- _ O
Here -X- _ O
we -X- _ O
use -X- _ O
[ -X- _ O
MASK_P -X- _ O
] -X- _ O
for -X- _ O
masking -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
some -X- _ O
character -X- _ O
words -X- _ O
have -X- _ O
more -X- _ O
than -X- _ O
two -X- _ O
translations -X- _ O
, -X- _ O
e.g. -X- _ O
" -X- _ O
people -X- _ O
" -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
evaluation -X- _ O
metric -X- _ O
with -X- _ O
the -X- _ O
color -X- _ O
- -X- _ O
based -X- _ O
probing -X- _ O
task -X- _ O
, -X- _ O
including -X- _ O
relaxed -X- _ O
and -X- _ O
strict -X- _ O
two -X- _ O
criteria -X- _ O
. -X- _ O

Noun -X- _ O
- -X- _ O
based -X- _ O
Probing -X- _ O
For -X- _ O
more -X- _ O
complex -X- _ O
scenarios -X- _ O
, -X- _ O
a -X- _ O
sentence -X- _ O
can -X- _ O
be -X- _ O
masked -X- _ O
with -X- _ O
several -X- _ O
kinds -X- _ O
of -X- _ O
ambiguous -X- _ O
words -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
animals -X- _ O
, -X- _ O
clothing -X- _ O
, -X- _ O
and -X- _ O
vehicles -X- _ O
, -X- _ O
provided -X- _ O
by -X- _ O
Flickr30 -X- _ O
K -X- _ O
( -X- _ O
Plummer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O
High -X- _ O
- -X- _ O
frequency -X- _ O
words -X- _ O
labeled -X- _ O
with -X- _ O
noun -X- _ O
( -X- _ O
or -X- _ O
nouns -X- _ O
) -X- _ O
are -X- _ O
more -X- _ O
likely -X- _ O
to -X- _ O
be -X- _ O
masked -X- _ O
as -X- _ O
[ -X- _ O
MASK_N -X- _ O
] -X- _ O
( -X- _ O
or -X- _ O
[ -X- _ O
MASK_NS -X- _ O
] -X- _ O
) -X- _ O
) -X- _ O
. -X- _ O
See -X- _ O
Table -X- _ O
1 -X- _ O
for -X- _ O
example -X- _ O
insufficient -X- _ O
text -X- _ O
with -X- _ O
different -X- _ O
numbers -X- _ O
of -X- _ O
masks -X- _ O
. -X- _ O

Various -X- _ O
Vision -X- _ O
Features -X- _ O

In -X- _ O
addition -X- _ O
to -X- _ O
ResNet-50 -X- _ B-MethodName
, -X- _ O
we -X- _ O
choose -X- _ O
several -X- _ O
Transformer -X- _ B-MethodName
- -X- _ O
based -X- _ O
vision -X- _ O
models -X- _ O
. -X- _ O

• -X- _ O
General -X- _ O
Backbone -X- _ O
. -X- _ O
Vision -X- _ B-MethodName
Transformer -X- _ I-MethodName
( -X- _ O
ViT -X- _ B-MethodName
) -X- _ O
and -X- _ O
Swin -X- _ B-MethodName
Transformer -X- _ I-MethodName
are -X- _ O
popular -X- _ O
models -X- _ O
in -X- _ O
computer -X- _ O
vision -X- _ O
( -X- _ O
Dosovitskiy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021b -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
ViT -X- _ B-MethodName
with -X- _ O
various -X- _ O
model -X- _ O
capacities -X- _ O
to -X- _ O
vary -X- _ O
from -X- _ O
weak -X- _ O
to -X- _ O
strong -X- _ O
ViT -X- _ B-MethodName
models -X- _ O
. -X- _ O

• -X- _ O
Object -X- _ B-TaskName
- -X- _ I-TaskName
detection -X- _ I-TaskName
. -X- _ O
For -X- _ O
pretrained -X- _ O
objectdetection -X- _ B-TaskName
vision -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
choose -X- _ O
DETR -X- _ B-MethodName
( -X- _ O
Carion -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
QueryInst -X- _ B-MethodName
( -X- _ O
Fang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
for -X- _ O
their -X- _ O
strong -X- _ O
performance -X- _ O
. -X- _ O
• -X- _ O
Image -X- _ B-TaskName
Captioning -X- _ I-TaskName
. -X- _ O
For -X- _ O
image -X- _ B-TaskName
captioning -X- _ I-TaskName
models -X- _ O
, -X- _ O
we -X- _ O
choose -X- _ O
CATR -X- _ B-MethodName
2 -X- _ O
because -X- _ O
it -X- _ O
is -X- _ O
a -X- _ O
Transformer -X- _ B-MethodName
- -X- _ O
based -X- _ O
image -X- _ B-TaskName
captioning -X- _ I-TaskName
architecture -X- _ O
and -X- _ O
can -X- _ O
be -X- _ O
easily -X- _ O
implemented -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
ViT -X- _ B-MethodName
. -X- _ O

We -X- _ O
form -X- _ O
a -X- _ O
number -X- _ O
of -X- _ O
vision -X- _ O
features -X- _ O
by -X- _ O
combining -X- _ O
the -X- _ O
methods -X- _ O
described -X- _ O
above -X- _ O
. -X- _ O
More -X- _ O
details -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
Section -X- _ O
3 -X- _ O
. -X- _ O

Selective -X- _ O
Attention -X- _ O

ViT -X- _ B-MethodName
and -X- _ O
related -X- _ O
models -X- _ O
perform -X- _ O
in -X- _ O
almost -X- _ O
the -X- _ O
same -X- _ O
way -X- _ O
as -X- _ O
Transformer -X- _ B-MethodName
in -X- _ O
NLP -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
Unlike -X- _ O
the -X- _ O
general -X- _ O
models -X- _ O
in -X- _ O
CV -X- _ O
, -X- _ O
ViT -X- _ B-MethodName
does -X- _ O
not -X- _ O
represent -X- _ O
the -X- _ O
image -X- _ O
as -X- _ O
a -X- _ O
single -X- _ O
vector -X- _ O
. -X- _ O
Instead -X- _ O
, -X- _ O
it -X- _ O
generates -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
patches -X- _ O
for -X- _ O
image -X- _ O
representation -X- _ O
. -X- _ O
An -X- _ O
advantage -X- _ O
of -X- _ O
this -X- _ O
design -X- _ O
is -X- _ O
that -X- _ O
we -X- _ O
can -X- _ O
use -X- _ O
the -X- _ O
attention -X- _ O
mechanism -X- _ O
to -X- _ O
correlate -X- _ O
image -X- _ O
patches -X- _ O
to -X- _ O
words -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
a -X- _ O
selective -X- _ O
attention -X- _ O
model -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
patch -X- _ O
- -X- _ O
level -X- _ O
contribution -X- _ O
of -X- _ O
the -X- _ O
image -X- _ O
. -X- _ O
See -X- _ O
Figure -X- _ O
1 -X- _ O
for -X- _ O
the -X- _ O
architecture -X- _ O
. -X- _ O

Text -X- _ O
- -X- _ O
only -X- _ O
Transformer -X- _ B-MethodName
Transformer -X- _ B-MethodName
follows -X- _ O
an -X- _ O
encoder -X- _ O
- -X- _ O
decoder -X- _ O
paradigm -X- _ O
( -X- _ O
the -X- _ O
purple -X- _ O
region -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
encoder -X- _ O
is -X- _ O
a -X- _ O
stack -X- _ O
of -X- _ O
identical -X- _ O
layers -X- _ O
. -X- _ O
Each -X- _ O
layer -X- _ O
consists -X- _ O
of -X- _ O
a -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
( -X- _ O
SAN -X- _ O
) -X- _ O
block -X- _ O
and -X- _ O
a -X- _ O
feedforward -X- _ O
network -X- _ O
( -X- _ O
FFN -X- _ O
) -X- _ O
block -X- _ O
. -X- _ O
The -X- _ O
decoder -X- _ O
shares -X- _ O
a -X- _ O
similar -X- _ O
design -X- _ O
with -X- _ O
the -X- _ O
encoder -X- _ O
, -X- _ O
but -X- _ O
with -X- _ O
an -X- _ O
additional -X- _ O
cross -X- _ O
- -X- _ O
attention -X- _ O
block -X- _ O
. -X- _ O

Gated -X- _ B-MethodName
Fusion -X- _ I-MethodName
Gated -X- _ B-MethodName
fusion -X- _ I-MethodName
mechanism -X- _ O
is -X- _ O
a -X- _ O
popular -X- _ O
technique -X- _ O
for -X- _ O
fusing -X- _ O
representations -X- _ O
from -X- _ O
different -X- _ O
sources -X- _ O
( -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
. -X- _ O
Given -X- _ O
the -X- _ O
text -X- _ O
input -X- _ O
X -X- _ O
text -X- _ O
and -X- _ O
the -X- _ O
image -X- _ O
input -X- _ O
X -X- _ O
img -X- _ O
, -X- _ O
the -X- _ O
text -X- _ O
representation -X- _ O
H -X- _ O
text -X- _ O
and -X- _ O
the -X- _ O
image -X- _ O
feature -X- _ O
H -X- _ O
img -X- _ O
can -X- _ O
be -X- _ O
defined -X- _ O
as -X- _ O
: -X- _ O

H -X- _ O
text -X- _ O
= -X- _ O
TransformerEncoder -X- _ O
( -X- _ O
X -X- _ O
text -X- _ O
) -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
H -X- _ O
img -X- _ O
= -X- _ O
W -X- _ O
ViT -X- _ O
( -X- _ O
X -X- _ O
img -X- _ O
) -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O

where -X- _ O
W -X- _ O
is -X- _ O
a -X- _ O
projection -X- _ O
matrix -X- _ O
to -X- _ O
convert -X- _ O
the -X- _ O
shape -X- _ O
of -X- _ O
ViT -X- _ B-MethodName
( -X- _ O
X -X- _ O
img -X- _ O
) -X- _ O
into -X- _ O
that -X- _ O
of -X- _ O
H -X- _ O
text -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
ViT -X- _ B-MethodName
( -X- _ O
• -X- _ O
) -X- _ O
can -X- _ O
be -X- _ O
replaced -X- _ O
by -X- _ O
other -X- _ O
vision -X- _ O
models -X- _ O
, -X- _ O
e.g. -X- _ O
DETR -X- _ B-MethodName
, -X- _ O
Swin -X- _ B-MethodName
Transformer -X- _ I-MethodName
and -X- _ O
etc -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
the -X- _ O
gate -X- _ O
λ -X- _ O
∈ -X- _ O
[ -X- _ O
0 -X- _ O
, -X- _ O
1 -X- _ O
] -X- _ O
and -X- _ O
the -X- _ O
fuzed -X- _ O
output -X- _ O
are -X- _ O
defined -X- _ O
as -X- _ O
: -X- _ O

λ -X- _ O
= -X- _ O
Sigmoid -X- _ O
( -X- _ O
U -X- _ O
H -X- _ O
text -X- _ O
+ -X- _ O
V -X- _ O
H -X- _ O
img -X- _ O
) -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
H -X- _ O
Out -X- _ O
= -X- _ O
( -X- _ O
1 -X- _ O
− -X- _ O
λ -X- _ O
) -X- _ O
• -X- _ O
H -X- _ O
text -X- _ O
+ -X- _ O
λ -X- _ O
• -X- _ O
H -X- _ O
img -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O

where -X- _ O
U -X- _ O
and -X- _ O
V -X- _ O
are -X- _ O
trainable -X- _ O
variables -X- _ O
. -X- _ O
λ -X- _ O
controls -X- _ O
how -X- _ O
much -X- _ O
visual -X- _ O
information -X- _ O
is -X- _ O
kept -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
the -X- _ O
fusion -X- _ O
vector -X- _ O
H -X- _ O
Out -X- _ O
is -X- _ O
fed -X- _ O
into -X- _ O
the -X- _ O
decoder -X- _ O
. -X- _ O
See -X- _ O
the -X- _ O
right -X- _ O
side -X- _ O
of -X- _ O
the -X- _ O
pink -X- _ O
region -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
for -X- _ O
an -X- _ O
illustration -X- _ O
of -X- _ O
the -X- _ O
gated -X- _ B-MethodName
fusion -X- _ I-MethodName
models -X- _ O
. -X- _ O

Selective -X- _ O
Attention -X- _ O
After -X- _ O
obtaining -X- _ O
the -X- _ O
text -X- _ O
and -X- _ O
image -X- _ O
representations -X- _ O
( -X- _ O
or -X- _ O
features -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
singlehead -X- _ O
attention -X- _ O
network -X- _ O
to -X- _ O
correlate -X- _ O
words -X- _ O
with -X- _ O
image -X- _ O
patches -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
query -X- _ O
, -X- _ O
key -X- _ O
and -X- _ O
value -X- _ O
are -X- _ O
H -X- _ O
text -X- _ O
, -X- _ O
H -X- _ O
img -X- _ O
and -X- _ O
H -X- _ O
img -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
Then -X- _ O
the -X- _ O
selective -X- _ O
attention -X- _ O
output -X- _ O
H -X- _ O
img -X- _ O
attn -X- _ O
is -X- _ O
defined -X- _ O
to -X- _ O
be -X- _ O
: -X- _ O
3 -X- _ O
Experiments -X- _ O

H -X- _ O
img -X- _ O
attn -X- _ O
= -X- _ O
Softmax -X- _ O
( -X- _ O
QK -X- _ O
T -X- _ O
√ -X- _ O
d -X- _ O
k -X- _ O
) -X- _ O
V -X- _ O
( -X- _ O

Datasets -X- _ O

We -X- _ O
conducted -X- _ O
experiments -X- _ O
on -X- _ O
the -X- _ O
widely -X- _ O
used -X- _ O
Multi30 -X- _ B-DatasetName
K -X- _ I-DatasetName
benchmark -X- _ O
. -X- _ O
The -X- _ O
training -X- _ O
and -X- _ O
validation -X- _ O
sets -X- _ O
consisted -X- _ O
of -X- _ O
29 -X- _ O
, -X- _ O
000 -X- _ O
and -X- _ O
1 -X- _ O
, -X- _ O
014 -X- _ O
instances -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
We -X- _ O
reported -X- _ O
the -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
Test2016 -X- _ B-DatasetName
, -X- _ O
Test2017 -X- _ B-DatasetName
and -X- _ O
MSCOCO -X- _ B-DatasetName
test -X- _ O
sets -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
MSCOCO -X- _ B-DatasetName
is -X- _ O
more -X- _ O
challenging -X- _ O
for -X- _ O
MMT -X- _ B-TaskName
models -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
outof -X- _ O
- -X- _ O
domain -X- _ O
instances -X- _ O
with -X- _ O
ambiguous -X- _ O
verbs -X- _ O
. -X- _ O
Following -X- _ O
the -X- _ O
setup -X- _ O
in -X- _ O
( -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
learned -X- _ O
a -X- _ O
joint -X- _ O
BPE -X- _ O
code -X- _ O
for -X- _ O
10 -X- _ O
, -X- _ O
000 -X- _ O
merging -X- _ O
operations -X- _ O
for -X- _ O
both -X- _ O
the -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
languages -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
vocabularies -X- _ O
of -X- _ O
9 -X- _ O
, -X- _ O
716 -X- _ O
and -X- _ O
9 -X- _ O
, -X- _ O
548 -X- _ O
entries -X- _ O
for -X- _ O
the -X- _ O
En -X- _ B-TaskName
- -X- _ I-TaskName
De -X- _ I-TaskName
and -X- _ O
En -X- _ B-TaskName
- -X- _ I-TaskName
Fr -X- _ I-TaskName
tasks -X- _ O
. -X- _ O

Experimental -X- _ O
Setups -X- _ O

We -X- _ O
followed -X- _ O
the -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
's -X- _ O
work -X- _ O
to -X- _ O
conduct -X- _ O
experiments -X- _ O
with -X- _ O
Transformer -X- _ B-MethodName
- -X- _ O
Tiny -X- _ O
configuration -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
more -X- _ O
suited -X- _ O
for -X- _ O
small -X- _ O
datasets -X- _ O
like -X- _ O
Multi30K. -X- _ B-DatasetName
Note -X- _ O
that -X- _ O
smaller -X- _ O
models -X- _ O
even -X- _ O
obtain -X- _ O
higher -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
than -X- _ O
pervious -X- _ O
MMT -X- _ B-TaskName
models -X- _ O
. -X- _ O

Similar -X- _ O
observations -X- _ O
have -X- _ O
been -X- _ O
discussed -X- _ O
when -X- _ O
building -X- _ O
context -X- _ O
- -X- _ O
aware -X- _ O
machine -X- _ O
translation -X- _ O
models -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
consists -X- _ O
of -X- _ O
4 -X- _ O
encoder -X- _ O
and -X- _ O
decoder -X- _ O
layers -X- _ O
. -X- _ O
The -X- _ O
hidden -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
is -X- _ O
128 -X- _ B-HyperparameterValue
and -X- _ O
the -X- _ O
filter -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
FFN -X- _ O
is -X- _ O
256 -X- _ B-HyperparameterValue
. -X- _ O
There -X- _ O
are -X- _ O
4 -X- _ B-HyperparameterValue
heads -X- _ B-HyperparameterName
in -X- _ O
the -X- _ O
multi -X- _ O
- -X- _ O
head -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
mechanism -X- _ O
. -X- _ O
We -X- _ O
set -X- _ O
the -X- _ O
dropout -X- _ B-HyperparameterName
as -X- _ O
0.3 -X- _ B-HyperparameterValue
and -X- _ O
the -X- _ O
label -X- _ B-HyperparameterName
smoothing -X- _ I-HyperparameterName
as -X- _ O
0.1 -X- _ B-HyperparameterValue
. -X- _ O

Our -X- _ O
implementation -X- _ O
was -X- _ O
based -X- _ O
on -X- _ O
Fairseq -X- _ O
( -X- _ O
Ott -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
training -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
Adam -X- _ O
Optimizer -X- _ O
( -X- _ O
Kingma -X- _ O
and -X- _ O
Ba -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
with -X- _ O
β -X- _ B-HyperparameterName
1 -X- _ I-HyperparameterName
= -X- _ O
0.9 -X- _ B-HyperparameterValue
, -X- _ O
β -X- _ B-HyperparameterName
2 -X- _ I-HyperparameterName
= -X- _ O
0.98 -X- _ B-HyperparameterValue
and -X- _ O
= -X- _ O
10 -X- _ B-HyperparameterValue
−8 -X- _ I-HyperparameterValue
. -X- _ O
We -X- _ O
adopted -X- _ O
the -X- _ O
same -X- _ O
learning -X- _ O
rate -X- _ O
schedule -X- _ O
as -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
first -X- _ O
increased -X- _ O
linearly -X- _ O
for -X- _ O
warmup -X- _ B-HyperparameterName
= -X- _ O
2000 -X- _ B-HyperparameterValue
steps -X- _ I-HyperparameterValue
from -X- _ O
1e -X- _ B-HyperparameterValue
−7 -X- _ I-HyperparameterValue
to -X- _ O
5e -X- _ B-HyperparameterValue
−3 -X- _ I-HyperparameterValue
. -X- _ O
After -X- _ O
the -X- _ O
warmup -X- _ O
, -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
decayed -X- _ O
proportionally -X- _ O
to -X- _ O
the -X- _ O
inverse -X- _ O
square -X- _ O
root -X- _ O
of -X- _ O
the -X- _ O
current -X- _ O
step -X- _ O
. -X- _ O
Each -X- _ O
training -X- _ O
batch -X- _ O
contained -X- _ O
4 -X- _ B-HyperparameterValue
, -X- _ I-HyperparameterValue
096 -X- _ I-HyperparameterValue
tokens -X- _ B-HyperparameterName
. -X- _ O
We -X- _ O
also -X- _ O
adopted -X- _ O
the -X- _ O
early -X- _ O
- -X- _ O
stop -X- _ O
training -X- _ O
strategy -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
to -X- _ O
avoid -X- _ O
the -X- _ O
overfitting -X- _ O
issue -X- _ O
. -X- _ O

For -X- _ O
evaluation -X- _ O
, -X- _ O
we -X- _ O
averaged -X- _ O
the -X- _ O
last -X- _ O
10 -X- _ B-HyperparameterValue
checkpoints -X- _ B-HyperparameterName
for -X- _ O
more -X- _ O
reliable -X- _ O
results -X- _ O
. -X- _ O
The -X- _ O
width -X- _ O
of -X- _ O
beam -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
was -X- _ O
set -X- _ O
to -X- _ O
5 -X- _ B-HyperparameterValue
. -X- _ O
The -X- _ O
performance -X- _ O
was -X- _ O
measured -X- _ O
by -X- _ O
BLEU -X- _ B-MetricName
and -X- _ O
METEOR -X- _ B-MetricName
for -X- _ O
all -X- _ O
test -X- _ O
sets -X- _ O
. -X- _ O
Also -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
accuracy -X- _ B-MetricName
for -X- _ O
evaluation -X- _ O
on -X- _ O
the -X- _ O
probing -X- _ O
tasks -X- _ O
. -X- _ O

Results -X- _ O

Table -X- _ O
2 -X- _ O
summarizes -X- _ O
the -X- _ O
results -X- _ O
on -X- _ O
standard -X- _ O
MMT -X- _ B-TaskName
data -X- _ O
. -X- _ O
Each -X- _ O
model -X- _ O
was -X- _ O
evaluated -X- _ O
on -X- _ O
three -X- _ O
test -X- _ O
sets -X- _ O
on -X- _ O
two -X- _ O
language -X- _ O
pairs -X- _ O
. -X- _ O
We -X- _ O
see -X- _ O
, -X- _ O
first -X- _ O
of -X- _ O
all -X- _ O
, -X- _ O
that -X- _ O
the -X- _ O
improvements -X- _ O
of -X- _ O
previous -X- _ O
methods -X- _ O
( -X- _ O
Rows -X- _ O
2 -X- _ O
- -X- _ O
4 -X- _ O
) -X- _ O
over -X- _ O
the -X- _ O
tiny -X- _ O
baseline -X- _ O
are -X- _ O
marginal -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
both -X- _ O
BLEU -X- _ B-MetricName
and -X- _ O
METEOR -X- _ B-MetricName
. -X- _ O
This -X- _ O
confirms -X- _ O
the -X- _ O
assumption -X- _ O
that -X- _ O
the -X- _ O
visual -X- _ O
features -X- _ O
are -X- _ O
not -X- _ O
fully -X- _ O
used -X- _ O
if -X- _ O
the -X- _ O
text -X- _ O
is -X- _ O
complete -X- _ O
( -X- _ O
Caglayan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
When -X- _ O
switching -X- _ O
the -X- _ O
vision -X- _ O
features -X- _ O
from -X- _ O
ResNet -X- _ B-MethodName
( -X- _ O
Row.5 -X- _ O
) -X- _ O
to -X- _ O
ViT -X- _ B-MethodName
( -X- _ O
Row.6 -X- _ O
) -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
no -X- _ O
significant -X- _ O
BLEU -X- _ B-MetricName
gains -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
test -X- _ O
them -X- _ O
on -X- _ O
the -X- _ O
proposed -X- _ O
probing -X- _ O
tasks -X- _ O
to -X- _ O
examine -X- _ O
the -X- _ O
" -X- _ O
real -X- _ O
" -X- _ O
contribution -X- _ O
to -X- _ O
MMT -X- _ B-TaskName
. -X- _ O

Color -X- _ O
- -X- _ O
based -X- _ O
Probing -X- _ O
Table -X- _ O
3 -X- _ O
shows -X- _ O
the -X- _ O
accuracy -X- _ B-MetricName
on -X- _ O
the -X- _ O
color -X- _ O
- -X- _ O
based -X- _ O
probing -X- _ O
task -X- _ O
. -X- _ O
We -X- _ O
see -X- _ O
that -X- _ O
the -X- _ O
accuracy -X- _ B-MetricName
improvement -X- _ O
of -X- _ O
the -X- _ O
gated -X- _ B-MethodName
fusion -X- _ I-MethodName
method -X- _ O
is -X- _ O
marginal -X- _ O
by -X- _ O
both -X- _ O
restrict -X- _ O
and -X- _ O
relaxed -X- _ O
criteria -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
replacing -X- _ O
ResNet -X- _ B-MethodName
with -X- _ O
ViT -X- _ B-MethodName
yields -X- _ O
gains -X- _ O
of -X- _ O
over -X- _ O
8 -X- _ B-MetricValue
accuracy -X- _ B-MetricName
points -X- _ O
across -X- _ O
three -X- _ O
test -X- _ O

Analysis -X- _ O
4.1 -X- _ O
How -X- _ O
Vision -X- _ O
Features -X- _ O
Improve -X- _ O
the -X- _ O
MMT -X- _ B-TaskName

We -X- _ O
further -X- _ O
explore -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
model -X- _ O
capacity -X- _ O
. -X- _ O

Here -X- _ O
, -X- _ O
we -X- _ O
report -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
ViT -X- _ B-MethodName
and -X- _ O
Swin -X- _ B-MethodName
Transformer -X- _ I-MethodName
because -X- _ O
they -X- _ O
are -X- _ O
strong -X- _ O
models -X- _ O
in -X- _ O
recent -X- _ O
studies -X- _ O
. -X- _ O
Our -X- _ O
conjecture -X- _ O
here -X- _ O
is -X- _ O
that -X- _ O
larger -X- _ O
ViT -X- _ B-MethodName
/ -X- _ O
Swin -X- _ B-MethodName
models -X- _ O
can -X- _ O
describe -X- _ O
the -X- _ O
image -X- _ O
more -X- _ O
accurately -X- _ O
, -X- _ O
which -X- _ O
enables -X- _ O
the -X- _ O
text -X- _ O
encoder -X- _ O
to -X- _ O
receive -X- _ O
richer -X- _ O
complementary -X- _ O
information -X- _ O
. -X- _ O
Figure -X- _ O
3 -X- _ O
depicts -X- _ O
the -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
in -X- _ O
progressive -X- _ O
noun -X- _ O
masking -X- _ O
scenarios -X- _ O
. -X- _ O
Intuitively -X- _ O
, -X- _ O
larger -X- _ O
ViT -X- _ B-MethodName
and -X- _ O
Swin -X- _ O
models -X- _ O
provide -X- _ O
more -X- _ O
complementary -X- _ O
knowledge -X- _ O
to -X- _ O
complete -X- _ O
the -X- _ O
insufficient -X- _ O
text -X- _ O
representations -X- _ O
. -X- _ O
Nevertheless -X- _ O
, -X- _ O
a -X- _ O
counterintuitive -X- _ O
phenomenon -X- _ O
is -X- _ O
the -X- _ O
inferiority -X- _ O
of -X- _ O
Swin -X- _ O
across -X- _ O
all -X- _ O
scenarios -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
configuration -X- _ O
, -X- _ O
though -X- _ O
it -X- _ O
outperforms -X- _ O
ViT -X- _ B-MethodName
on -X- _ O
most -X- _ O
computer -X- _ O
vision -X- _ O
benchmarks -X- _ O
. -X- _ O
We -X- _ O
attribute -X- _ O
the -X- _ O
reason -X- _ O
to -X- _ O
the -X- _ O
short -X- _ O
length -X- _ O
of -X- _ O
the -X- _ O
patch -X- _ O
sequence -X- _ O
. -X- _ O
In -X- _ O
patch -X- _ O
, -X- _ O
ViT -X- _ B-MethodName
has -X- _ O
a -X- _ O
length -X- _ O
of -X- _ O
577 -X- _ O
( -X- _ O
576 -X- _ O
sequence -X- _ O
segments -X- _ O
and -X- _ O
a -X- _ O
special -X- _ O
token -X- _ O
CLS -X- _ O
) -X- _ O
when -X- _ O
the -X- _ O
image -X- _ O
resolution -X- _ O
and -X- _ O
the -X- _ O
patch -X- _ O
size -X- _ O
are -X- _ O
384 -X- _ O
× -X- _ O
384 -X- _ O
and -X- _ O
16×16 -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
Swin -X- _ B-MethodName
has -X- _ O
a -X- _ O
fixed -X- _ O
sequence -X- _ O
length -X- _ O
( -X- _ O
49 -X- _ O
) -X- _ O
restricted -X- _ O
by -X- _ O
the -X- _ O
shifted -X- _ O
window -X- _ O
operation -X- _ O
. -X- _ O
This -X- _ O
leads -X- _ O
to -X- _ O
more -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
local -X- _ O
features -X- _ O
for -X- _ O
ViT -X- _ B-MethodName
, -X- _ O
which -X- _ O
is -X- _ O
beneficial -X- _ O
to -X- _ O
the -X- _ O
selective -X- _ O
attention -X- _ O
mechanism -X- _ O
for -X- _ O
extracting -X- _ O
more -X- _ O
relevant -X- _ O
pieces -X- _ O
. -X- _ O

Impact -X- _ O
of -X- _ O
Learning -X- _ O
Objectives -X- _ O

Then -X- _ O
, -X- _ O
we -X- _ O
investigate -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
the -X- _ O
enhanced -X- _ O
vision -X- _ O
features -X- _ O
on -X- _ O
MMT -X- _ B-TaskName
. -X- _ O
Previous -X- _ O
studies -X- _ O
have -X- _ O
already -X- _ O
attempted -X- _ O
to -X- _ O
leverage -X- _ O
object -X- _ O
- -X- _ O
detection -X- _ O
features -X- _ O
Wang -X- _ O
and -X- _ O
Xiong -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
but -X- _ O
the -X- _ O
observation -X- _ O
here -X- _ O
is -X- _ O
slightly -X- _ O
different -X- _ O
. -X- _ O
Beyond -X- _ O
the -X- _ O
object -X- _ B-TaskName
- -X- _ I-TaskName
detection -X- _ I-TaskName
pretrained -X- _ O
features -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
take -X- _ O
the -X- _ O
image -X- _ B-TaskName
captioning -X- _ I-TaskName
task -X- _ O
into -X- _ O
account -X- _ O
. -X- _ O

Rows -X- _ O
11 -X- _ O
- -X- _ O
13 -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
summarize -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
three -X- _ O
enhanced -X- _ O
vision -X- _ O
features -X- _ O
on -X- _ O
the -X- _ O
standard -X- _ O
MMT -X- _ B-TaskName
data -X- _ O
, -X- _ O
and -X- _ O
Figure -X- _ O
4 -X- _ O
depicts -X- _ O
the -X- _ O
results -X- _ O
on -X- _ O
insufficient -X- _ O
texts -X- _ O
. -X- _ O
Here -X- _ O
we -X- _ O
choose -X- _ O
ViT -X- _ B-MethodName
- -X- _ O
Tinybased -X- _ O
models -X- _ O
for -X- _ O
comparison -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
similar -X- _ O
model -X- _ O
capacity -X- _ O
they -X- _ O
own -X- _ O
3 -X- _ O
. -X- _ O
We -X- _ O
see -X- _ O
that -X- _ O
not -X- _ O
only -X- _ O
the -X- _ O
object -X- _ B-TaskName
- -X- _ I-TaskName
detection -X- _ I-TaskName
( -X- _ O
DETR -X- _ B-MethodName
and -X- _ O
QueryInst -X- _ B-MethodName
) -X- _ O
, -X- _ O
but -X- _ O
also -X- _ O
the -X- _ O
image -X- _ B-TaskName
captioning -X- _ I-TaskName
( -X- _ O
CATR -X- _ B-MethodName
) -X- _ O
pretrained -X- _ O
fea- -X- _ O
A -X- _ O
boy -X- _ O
plays -X- _ O
in -X- _ O
the -X- _ O
leaves -X- _ O
among -X- _ O
the -X- _ O
ducks -X- _ O
. -X- _ O

A -X- _ O
boy -X- _ O
plays -X- _ O
in -X- _ O
the -X- _ O
[ -X- _ O
MASK_NS -X- _ O
] -X- _ O
among -X- _ O
the -X- _ O
[ -X- _ O
MASK_NS -X- _ O
] -X- _ O
. -X- _ O

SRC -X- _ O
: -X- _ O
MASK -X- _ O
: -X- _ O

A -X- _ O
woman -X- _ O
is -X- _ O
holding -X- _ O
a -X- _ O
small -X- _ O
white -X- _ O
statue -X- _ O
. -X- _ O

A -X- _ O
[ -X- _ O
MASK_P -X- _ O
] -X- _ O
is -X- _ O
holding -X- _ O
a -X- _ O
small -X- _ O
tures -X- _ O
obtain -X- _ O
superior -X- _ O
performance -X- _ O
compared -X- _ O
with -X- _ O
ViT -X- _ B-MethodName
- -X- _ O
tiny -X- _ O
( -X- _ O
Row -X- _ O
8 -X- _ O
) -X- _ O
when -X- _ O
the -X- _ O
text -X- _ O
is -X- _ O
complete -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
consistent -X- _ O
with -X- _ O
previous -X- _ O
findings -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
advantages -X- _ O
do -X- _ O
not -X- _ O
persist -X- _ O
when -X- _ O
switching -X- _ O
to -X- _ O
limited -X- _ O
text -X- _ O
scenarios -X- _ O
. -X- _ O
A -X- _ O
possible -X- _ O
explanation -X- _ O
is -X- _ O
that -X- _ O
these -X- _ O
methods -X- _ O
are -X- _ O
sensitive -X- _ O
to -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
the -X- _ O
extracted -X- _ O
objects -X- _ O
. -X- _ O
We -X- _ O
leave -X- _ O
this -X- _ O
as -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O

Impact -X- _ O
of -X- _ O
Resolution -X- _ O
and -X- _ O
Patch -X- _ O
Size -X- _ O

It -X- _ O
is -X- _ O
well -X- _ O
- -X- _ O
known -X- _ O
that -X- _ O
higher -X- _ O
resolutions -X- _ O
are -X- _ O
beneficial -X- _ O
to -X- _ O
the -X- _ O
accuracy -X- _ B-MetricName
improvement -X- _ O
in -X- _ O
computer -X- _ O
vision -X- _ O
tasks -X- _ O
( -X- _ O
Dosovitskiy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Despite -X- _ O
the -X- _ O
success -X- _ O
of -X- _ O
the -X- _ O
Transformer -X- _ B-MethodName
architecture -X- _ O
, -X- _ O
recent -X- _ O
studies -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
success -X- _ O
of -X- _ O
ViT -X- _ B-MethodName
mainly -X- _ O
comes -X- _ O
from -X- _ O
the -X- _ O
successful -X- _ O
use -X- _ O
of -X- _ O
the -X- _ O
patch -X- _ O
schema -X- _ O
( -X- _ O
Dosovitskiy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Here -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
MMT -X- _ B-TaskName
systems -X- _ O
with -X- _ O
different -X- _ O
resolutions -X- _ O
and -X- _ O
patch -X- _ O
sizes -X- _ O
based -X- _ O
on -X- _ O
ViT -X- _ B-MethodName
- -X- _ O
Base -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
on -X- _ O
three -X- _ O
probing -X- _ O
tasks -X- _ O
( -X- _ O
see -X- _ O
Table -X- _ O
5 -X- _ O
) -X- _ O
again -X- _ O
confirm -X- _ O
the -X- _ O
above -X- _ O
assumption -X- _ O
that -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
vision -X- _ O
features -X- _ O
are -X- _ O
more -X- _ O
suited -X- _ O
for -X- _ O
the -X- _ O
selective -X- _ O
attention -X- _ O
. -X- _ O
Also -X- _ O
, -X- _ O
the -X- _ O
attention -X- _ O
map -X- _ O
visualized -X- _ O
in -X- _ O
Figure -X- _ O
5 -X- _ O
demonstrates -X- _ O
that -X- _ O
high -X- _ O
resolution -X- _ O
with -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
patch -X- _ O
schema -X- _ O
can -X- _ O
attend -X- _ O
to -X- _ O
correct -X- _ O
regions -X- _ O
of -X- _ O
the -X- _ O
image -X- _ O
for -X- _ O
each -X- _ O
masked -X- _ O
token -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
both -X- _ O
models -X- _ O
pay -X- _ O
the -X- _ O
right -X- _ O
attention -X- _ O
to -X- _ O
the -X- _ O
masked -X- _ O
character -X- _ O
and -X- _ O
noun -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
low -X- _ O
resolution -X- _ O
fails -X- _ O
to -X- _ O
detect -X- _ O
the -X- _ O
right -X- _ O
region -X- _ O
of -X- _ O
color -X- _ O
. -X- _ O
The -X- _ O
finding -X- _ O
here -X- _ O
may -X- _ O
shed -X- _ O
light -X- _ O
to -X- _ O
other -X- _ O
multimodal -X- _ O
tasks -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
VQA -X- _ O
. -X- _ O

Incongruent -X- _ O
Decoding -X- _ O

Incongruent -X- _ O
decoding -X- _ O
is -X- _ O
a -X- _ O
widely -X- _ O
used -X- _ O
manner -X- _ O
to -X- _ O
evaluate -X- _ O
whether -X- _ O
the -X- _ O
visual -X- _ O
modality -X- _ O
contributes -X- _ O
to -X- _ O
the -X- _ O
text -X- _ O
( -X- _ O
Caglayan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
( -X- _ O
Caglayan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
, -X- _ O
2021 -X- _ O
. -X- _ O
Table -X- _ O
6 -X- _ O
shows -X- _ O
that -X- _ O
incongruent -X- _ O
decoding -X- _ O
causes -X- _ O
obvious -X- _ O
BLEU -X- _ B-MetricName
drops -X- _ O
except -X- _ O
for -X- _ O
the -X- _ O
ResNet -X- _ B-MethodName
feature -X- _ O
. -X- _ O
ViT -X- _ B-MethodName
beats -X- _ O
the -X- _ O
ResNet -X- _ B-MethodName
with -X- _ O
gated -X- _ O
fusion -X- _ O
. -X- _ O
It -X- _ O
yields -X- _ O
higher -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
with -X- _ O
congruent -X- _ O
decoding -X- _ O
and -X- _ O
exhibits -X- _ O
a -X- _ O
larger -X- _ O
BLEU -X- _ B-MetricName
drop -X- _ O
with -X- _ O
incongruent -X- _ O
decoding -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
ViT -X- _ B-MethodName
features -X- _ O
learned -X- _ O
from -X- _ O
scratch -X- _ O
are -X- _ O
also -X- _ O
insensitive -X- _ O
to -X- _ O
the -X- _ O
visual -X- _ O
modality -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
reasonable -X- _ O
that -X- _ O
the -X- _ O
learned -X- _ O
vision -X- _ O
systems -X- _ O
are -X- _ O
not -X- _ O
sufficiently -X- _ O
strong -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
data -X- _ O
scarcity -X- _ O
of -X- _ O
Multi30K. -X- _ B-DatasetName
Thus -X- _ O
the -X- _ O
visual -X- _ O
modality -X- _ O
acts -X- _ O
more -X- _ O
like -X- _ O
noise -X- _ O
signals -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
focusing -X- _ O
on -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
pretrained -X- _ O
selective -X- _ O
attention -X- _ O
+ -X- _ O
ViT -X- _ B-MethodName
, -X- _ O
the -X- _ O
gap -X- _ O
between -X- _ O
congruent -X- _ O
and -X- _ O
incongruent -X- _ O
decoding -X- _ O
gradually -X- _ O
becomes -X- _ O
larger -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
investigate -X- _ O
whether -X- _ O
the -X- _ O
ensemble -X- _ O
vision -X- _ O
features -X- _ O
can -X- _ O
help -X- _ O
. -X- _ O
Concretely -X- _ O
, -X- _ O
we -X- _ O
choose -X- _ O
ViT -X- _ B-MethodName
and -X- _ O
CATR -X- _ B-MethodName
to -X- _ O
independently -X- _ O
generate -X- _ O
the -X- _ O
fused -X- _ O
representations -X- _ O
with -X- _ O
the -X- _ O
text -X- _ O
feature -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
the -X- _ O
ensemble -X- _ O
feature -X- _ O
is -X- _ O
obtained -X- _ O
based -X- _ O
on -X- _ O
them -X- _ O
. -X- _ O
We -X- _ O
see -X- _ O
that -X- _ O
the -X- _ O
ensemble -X- _ O
vision -X- _ O
feature -X- _ O
performs -X- _ O
the -X- _ O
best -X- _ O
on -X- _ O
the -X- _ O
congruent -X- _ O
decoding -X- _ O
, -X- _ O
and -X- _ O
achieves -X- _ O
the -X- _ O
largest -X- _ O
( -X- _ O
a -X- _ O
man -X- _ O
is -X- _ O
leaning -X- _ O
on -X- _ O
a -X- _ O
wall -X- _ O
with -X- _ O
trees -X- _ O
on -X- _ O
the -X- _ O
street -X- _ O
. -X- _ O
) -X- _ O
ViT -X- _ B-MethodName
: -X- _ O
ein -X- _ O
kind -X- _ O
lehnt -X- _ O
sich -X- _ O
an -X- _ O
einem -X- _ O
auto -X- _ O
mit -X- _ O
blumen -X- _ O
auf -X- _ O
dem -X- _ O
gehweg -X- _ O
. -X- _ O

( -X- _ O
a -X- _ O
child -X- _ O
is -X- _ O
leaning -X- _ O
on -X- _ O
a -X- _ O
car -X- _ O
with -X- _ O
flowers -X- _ O
on -X- _ O
the -X- _ O
sidewalk -X- _ O
. -X- _ O
) -X- _ O
BLEU -X- _ B-MetricName
gaps -X- _ O
on -X- _ O
four -X- _ O
masking -X- _ O
scenarios -X- _ O
compared -X- _ O
with -X- _ O
other -X- _ O
systems -X- _ O
. -X- _ O
These -X- _ O
results -X- _ O
again -X- _ O
indicate -X- _ O
that -X- _ O
stronger -X- _ O
visual -X- _ O
contexts -X- _ O
indeed -X- _ O
help -X- _ O
. -X- _ O

Case -X- _ O
Study -X- _ O

Finally -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
several -X- _ O
real -X- _ O
cases -X- _ O
. -X- _ O
We -X- _ O
choose -X- _ O
gated -X- _ B-MethodName
fusion -X- _ I-MethodName
( -X- _ O
CNN -X- _ B-MethodName
) -X- _ O
( -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
and -X- _ O
selective -X- _ O
attention -X- _ B-MethodName
+ -X- _ O
ViT_Base -X- _ B-MethodName
( -X- _ O
ViT -X- _ B-MethodName
) -X- _ O
for -X- _ O
comparison -X- _ O
. -X- _ O
The -X- _ O
qualitative -X- _ O
examples -X- _ O
in -X- _ O
Table -X- _ O
7 -X- _ O
demonstrate -X- _ O
that -X- _ O
the -X- _ O
visual -X- _ O
modality -X- _ O
is -X- _ O
complementary -X- _ O
rather -X- _ O
than -X- _ O
redundant -X- _ O
if -X- _ O
the -X- _ O
text -X- _ O
is -X- _ O
insufficient -X- _ O
. -X- _ O
To -X- _ O
figure -X- _ O
out -X- _ O
whether -X- _ O
the -X- _ O
German -X- _ O
translation -X- _ O
is -X- _ O
right -X- _ O
or -X- _ O
not -X- _ O
, -X- _ O
we -X- _ O
provide -X- _ O
the -X- _ O
human -X- _ O
- -X- _ O
translation -X- _ O
results -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
we -X- _ O
see -X- _ O
the -X- _ O
top -X- _ O
half -X- _ O
case -X- _ O
of -X- _ O
Table -X- _ O
7 -X- _ O
, -X- _ O
ViT -X- _ B-MethodName
can -X- _ O
fill -X- _ O
in -X- _ O
the -X- _ O
masked -X- _ O
entities -X- _ O
and -X- _ O
generate -X- _ O
the -X- _ O
correct -X- _ O
translations -X- _ O
even -X- _ O
four -X- _ O
entities -X- _ O
were -X- _ O
masked -X- _ O
. -X- _ O
Unfortunately -X- _ O
, -X- _ O
CNN -X- _ B-MethodName
incorrectly -X- _ O
judges -X- _ O
the -X- _ O
man -X- _ O
as -X- _ O
a -X- _ O
woman -X- _ O
. -X- _ O
Also -X- _ O
, -X- _ O
it -X- _ O
can -X- _ O
not -X- _ O
distinguish -X- _ O
the -X- _ O
right -X- _ O
color -X- _ O
of -X- _ O
shirt -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
complex -X- _ O
background -X- _ O
. -X- _ O
When -X- _ O
given -X- _ O
a -X- _ O
more -X- _ O
complex -X- _ O
image -X- _ O
( -X- _ O
the -X- _ O
bottom -X- _ O
half -X- _ O
case -X- _ O
) -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
still -X- _ O
a -X- _ O
challenge -X- _ O
for -X- _ O
ViT -X- _ B-MethodName
to -X- _ O
generate -X- _ O
the -X- _ O
right -X- _ O
translation -X- _ O
. -X- _ O
The -X- _ O
observation -X- _ O
here -X- _ O
inspires -X- _ O
us -X- _ O
to -X- _ O
design -X- _ O
a -X- _ O
more -X- _ O
powerful -X- _ O
fusion -X- _ O
method -X- _ O
. -X- _ O
Also -X- _ O
, -X- _ O
the -X- _ O
data -X- _ O
scarcity -X- _ O
problem -X- _ O
is -X- _ O
a -X- _ O
root -X- _ O
issue -X- _ O
to -X- _ O
prevent -X- _ O
us -X- _ O
from -X- _ O
further -X- _ O
improving -X- _ O
the -X- _ O
cross -X- _ O
- -X- _ O
modal -X- _ O
translation -X- _ O
quality -X- _ O
. -X- _ O

Related -X- _ O
Work -X- _ O

Multimodal -X- _ B-TaskName
machine -X- _ I-TaskName
translation -X- _ I-TaskName
is -X- _ O
a -X- _ O
cross -X- _ O
- -X- _ O
domain -X- _ O
task -X- _ O
in -X- _ O
the -X- _ O
field -X- _ O
of -X- _ O
machine -X- _ O
translation -X- _ O
. -X- _ O
Early -X- _ O
attempts -X- _ O
mainly -X- _ O
focused -X- _ O
on -X- _ O
enhancing -X- _ O
the -X- _ O
MMT -X- _ B-TaskName
model -X- _ O
by -X- _ O
better -X- _ O
incorporation -X- _ O
of -X- _ O
the -X- _ O
vision -X- _ O
features -X- _ O
( -X- _ O
Calixto -X- _ O
and -X- _ O
Liu -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Elliott -X- _ O
and -X- _ O
Kádár -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Delbrouck -X- _ O
and -X- _ O
Dupont -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
directly -X- _ O
encoding -X- _ O
the -X- _ O
whole -X- _ O
image -X- _ O
feature -X- _ O
brings -X- _ O
additional -X- _ O
noise -X- _ O
to -X- _ O
the -X- _ O
text -X- _ O
( -X- _ O
Yao -X- _ O
and -X- _ O
Wan -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021a -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
address -X- _ O
the -X- _ O
above -X- _ O
issue -X- _ O
, -X- _ O
Yao -X- _ O
and -X- _ O
Wan -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
proposed -X- _ O
a -X- _ O
multimodal -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
to -X- _ O
consider -X- _ O
the -X- _ O
relative -X- _ O
difference -X- _ O
of -X- _ O
information -X- _ O
between -X- _ O
two -X- _ O
modalities -X- _ O
. -X- _ O
Similarly -X- _ O
, -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021a -X- _ O
) -X- _ O
used -X- _ O
a -X- _ O
Gumbel -X- _ O
Softmax -X- _ O
to -X- _ O
achieve -X- _ O
the -X- _ O
same -X- _ O
goal -X- _ O
. -X- _ O

Researchers -X- _ O
also -X- _ O
realize -X- _ O
that -X- _ O
the -X- _ O
visual -X- _ O
modality -X- _ O
may -X- _ O
be -X- _ O
redundant -X- _ O
. -X- _ O
Irrelevant -X- _ O
images -X- _ O
have -X- _ O
little -X- _ O
impact -X- _ O
on -X- _ O
the -X- _ O
translation -X- _ O
quality -X- _ O
, -X- _ O
and -X- _ O
no -X- _ O
significant -X- _ O
BLEU -X- _ B-MetricName
drop -X- _ O
is -X- _ O
observed -X- _ O
even -X- _ O
the -X- _ O
image -X- _ O
is -X- _ O
absent -X- _ O
( -X- _ O
Elliott -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
Encouraging -X- _ O
results -X- _ O
appeared -X- _ O
in -X- _ O
Caglayan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
's -X- _ O
work -X- _ O
. -X- _ O
They -X- _ O
pointed -X- _ O
out -X- _ O
that -X- _ O
the -X- _ O
visual -X- _ O
modality -X- _ O
is -X- _ O
still -X- _ O
useful -X- _ O
when -X- _ O
the -X- _ O
linguistic -X- _ O
context -X- _ O
is -X- _ O
scarce -X- _ O
, -X- _ O
but -X- _ O
is -X- _ O
less -X- _ O
sensitive -X- _ O
when -X- _ O
exposed -X- _ O
to -X- _ O
complete -X- _ O
sentences -X- _ O
. -X- _ O
More -X- _ O
recently -X- _ O
, -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
attributed -X- _ O
the -X- _ O
BLEU -X- _ B-MetricName
gain -X- _ O
on -X- _ O
MMT -X- _ B-TaskName
tasks -X- _ O
to -X- _ O
the -X- _ O
regularization -X- _ O
training -X- _ O
, -X- _ O
and -X- _ O
they -X- _ O
again -X- _ O
emphasized -X- _ O
the -X- _ O
imperative -X- _ O
of -X- _ O
constructing -X- _ O
proper -X- _ O
insufficient -X- _ O
textual -X- _ O
input -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
worthy -X- _ O
to -X- _ O
note -X- _ O
that -X- _ O
the -X- _ O
proposed -X- _ O
probing -X- _ O
task -X- _ O
is -X- _ O
an -X- _ O
improved -X- _ O
version -X- _ O
based -X- _ O
upon -X- _ O
previous -X- _ O
work -X- _ O
( -X- _ O
Caglayan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
opensource -X- _ O
the -X- _ O
preprocessed -X- _ O
data -X- _ O
and -X- _ O
the -X- _ O
corresponding -X- _ O
scripts -X- _ O
for -X- _ O
the -X- _ O
subsequent -X- _ O
researchers -X- _ O
to -X- _ O
experiment -X- _ O
on -X- _ O
. -X- _ O

Another -X- _ O
line -X- _ O
of -X- _ O
research -X- _ O
is -X- _ O
to -X- _ O
explore -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
cross -X- _ O
- -X- _ O
modal -X- _ O
pretraining -X- _ O
models -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
way -X- _ O
, -X- _ O
the -X- _ O
MMT -X- _ B-TaskName
task -X- _ O
is -X- _ O
regarded -X- _ O
as -X- _ O
a -X- _ O
downstream -X- _ O
task -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
CLIP -X- _ O
( -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
general -X- _ O
cross -X- _ O
- -X- _ O
modal -X- _ O
pretraining -X- _ O
model -X- _ O
, -X- _ O
which -X- _ O
learns -X- _ O
to -X- _ O
perform -X- _ O
a -X- _ O
wide -X- _ O
variety -X- _ O
of -X- _ O
tasks -X- _ O
via -X- _ O
natural -X- _ O
language -X- _ O
prompting -X- _ O
. -X- _ O
Caglayan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
presented -X- _ O
a -X- _ O
MMT -X- _ B-TaskName
- -X- _ O
specific -X- _ O
pretraining -X- _ O
model -X- _ O
which -X- _ O
combines -X- _ O
the -X- _ O
translation -X- _ O
language -X- _ O
modeling -X- _ O
with -X- _ O
masked -X- _ O
region -X- _ O
classification -X- _ O
objectives -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
make -X- _ O
a -X- _ O
systematic -X- _ O
study -X- _ O
on -X- _ O
whether -X- _ O
stronger -X- _ O
vision -X- _ O
features -X- _ O
are -X- _ O
helpful -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
extend -X- _ O
the -X- _ O
research -X- _ O
to -X- _ O
enhanced -X- _ O
features -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
object -X- _ B-TaskName
- -X- _ I-TaskName
detection -X- _ I-TaskName
and -X- _ O
image -X- _ B-TaskName
captioning -X- _ I-TaskName
, -X- _ O
which -X- _ O
are -X- _ O
complementary -X- _ O
to -X- _ O
previous -X- _ O
work -X- _ O
. -X- _ O

Conclusions -X- _ O

In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
stronger -X- _ O
vision -X- _ O
features -X- _ O
( -X- _ O
e.g. -X- _ O
ViT -X- _ B-MethodName
- -X- _ O
like -X- _ O
models -X- _ O
) -X- _ O
strengthen -X- _ O
MMT -X- _ B-TaskName
systems -X- _ O
on -X- _ O
three -X- _ O
proposed -X- _ O
probing -X- _ O
tasks -X- _ O
. -X- _ O
We -X- _ O
present -X- _ O
a -X- _ O
selective -X- _ O
attention -X- _ O
method -X- _ O
for -X- _ O
ViT -X- _ B-MethodName
- -X- _ O
based -X- _ O
models -X- _ O
to -X- _ O
make -X- _ O
better -X- _ O
use -X- _ O
of -X- _ O
the -X- _ O
patch -X- _ O
- -X- _ O
level -X- _ O
representation -X- _ O
. -X- _ O
The -X- _ O
result -X- _ O
here -X- _ O
shows -X- _ O
a -X- _ O
promising -X- _ O
line -X- _ O
of -X- _ O
research -X- _ O
on -X- _ O
developing -X- _ O
better -X- _ O
vision -X- _ O
models -X- _ O
for -X- _ O
multimodal -X- _ O
tasks -X- _ O
. -X- _ O
As -X- _ O
far -X- _ O
as -X- _ O
we -X- _ O
know -X- _ O
, -X- _ O
this -X- _ O
is -X- _ O
the -X- _ O
first -X- _ O
attempt -X- _ O
to -X- _ O
build -X- _ O
MMT -X- _ B-TaskName
systems -X- _ O
with -X- _ O
Transformer -X- _ B-MethodName
only -X- _ O
. -X- _ O
In -X- _ O
future -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
are -X- _ O
willing -X- _ O
to -X- _ O
investigate -X- _ O
whether -X- _ O
it -X- _ O
is -X- _ O
possible -X- _ O
to -X- _ O
use -X- _ O
a -X- _ O
single -X- _ O
set -X- _ O
of -X- _ O
parameters -X- _ O
to -X- _ O
encode -X- _ O
the -X- _ O
vision -X- _ O
and -X- _ O
text -X- _ O
modalities -X- _ O
. -X- _ O

Acknowledgments -X- _ O

This -X- _ O
work -X- _ O
was -X- _ O
supported -X- _ O
in -X- _ O
part -X- _ O
by -X- _ O
the -X- _ O
National -X- _ O
Science -X- _ O
Foundation -X- _ O
of -X- _ O
China -X- _ O
( -X- _ O
Nos -X- _ O
. -X- _ O
61732005 -X- _ O
and -X- _ O
61876035 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
National -X- _ O
Key -X- _ O
R -X- _ O
& -X- _ O
D -X- _ O
Project -X- _ O
of -X- _ O
China -X- _ O
( -X- _ O
No -X- _ O
. -X- _ O
2019QY1801 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
China -X- _ O
HTRD -X- _ O
Center -X- _ O
Project -X- _ O
( -X- _ O
No -X- _ O
. -X- _ O
2020AAA0107904 -X- _ O
) -X- _ O
and -X- _ O
Yunnan -X- _ O
Provincial -X- _ O
Major -X- _ O
Science -X- _ O
and -X- _ O
Technology -X- _ O
Special -X- _ O
Plan -X- _ O
Projects -X- _ O
( -X- _ O
Nos -X- _ O
. -X- _ O
201902D08001905 -X- _ O
and -X- _ O
202103AA080015 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
authors -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
thank -X- _ O
anonymous -X- _ O
reviewers -X- _ O
for -X- _ O
their -X- _ O
valuable -X- _ O
comments -X- _ O
. -X- _ O
And -X- _ O
thank -X- _ O
Yufan -X- _ O
Jiang -X- _ O
for -X- _ O
his -X- _ O
helpful -X- _ O
advice -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
paper -X- _ O
. -X- _ O

