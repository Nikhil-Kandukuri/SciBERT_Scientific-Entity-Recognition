-DOCSTART- -X- O
CoMPM -X- _ B-MethodName
: -X- _ O
Context -X- _ B-MethodName
Modeling -X- _ I-MethodName
with -X- _ I-MethodName
Speaker -X- _ I-MethodName
's -X- _ I-MethodName
Pre -X- _ I-MethodName
- -X- _ I-MethodName
trained -X- _ I-MethodName
Memory -X- _ I-MethodName
Tracking -X- _ I-MethodName
for -X- _ O
Emotion -X- _ B-TaskName
Recognition -X- _ I-TaskName
in -X- _ I-TaskName
Conversation -X- _ I-TaskName

As -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
interactive -X- _ O
machines -X- _ O
grow -X- _ O
, -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
Emotion -X- _ B-TaskName
Recognition -X- _ I-TaskName
in -X- _ I-TaskName
Conversation -X- _ I-TaskName
( -X- _ O
ERC -X- _ B-TaskName
) -X- _ O
became -X- _ O
more -X- _ O
important -X- _ O
. -X- _ O
If -X- _ O
the -X- _ O
machine -X- _ O
- -X- _ O
generated -X- _ O
sentences -X- _ O
reflect -X- _ O
emotion -X- _ O
, -X- _ O
more -X- _ O
human -X- _ O
- -X- _ O
like -X- _ O
sympathetic -X- _ O
conversations -X- _ O
are -X- _ O
possible -X- _ O
. -X- _ O
Since -X- _ O
emotion -X- _ B-TaskName
recognition -X- _ I-TaskName
in -X- _ I-TaskName
conversation -X- _ I-TaskName
is -X- _ O
inaccurate -X- _ O
if -X- _ O
the -X- _ O
previous -X- _ O
utterances -X- _ O
are -X- _ O
not -X- _ O
taken -X- _ O
into -X- _ O
account -X- _ O
, -X- _ O
many -X- _ O
studies -X- _ O
reflect -X- _ O
the -X- _ O
dialogue -X- _ O
context -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
performances -X- _ O
. -X- _ O
Many -X- _ O
recent -X- _ O
approaches -X- _ O
show -X- _ O
performance -X- _ O
improvement -X- _ O
by -X- _ O
combining -X- _ O
knowledge -X- _ O
into -X- _ O
modules -X- _ O
learned -X- _ O
from -X- _ O
external -X- _ O
structured -X- _ O
data -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
structured -X- _ O
data -X- _ O
is -X- _ O
difficult -X- _ O
to -X- _ O
access -X- _ O
in -X- _ O
non -X- _ O
- -X- _ O
English -X- _ O
languages -X- _ O
, -X- _ O
making -X- _ O
it -X- _ O
difficult -X- _ O
to -X- _ O
extend -X- _ O
to -X- _ O
other -X- _ O
languages -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
extract -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
memory -X- _ O
using -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
model -X- _ O
as -X- _ O
an -X- _ O
extractor -X- _ O
of -X- _ O
external -X- _ O
knowledge -X- _ O
. -X- _ O
We -X- _ O
introduce -X- _ O
CoMPM -X- _ B-MethodName
, -X- _ O
which -X- _ O
combines -X- _ O
the -X- _ O
speaker -X- _ O
's -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
memory -X- _ O
with -X- _ O
the -X- _ O
context -X- _ O
model -X- _ O
, -X- _ O
and -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
memory -X- _ O
significantly -X- _ O
improves -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
context -X- _ O
model -X- _ O
. -X- _ O
CoMPM -X- _ B-MethodName
achieves -X- _ O
the -X- _ O
first -X- _ O
or -X- _ O
second -X- _ O
performance -X- _ O
on -X- _ O
all -X- _ O
data -X- _ O
and -X- _ O
is -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
among -X- _ O
systems -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
leverage -X- _ O
structured -X- _ O
data -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
our -X- _ O
method -X- _ O
shows -X- _ O
that -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
extended -X- _ O
to -X- _ O
other -X- _ O
languages -X- _ O
because -X- _ O
structured -X- _ O
knowledge -X- _ O
is -X- _ O
not -X- _ O
required -X- _ O
, -X- _ O
unlike -X- _ O
previous -X- _ O
methods -X- _ O
. -X- _ O
Our -X- _ O
code -X- _ O
is -X- _ O
available -X- _ O
on -X- _ O
github -X- _ O
1 -X- _ O
. -X- _ O

Introduction -X- _ O

As -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
applications -X- _ O
such -X- _ O
as -X- _ O
interactive -X- _ O
chatbots -X- _ O
or -X- _ O
social -X- _ O
media -X- _ O
that -X- _ O
are -X- _ O
used -X- _ O
by -X- _ O
many -X- _ O
users -X- _ O
has -X- _ O
recently -X- _ O
increased -X- _ O
dramatically -X- _ O
, -X- _ O
Emotion -X- _ B-TaskName
Recognition -X- _ I-TaskName
in -X- _ I-TaskName
Conversation -X- _ I-TaskName
( -X- _ O
ERC -X- _ B-TaskName
) -X- _ O
plays -X- _ O
a -X- _ O
more -X- _ O
important -X- _ O
role -X- _ O
in -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
, -X- _ O
and -X- _ O
as -X- _ O
a -X- _ O
proof -X- _ O
, -X- _ O
a -X- _ O
lot -X- _ O
of -X- _ O
research -X- _ O
Ghosal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Jiao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
has -X- _ O
been -X- _ O
conducted -X- _ O
on -X- _ O
the -X- _ O
task -X- _ O
. -X- _ O

The -X- _ O
ERC -X- _ B-TaskName
module -X- _ O
increases -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
empathetic -X- _ O
conversations -X- _ O
with -X- _ O
the -X- _ O
users -X- _ O
and -X- _ O
can -X- _ O
be -X- _ O
1 -X- _ O
https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
github.com -X- _ O
/ -X- _ O
rungjoo -X- _ O
/ -X- _ O
CoMPM -X- _ B-MethodName
Figure -X- _ O
1 -X- _ O
: -X- _ O
An -X- _ O
example -X- _ O
of -X- _ O
MELD -X- _ B-DatasetName
dataset -X- _ O
utilized -X- _ O
when -X- _ O
sending -X- _ O
tailored -X- _ O
push -X- _ O
messages -X- _ O
to -X- _ O
the -X- _ O
users -X- _ O
( -X- _ O
Shin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Zandie -X- _ O
and -X- _ O
Mahoor -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
emotion -X- _ B-TaskName
recognition -X- _ I-TaskName
can -X- _ O
be -X- _ O
effectively -X- _ O
used -X- _ O
for -X- _ O
opinion -X- _ O
mining -X- _ O
, -X- _ O
recommender -X- _ O
systems -X- _ O
, -X- _ O
and -X- _ O
healthcare -X- _ O
systems -X- _ O
where -X- _ O
it -X- _ O
can -X- _ O
improve -X- _ O
the -X- _ O
service -X- _ O
qualities -X- _ O
by -X- _ O
providing -X- _ O
personalized -X- _ O
results -X- _ O
. -X- _ O
As -X- _ O
these -X- _ O
interactive -X- _ O
machines -X- _ O
increase -X- _ O
, -X- _ O
the -X- _ O
ERC -X- _ B-TaskName
module -X- _ O
plays -X- _ O
an -X- _ O
increasingly -X- _ O
important -X- _ O
role -X- _ O
. -X- _ O
Figure -X- _ O
1 -X- _ O
is -X- _ O
an -X- _ O
example -X- _ O
of -X- _ O
a -X- _ O
conversation -X- _ O
in -X- _ O
which -X- _ O
two -X- _ O
speakers -X- _ O
are -X- _ O
angry -X- _ O
at -X- _ O
each -X- _ O
other -X- _ O
. -X- _ O
The -X- _ O
emotion -X- _ O
of -X- _ O
speaker -X- _ O
B -X- _ O
's -X- _ O
utterance -X- _ O
( -X- _ O
" -X- _ O
How -X- _ O
'd -X- _ O
you -X- _ O
get -X- _ O
to -X- _ O
that -X- _ O
? -X- _ O
" -X- _ O
) -X- _ O
is -X- _ O
angry -X- _ O
. -X- _ O
If -X- _ O
the -X- _ O
system -X- _ O
does -X- _ O
not -X- _ O
take -X- _ O
into -X- _ O
account -X- _ O
previous -X- _ O
utterances -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
difficult -X- _ O
to -X- _ O
properly -X- _ O
recognize -X- _ O
emotions -X- _ O
. -X- _ O
Like -X- _ O
the -X- _ O
previous -X- _ O
studies -X- _ O
( -X- _ O
Ghosal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
utterance -X- _ O
- -X- _ O
level -X- _ O
emotion -X- _ O
recognition -X- _ O
, -X- _ O
which -X- _ O
does -X- _ O
not -X- _ O
consider -X- _ O
the -X- _ O
previous -X- _ O
utterance -X- _ O
, -X- _ O
have -X- _ O
limitations -X- _ O
and -X- _ O
experiments -X- _ O
result -X- _ O
in -X- _ O
poor -X- _ O
performances -X- _ O
. -X- _ O

Therefore -X- _ O
, -X- _ O
recent -X- _ O
studies -X- _ O
are -X- _ O
attempting -X- _ O
to -X- _ O
recognize -X- _ O
emotions -X- _ O
while -X- _ O
taking -X- _ O
into -X- _ O
account -X- _ O
the -X- _ O
previous -X- _ O
utterances -X- _ O
. -X- _ O
Representatively -X- _ O
, -X- _ O
Dia -X- _ O
- -X- _ O
logueRNN -X- _ O
recognizes -X- _ O
the -X- _ O
present -X- _ O
emotion -X- _ O
by -X- _ O
tracking -X- _ O
context -X- _ O
from -X- _ O
the -X- _ O
previous -X- _ O
utterances -X- _ O
and -X- _ O
the -X- _ O
speaker -X- _ O
's -X- _ O
emotion -X- _ O
. -X- _ O
AGHMN -X- _ O
( -X- _ O
Jiao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
considers -X- _ O
the -X- _ O
previous -X- _ O
utterances -X- _ O
through -X- _ O
memory -X- _ O
summarizing -X- _ O
using -X- _ O
GRU -X- _ O
with -X- _ O
attention -X- _ O
. -X- _ O

Many -X- _ O
recent -X- _ O
studies -X- _ O
use -X- _ O
external -X- _ O
knowledge -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
ERC -X- _ B-TaskName
performance -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
this -X- _ O
exter -X- _ O
- -X- _ O
nal -X- _ O
knowledge -X- _ O
is -X- _ O
often -X- _ O
only -X- _ O
available -X- _ O
in -X- _ O
English -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
utilize -X- _ O
the -X- _ O
previous -X- _ O
methods -X- _ O
in -X- _ O
languages -X- _ O
of -X- _ O
other -X- _ O
countries -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
expensive -X- _ O
and -X- _ O
difficult -X- _ O
to -X- _ O
utilize -X- _ O
because -X- _ O
external -X- _ O
knowledge -X- _ O
data -X- _ O
must -X- _ O
be -X- _ O
newly -X- _ O
constructed -X- _ O
. -X- _ O
In -X- _ O
recent -X- _ O
NLP -X- _ O
studies -X- _ O
, -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
model -X- _ O
, -X- _ O
it -X- _ O
has -X- _ O
already -X- _ O
been -X- _ O
developed -X- _ O
in -X- _ O
many -X- _ O
countries -X- _ O
. -X- _ O
Since -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
are -X- _ O
trained -X- _ O
by -X- _ O
unsupervised -X- _ O
learning -X- _ O
, -X- _ O
these -X- _ O
models -X- _ O
are -X- _ O
relatively -X- _ O
usable -X- _ O
approaches -X- _ O
regardless -X- _ O
of -X- _ O
language -X- _ O
types -X- _ O
. -X- _ O
Petroni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
introduces -X- _ O
that -X- _ O
these -X- _ O
language -X- _ O
models -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
as -X- _ O
knowledge -X- _ O
bases -X- _ O
and -X- _ O
have -X- _ O
many -X- _ O
advantages -X- _ O
over -X- _ O
the -X- _ O
structured -X- _ O
knowledge -X- _ O
bases -X- _ O
. -X- _ O
Based -X- _ O
on -X- _ O
these -X- _ O
studies -X- _ O
, -X- _ O
we -X- _ O
eliminate -X- _ O
the -X- _ O
dependence -X- _ O
on -X- _ O
structured -X- _ O
external -X- _ O
data -X- _ O
used -X- _ O
in -X- _ O
cutting -X- _ O
- -X- _ O
edge -X- _ O
systems -X- _ O
and -X- _ O
use -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
model -X- _ O
as -X- _ O
a -X- _ O
feature -X- _ O
extractor -X- _ O
of -X- _ O
knowledge -X- _ O
. -X- _ O

CoMPM -X- _ B-MethodName
, -X- _ O
introduced -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
is -X- _ O
composed -X- _ O
of -X- _ O
two -X- _ O
modules -X- _ O
that -X- _ O
take -X- _ O
into -X- _ O
account -X- _ O
previous -X- _ O
utterances -X- _ O
in -X- _ O
dialogue -X- _ O
. -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
The -X- _ O
first -X- _ O
is -X- _ O
a -X- _ O
context -X- _ O
embedding -X- _ O
module -X- _ O
( -X- _ O
CoM -X- _ O
) -X- _ O
that -X- _ O
reflects -X- _ O
all -X- _ O
previous -X- _ O
utterances -X- _ O
as -X- _ O
context -X- _ O
. -X- _ O
CoM -X- _ O
is -X- _ O
an -X- _ O
auto -X- _ O
- -X- _ O
regressive -X- _ O
model -X- _ O
that -X- _ O
predicts -X- _ O
the -X- _ O
current -X- _ O
emotion -X- _ O
through -X- _ O
attention -X- _ O
between -X- _ O
the -X- _ O
previous -X- _ O
utterances -X- _ O
of -X- _ O
the -X- _ O
conversation -X- _ O
and -X- _ O
the -X- _ O
current -X- _ O
utterance -X- _ O
. -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
The -X- _ O
second -X- _ O
is -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
memory -X- _ O
module -X- _ O
( -X- _ O
PM -X- _ O
) -X- _ O
that -X- _ O
extracts -X- _ O
memory -X- _ O
from -X- _ O
utterances -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
model -X- _ O
as -X- _ O
the -X- _ O
memory -X- _ O
embedding -X- _ O
where -X- _ O
the -X- _ O
utterances -X- _ O
are -X- _ O
passed -X- _ O
into -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
PM -X- _ O
to -X- _ O
help -X- _ O
predict -X- _ O
the -X- _ O
emotion -X- _ O
of -X- _ O
the -X- _ O
speaker -X- _ O
by -X- _ O
taking -X- _ O
into -X- _ O
account -X- _ O
the -X- _ O
speaker -X- _ O
's -X- _ O
linguistic -X- _ O
preferences -X- _ O
and -X- _ O
characteristics -X- _ O
. -X- _ O

We -X- _ O
experiment -X- _ O
on -X- _ O
4 -X- _ O
different -X- _ O
English -X- _ O
ERC -X- _ B-TaskName
datasets -X- _ O
. -X- _ O
Multi -X- _ O
- -X- _ O
party -X- _ O
datasets -X- _ O
are -X- _ O
MELD -X- _ B-DatasetName
and -X- _ O
EmoryNLP -X- _ B-DatasetName
( -X- _ O
Zahiri -X- _ O
and -X- _ O
Choi -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
dyadic -X- _ O
datasets -X- _ O
are -X- _ O
IEMOCAP -X- _ B-DatasetName
( -X- _ O
Busso -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
and -X- _ O
DailyDialog -X- _ B-DatasetName
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
CoMPM -X- _ B-MethodName
achieves -X- _ O
the -X- _ O
first -X- _ O
or -X- _ O
second -X- _ O
performance -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
evaluation -X- _ O
metric -X- _ O
compared -X- _ O
to -X- _ O
all -X- _ O
previous -X- _ O
systems -X- _ O
. -X- _ O
We -X- _ O
perform -X- _ O
an -X- _ O
ablation -X- _ O
study -X- _ O
on -X- _ O
each -X- _ O
module -X- _ O
to -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
proposed -X- _ O
approach -X- _ O
is -X- _ O
effective -X- _ O
. -X- _ O
Further -X- _ O
experiments -X- _ O
also -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
approach -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
in -X- _ O
other -X- _ O
languages -X- _ O
and -X- _ O
show -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
CoMPM -X- _ B-MethodName
when -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
data -X- _ O
is -X- _ O
limited -X- _ O
. -X- _ O

Related -X- _ O
Work -X- _ O

Many -X- _ O
recent -X- _ O
studies -X- _ O
use -X- _ O
external -X- _ O
knowledge -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
ERC -X- _ B-TaskName
performance -X- _ O
. -X- _ O
KET -X- _ O
( -X- _ O
Zhong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
is -X- _ O
used -X- _ O
as -X- _ O
external -X- _ O
knowledge -X- _ O
based -X- _ O
on -X- _ O
ConceptNet -X- _ O
( -X- _ O
Speer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
and -X- _ O
emotion -X- _ O
lex -X- _ O
- -X- _ O
icon -X- _ O
NRC_VAD -X- _ O
( -X- _ O
Mohammad -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
as -X- _ O
the -X- _ O
commonsense -X- _ O
knowledge -X- _ O
. -X- _ O
ConceptNet -X- _ O
is -X- _ O
a -X- _ O
knowledge -X- _ O
graph -X- _ O
that -X- _ O
connects -X- _ O
words -X- _ O
and -X- _ O
phrases -X- _ O
in -X- _ O
natural -X- _ O
language -X- _ O
using -X- _ O
labeled -X- _ O
edges -X- _ O
. -X- _ O
NRC_VAD -X- _ O
Lexicon -X- _ O
has -X- _ O
human -X- _ O
ratings -X- _ O
of -X- _ O
valence -X- _ O
, -X- _ O
arousal -X- _ O
, -X- _ O
and -X- _ O
dominance -X- _ O
for -X- _ O
more -X- _ O
than -X- _ O
20,000 -X- _ O
English -X- _ O
words -X- _ O
. -X- _ O
COSMIC -X- _ O
( -X- _ O
Ghosal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
Psychological -X- _ O
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
improve -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
emotion -X- _ O
recognition -X- _ O
by -X- _ O
extracting -X- _ O
commonsense -X- _ O
knowledge -X- _ O
of -X- _ O
the -X- _ O
previous -X- _ O
utterances -X- _ O
. -X- _ O
Commonsense -X- _ O
knowledge -X- _ O
feature -X- _ O
is -X- _ O
extracted -X- _ O
and -X- _ O
leveraged -X- _ O
with -X- _ O
COMET -X- _ O
( -X- _ O
Bosselut -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
trained -X- _ O
with -X- _ O
ATOMIC -X- _ O
( -X- _ O
The -X- _ O
Atlas -X- _ O
of -X- _ O
Machine -X- _ O
Commonsense -X- _ O
) -X- _ O
. -X- _ O
ATOMIC -X- _ O
has -X- _ O
9 -X- _ O
sentence -X- _ O
relation -X- _ O
types -X- _ O
with -X- _ O
inferential -X- _ O
if -X- _ O
- -X- _ O
then -X- _ O
commonsense -X- _ O
knowledge -X- _ O
expressed -X- _ O
in -X- _ O
text -X- _ O
. -X- _ O
ToDKAT -X- _ O
( -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
improves -X- _ O
performance -X- _ O
by -X- _ O
combining -X- _ O
commonsense -X- _ O
knowledge -X- _ O
using -X- _ O
COMET -X- _ O
and -X- _ O
topic -X- _ O
discovery -X- _ O
using -X- _ O
VHRED -X- _ O
( -X- _ O
Serban -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
to -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O

Ekman -X- _ O
( -X- _ O
Ekman -X- _ O
, -X- _ O
1992 -X- _ O
) -X- _ O
constructs -X- _ O
taxonomy -X- _ O
of -X- _ O
six -X- _ O
common -X- _ O
emotions -X- _ O
( -X- _ O
Joy -X- _ O
, -X- _ O
Sadness -X- _ O
, -X- _ O
Fear -X- _ O
, -X- _ O
Anger -X- _ O
, -X- _ O
Surprise -X- _ O
, -X- _ O
and -X- _ O
Disgust -X- _ O
) -X- _ O
from -X- _ O
human -X- _ O
facial -X- _ O
expressions -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
Ekman -X- _ O
explains -X- _ O
that -X- _ O
a -X- _ O
multimodal -X- _ O
view -X- _ O
is -X- _ O
important -X- _ O
for -X- _ O
multiple -X- _ O
emotions -X- _ O
recognition -X- _ O
. -X- _ O
The -X- _ O
multi -X- _ O
- -X- _ O
modal -X- _ O
data -X- _ O
such -X- _ O
as -X- _ O
MELD -X- _ B-DatasetName
and -X- _ O
IEMOCAP -X- _ B-DatasetName
are -X- _ O
some -X- _ O
of -X- _ O
the -X- _ O
available -X- _ O
standard -X- _ O
datasets -X- _ O
for -X- _ O
emotion -X- _ O
recognition -X- _ O
and -X- _ O
they -X- _ O
are -X- _ O
composed -X- _ O
of -X- _ O
text -X- _ O
, -X- _ O
speech -X- _ O
and -X- _ O
vision -X- _ O
- -X- _ O
based -X- _ O
data -X- _ O
. -X- _ O
Datcu -X- _ O
and -X- _ O
Rothkrantz -X- _ O
( -X- _ O
2014 -X- _ O
) -X- _ O
uses -X- _ O
speech -X- _ O
and -X- _ O
visual -X- _ O
information -X- _ O
to -X- _ O
recognize -X- _ O
emotions -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
Alm -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
attempts -X- _ O
to -X- _ O
recognize -X- _ O
emotions -X- _ O
based -X- _ O
on -X- _ O
text -X- _ O
information -X- _ O
. -X- _ O
MELD -X- _ B-DatasetName
and -X- _ O
ICON -X- _ O
( -X- _ O
Hazarika -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018a -X- _ O
) -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
more -X- _ O
multi -X- _ O
- -X- _ O
modal -X- _ O
information -X- _ O
is -X- _ O
used -X- _ O
, -X- _ O
the -X- _ O
better -X- _ O
the -X- _ O
performance -X- _ O
and -X- _ O
the -X- _ O
text -X- _ O
information -X- _ O
plays -X- _ O
the -X- _ O
most -X- _ O
important -X- _ O
role -X- _ O
. -X- _ O
Multimodal -X- _ O
information -X- _ O
is -X- _ O
not -X- _ O
always -X- _ O
given -X- _ O
in -X- _ O
most -X- _ O
social -X- _ O
media -X- _ O
, -X- _ O
especially -X- _ O
in -X- _ O
chatbot -X- _ O
systems -X- _ O
where -X- _ O
they -X- _ O
are -X- _ O
mainly -X- _ O
composed -X- _ O
of -X- _ O
text -X- _ O
- -X- _ O
based -X- _ O
systems -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
design -X- _ O
and -X- _ O
introduce -X- _ O
a -X- _ O
text -X- _ O
- -X- _ O
based -X- _ O
emotion -X- _ B-TaskName
recognition -X- _ I-TaskName
system -X- _ O
using -X- _ O
neural -X- _ O
networks -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
previous -X- _ O
studies -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
Hazarika -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018b -X- _ O
) -X- _ O
; -X- _ O
Zadeh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
; -X- _ O
, -X- _ O
most -X- _ O
works -X- _ O
focused -X- _ O
on -X- _ O
dyadic -X- _ O
- -X- _ O
party -X- _ O
conversation -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
multi -X- _ O
- -X- _ O
party -X- _ O
conversation -X- _ O
datasets -X- _ O
including -X- _ O
MELD -X- _ B-DatasetName
and -X- _ O
EmoryNLP -X- _ B-DatasetName
have -X- _ O
become -X- _ O
available -X- _ O
, -X- _ O
a -X- _ O
lot -X- _ O
of -X- _ O
recent -X- _ O
research -X- _ O
is -X- _ O
being -X- _ O
conducted -X- _ O
on -X- _ O
multi -X- _ O
- -X- _ O
party -X- _ O
dialogues -X- _ O
such -X- _ O
as -X- _ O
; -X- _ O
Jiao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
; -X- _ O
Ghosal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
general -X- _ O
, -X- _ O
the -X- _ O
multi -X- _ O
- -X- _ O
party -X- _ O
conversations -X- _ O
have -X- _ O
higher -X- _ O
speaker -X- _ O
dependency -X- _ O
than -X- _ O
the -X- _ O
dyadic -X- _ O
- -X- _ O
party -X- _ O
dialogues -X- _ O
, -X- _ O
therefore -X- _ O
have -X- _ O
more -X- _ O
conditions -X- _ O
to -X- _ O
consider -X- _ O
and -X- _ O
result -X- _ O
in -X- _ O
poor -X- _ O
performance -X- _ O
. -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
; -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018a -X- _ O
) -X- _ O
shows -X- _ O
that -X- _ O
commonsense -X- _ O
knowledge -X- _ O
is -X- _ O
important -X- _ O
for -X- _ O
understanding -X- _ O
conversations -X- _ O
and -X- _ O
generating -X- _ O
appropriate -X- _ O
responses -X- _ O
. -X- _ O
reports -X- _ O
that -X- _ O
the -X- _ O
lack -X- _ O
of -X- _ O
external -X- _ O
knowledge -X- _ O
makes -X- _ O
it -X- _ O
difficult -X- _ O
to -X- _ O
classify -X- _ O
implicit -X- _ O
emotions -X- _ O
from -X- _ O
the -X- _ O
conversation -X- _ O
history -X- _ O
. -X- _ O
EDA -X- _ O
( -X- _ O
Bothe -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
expands -X- _ O
the -X- _ O
multi -X- _ O
- -X- _ O
modal -X- _ O
emotion -X- _ O
datasets -X- _ O
by -X- _ O
extracting -X- _ O
dialog -X- _ O
acts -X- _ O
from -X- _ O
MELD -X- _ B-DatasetName
and -X- _ O
IEMOCAP -X- _ B-DatasetName
and -X- _ O
finds -X- _ O
out -X- _ O
that -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
correlation -X- _ O
between -X- _ O
dialogue -X- _ O
acts -X- _ O
and -X- _ O
emotion -X- _ O
labels -X- _ O
. -X- _ O

Approach -X- _ O

Problem -X- _ O
Statement -X- _ O

In -X- _ O
a -X- _ O
conversation -X- _ O
, -X- _ O
M -X- _ O
sequential -X- _ O
utterances -X- _ O
are -X- _ O
given -X- _ O
as -X- _ O
[ -X- _ O
( -X- _ O
u -X- _ O
1 -X- _ O
, -X- _ O
p -X- _ O
u -X- _ O
1 -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
u -X- _ O
2 -X- _ O
, -X- _ O
p -X- _ O
u -X- _ O
2 -X- _ O
) -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
( -X- _ O
u -X- _ O
M -X- _ O
, -X- _ O
p -X- _ O
u -X- _ O
M -X- _ O
) -X- _ O
] -X- _ O
. -X- _ O
u -X- _ O
i -X- _ O
is -X- _ O
the -X- _ O
utterance -X- _ O
which -X- _ O
the -X- _ O
speaker -X- _ O
p -X- _ O
u -X- _ O
i -X- _ O
uttered -X- _ O
, -X- _ O
where -X- _ O
p -X- _ O
u -X- _ O
i -X- _ O
is -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
conversation -X- _ O
participants -X- _ O
. -X- _ O
While -X- _ O
p -X- _ O
u -X- _ O
i -X- _ O
and -X- _ O
p -X- _ O
u -X- _ O
j -X- _ O
( -X- _ O
i -X- _ O
̸ -X- _ O
= -X- _ O
j -X- _ O
) -X- _ O
can -X- _ O
be -X- _ O
the -X- _ O
same -X- _ O
speaker -X- _ O
, -X- _ O
the -X- _ O
minimum -X- _ O
number -X- _ O
of -X- _ O
the -X- _ O
unique -X- _ O
conversation -X- _ O
participants -X- _ O
should -X- _ O
be -X- _ O
2 -X- _ O
or -X- _ O
more -X- _ O
. -X- _ O
The -X- _ O
ERC -X- _ B-TaskName
is -X- _ O
a -X- _ O
task -X- _ O
of -X- _ O
predicting -X- _ O
the -X- _ O
emotion -X- _ O
e -X- _ O
t -X- _ O
of -X- _ O
u -X- _ O
t -X- _ O
, -X- _ O
the -X- _ O
utterance -X- _ O
of -X- _ O
the -X- _ O
t -X- _ O
- -X- _ O
th -X- _ O
turn -X- _ O
, -X- _ O
given -X- _ O
the -X- _ O
previous -X- _ O
utterances -X- _ O
h -X- _ O
t -X- _ O
= -X- _ O
{ -X- _ O
u -X- _ O
1 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
u -X- _ O
t−1 -X- _ O
} -X- _ O
. -X- _ O
Emotions -X- _ O
are -X- _ O
labeled -X- _ O
as -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
predefined -X- _ O
classes -X- _ O
depending -X- _ O
on -X- _ O
the -X- _ O
dataset -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
emotions -X- _ O
we -X- _ O
experimented -X- _ O
with -X- _ O
are -X- _ O
either -X- _ O
6 -X- _ O
or -X- _ O
7 -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
experimented -X- _ O
with -X- _ O
a -X- _ O
sentiment -X- _ O
classification -X- _ O
dataset -X- _ O
which -X- _ O
provides -X- _ O
sentiment -X- _ O
labels -X- _ O
consisting -X- _ O
of -X- _ O
positive -X- _ O
, -X- _ O
negative -X- _ O
and -X- _ O
neutral -X- _ O
. -X- _ O

Model -X- _ O
Overview -X- _ O

Figure -X- _ O
2 -X- _ O
shows -X- _ O
an -X- _ O
overview -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
. -X- _ O
Our -X- _ O
ERC -X- _ B-TaskName
neural -X- _ O
network -X- _ O
model -X- _ O
is -X- _ O
composed -X- _ O
of -X- _ O
two -X- _ O
modules -X- _ O
. -X- _ O
The -X- _ O
first -X- _ O
is -X- _ O
CoM -X- _ O
which -X- _ O
catches -X- _ O
the -X- _ O
underlying -X- _ O
effect -X- _ O
of -X- _ O
all -X- _ O
previous -X- _ O
utterances -X- _ O
on -X- _ O
the -X- _ O
current -X- _ O
speaker -X- _ O
's -X- _ O
emotions -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
context -X- _ O
model -X- _ O
to -X- _ O
handle -X- _ O
the -X- _ O
relationship -X- _ O
between -X- _ O
the -X- _ O
current -X- _ O
and -X- _ O
the -X- _ O
previous -X- _ O
utterances -X- _ O
. -X- _ O
The -X- _ O
second -X- _ O
one -X- _ O
is -X- _ O
PM -X- _ O
that -X- _ O
leverages -X- _ O
only -X- _ O
the -X- _ O
speaker -X- _ O
's -X- _ O
previous -X- _ O
utterances -X- _ O
, -X- _ O
through -X- _ O
which -X- _ O
we -X- _ O
want -X- _ O
to -X- _ O
reflect -X- _ O
the -X- _ O
speaker -X- _ O
's -X- _ O
knowledge -X- _ O
. -X- _ O

If -X- _ O
the -X- _ O
CoM -X- _ O
and -X- _ O
PM -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
different -X- _ O
backbones -X- _ O
, -X- _ O
we -X- _ O
consider -X- _ O
them -X- _ O
to -X- _ O
be -X- _ O
unaligned -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
each -X- _ O
other -X- _ O
's -X- _ O
output -X- _ O
representations -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
design -X- _ O
the -X- _ O
PM -X- _ O
to -X- _ O
follow -X- _ O
CoM -X- _ O
so -X- _ O
that -X- _ O
the -X- _ O
output -X- _ O
representations -X- _ O
of -X- _ O
CoM -X- _ O
and -X- _ O
PM -X- _ O
can -X- _ O
mutually -X- _ O
understand -X- _ O
each -X- _ O
other -X- _ O
. -X- _ O
If -X- _ O
CoM -X- _ O
and -X- _ O
PM -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
different -X- _ O
architectures -X- _ O
, -X- _ O
CoMPM -X- _ B-MethodName
is -X- _ O
trained -X- _ O
to -X- _ O
understand -X- _ O
each -X- _ O
other -X- _ O
's -X- _ O
representations -X- _ O
by -X- _ O
matching -X- _ O
dimensions -X- _ O
using -X- _ O
W -X- _ O
p -X- _ O
in -X- _ O
Equation -X- _ O
4 -X- _ O
. -X- _ O
The -X- _ O
combination -X- _ O
of -X- _ O
CoM -X- _ O
and -X- _ O
PM -X- _ O
is -X- _ O
described -X- _ O
in -X- _ O
Section -X- _ O
4.5 -X- _ O
. -X- _ O

CoM -X- _ O
: -X- _ O
Context -X- _ O
Embedding -X- _ O
Module -X- _ O

The -X- _ O
context -X- _ O
embedding -X- _ O
module -X- _ O
predicts -X- _ O
e -X- _ O
t -X- _ O
by -X- _ O
considering -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
utterances -X- _ O
before -X- _ O
the -X- _ O
t -X- _ O
- -X- _ O
th -X- _ O
turn -X- _ O
as -X- _ O
the -X- _ O
dialogue -X- _ O
context -X- _ O
. -X- _ O
The -X- _ O
example -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
shows -X- _ O
how -X- _ O
the -X- _ O
model -X- _ O
predicts -X- _ O
the -X- _ O
emotion -X- _ O
of -X- _ O
u -X- _ O
6 -X- _ O
uttered -X- _ O
by -X- _ O
s -X- _ O
A -X- _ O
, -X- _ O
given -X- _ O
a -X- _ O
conversation -X- _ O
of -X- _ O
three -X- _ O
participants -X- _ O
( -X- _ O
s -X- _ O
A -X- _ O
, -X- _ O
s -X- _ O
B -X- _ O
, -X- _ O
s -X- _ O
C -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
previous -X- _ O
utterances -X- _ O
are -X- _ O
h -X- _ O
6 -X- _ O
= -X- _ O
{ -X- _ O
u -X- _ O
1 -X- _ O
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
u -X- _ O
5 -X- _ O
} -X- _ O
and -X- _ O
e -X- _ O
6 -X- _ O
is -X- _ O
predicted -X- _ O
while -X- _ O
considering -X- _ O
the -X- _ O
relationship -X- _ O
between -X- _ O
u -X- _ O
6 -X- _ O
and -X- _ O
h -X- _ O
6 -X- _ O
. -X- _ O

We -X- _ O
consider -X- _ O
multi -X- _ O
- -X- _ O
party -X- _ O
conversations -X- _ O
where -X- _ O
2 -X- _ O
or -X- _ O
more -X- _ O
speakers -X- _ O
are -X- _ O
involved -X- _ O
. -X- _ O
A -X- _ O
special -X- _ O
token -X- _ O
< -X- _ O
s -X- _ O
P -X- _ O
> -X- _ O
is -X- _ O
introduced -X- _ O
to -X- _ O
distinguish -X- _ O
participants -X- _ O
in -X- _ O
the -X- _ O
conversation -X- _ O
and -X- _ O
to -X- _ O
handle -X- _ O
the -X- _ O
speaker -X- _ O
's -X- _ O
dependency -X- _ O
where -X- _ O
P -X- _ O
is -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
participants -X- _ O
. -X- _ O
In -X- _ O
other -X- _ O
words -X- _ O
, -X- _ O
the -X- _ O
same -X- _ O
special -X- _ O
token -X- _ O
appears -X- _ O
before -X- _ O
the -X- _ O
utterances -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
speaker -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
an -X- _ O
Transformer -X- _ O
encoder -X- _ O
as -X- _ O
a -X- _ O
context -X- _ O
model -X- _ O
. -X- _ O
In -X- _ O
many -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
tasks -X- _ O
, -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
model -X- _ O
has -X- _ O
been -X- _ O
proven -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
also -X- _ O
set -X- _ O
the -X- _ O
initial -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
RoBERTa -X- _ B-HyperparameterName
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
RoBERTa -X- _ B-HyperparameterName
is -X- _ O
an -X- _ O
unsupervised -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
model -X- _ O
with -X- _ O
largescale -X- _ O
open -X- _ O
- -X- _ O
domain -X- _ O
corpora -X- _ O
of -X- _ O
unlabeled -X- _ O
text -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
embedding -X- _ O
of -X- _ O
the -X- _ O
special -X- _ O
token -X- _ O
< -X- _ O
cls -X- _ O
> -X- _ O
to -X- _ O
predict -X- _ O
emotion -X- _ O
. -X- _ O
The -X- _ O
< -X- _ O
cls -X- _ O
> -X- _ O
token -X- _ O
is -X- _ O
concatenated -X- _ O
at -X- _ O
the -X- _ O
beginning -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
and -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
context -X- _ O
model -X- _ O
is -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

c -X- _ O
t -X- _ O
= -X- _ O
CoM -X- _ O
( -X- _ O
< -X- _ O
cls -X- _ O
> -X- _ O
, -X- _ O
P -X- _ O
: -X- _ O
t−1 -X- _ O
, -X- _ O
h -X- _ O
t -X- _ O
, -X- _ O
u -X- _ O
t -X- _ O
) -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O

where -X- _ O
P -X- _ O
: -X- _ O
t−1 -X- _ O
is -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
speakers -X- _ O
in -X- _ O
the -X- _ O
previous -X- _ O
turns -X- _ O
. -X- _ O
c -X- _ O
t -X- _ O
∈ -X- _ O
R -X- _ O
1×hc -X- _ O
and -X- _ O
h -X- _ O
c -X- _ O
is -X- _ O
the -X- _ O
dimension -X- _ O
of -X- _ O
CoM -X- _ O
. -X- _ O

PM -X- _ O
: -X- _ O
Pre -X- _ O
- -X- _ O
trained -X- _ O
Memory -X- _ O
Module -X- _ O

External -X- _ O
knowledge -X- _ O
is -X- _ O
known -X- _ O
to -X- _ O
play -X- _ O
an -X- _ O
important -X- _ O
role -X- _ O
in -X- _ O
understanding -X- _ O
conversation -X- _ O
. -X- _ O
Pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
can -X- _ O
be -X- _ O
trained -X- _ O
on -X- _ O
numerous -X- _ O
corpora -X- _ O
and -X- _ O
be -X- _ O
used -X- _ O
as -X- _ O
an -X- _ O
external -X- _ O
knowledge -X- _ O
base -X- _ O
. -X- _ O
Inspired -X- _ O
by -X- _ O
previous -X- _ O
studies -X- _ O
that -X- _ O
the -X- _ O
speaker -X- _ O
's -X- _ O
knowledge -X- _ O
helps -X- _ O
to -X- _ O
judge -X- _ O
emotions -X- _ O
, -X- _ O
we -X- _ O
extract -X- _ O
and -X- _ O
track -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
memory -X- _ O
from -X- _ O
the -X- _ O
speaker -X- _ O
's -X- _ O
previous -X- _ O
utterances -X- _ O
to -X- _ O
utilize -X- _ O
the -X- _ O
emotions -X- _ O
of -X- _ O
the -X- _ O
current -X- _ O
utterance -X- _ O
u -X- _ O
t -X- _ O
. -X- _ O
If -X- _ O
the -X- _ O
speaker -X- _ O
has -X- _ O
never -X- _ O
appeared -X- _ O
before -X- _ O
the -X- _ O
current -X- _ O
turn -X- _ O
, -X- _ O
the -X- _ O
result -X- _ O
of -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
memory -X- _ O
is -X- _ O
considered -X- _ O
a -X- _ O
zero -X- _ O
vector -X- _ O
. -X- _ O
Since -X- _ O
< -X- _ O
cls -X- _ O
> -X- _ O
is -X- _ O
mostly -X- _ O
used -X- _ O
for -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
classifying -X- _ O
sentences -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
embedding -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
< -X- _ O
cls -X- _ O
> -X- _ O
token -X- _ O
as -X- _ O
a -X- _ O
vector -X- _ O
representing -X- _ O
the -X- _ O
utterance -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

k -X- _ O
i -X- _ O
= -X- _ O
PM -X- _ O
( -X- _ O
< -X- _ O
cls -X- _ O
> -X- _ O
, -X- _ O
u -X- _ O
i -X- _ O
) -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O

where -X- _ O
p -X- _ O
u -X- _ O
i -X- _ O
= -X- _ O
p -X- _ O
S -X- _ O
, -X- _ O
S -X- _ O
is -X- _ O
the -X- _ O
speaker -X- _ O
of -X- _ O
the -X- _ O
current -X- _ O
utterance -X- _ O
. -X- _ O
k -X- _ O
i -X- _ O
∈ -X- _ O
R -X- _ O
1×h -X- _ O
k -X- _ O
and -X- _ O
h -X- _ O
k -X- _ O
is -X- _ O
the -X- _ O
dimension -X- _ O
of -X- _ O
PM -X- _ O
. -X- _ O

CoMPM -X- _ B-MethodName
: -X- _ O
Combination -X- _ O
of -X- _ O
CoM -X- _ O
and -X- _ O
PM -X- _ O

We -X- _ O
combine -X- _ O
CoM -X- _ O
and -X- _ O
PM -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
speaker -X- _ O
's -X- _ O
emotion -X- _ O
. -X- _ O
In -X- _ O
many -X- _ O
dialogue -X- _ O
systems -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018b -X- _ O
; -X- _ O
Ma -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
known -X- _ O
that -X- _ O
utterances -X- _ O
close -X- _ O
to -X- _ O
the -X- _ O
current -X- _ O
turn -X- _ O
are -X- _ O
important -X- _ O
for -X- _ O
response -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
assume -X- _ O
that -X- _ O
utterances -X- _ O
close -X- _ O
to -X- _ O
the -X- _ O
current -X- _ O
utterance -X- _ O
will -X- _ O
be -X- _ O
important -X- _ O
in -X- _ O
emotional -X- _ O
recognition -X- _ O
. -X- _ O

Tracking -X- _ O
Method -X- _ O

We -X- _ O
use -X- _ O
k -X- _ O
i -X- _ O
tracking -X- _ O
method -X- _ O
using -X- _ O
GRU -X- _ O
. -X- _ O
The -X- _ O
tracking -X- _ O
method -X- _ O
assumes -X- _ O
that -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
all -X- _ O
previous -X- _ O
speaker -X- _ O
utterances -X- _ O
to -X- _ O
the -X- _ O
current -X- _ O
emotion -X- _ O
is -X- _ O
not -X- _ O
equal -X- _ O
and -X- _ O
varies -X- _ O
with -X- _ O
the -X- _ O
distance -X- _ O
of -X- _ O
the -X- _ O
current -X- _ O
utterance -X- _ O
. -X- _ O
In -X- _ O
other -X- _ O
words -X- _ O
, -X- _ O
since -X- _ O
the -X- _ O
flow -X- _ O
of -X- _ O
conversation -X- _ O
changes -X- _ O
as -X- _ O
it -X- _ O
progresses -X- _ O
, -X- _ O
the -X- _ O
effect -X- _ O
on -X- _ O
emotion -X- _ O
may -X- _ O
differ -X- _ O
depending -X- _ O
on -X- _ O
the -X- _ O
distance -X- _ O
from -X- _ O
the -X- _ O
current -X- _ O
utterance -X- _ O
. -X- _ O
We -X- _ O
track -X- _ O
and -X- _ O
capture -X- _ O
the -X- _ O
sequential -X- _ O
position -X- _ O
information -X- _ O
of -X- _ O
k -X- _ O
i -X- _ O
using -X- _ O
a -X- _ O
unidirectional -X- _ O
GRU -X- _ O
: -X- _ O

kt -X- _ O
t -X- _ O
= -X- _ O
GRU -X- _ O
( -X- _ O
k -X- _ O
i -X- _ O
1 -X- _ O
, -X- _ O
k -X- _ O
i -X- _ O
2 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
k -X- _ O
in -X- _ O
) -X- _ O
( -X- _ O
3 -X- _ O

) -X- _ O

where -X- _ O
t -X- _ O
is -X- _ O
the -X- _ O
turn -X- _ O
index -X- _ O
of -X- _ O
the -X- _ O
current -X- _ O
utterance -X- _ O
, -X- _ O
n -X- _ O
is -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
previous -X- _ O
utterances -X- _ O
of -X- _ O
the -X- _ O
speaker -X- _ O
, -X- _ O
and -X- _ O
i -X- _ O
s -X- _ O
( -X- _ O
s -X- _ O
= -X- _ O
1 -X- _ O
, -X- _ O
2 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
n -X- _ O
) -X- _ O
is -X- _ O
each -X- _ O
turn -X- _ O
uttered -X- _ O
. -X- _ O
kt -X- _ O
t -X- _ O
∈ -X- _ O
R -X- _ O
1×hc -X- _ O
is -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
k -X- _ O
in -X- _ O
and -X- _ O
as -X- _ O
a -X- _ O
result -X- _ O
, -X- _ O
the -X- _ O
knowledge -X- _ O
of -X- _ O
distant -X- _ O
utterance -X- _ O
is -X- _ O
diluted -X- _ O
and -X- _ O
the -X- _ O
effect -X- _ O
on -X- _ O
the -X- _ O
current -X- _ O
utterance -X- _ O
is -X- _ O
reduced -X- _ O
. -X- _ O
GRU -X- _ O
is -X- _ O
composed -X- _ O
of -X- _ O
2 -X- _ O
- -X- _ O
layers -X- _ O
, -X- _ O
the -X- _ O
dimension -X- _ O
of -X- _ O
the -X- _ O
output -X- _ O
vector -X- _ O
is -X- _ O
h -X- _ O
c -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
dropout -X- _ O
is -X- _ O
set -X- _ O
to -X- _ O
0.3 -X- _ O
during -X- _ O
training -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
the -X- _ O
output -X- _ O
vector -X- _ O
o -X- _ O
t -X- _ O
is -X- _ O
obtained -X- _ O
by -X- _ O
adding -X- _ O
kt -X- _ O
t -X- _ O
and -X- _ O
c -X- _ O
t -X- _ O
in -X- _ O
Equation -X- _ O
4 -X- _ O
. -X- _ O

o -X- _ O
t -X- _ O
= -X- _ O
c -X- _ O
t -X- _ O
+ -X- _ O
W -X- _ O
p -X- _ O
( -X- _ O
kt -X- _ O
t -X- _ O
) -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O

where -X- _ O
, -X- _ O
W -X- _ O
p -X- _ O
is -X- _ O
a -X- _ O
matrix -X- _ O
that -X- _ O
projects -X- _ O
the -X- _ O
pretrained -X- _ O
memory -X- _ O
to -X- _ O
the -X- _ O
dimension -X- _ O
of -X- _ O
the -X- _ O
context -X- _ O
output -X- _ O
, -X- _ O
and -X- _ O
is -X- _ O
used -X- _ O
only -X- _ O
when -X- _ O
PM -X- _ O
and -X- _ O
CoM -X- _ O
are -X- _ O
different -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
. -X- _ O

Emotion -X- _ O
Prediction -X- _ O

Softmax -X- _ O
is -X- _ O
applied -X- _ O
to -X- _ O
the -X- _ O
vector -X- _ O
multiplied -X- _ O
by -X- _ O
o -X- _ O
t -X- _ O
and -X- _ O
the -X- _ O
linear -X- _ O
matrix -X- _ O
W -X- _ O
o -X- _ O
∈ -X- _ O
R -X- _ O
he×hc -X- _ O
to -X- _ O
obtain -X- _ O
the -X- _ O
probability -X- _ O
distribution -X- _ O
of -X- _ O
emotion -X- _ O
classes -X- _ O
, -X- _ O
where -X- _ O
h -X- _ O
e -X- _ O
is -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
emotion -X- _ O
classes -X- _ O
. -X- _ O
e -X- _ O
t -X- _ O
is -X- _ O
the -X- _ O
predicted -X- _ O
emotion -X- _ O
class -X- _ O
that -X- _ O
corresponds -X- _ O
to -X- _ O
the -X- _ O
index -X- _ O
of -X- _ O
the -X- _ O
largest -X- _ O
probability -X- _ O
from -X- _ O
the -X- _ O
emotion -X- _ O
class -X- _ O
distribution -X- _ O
. -X- _ O

P -X- _ O
( -X- _ O
e -X- _ O
) -X- _ O
= -X- _ O
softmax -X- _ O
( -X- _ O
W -X- _ O
o -X- _ O
( -X- _ O
o -X- _ O
t -X- _ O
) -X- _ O
) -X- _ O
( -X- _ O
5 -X- _ O

) -X- _ O

The -X- _ O
objective -X- _ O
is -X- _ O
to -X- _ O
minimize -X- _ O
the -X- _ O
cross -X- _ O
entropy -X- _ O
loss -X- _ O
so -X- _ O
that -X- _ O
e -X- _ O
t -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
the -X- _ O
ground -X- _ O
truth -X- _ O
emotional -X- _ O
label -X- _ O
. -X- _ O

Experiments -X- _ O

Dataset -X- _ O

We -X- _ O
experiment -X- _ O
on -X- _ O
four -X- _ O
benchmark -X- _ O
datasets -X- _ O
. -X- _ O
MELD -X- _ B-DatasetName
and -X- _ O
EmoryNLP -X- _ B-DatasetName
( -X- _ O
Zahiri -X- _ O
and -X- _ O
Choi -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
are -X- _ O
multi -X- _ O
- -X- _ O
party -X- _ O
datasets -X- _ O
, -X- _ O
while -X- _ O
IEMOCAP -X- _ B-DatasetName
( -X- _ O
Busso -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
and -X- _ O
DailyDialog -X- _ B-DatasetName
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
are -X- _ O
dyadic -X- _ O
- -X- _ O
party -X- _ O
datasets -X- _ O
. -X- _ O
The -X- _ O
statistics -X- _ O
of -X- _ O
the -X- _ O
dataset -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O

IEMOCAP -X- _ B-DatasetName
is -X- _ O
a -X- _ O
dataset -X- _ O
involving -X- _ O
10 -X- _ O
speakers -X- _ O
, -X- _ O
and -X- _ O
each -X- _ O
conversation -X- _ O
involves -X- _ O
2 -X- _ O
speakers -X- _ O
and -X- _ O
the -X- _ O
emotion -X- _ O
- -X- _ O
inventory -X- _ O
is -X- _ O
given -X- _ O
as -X- _ O
" -X- _ O
happy -X- _ O
, -X- _ O
sad -X- _ O
, -X- _ O
angry -X- _ O
, -X- _ O
excited -X- _ O
, -X- _ O
frustrated -X- _ O
and -X- _ O
neutral -X- _ O
" -X- _ O
. -X- _ O
The -X- _ O
train -X- _ O
and -X- _ O
development -X- _ O
dataset -X- _ O
is -X- _ O
a -X- _ O
conversation -X- _ O
involving -X- _ O
the -X- _ O
previous -X- _ O
eight -X- _ O
speakers -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
train -X- _ O
and -X- _ O
development -X- _ O
are -X- _ O
divided -X- _ O
into -X- _ O
random -X- _ O
splits -X- _ O
at -X- _ O
a -X- _ O
ratio -X- _ O
of -X- _ O
9:1 -X- _ O
. -X- _ O
The -X- _ O
test -X- _ O
dataset -X- _ O
is -X- _ O
a -X- _ O
conversation -X- _ O
involving -X- _ O
two -X- _ O
later -X- _ O
speakers -X- _ O
. -X- _ O

DailyDialog -X- _ B-DatasetName
is -X- _ O
a -X- _ O
dataset -X- _ O
of -X- _ O
daily -X- _ O
conversations -X- _ O
between -X- _ O
two -X- _ O
speakers -X- _ O
and -X- _ O
the -X- _ O
emotion -X- _ O
- -X- _ O
inventory -X- _ O
is -X- _ O
given -X- _ O
as -X- _ O
" -X- _ O
anger -X- _ O
, -X- _ O
disgust -X- _ O
, -X- _ O
fear -X- _ O
, -X- _ O
joy -X- _ O
, -X- _ O
surprise -X- _ O
, -X- _ O
sadness -X- _ O
and -X- _ O
neutral -X- _ O
" -X- _ O
. -X- _ O
Since -X- _ O
more -X- _ O
than -X- _ O
82 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
are -X- _ O
tagged -X- _ O
as -X- _ O
neutral -X- _ O
, -X- _ O
neutral -X- _ O
emotions -X- _ O
are -X- _ O
excluded -X- _ O
when -X- _ O
evaluating -X- _ O
systems -X- _ O
with -X- _ O
Micro -X- _ O
- -X- _ O
F1 -X- _ O
as -X- _ O
did -X- _ O
in -X- _ O
the -X- _ O
previous -X- _ O
studies -X- _ O
. -X- _ O

MELD -X- _ B-DatasetName
is -X- _ O
a -X- _ O
dataset -X- _ O
based -X- _ O
on -X- _ O
Friends -X- _ O
TV -X- _ O
show -X- _ O
and -X- _ O
provides -X- _ O
two -X- _ O
taxonomy -X- _ O
: -X- _ O
emotion -X- _ O
and -X- _ O
sentiment -X- _ O
. -X- _ O
MELD -X- _ B-DatasetName
's -X- _ O
emotion -X- _ O
- -X- _ O
inventory -X- _ O
is -X- _ O
given -X- _ O
as -X- _ O
" -X- _ O
anger -X- _ O
, -X- _ O
disgust -X- _ O
, -X- _ O
sadness -X- _ O
, -X- _ O
joy -X- _ O
, -X- _ O
surprise -X- _ O
, -X- _ O
fear -X- _ O
and -X- _ O
neutrality -X- _ O
" -X- _ O
following -X- _ O
Ekman -X- _ O
( -X- _ O
Ekman -X- _ O
, -X- _ O
1992 -X- _ O
) -X- _ O
and -X- _ O
sentiment -X- _ O
- -X- _ O
inventory -X- _ O
is -X- _ O
given -X- _ O
as -X- _ O
" -X- _ O
positive -X- _ O
, -X- _ O
negative -X- _ O
and -X- _ O
neutral -X- _ O
" -X- _ O
. -X- _ O
EmoryNLP -X- _ B-DatasetName
, -X- _ O
like -X- _ O
MELD -X- _ B-DatasetName
, -X- _ O
is -X- _ O
also -X- _ O
a -X- _ O
dataset -X- _ O
based -X- _ O
on -X- _ O
Friends -X- _ O
TV -X- _ O
show -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
emotion -X- _ O
- -X- _ O
inventory -X- _ O
is -X- _ O
given -X- _ O
as -X- _ O
" -X- _ O
joyful -X- _ O
, -X- _ O
peaceful -X- _ O
, -X- _ O
powerful -X- _ O
, -X- _ O
scared -X- _ O
, -X- _ O
mad -X- _ O
, -X- _ O
sad -X- _ O
and -X- _ O
neutral -X- _ O
" -X- _ O
. -X- _ O
Sentiment -X- _ O
labels -X- _ O
are -X- _ O
not -X- _ O
provided -X- _ O
, -X- _ O
but -X- _ O
sentiment -X- _ O
classes -X- _ O
can -X- _ O
be -X- _ O
grouped -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
positive -X- _ O
: -X- _ O
{ -X- _ O
joyful -X- _ O
, -X- _ O
peaceful -X- _ O
, -X- _ O
powerful -X- _ O
} -X- _ O
, -X- _ O
negative -X- _ O
: -X- _ O
{ -X- _ O
scared -X- _ O
, -X- _ O
mad -X- _ O
, -X- _ O
sad -X- _ O
} -X- _ O
, -X- _ O
neutral -X- _ O
: -X- _ O
{ -X- _ O
neutral -X- _ O
} -X- _ O

Training -X- _ O
Setup -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
model -X- _ O
from -X- _ O
the -X- _ O
huggingface -X- _ O
library -X- _ O
2 -X- _ O
. -X- _ O
The -X- _ O
optimizer -X- _ B-HyperparameterName
is -X- _ O
AdamW -X- _ O
and -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
is -X- _ O
1e-5 -X- _ B-HyperparameterValue
as -X- _ O
an -X- _ O
initial -X- _ O
value -X- _ O
. -X- _ O
The -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
scheduler -X- _ O
used -X- _ O
for -X- _ O
training -X- _ O
is -X- _ O
get_linear_schedule_with_warmup -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
maximum -X- _ O
value -X- _ O
of -X- _ O
10 -X- _ O
is -X- _ O
used -X- _ O
for -X- _ O
the -X- _ O
gradient -X- _ O
clipping -X- _ O
. -X- _ O
We -X- _ O
select -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
validation -X- _ O
set -X- _ O
. -X- _ O
All -X- _ O
experiments -X- _ O
are -X- _ O
conducted -X- _ O
on -X- _ O
one -X- _ O
V100 -X- _ O
GPU -X- _ O
with -X- _ O
32 -X- _ O
GB -X- _ O
memory -X- _ O
. -X- _ O

Previous -X- _ O
Method -X- _ O

We -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
proposed -X- _ O
approach -X- _ O
is -X- _ O
effective -X- _ O
by -X- _ O
comparing -X- _ O
it -X- _ O
with -X- _ O
various -X- _ O
baselines -X- _ O
and -X- _ O
the -X- _ O
stateof -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
methods -X- _ O
. -X- _ O

KET -X- _ O
( -X- _ O
Zhong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
Knowledge -X- _ O
Enriched -X- _ O
Transformer -X- _ O
that -X- _ O
reflects -X- _ O
contextual -X- _ O
utterances -X- _ O
with -X- _ O
a -X- _ O
hierarchical -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
and -X- _ O
leverages -X- _ O
external -X- _ O
commonsense -X- _ O
knowledge -X- _ O
by -X- _ O
using -X- _ O
a -X- _ O
context -X- _ O
- -X- _ O
aware -X- _ O
affective -X- _ O
graph -X- _ O
attention -X- _ O
mechanism -X- _ O
. -X- _ O

DialogueRNN -X- _ O
uses -X- _ O
a -X- _ O
GRU -X- _ O
network -X- _ O
to -X- _ O
keep -X- _ O
track -X- _ O
of -X- _ O
the -X- _ O
individual -X- _ O
party -X- _ O
states -X- _ O
in -X- _ O
the -X- _ O
conversation -X- _ O
to -X- _ O
predict -X- _ O
emotions -X- _ O
. -X- _ O
This -X- _ O
model -X- _ O
assumes -X- _ O
that -X- _ O
there -X- _ O
are -X- _ O
three -X- _ O
factors -X- _ O
in -X- _ O
emotion -X- _ O
prediction -X- _ O
: -X- _ O
the -X- _ O
speaker -X- _ O
, -X- _ O
the -X- _ O
context -X- _ O
from -X- _ O
the -X- _ O
preceding -X- _ O
utterances -X- _ O
and -X- _ O
the -X- _ O
emotion -X- _ O
of -X- _ O
the -X- _ O
preceding -X- _ O
utterances -X- _ O
. -X- _ O
Also -X- _ O
, -X- _ O
Ghosal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
shows -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
RoBERTa+DialogueRNN -X- _ B-HyperparameterName
when -X- _ O
the -X- _ O
vectors -X- _ O
of -X- _ O
the -X- _ O
tokens -X- _ O
are -X- _ O
extracted -X- _ O
with -X- _ O
a -X- _ O
pretrained -X- _ O
RoBERTa -X- _ B-HyperparameterName
. -X- _ O

RGAT+P -X- _ B-MethodName
( -X- _ O
Ishiwatari -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
( -X- _ O
relational -X- _ O
graph -X- _ O
attention -X- _ O
networks -X- _ O
) -X- _ O
proposes -X- _ O
relational -X- _ O
position -X- _ O
encodings -X- _ O
with -X- _ O
sequential -X- _ O
information -X- _ O
reflecting -X- _ O
the -X- _ O
relational -X- _ O
graph -X- _ O
structure -X- _ O
, -X- _ O
which -X- _ O
shows -X- _ O
that -X- _ O
both -X- _ O
the -X- _ O
speaker -X- _ O
dependency -X- _ O
and -X- _ O
the -X- _ O
sequential -X- _ O
information -X- _ O
can -X- _ O
be -X- _ O
captured -X- _ O
. -X- _ O

HiTrans -X- _ B-MethodName
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
Trans -X- _ O
utilize -X- _ O
BERT -X- _ O
as -X- _ O
the -X- _ O
low -X- _ O
- -X- _ O
level -X- _ O
transformer -X- _ O
to -X- _ O
generate -X- _ O
local -X- _ O
utterance -X- _ O
representations -X- _ O
, -X- _ O
and -X- _ O
feed -X- _ O
them -X- _ O
into -X- _ O
another -X- _ O
high -X- _ O
- -X- _ O
level -X- _ O
transformer -X- _ O
. -X- _ O

COSMIC -X- _ B-MethodName
( -X- _ O
Ghosal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
incorporates -X- _ O
different -X- _ O
elements -X- _ O
of -X- _ O
commonsense -X- _ O
such -X- _ O
as -X- _ O
mental -X- _ O
states -X- _ O
, -X- _ O
events -X- _ O
and -X- _ O
causal -X- _ O
relations -X- _ O
, -X- _ O
and -X- _ O
learns -X- _ O
the -X- _ O
relations -X- _ O
between -X- _ O
participants -X- _ O
in -X- _ O
the -X- _ O
conversation -X- _ O
. -X- _ O
This -X- _ O
model -X- _ O
uses -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
RoBERTa -X- _ B-HyperparameterName
as -X- _ O
a -X- _ O
feature -X- _ O
extractor -X- _ O
and -X- _ O
leverages -X- _ O
COMET -X- _ O
trained -X- _ O
with -X- _ O
ATOMIC -X- _ O
as -X- _ O
the -X- _ O
commonsense -X- _ O
knowledge -X- _ O
. -X- _ O
( -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
proposes -X- _ O
a -X- _ O
discourse -X- _ O
- -X- _ O
aware -X- _ O
graph -X- _ O
neural -X- _ O
network -X- _ O
that -X- _ O
utilizes -X- _ O
self -X- _ O
- -X- _ O
speaker -X- _ O
dependency -X- _ O
of -X- _ O
interlocutors -X- _ O
as -X- _ O
a -X- _ O
relational -X- _ O
convolution -X- _ O
and -X- _ O
informative -X- _ O
cues -X- _ O
of -X- _ O
dependent -X- _ O
utterances -X- _ O
as -X- _ O
a -X- _ O
gated -X- _ O
convolution -X- _ O
. -X- _ O

ERMC -X- _ B-MethodName
- -X- _ I-MethodName
DisGCN -X- _ I-MethodName

Psychological -X- _ O
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
uses -X- _ O
commonsense -X- _ O
knowledge -X- _ O
as -X- _ O
enrich -X- _ O
edges -X- _ O
and -X- _ O
processes -X- _ O
it -X- _ O
with -X- _ O
graph -X- _ O
transformer -X- _ O
. -X- _ O
Psychological -X- _ O
performs -X- _ O
emotion -X- _ O
recognition -X- _ O
by -X- _ O
utilizing -X- _ O
intention -X- _ O
of -X- _ O
utterances -X- _ O
from -X- _ O
not -X- _ O
only -X- _ O
past -X- _ O
contexts -X- _ O
but -X- _ O
also -X- _ O
future -X- _ O
context -X- _ O
. -X- _ O

DialogueCRN -X- _ B-MethodName
( -X- _ O
Hu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
introduces -X- _ O
an -X- _ O
intuitive -X- _ O
retrieving -X- _ O
process -X- _ O
, -X- _ O
the -X- _ O
reasoning -X- _ O
module -X- _ O
, -X- _ O
which -X- _ O
understands -X- _ O
both -X- _ O
situation -X- _ O
- -X- _ O
level -X- _ O
and -X- _ O
speakerlevel -X- _ O
contexts -X- _ O
. -X- _ O

ToDKAT -X- _ B-MethodName
( -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
proposes -X- _ O
a -X- _ O
language -X- _ O
model -X- _ O
with -X- _ O
topic -X- _ O
detection -X- _ O
added -X- _ O
, -X- _ O
and -X- _ O
improves -X- _ O
performance -X- _ O
by -X- _ O
combining -X- _ O
it -X- _ O
with -X- _ O
commonsense -X- _ O
knowledge -X- _ O
. -X- _ O
The -X- _ O
performance -X- _ O
of -X- _ O
ToDKAT -X- _ B-MethodName
in -X- _ O
MELD -X- _ B-DatasetName
was -X- _ O
re -X- _ O
- -X- _ O
released -X- _ O
on -X- _ O
github -X- _ O
3 -X- _ O
. -X- _ O

Table -X- _ O
2 -X- _ O
shows -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
previous -X- _ O
methods -X- _ O
and -X- _ O
our -X- _ O
models -X- _ O
. -X- _ O
CoM -X- _ O
used -X- _ O
alone -X- _ O
does -X- _ O
not -X- _ O
leverage -X- _ O
PM -X- _ O
and -X- _ O
predicts -X- _ O
emotions -X- _ O
by -X- _ O
considering -X- _ O
only -X- _ O
the -X- _ O
dialogue -X- _ O
context -X- _ O
. -X- _ O
PM -X- _ O
used -X- _ O
alone -X- _ O
is -X- _ O
not -X- _ O
used -X- _ O
as -X- _ O
a -X- _ O
memory -X- _ O
module -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
same -X- _ O
backbone -X- _ O
is -X- _ O
used -X- _ O
. -X- _ O
PM -X- _ O
used -X- _ O
alone -X- _ O
predicts -X- _ O
emotion -X- _ O
only -X- _ O
with -X- _ O
the -X- _ O
utterance -X- _ O
of -X- _ O
the -X- _ O
current -X- _ O
turn -X- _ O
without -X- _ O
considering -X- _ O
the -X- _ O
context -X- _ O
. -X- _ O
CoMPM -X- _ B-MethodName
is -X- _ O
a -X- _ O
model -X- _ O
in -X- _ O
which -X- _ O
both -X- _ O
CoM -X- _ O
and -X- _ O
PM -X- _ O
parameters -X- _ O
are -X- _ O
updated -X- _ O
in -X- _ O
the -X- _ O
initial -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
LM -X- _ O
. -X- _ O
CoMPM -X- _ B-MethodName
( -X- _ O
f -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
model -X- _ O
in -X- _ O
which -X- _ O
PM -X- _ O
parameters -X- _ O
are -X- _ O
frozen -X- _ O
in -X- _ O
the -X- _ O
initial -X- _ O
state -X- _ O
( -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
LM -X- _ O
) -X- _ O
and -X- _ O
is -X- _ O
not -X- _ O
trained -X- _ O
further -X- _ O
, -X- _ O
and -X- _ O
CoMPM -X- _ B-MethodName
( -X- _ O
s -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
model -X- _ O
in -X- _ O
which -X- _ O
PM -X- _ O
is -X- _ O
trained -X- _ O
from -X- _ O
scratch -X- _ O
. -X- _ O
CoMPM -X- _ B-MethodName
( -X- _ O
k -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
model -X- _ O
in -X- _ O
which -X- _ O
PM -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
ConceptNet -X- _ O
. -X- _ O
Following -X- _ O
previous -X- _ O
studies -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
average -X- _ O
vector -X- _ O
for -X- _ O
each -X- _ O
token -X- _ O
in -X- _ O
PM -X- _ O
( -X- _ O
k -X- _ O
) -X- _ O
as -X- _ O
the -X- _ O
feature -X- _ O
of -X- _ O
the -X- _ O
utterance -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
model -X- _ O
provided -X- _ O
by -X- _ O
the -X- _ O
site -X- _ O
4 -X- _ O
as -X- _ O
PM -X- _ O
( -X- _ O
k -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
effect -X- _ O
of -X- _ O
PM -X- _ O
can -X- _ O
be -X- _ O
confirmed -X- _ O
through -X- _ O
the -X- _ O
performance -X- _ O
comparison -X- _ O
between -X- _ O
CoM -X- _ O
and -X- _ O
CoMPM -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
CoM -X- _ O
can -X- _ O
be -X- _ O
confirmed -X- _ O
by -X- _ O
comparing -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
CoM -X- _ O
and -X- _ O
PM -X- _ O
. -X- _ O
Since -X- _ O
PM -X- _ O
does -X- _ O
not -X- _ O
consider -X- _ O
context -X- _ O
, -X- _ O
it -X- _ O
showed -X- _ O
worse -X- _ O
performance -X- _ O
than -X- _ O
CoM -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
performance -X- _ O
gap -X- _ O
is -X- _ O
larger -X- _ O
in -X- _ O
the -X- _ O
IEMOCAP -X- _ B-DatasetName
dataset -X- _ O
with -X- _ O
a -X- _ O
higher -X- _ O
average -X- _ O
number -X- _ O
of -X- _ O
conversation -X- _ O
turns -X- _ O
. -X- _ O
As -X- _ O
a -X- _ O
result -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
combination -X- _ O
of -X- _ O
CoM -X- _ O
and -X- _ O
PM -X- _ O
is -X- _ O
effective -X- _ O
in -X- _ O
achieving -X- _ O
better -X- _ O
performance -X- _ O
. -X- _ O

We -X- _ O
confirm -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
PM -X- _ O
structure -X- _ O
in -X- _ O
the -X- _ O
model -X- _ O
through -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
CoMPM -X- _ B-MethodName
( -X- _ O
s -X- _ O
) -X- _ O
. -X- _ O

If -X- _ O
PM -X- _ O
parameters -X- _ O
are -X- _ O
not -X- _ O
frozen -X- _ O
and -X- _ O
are -X- _ O
instead -X- _ O
randomly -X- _ O
initialized -X- _ O
( -X- _ O
i.e. -X- _ O
PM -X- _ O
( -X- _ O
s -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
deteriorates -X- _ O
. -X- _ O
CoMPM -X- _ B-MethodName
( -X- _ O
s -X- _ O
) -X- _ O
performs -X- _ O
worse -X- _ O
than -X- _ O
CoMPM -X- _ B-MethodName
, -X- _ O
and -X- _ O
even -X- _ O
performs -X- _ O
worse -X- _ O
than -X- _ O
CoM -X- _ O
on -X- _ O
the -X- _ O
other -X- _ O
datasets -X- _ O
except -X- _ O
for -X- _ O
MELD -X- _ O
. -X- _ O
That -X- _ O
is -X- _ O
, -X- _ O
PM -X- _ O
( -X- _ O
s -X- _ O
) -X- _ O
can -X- _ O
not -X- _ O
be -X- _ O
regarded -X- _ O
as -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
memory -X- _ O
because -X- _ O
the -X- _ O
parameters -X- _ O
are -X- _ O
randomly -X- _ O
initialized -X- _ O
, -X- _ O
and -X- _ O
simply -X- _ O
increasing -X- _ O
the -X- _ O
model -X- _ O
complexity -X- _ O
does -X- _ O
not -X- _ O
help -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
performance -X- _ O
. -X- _ O
CoMPM -X- _ B-MethodName
( -X- _ O
f -X- _ O
) -X- _ O
shows -X- _ O
similar -X- _ O
performance -X- _ O
to -X- _ O
CoMPM -X- _ B-MethodName
and -X- _ O
achieves -X- _ O
better -X- _ O
performance -X- _ O
depending -X- _ O
on -X- _ O
the -X- _ O
data -X- _ O
. -X- _ O
PM -X- _ O
( -X- _ O
f -X- _ O
) -X- _ O
is -X- _ O
not -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
the -X- _ O
data -X- _ O
, -X- _ O
but -X- _ O
it -X- _ O
extracts -X- _ O
general -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
memory -X- _ O
from -X- _ O
a -X- _ O
pretrained -X- _ O
language -X- _ O
model -X- _ O
. -X- _ O
The -X- _ O
comparison -X- _ O
between -X- _ O
PM -X- _ O
and -X- _ O
PM -X- _ O
( -X- _ O
f -X- _ O
) -X- _ O
will -X- _ O
be -X- _ O
further -X- _ O
described -X- _ O
in -X- _ O
Section -X- _ O
4.6 -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
CoMPM -X- _ B-MethodName
( -X- _ O
k -X- _ O
) -X- _ O
shows -X- _ O
better -X- _ O
performance -X- _ O
than -X- _ O
CoM -X- _ O
, -X- _ O
PM -X- _ O
, -X- _ O
and -X- _ O
CoMPM -X- _ B-MethodName
( -X- _ O
s -X- _ O
) -X- _ O
except -X- _ O
for -X- _ O
IEMOCAP -X- _ B-DatasetName
. -X- _ O
In -X- _ O
IEMOCAP -X- _ B-DatasetName
, -X- _ O
CoMPM -X- _ B-MethodName
( -X- _ O
k -X- _ O
) -X- _ O
has -X- _ O
lower -X- _ O
performance -X- _ O
than -X- _ O
CoM. -X- _ O
For -X- _ O
all -X- _ O
datasets -X- _ O
, -X- _ O
CoMPM -X- _ B-MethodName
( -X- _ O
k -X- _ O
) -X- _ O
performs -X- _ O
slightly -X- _ O
worse -X- _ O
than -X- _ O
CoMPM -X- _ B-MethodName
. -X- _ O
In -X- _ O
other -X- _ O
words -X- _ O
, -X- _ O
ConceptNet -X- _ O
improves -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
CoMPM -X- _ B-MethodName
, -X- _ O
but -X- _ O
is -X- _ O
not -X- _ O
as -X- _ O
effective -X- _ O
as -X- _ O
pretrained -X- _ O
memory -X- _ O
. -X- _ O
As -X- _ O
a -X- _ O
result -X- _ O
, -X- _ O
we -X- _ O
regard -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
memory -X- _ O
as -X- _ O
compressed -X- _ O
knowledge -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
play -X- _ O
a -X- _ O
role -X- _ O
similar -X- _ O
to -X- _ O
external -X- _ O
knowledge -X- _ O
used -X- _ O
in -X- _ O
cuttingedge -X- _ O
systems -X- _ O
. -X- _ O

The -X- _ O
best -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
approaches -X- _ O
is -X- _ O
CoMPM -X- _ B-MethodName
or -X- _ O
CoMPM -X- _ B-MethodName
( -X- _ O
f -X- _ O
) -X- _ O
, -X- _ O
both -X- _ O
of -X- _ O
which -X- _ O
combine -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
memory -X- _ O
. -X- _ O
We -X- _ O
achieve -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performance -X- _ O
among -X- _ O
all -X- _ O
systems -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
leverage -X- _ O
structured -X- _ O
external -X- _ O
data -X- _ O
and -X- _ O
achieve -X- _ O
the -X- _ O
first -X- _ O
or -X- _ O
second -X- _ O
performance -X- _ O
even -X- _ O
including -X- _ O
systems -X- _ O
that -X- _ O
leverage -X- _ O
external -X- _ O
data -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
our -X- _ O
approach -X- _ O
can -X- _ O
be -X- _ O
extended -X- _ O
to -X- _ O
other -X- _ O
languages -X- _ O
without -X- _ O
structured -X- _ O
external -X- _ O
data -X- _ O
as -X- _ O
well -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
described -X- _ O
in -X- _ O
Section -X- _ O
4.7 -X- _ O
. -X- _ O

Combinations -X- _ O
of -X- _ O
CoM -X- _ O
and -X- _ O
PM -X- _ O

We -X- _ O
experiment -X- _ O
with -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
memory -X- _ O
of -X- _ O
different -X- _ O
language -X- _ O
models -X- _ O
. -X- _ O
To -X- _ O
eliminate -X- _ O
the -X- _ O
influence -X- _ O
of -X- _ O
the -X- _ O
PM -X- _ O
structure -X- _ O
, -X- _ O
we -X- _ O
freeze -X- _ O
the -X- _ O
parameters -X- _ O
of -X- _ O
PM -X- _ O
and -X- _ O
use -X- _ O
it -X- _ O
as -X- _ O
a -X- _ O
feature -X- _ O
extractor -X- _ O
. -X- _ O
Table -X- _ O
3 -X- _ O
shows -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
pretrained -X- _ O
memory -X- _ O
extracted -X- _ O
by -X- _ O
the -X- _ O
different -X- _ O
language -X- _ O
models -X- _ O
. -X- _ O
If -X- _ O
PM -X- _ O
and -X- _ O
CoM -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
different -X- _ O
backbones -X- _ O
, -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
memory -X- _ O
is -X- _ O
projected -X- _ O
through -X- _ O
W -X- _ O
p -X- _ O
as -X- _ O
the -X- _ O
dimension -X- _ O
of -X- _ O
the -X- _ O
context -X- _ O
output -X- _ O
. -X- _ O
RoBERTa+BERT -X- _ B-HyperparameterName
and -X- _ O
RoBERTa+GPT2 -X- _ B-HyperparameterName
( -X- _ O
combination -X- _ O
of -X- _ O
CoM -X- _ O
and -X- _ O
PM -X- _ O
( -X- _ O
f -X- _ O
) -X- _ O
) -X- _ O
have -X- _ O
lower -X- _ O
performance -X- _ O
than -X- _ O
RoBERTa+RoBERTa -X- _ B-HyperparameterName
, -X- _ O
which -X- _ O
is -X- _ O
inferred -X- _ O
because -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
memory -X- _ O
of -X- _ O
RoBERTa -X- _ B-HyperparameterName
contains -X- _ O
richer -X- _ O
information -X- _ O
than -X- _ O
BERT -X- _ O
and -X- _ O
GPT2 -X- _ O
. -X- _ O
Since -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
lot -X- _ O
of -X- _ O
training -X- _ O
data -X- _ O
in -X- _ O
the -X- _ O
diallydialog -X- _ O
and -X- _ O
W -X- _ O
p -X- _ O
is -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
to -X- _ O
the -X- _ O
data -X- _ O
to -X- _ O
mutually -X- _ O
understand -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
memory -X- _ O
and -X- _ O
context -X- _ O
representation -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
infer -X- _ O
that -X- _ O
performance -X- _ O
does -X- _ O
not -X- _ O
decrease -X- _ O
even -X- _ O
if -X- _ O
the -X- _ O
PM -X- _ O
changes -X- _ O
from -X- _ O
the -X- _ O
dailydialog -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
even -X- _ O
if -X- _ O
other -X- _ O
PMs -X- _ O
are -X- _ O
used -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
is -X- _ O
improved -X- _ O
compared -X- _ O
to -X- _ O
using -X- _ O
only -X- _ O
CoM -X- _ O
, -X- _ O
so -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
memory -X- _ O
of -X- _ O
other -X- _ O
language -X- _ O
models -X- _ O
is -X- _ O
also -X- _ O
effective -X- _ O
for -X- _ O
emotion -X- _ O
recognition -X- _ O
. -X- _ O

BERT+RoBERTa -X- _ B-HyperparameterName
has -X- _ O
a -X- _ O
larger -X- _ O
performance -X- _ O
decrease -X- _ O
than -X- _ O
RoBERTa+BERT -X- _ B-HyperparameterName
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
in -X- _ O
IEMOCAP -X- _ B-DatasetName
data -X- _ O
with -X- _ O
a -X- _ O
long -X- _ O
average -X- _ O
number -X- _ O
of -X- _ O
turns -X- _ O
in -X- _ O
the -X- _ O
context -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
deteriorates -X- _ O
significantly -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
BERT+RoBERTa -X- _ B-HyperparameterName
is -X- _ O
lower -X- _ O
than -X- _ O
CoM -X- _ O
( -X- _ O
RoBERTa -X- _ B-HyperparameterName
) -X- _ O
, -X- _ O
which -X- _ O
supports -X- _ O
that -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
CoM -X- _ O
is -X- _ O
a -X- _ O
more -X- _ O
important -X- _ O
factor -X- _ O
than -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
memory -X- _ O
. -X- _ O
In -X- _ O
other -X- _ O
words -X- _ O
, -X- _ O
we -X- _ O
confirm -X- _ O
that -X- _ O
CoM -X- _ O
is -X- _ O
more -X- _ O
important -X- _ O
than -X- _ O
PM -X- _ O
in -X- _ O
our -X- _ O
system -X- _ O
for -X- _ O
performance -X- _ O
, -X- _ O
and -X- _ O
it -X- _ O
is -X- _ O
effective -X- _ O
to -X- _ O
focus -X- _ O
on -X- _ O
context -X- _ O
modeling -X- _ O
rather -X- _ O
than -X- _ O
external -X- _ O
knowledge -X- _ O
in -X- _ O
the -X- _ O
study -X- _ O
of -X- _ O
emotion -X- _ O
recognition -X- _ O
in -X- _ O
conversation -X- _ O
. -X- _ O

Training -X- _ O
with -X- _ O
Less -X- _ O
Data -X- _ O

CoMPM -X- _ B-MethodName
is -X- _ O
an -X- _ O
approach -X- _ O
that -X- _ O
eliminates -X- _ O
dependence -X- _ O
on -X- _ O
external -X- _ O
sources -X- _ O
and -X- _ O
is -X- _ O
easily -X- _ O
extensible -X- _ O
to -X- _ O
any -X- _ O
language -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
insufficient -X- _ O
number -X- _ O
of -X- _ O
emotional -X- _ O
data -X- _ O
available -X- _ O
in -X- _ O
other -X- _ O
countries -X- _ O
( -X- _ O
or -X- _ O
actual -X- _ O
service -X- _ O
) -X- _ O
remains -X- _ O
a -X- _ O
problem -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
additional -X- _ O
experiments -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
use -X- _ O
ratio -X- _ O
of -X- _ O
training -X- _ O
data -X- _ O
in -X- _ O
MELD -X- _ B-DatasetName
and -X- _ O
EmoryNLP -X- _ B-DatasetName
, -X- _ O
where -X- _ O
there -X- _ O
is -X- _ O
neither -X- _ O
too -X- _ O
much -X- _ O
nor -X- _ O
too -X- _ O
little -X- _ O
data -X- _ O
. -X- _ O
Figure -X- _ O
3 -X- _ O
shows -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
ratio -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
In -X- _ O
MELD -X- _ B-DatasetName
and -X- _ O
EmoryNLP -X- _ B-DatasetName
, -X- _ O
even -X- _ O
if -X- _ O
only -X- _ O
60 -X- _ O
% -X- _ O
and -X- _ O
80 -X- _ O
% -X- _ O
are -X- _ O
used -X- _ O
, -X- _ O
respectively -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
decreases -X- _ O
by -X- _ O
only -X- _ O
3 -X- _ O
points -X- _ O
. -X- _ O
The -X- _ O
value -X- _ O
in -X- _ O
parentheses -X- _ O
is -X- _ O
the -X- _ O
performance -X- _ O
difference -X- _ O
from -X- _ O
the -X- _ O
original -X- _ O
CoMPM -X- _ B-MethodName
( -X- _ O
f -X- _ O
) -X- _ O
( -X- _ O
RoBERTa -X- _ B-HyperparameterName
+ -X- _ I-HyperparameterName
RoBERTa -X- _ I-HyperparameterName
) -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
bert -X- _ O
- -X- _ O
large -X- _ O
- -X- _ O
uncased -X- _ O
and -X- _ O
GPT2 -X- _ O
- -X- _ O
medium -X- _ O
versions -X- _ O
. -X- _ O

Table -X- _ O
2 -X- _ O
shows -X- _ O
that -X- _ O
CoMPM -X- _ B-MethodName
( -X- _ O
f -X- _ O
) -X- _ O
achieves -X- _ O
better -X- _ O
performance -X- _ O
than -X- _ O
CoMPM -X- _ B-MethodName
in -X- _ O
the -X- _ O
emotion -X- _ O
classification -X- _ O
of -X- _ O
IMEOCAP -X- _ B-DatasetName
and -X- _ O
EmoryNLP -X- _ B-DatasetName
, -X- _ O
which -X- _ O
has -X- _ O
fewer -X- _ O
training -X- _ O
data -X- _ O
than -X- _ O
other -X- _ O
settings -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
if -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
lot -X- _ O
of -X- _ O
training -X- _ O
data -X- _ O
, -X- _ O
CoMPM -X- _ B-MethodName
shows -X- _ O
better -X- _ O
performance -X- _ O
. -X- _ O
Figure -X- _ O
3 -X- _ O
shows -X- _ O
that -X- _ O
as -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
data -X- _ O
decreases -X- _ O
, -X- _ O
CoMPM -X- _ B-MethodName
( -X- _ O
f -X- _ O
) -X- _ O
shows -X- _ O
better -X- _ O
results -X- _ O
than -X- _ O
CoMPM -X- _ B-MethodName
, -X- _ O
which -X- _ O
indicates -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
better -X- _ O
to -X- _ O
freeze -X- _ O
the -X- _ O
parameters -X- _ O
of -X- _ O
PM -X- _ O
when -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
training -X- _ O
data -X- _ O
is -X- _ O
insufficient -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
if -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
lot -X- _ O
of -X- _ O
training -X- _ O
data -X- _ O
in -X- _ O
the -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
application -X- _ O
, -X- _ O
CoMPM -X- _ B-MethodName
is -X- _ O
expected -X- _ O
to -X- _ O
achieve -X- _ O
good -X- _ O
performance -X- _ O
, -X- _ O
otherwise -X- _ O
it -X- _ O
is -X- _ O
CoMPM -X- _ B-MethodName
( -X- _ O
f -X- _ O
) -X- _ O
. -X- _ O

ERC -X- _ B-TaskName
in -X- _ O
other -X- _ O
languages -X- _ O

Previous -X- _ O
studies -X- _ O
mostly -X- _ O
utilize -X- _ O
external -X- _ O
knowledge -X- _ O
to -X- _ O
improve -X- _ O
performance -X- _ O
, -X- _ O
but -X- _ O
these -X- _ O
approaches -X- _ O
require -X- _ O
additional -X- _ O
publicly -X- _ O
available -X- _ O
data -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
mainly -X- _ O
available -X- _ O
for -X- _ O
English -X- _ O
. -X- _ O
Indeed -X- _ O
, -X- _ O
structured -X- _ O
knowledge -X- _ O
and -X- _ O
ERC -X- _ B-TaskName
data -X- _ O
are -X- _ O
lacking -X- _ O
in -X- _ O
other -X- _ O
languages -X- _ O
. -X- _ O
Our -X- _ O
approach -X- _ O
can -X- _ O
be -X- _ O
extended -X- _ O
to -X- _ O
other -X- _ O
languages -X- _ O
without -X- _ O
building -X- _ O
additional -X- _ O
external -X- _ O
knowledge -X- _ O
and -X- _ O
achieves -X- _ O
better -X- _ O
performance -X- _ O
than -X- _ O
simply -X- _ O
using -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
model -X- _ O
. -X- _ O

Korean -X- _ O
Dataset -X- _ O

We -X- _ O
constructed -X- _ O
data -X- _ O
composed -X- _ O
of -X- _ O
two -X- _ O
speakers -X- _ O
in -X- _ O
Korean -X- _ O
, -X- _ O
and -X- _ O
emotion -X- _ O
- -X- _ O
inventory -X- _ O
is -X- _ O
given -X- _ O
as -X- _ O
" -X- _ O
surprise -X- _ O
, -X- _ O
fear -X- _ O
, -X- _ O
ambiguous -X- _ O
, -X- _ O
sad -X- _ O
, -X- _ O
disgust -X- _ O
, -X- _ O
joy -X- _ O
, -X- _ O
bored -X- _ O
, -X- _ O
embarrassed -X- _ O
, -X- _ O
neutral -X- _ O
" -X- _ O
. -X- _ O
The -X- _ O
total -X- _ O
number -X- _ O
of -X- _ O
sessions -X- _ O
is -X- _ O
1000 -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
average -X- _ O
number -X- _ O
of -X- _ O
utterance -X- _ O
turns -X- _ O
is -X- _ O
13.4 -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
data -X- _ O
randomly -X- _ O
divided -X- _ O
into -X- _ O
train -X- _ B-HyperparameterName
: -X- _ I-HyperparameterName
dev -X- _ I-HyperparameterName
: -X- _ I-HyperparameterName
test -X- _ I-HyperparameterName
in -X- _ O
a -X- _ O
ratio -X- _ O
of -X- _ O
8:1:1 -X- _ B-HyperparameterValue
. -X- _ O
This -X- _ O
dataset -X- _ O
is -X- _ O
for -X- _ O
actual -X- _ O
service -X- _ O
and -X- _ O
is -X- _ O
not -X- _ O
released -X- _ O
to -X- _ O
the -X- _ O
public -X- _ O
. -X- _ O

Results -X- _ O
in -X- _ O
the -X- _ O
Korean -X- _ O
Dataset -X- _ O

In -X- _ O
Korean -X- _ O
, -X- _ O
our -X- _ O
results -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
. -X- _ O
The -X- _ O
backbone -X- _ O
of -X- _ O
CoM -X- _ O
and -X- _ O
PM -X- _ O
is -X- _ O
Korean -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
BERT -X- _ I-HyperparameterName
owned -X- _ O
by -X- _ O
the -X- _ O
company -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
Korean -X- _ O
dataset -X- _ O
, -X- _ O
like -X- _ O
the -X- _ O
English -X- _ O
dataset -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
is -X- _ O
good -X- _ O
in -X- _ O
the -X- _ O
order -X- _ O
of -X- _ O
CoMPM -X- _ B-MethodName
, -X- _ O
CoM -X- _ O
, -X- _ O
and -X- _ O
PM -X- _ O
. -X- _ O
Our -X- _ O
approach -X- _ O
simply -X- _ O
shows -X- _ O
a -X- _ O
significant -X- _ O
performance -X- _ O
improvement -X- _ O
on -X- _ O
baselines -X- _ O
that -X- _ O
are -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
to -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
and -X- _ O
works -X- _ O
well -X- _ O
for -X- _ O
other -X- _ O
languages -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
for -X- _ O
English -X- _ O
. -X- _ O

Conclusion -X- _ O

We -X- _ O
propose -X- _ O
CoMPM -X- _ B-MethodName
that -X- _ O
leverages -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
memory -X- _ O
using -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
model -X- _ O
. -X- _ O
CoMPM -X- _ B-MethodName
consists -X- _ O
of -X- _ O
a -X- _ O
context -X- _ O
embedding -X- _ O
module -X- _ O
( -X- _ O
CoM -X- _ O
) -X- _ O
and -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
memory -X- _ O
module -X- _ O
( -X- _ O
PM -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
experimental -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
each -X- _ O
module -X- _ O
is -X- _ O
effective -X- _ O
in -X- _ O
improving -X- _ O
the -X- _ O
performance -X- _ O
. -X- _ O
CoMPM -X- _ B-MethodName
outperforms -X- _ O
baselines -X- _ O
on -X- _ O
both -X- _ O
dyadic -X- _ O
- -X- _ O
party -X- _ O
and -X- _ O
multi -X- _ O
- -X- _ O
party -X- _ O
datasets -X- _ O
and -X- _ O
achieves -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
among -X- _ O
systems -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
use -X- _ O
external -X- _ O
knowledge -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
CoMPM -X- _ B-MethodName
achieves -X- _ O
performance -X- _ O
comparable -X- _ O
to -X- _ O
cutting -X- _ O
- -X- _ O
edge -X- _ O
systems -X- _ O
that -X- _ O
leverage -X- _ O
structured -X- _ O
external -X- _ O
knowledge -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
memory -X- _ O
of -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
. -X- _ O
By -X- _ O
combining -X- _ O
other -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
memories -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
memory -X- _ O
extracted -X- _ O
with -X- _ O
RoBERTa -X- _ B-HyperparameterName
is -X- _ O
richer -X- _ O
and -X- _ O
more -X- _ O
effective -X- _ O
than -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
memory -X- _ O
extracted -X- _ O
with -X- _ O
BERT -X- _ B-HyperparameterName
or -X- _ O
GPT2 -X- _ B-HyperparameterName
. -X- _ O
Since -X- _ O
we -X- _ O
believe -X- _ O
that -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
memory -X- _ O
is -X- _ O
proportional -X- _ O
to -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
a -X- _ O
language -X- _ O
model -X- _ O
, -X- _ O
a -X- _ O
language -X- _ O
model -X- _ O
with -X- _ O
a -X- _ O
large -X- _ O
training -X- _ O
corpus -X- _ O
and -X- _ O
many -X- _ O
parameters -X- _ O
is -X- _ O
considered -X- _ O
to -X- _ O
be -X- _ O
more -X- _ O
effective -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
context -X- _ O
modeling -X- _ O
is -X- _ O
more -X- _ O
important -X- _ O
than -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
memory -X- _ O
for -X- _ O
emotion -X- _ B-TaskName
recognition -X- _ I-TaskName
in -X- _ I-TaskName
conversation -X- _ I-TaskName
, -X- _ O
and -X- _ O
future -X- _ O
research -X- _ O
will -X- _ O
focus -X- _ O
on -X- _ O
context -X- _ O
modeling -X- _ O
. -X- _ O

Additionally -X- _ O
, -X- _ O
our -X- _ O
approach -X- _ O
achieves -X- _ O
competitive -X- _ O
performance -X- _ O
and -X- _ O
does -X- _ O
not -X- _ O
require -X- _ O
externally -X- _ O
structured -X- _ O
data -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
easily -X- _ O
extended -X- _ O
to -X- _ O
Korean -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
English -X- _ O
, -X- _ O
and -X- _ O
it -X- _ O
is -X- _ O
expected -X- _ O
to -X- _ O
be -X- _ O
effective -X- _ O
in -X- _ O
other -X- _ O
countries -X- _ O
. -X- _ O

