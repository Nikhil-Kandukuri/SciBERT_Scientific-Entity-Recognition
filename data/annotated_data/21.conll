-DOCSTART- -X- O
AUTOSUMM -X- _ B-TaskName
: -X- _ O
Automatic -X- _ B-TaskName
Model -X- _ I-TaskName
Creation -X- _ I-TaskName
for -X- _ I-TaskName
Text -X- _ I-TaskName
Summarization -X- _ I-TaskName

Recent -X- _ O
efforts -X- _ O
to -X- _ O
develop -X- _ O
deep -X- _ O
learning -X- _ O
models -X- _ O
for -X- _ O
text -X- _ O
generation -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
extractive -X- _ O
and -X- _ O
abstractive -X- _ O
summarization -X- _ O
have -X- _ O
resulted -X- _ O
in -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performances -X- _ O
on -X- _ O
various -X- _ O
datasets -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
obtaining -X- _ O
the -X- _ O
best -X- _ O
model -X- _ O
configuration -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
dataset -X- _ O
requires -X- _ O
an -X- _ O
extensive -X- _ O
knowledge -X- _ O
of -X- _ O
deep -X- _ O
learning -X- _ O
specifics -X- _ O
like -X- _ O
model -X- _ O
architecture -X- _ O
, -X- _ O
tuning -X- _ O
parameters -X- _ O
etc -X- _ O
. -X- _ O
, -X- _ O
and -X- _ O
is -X- _ O
often -X- _ O
extremely -X- _ O
challenging -X- _ O
for -X- _ O
a -X- _ O
non -X- _ O
- -X- _ O
expert -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
methods -X- _ O
to -X- _ O
automatically -X- _ O
create -X- _ O
deep -X- _ O
learning -X- _ O
models -X- _ O
for -X- _ O
the -X- _ O
tasks -X- _ O
of -X- _ O
extractive -X- _ O
and -X- _ O
abstractive -X- _ O
text -X- _ O
summarization -X- _ O
. -X- _ O
Based -X- _ O
on -X- _ O
the -X- _ O
recent -X- _ O
advances -X- _ O
in -X- _ O
Automated -X- _ O
Machine -X- _ O
Learning -X- _ O
and -X- _ O
the -X- _ O
success -X- _ O
of -X- _ O
large -X- _ O
language -X- _ O
models -X- _ O
such -X- _ O
as -X- _ O
BERT -X- _ O
and -X- _ O
GPT-2 -X- _ O
in -X- _ O
encoding -X- _ O
knowledge -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
combination -X- _ O
of -X- _ O
Neural -X- _ O
Architecture -X- _ O
Search -X- _ O
( -X- _ O
NAS -X- _ O
) -X- _ O
and -X- _ O
Knowledge -X- _ O
Distillation -X- _ O
( -X- _ O
KD -X- _ O
) -X- _ O
techniques -X- _ O
to -X- _ O
perform -X- _ O
model -X- _ O
search -X- _ O
and -X- _ O
compression -X- _ O
using -X- _ O
the -X- _ O
vast -X- _ O
knowledge -X- _ O
provided -X- _ O
by -X- _ O
these -X- _ O
language -X- _ O
models -X- _ O
to -X- _ O
develop -X- _ O
smaller -X- _ O
, -X- _ O
customized -X- _ O
models -X- _ O
for -X- _ O
any -X- _ O
given -X- _ O
dataset -X- _ O
. -X- _ O
We -X- _ O
present -X- _ O
extensive -X- _ O
empirical -X- _ O
results -X- _ O
to -X- _ O
illustrate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
creation -X- _ O
methods -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
inference -X- _ O
time -X- _ O
and -X- _ O
model -X- _ O
size -X- _ O
, -X- _ O
while -X- _ O
achieving -X- _ O
near -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performances -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
accuracy -X- _ O
across -X- _ O
a -X- _ O
range -X- _ O
of -X- _ O
datasets -X- _ O
. -X- _ O

Introduction -X- _ O

Machine -X- _ O
learning -X- _ O
algorithms -X- _ O
, -X- _ O
particularly -X- _ O
, -X- _ O
deep -X- _ O
learning -X- _ O
techniques -X- _ O
have -X- _ O
led -X- _ O
to -X- _ O
the -X- _ O
simplification -X- _ O
of -X- _ O
several -X- _ O
computationally -X- _ O
expensive -X- _ O
tasks -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
training -X- _ O
and -X- _ O
optimizing -X- _ O
these -X- _ O
models -X- _ O
for -X- _ O
different -X- _ O
tasks -X- _ O
demand -X- _ O
the -X- _ O
experienced -X- _ O
engineering -X- _ O
resources -X- _ O
and -X- _ O
require -X- _ O
expertise -X- _ O
, -X- _ O
making -X- _ O
it -X- _ O
difficult -X- _ O
for -X- _ O
non -X- _ O
- -X- _ O
experts -X- _ O
. -X- _ O
Automated -X- _ O
Machine -X- _ O
Learning -X- _ O
is -X- _ O
a -X- _ O
strategy -X- _ O
to -X- _ O
automate -X- _ O
this -X- _ O
pipeline -X- _ O
for -X- _ O
model -X- _ O
creation -X- _ O
including -X- _ O
automated -X- _ O
generation -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
itself -X- _ O
. -X- _ O
* -X- _ O
Work -X- _ O
done -X- _ O
while -X- _ O
authors -X- _ O
were -X- _ O
at -X- _ O
Adobe -X- _ O
Research -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
case -X- _ O
of -X- _ O
Natural -X- _ O
Language -X- _ O
Processing -X- _ O
and -X- _ O
Text -X- _ O
analysis -X- _ O
, -X- _ O
the -X- _ O
advent -X- _ O
of -X- _ O
large -X- _ O
language -X- _ O
models -X- _ O
such -X- _ O
as -X- _ O
BERT -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
GPT2 -X- _ O
( -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
more -X- _ O
recently -X- _ O
GPT3 -X- _ O
( -X- _ O
Brown -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
have -X- _ O
created -X- _ O
resources -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
exploited -X- _ O
for -X- _ O
the -X- _ O
creation -X- _ O
of -X- _ O
robust -X- _ O
models -X- _ O
for -X- _ O
several -X- _ O
downstream -X- _ O
NLP -X- _ O
tasks -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
need -X- _ O
for -X- _ O
ML -X- _ O
expertise -X- _ O
creates -X- _ O
a -X- _ O
bottleneck -X- _ O
. -X- _ O
Further -X- _ O
, -X- _ O
these -X- _ O
deep -X- _ O
learning -X- _ O
models -X- _ O
have -X- _ O
thousands -X- _ O
of -X- _ O
parameters -X- _ B-MetricName
and -X- _ O
need -X- _ O
fairly -X- _ O
large -X- _ O
datasets -X- _ O
and -X- _ O
computational -X- _ B-MetricName
resources -X- _ I-MetricName
for -X- _ O
training -X- _ O
. -X- _ O

We -X- _ O
focus -X- _ O
on -X- _ O
providing -X- _ O
algorithms -X- _ O
for -X- _ O
autogeneration -X- _ B-TaskName
of -X- _ I-TaskName
ML -X- _ I-TaskName
models -X- _ I-TaskName
for -X- _ I-TaskName
complex -X- _ I-TaskName
NLP -X- _ I-TaskName
tasks -X- _ I-TaskName
such -X- _ I-TaskName
as -X- _ I-TaskName
extraction -X- _ I-TaskName
and -X- _ I-TaskName
generation -X- _ I-TaskName
, -X- _ O
making -X- _ O
them -X- _ O
accessible -X- _ O
to -X- _ O
non -X- _ O
experts -X- _ O
. -X- _ O
Our -X- _ O
proposed -X- _ O
approaches -X- _ O
feed -X- _ O
off -X- _ O
the -X- _ O
knowledge -X- _ O
available -X- _ O
in -X- _ O
large -X- _ O
pretrained -X- _ O
models -X- _ O
to -X- _ O
auto -X- _ O
- -X- _ O
generate -X- _ O
new -X- _ O
, -X- _ O
smaller -X- _ O
, -X- _ O
customized -X- _ O
models -X- _ O
for -X- _ O
a -X- _ O
custom -X- _ O
dataset -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
the -X- _ O
major -X- _ O
contributions -X- _ O
are -X- _ O
as -X- _ O
follows -X- _ O
. -X- _ O

Figure -X- _ O
1 -X- _ O
shows -X- _ O
the -X- _ O
overview -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
creation -X- _ O
framework -X- _ O
. -X- _ O
The -X- _ O
input -X- _ O
is -X- _ O
the -X- _ O
dataset -X- _ O
and -X- _ O
task -X- _ O
specifications -X- _ O
( -X- _ O
summary -X- _ O
type -X- _ O
, -X- _ O
size -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
output -X- _ O
is -X- _ O
a -X- _ O
custom -X- _ O
trained -X- _ O
summarization -X- _ O
model -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
further -X- _ O
used -X- _ O
to -X- _ O
create -X- _ O
text -X- _ O
summaries -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
generate -X- _ O
models -X- _ O
for -X- _ O
both -X- _ O
extractive -X- _ O
and -X- _ O
abstractive -X- _ O
summarization -X- _ O
tasks -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
former -X- _ O
being -X- _ O
a -X- _ O
binary -X- _ O
classification -X- _ O
task -X- _ O
to -X- _ O
extract -X- _ O
summary -X- _ O
sentences -X- _ O
from -X- _ O
the -X- _ O
input -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
latter -X- _ O
aims -X- _ O
to -X- _ O
generate -X- _ O
summaries -X- _ O
containing -X- _ O
novel -X- _ O
words -X- _ O
and -X- _ O
phrases -X- _ O
that -X- _ O
may -X- _ O
not -X- _ O
be -X- _ O
present -X- _ O
in -X- _ O
the -X- _ O
input -X- _ O
text -X- _ O
. -X- _ O
Our -X- _ O
proposed -X- _ O
approaches -X- _ O
distills -X- _ O
knowledge -X- _ O
from -X- _ O
a -X- _ O
language -X- _ O
- -X- _ O
model -X- _ O
based -X- _ O
teacher -X- _ O
network -X- _ O
to -X- _ O
generate -X- _ O
an -X- _ O
encoder -X- _ O
- -X- _ O
decoder -X- _ O
- -X- _ O
based -X- _ O
child -X- _ O
model -X- _ O
. -X- _ O
We -X- _ O
present -X- _ O
two -X- _ O
algorithms -X- _ O
that -X- _ O
aid -X- _ O
in -X- _ O
auto -X- _ O
- -X- _ O
creation -X- _ O
of -X- _ O
different -X- _ O
types -X- _ O
of -X- _ O
resulting -X- _ O
' -X- _ O
child -X- _ O
' -X- _ O
models -X- _ O
- -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
a -X- _ O
model -X- _ O
with -X- _ O
convolutional -X- _ O
and -X- _ O
recurrent -X- _ O
units -X- _ O
and -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
a -X- _ O
mini -X- _ O
- -X- _ O
transformer -X- _ O
based -X- _ O
model -X- _ O
. -X- _ O
The -X- _ O
first -X- _ O
is -X- _ O
achieved -X- _ O
by -X- _ O
our -X- _ O
approach -X- _ O
AUTOSUMM -X- _ B-TaskName
- -X- _ I-TaskName
CREATE -X- _ I-TaskName
and -X- _ O
the -X- _ O
second -X- _ O
using -X- _ O
AUTOSUMM -X- _ B-TaskName
- -X- _ I-TaskName
DISTILL -X- _ I-TaskName
, -X- _ O
which -X- _ O
are -X- _ O
detailed -X- _ O
as -X- _ O
follows -X- _ O
. -X- _ O
Here -X- _ O
, -X- _ O
we -X- _ O
combine -X- _ O
knowledge -X- _ O
distillation -X- _ O
with -X- _ O
neural -X- _ O
architecture -X- _ O
search -X- _ O
to -X- _ O
auto -X- _ O
- -X- _ O
create -X- _ O
an -X- _ O
encoderdecoder -X- _ O
based -X- _ O
summarization -X- _ O
model -X- _ O
. -X- _ O
The -X- _ O
stages -X- _ O
in -X- _ O
this -X- _ O
method -X- _ O
include -X- _ O
: -X- _ O

AutoSumm -X- _ B-TaskName
- -X- _ I-TaskName
Create -X- _ I-TaskName

1 -X- _ O
. -X- _ O
Task -X- _ O
- -X- _ O
specific -X- _ O
knowledge -X- _ O
distillation -X- _ O
: -X- _ O
We -X- _ O
leverage -X- _ O
knowledge -X- _ O
from -X- _ O
a -X- _ O
transformer -X- _ O
- -X- _ O
based -X- _ O
BERT -X- _ O
model -X- _ O
( -X- _ O
teacher -X- _ O
) -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
for -X- _ O
extractive -X- _ O
and -X- _ O
abstractive -X- _ O
summarization -X- _ O
( -X- _ O
Liu -X- _ O
and -X- _ O
Lapata -X- _ O
, -X- _ O
2019b -X- _ O
) -X- _ O
on -X- _ O
the -X- _ O
given -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
( -X- _ O
summarization -X- _ O
) -X- _ O
dataset -X- _ O
. -X- _ O
The -X- _ O
predictions -X- _ O
from -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
are -X- _ O
used -X- _ O
for -X- _ O
distillation -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
the -X- _ O
sentences -X- _ O
classification -X- _ O
scores -X- _ O
for -X- _ O
extractive -X- _ O
and -X- _ O
probability -X- _ O
distributions -X- _ O
over -X- _ O
the -X- _ O
vocabulary -X- _ O
for -X- _ O
abstractive -X- _ O
are -X- _ O
augmented -X- _ O
to -X- _ O
the -X- _ O
ground -X- _ O
truth -X- _ O
. -X- _ O
A -X- _ O
Knowledge -X- _ O
Distillation -X- _ O
( -X- _ O
L -X- _ O
KD -X- _ O
) -X- _ O
loss -X- _ O
is -X- _ O
included -X- _ O
to -X- _ O
perform -X- _ O
informed -X- _ O
search -X- _ O
on -X- _ O
the -X- _ O
child -X- _ O
models -X- _ O
, -X- _ O
ensuring -X- _ O
that -X- _ O
they -X- _ O
mimic -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
teacher -X- _ O
. -X- _ O
In -X- _ O
extractive -X- _ O
summarization -X- _ O
, -X- _ O
L -X- _ O
KD -X- _ O
is -X- _ O
the -X- _ O
MSE -X- _ O
loss -X- _ O
between -X- _ O
soft -X- _ O
labels -X- _ O
from -X- _ O
augmented -X- _ O
data -X- _ O
and -X- _ O
the -X- _ O
scored -X- _ O
predicted -X- _ O
by -X- _ O
the -X- _ O
child -X- _ O
model -X- _ O
. -X- _ O

L -X- _ O
KD -X- _ O
= -X- _ O
n -X- _ O
i=1 -X- _ O
( -X- _ O
y -X- _ O
teacher -X- _ O
i -X- _ O
− -X- _ O
y -X- _ O
pred -X- _ O
i -X- _ O
) -X- _ O
2 -X- _ O

( -X- _ O
1 -X- _ O
) -X- _ O

In -X- _ O
abstractive -X- _ O
summarization -X- _ O
, -X- _ O
L -X- _ O
KD -X- _ O
is -X- _ O
calculated -X- _ O
at -X- _ O
each -X- _ O
time -X- _ O
step -X- _ O
t -X- _ O
using -X- _ O
soft -X- _ O
labels -X- _ O
P -X- _ O
teacher -X- _ O
( -X- _ O
y -X- _ O
t -X- _ O
) -X- _ O
from -X- _ O
teacher -X- _ O
model -X- _ O
and -X- _ O
the -X- _ O
predicted -X- _ O
labels -X- _ O
P -X- _ O
pred -X- _ O
( -X- _ O
y -X- _ O
t -X- _ O
) -X- _ O
from -X- _ O
child -X- _ O
model -X- _ O
over -X- _ O
vocab -X- _ O
V -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

L -X- _ O
KD -X- _ O
= -X- _ O
t -X- _ O
w∈V -X- _ O

P -X- _ O
teacher -X- _ O
( -X- _ O
y -X- _ O
t -X- _ O
= -X- _ O
w|y -X- _ O
1 -X- _ O
: -X- _ O
t−1 -X- _ O
, -X- _ O
X -X- _ O
) -X- _ O
. -X- _ O
log -X- _ O
( -X- _ O
P -X- _ O
pred -X- _ O
( -X- _ O
y -X- _ O
t -X- _ O
= -X- _ O
w|y -X- _ O
1 -X- _ O
: -X- _ O
t−1 -X- _ O
, -X- _ O
X -X- _ O
) -X- _ O
) -X- _ O

2 -X- _ O
. -X- _ O
Neural -X- _ O
Architectural -X- _ O
Search -X- _ O
: -X- _ O
Augmented -X- _ O
dataset -X- _ O
, -X- _ O
along -X- _ O
with -X- _ O
a -X- _ O
small -X- _ O
labelled -X- _ O
custom -X- _ O
dataset -X- _ O
, -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
train -X- _ O
the -X- _ O
NAS -X- _ O
module -X- _ O
, -X- _ O
which -X- _ O
searches -X- _ O
for -X- _ O
the -X- _ O
right -X- _ O
combination -X- _ O
of -X- _ O
cells -X- _ O
that -X- _ O
result -X- _ O
in -X- _ O
the -X- _ O
child -X- _ O
model -X- _ O
most -X- _ O
suited -X- _ O
for -X- _ O
the -X- _ O
summarization -X- _ O
task -X- _ O
. -X- _ O

In -X- _ O
our -X- _ O
approach -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
NAS -X- _ O
to -X- _ O
search -X- _ O
the -X- _ O
encoder -X- _ O
space -X- _ O
while -X- _ O
using -X- _ O
a -X- _ O
predefined -X- _ O
( -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
) -X- _ O
decoder -X- _ O
. -X- _ O
The -X- _ O
key -X- _ O
components -X- _ O
of -X- _ O
this -X- _ O
module -X- _ O
are -X- _ O
: -X- _ O
Search -X- _ O
space -X- _ O
. -X- _ O
Following -X- _ O
, -X- _ O
we -X- _ O
define -X- _ O
macro -X- _ O
search -X- _ O
space -X- _ O
, -X- _ O
such -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
can -X- _ O
be -X- _ O
represented -X- _ O
by -X- _ O
a -X- _ O
directed -X- _ O
acyclic -X- _ O
graph -X- _ O
( -X- _ O
DAG -X- _ O
) -X- _ O
with -X- _ O
nodes -X- _ O
representing -X- _ O
a -X- _ O
layer -X- _ O
from -X- _ O
the -X- _ O
search -X- _ O
space -X- _ O
and -X- _ O
edges -X- _ O
representing -X- _ O
the -X- _ O
directionality -X- _ O
of -X- _ O
flow -X- _ O
of -X- _ O
information -X- _ O
. -X- _ O
The -X- _ O
search -X- _ O
space -X- _ O
has -X- _ O
4 -X- _ O
key -X- _ O
cell -X- _ O
types -X- _ O
-CNN -X- _ O
( -X- _ O
kernel -X- _ O
sizes -X- _ O
1,3,5,7 -X- _ O
) -X- _ O
, -X- _ O
RNN -X- _ O
( -X- _ O
bidirectional -X- _ O
GRU -X- _ O
) -X- _ O
, -X- _ O
Pooling -X- _ O
layers -X- _ O
( -X- _ O
avg -X- _ O
. -X- _ O
pool -X- _ O
and -X- _ O
max -X- _ O
. -X- _ O
pool -X- _ O
with -X- _ O
stride -X- _ O
1 -X- _ O
and -X- _ O
uniform -X- _ O
padding -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
Multi -X- _ O
- -X- _ O
head -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
( -X- _ O
8 -X- _ O
heads -X- _ O
, -X- _ O
no -X- _ O
positional -X- _ O
embeddings -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
constrain -X- _ O
the -X- _ O
search -X- _ O
space -X- _ O
by -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
defining -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
skip -X- _ O
connections -X- _ O
allowed -X- _ O
, -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
limiting -X- _ O
the -X- _ O
maximum -X- _ O
number -X- _ O
of -X- _ O
layers -X- _ O
in -X- _ O
the -X- _ O
child -X- _ O
architecture -X- _ O
, -X- _ O
l -X- _ O
( -X- _ O
in -X- _ O
our -X- _ O
case -X- _ O
l -X- _ O
∈ -X- _ O
1,5,10,18,20 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
defining -X- _ O
the -X- _ O
cells -X- _ O
allowed -X- _ O
in -X- _ O
the -X- _ O
new -X- _ O
architecture -X- _ O
. -X- _ O
These -X- _ O
constraints -X- _ O
define -X- _ O
the -X- _ O
exhaustive -X- _ O
list -X- _ O
of -X- _ O
possibilities -X- _ O
for -X- _ O
the -X- _ O
NAS -X- _ O
algorithm -X- _ O
. -X- _ O

Search -X- _ O
algorithm -X- _ O
: -X- _ O
We -X- _ O
implement -X- _ O
ENAS -X- _ B-HyperparameterName
( -X- _ O
Pham -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
reinforcement -X- _ O
learning -X- _ O
( -X- _ O
RL -X- _ O
) -X- _ O
based -X- _ O
algorithm -X- _ O
used -X- _ O
for -X- _ O
several -X- _ O
NAS -X- _ O
implementations -X- _ O
( -X- _ O
Zoph -X- _ O
and -X- _ O
Le -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
It -X- _ O
consists -X- _ O
of -X- _ O
an -X- _ O
RNN -X- _ O
controller -X- _ O
network -X- _ O
, -X- _ O
that -X- _ O
samples -X- _ O
a -X- _ O
model -X- _ O
architecture -X- _ O
from -X- _ O
the -X- _ O
search -X- _ O
space -X- _ O
and -X- _ O
an -X- _ O
RL -X- _ O
reward -X- _ O
to -X- _ O
nudge -X- _ O
this -X- _ O
controller -X- _ O
towards -X- _ O
generating -X- _ O
an -X- _ O
optimal -X- _ O
architecture -X- _ O
. -X- _ O

Pre -X- _ O
- -X- _ O
defined -X- _ O
Model -X- _ O
Specifications -X- _ O
: -X- _ O
As -X- _ O
stated -X- _ O
earlier -X- _ O
, -X- _ O
we -X- _ O
auto -X- _ O
- -X- _ O
create -X- _ O
the -X- _ O
encoder -X- _ O
layers -X- _ O
in -X- _ O
the -X- _ O
model -X- _ O
but -X- _ O
predefine -X- _ O
the -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
decoder -X- _ O
. -X- _ O
For -X- _ O
extractive -X- _ O
summarization -X- _ O
, -X- _ O
the -X- _ O
decoder -X- _ O
is -X- _ O
a -X- _ O
scorer -X- _ O
function -X- _ O
with -X- _ O
sigmoid -X- _ O
activation -X- _ O
, -X- _ O
which -X- _ O
takes -X- _ O
in -X- _ O
the -X- _ O
text -X- _ O
representations -X- _ O
learnt -X- _ O
from -X- _ O
the -X- _ O
encoder -X- _ O
and -X- _ O
scores -X- _ O
each -X- _ O
sentence -X- _ O
on -X- _ O
a -X- _ O
scale -X- _ O
of -X- _ O
( -X- _ O
0,1 -X- _ O
] -X- _ O
. -X- _ O
The -X- _ O
sentences -X- _ O
with -X- _ O
the -X- _ O
high -X- _ O
scores -X- _ O
are -X- _ O
chosen -X- _ O
as -X- _ O
the -X- _ O
final -X- _ O
summary -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
summary -X- _ O
size -X- _ O
specified -X- _ O
. -X- _ O
For -X- _ O
abstractive -X- _ O
summarization -X- _ O
, -X- _ O
a -X- _ O
recurrent -X- _ O
neural -X- _ O
network -X- _ O
is -X- _ O
used -X- _ O
as -X- _ O
the -X- _ O
decoder -X- _ O
. -X- _ O
The -X- _ O
input -X- _ O
is -X- _ O
the -X- _ O
text -X- _ O
representation -X- _ O
from -X- _ O
the -X- _ O
encoder -X- _ O
and -X- _ O
the -X- _ O
output -X- _ O
is -X- _ O
a -X- _ O
generated -X- _ O
summary -X- _ O
( -X- _ O
generated -X- _ O
in -X- _ O
auto -X- _ O
- -X- _ O
regressive -X- _ O
manner -X- _ O
, -X- _ O
by -X- _ O
decoding -X- _ O
a -X- _ O
word -X- _ O
at -X- _ O
every -X- _ O
time -X- _ O
step -X- _ O
) -X- _ O
. -X- _ O

Loss -X- _ O
: -X- _ O
The -X- _ O
architectures -X- _ O
are -X- _ O
trained -X- _ O
with -X- _ O
a -X- _ O
crossentropy -X- _ B-HyperparameterName
loss -X- _ I-HyperparameterName
at -X- _ O
sentence -X- _ O
level -X- _ O
for -X- _ O
extractive -X- _ O
and -X- _ O
vocab -X- _ O
level -X- _ O
for -X- _ O
abstractive -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

Ext -X- _ O
( -X- _ O
L -X- _ O
CE -X- _ O
) -X- _ O
= -X- _ O
n -X- _ O
i=1 -X- _ O
( -X- _ O
p -X- _ O
gt -X- _ O
( -X- _ O
y -X- _ O
i -X- _ O
) -X- _ O
.log -X- _ O
( -X- _ O
y -X- _ O
child -X- _ O
i -X- _ O
) -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
Abs -X- _ O
( -X- _ O
L -X- _ O
CE -X- _ O
) -X- _ O
= -X- _ O
t -X- _ O
w∈V -X- _ O
P -X- _ O
gt -X- _ O
( -X- _ O
y -X- _ O
t -X- _ O
= -X- _ O
w -X- _ O
) -X- _ O
. -X- _ O
log -X- _ O
( -X- _ O
P -X- _ O
pred -X- _ O
( -X- _ O
y -X- _ O
t -X- _ O
= -X- _ O
w|y -X- _ O
1 -X- _ O
: -X- _ O
t−1 -X- _ O
, -X- _ O
X -X- _ O
) -X- _ O
) -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O

Final -X- _ O
Loss -X- _ O
: -X- _ O
The -X- _ O
final -X- _ O
end -X- _ O
- -X- _ O
end -X- _ O
loss -X- _ O
associated -X- _ O
with -X- _ O
this -X- _ O
framework -X- _ O
is -X- _ O
computed -X- _ O
as -X- _ O
the -X- _ O
weighted -X- _ O
sum -X- _ O
of -X- _ O
the -X- _ O
L -X- _ O
KD -X- _ O
and -X- _ O
L -X- _ O
CE -X- _ O
in -X- _ O
the -X- _ O
NAS -X- _ O
module -X- _ O
: -X- _ O

L -X- _ O
total -X- _ O
= -X- _ O
α -X- _ O
. -X- _ O
L -X- _ O
CE -X- _ O
+ -X- _ O
( -X- _ O
1 -X- _ O
− -X- _ O
α -X- _ O
) -X- _ O
.L -X- _ O
KD -X- _ O
( -X- _ O
5 -X- _ O
) -X- _ O

RL -X- _ O
Reward -X- _ O
: -X- _ O
A -X- _ O
reward -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
child -X- _ O
model -X- _ O
, -X- _ O
is -X- _ O
sent -X- _ O
back -X- _ O
to -X- _ O
the -X- _ O
RNN -X- _ O
controller -X- _ O
. -X- _ O
The -X- _ O
policy -X- _ O
gradients -X- _ O
of -X- _ O
the -X- _ O
RNN -X- _ O
controller -X- _ O
are -X- _ O
updated -X- _ O
through -X- _ O
REINFORCE -X- _ B-HyperparameterName
( -X- _ O
Williams -X- _ O
, -X- _ O
1992 -X- _ O
) -X- _ O
algorithm -X- _ O
. -X- _ O
Reward -X- _ O
( -X- _ O
R -X- _ O
) -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O
1 -X- _ O
− -X- _ O
Loss -X- _ O
valid -X- _ O
, -X- _ O
normalized -X- _ O
over -X- _ O
the -X- _ O
batchsize -X- _ O
. -X- _ O

Re -X- _ O
- -X- _ O
training -X- _ O
: -X- _ O
The -X- _ O
newly -X- _ O
generated -X- _ O
model -X- _ O
, -X- _ O
is -X- _ O
trained -X- _ O
using -X- _ O
the -X- _ O
user -X- _ O
- -X- _ O
provided -X- _ O
training -X- _ O
data -X- _ O
optimizing -X- _ O
for -X- _ O
the -X- _ O
total -X- _ O
loss -X- _ O
( -X- _ O
L -X- _ O
total -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
trained -X- _ O
model -X- _ O
can -X- _ O
generate -X- _ O
summaries -X- _ O
for -X- _ O
any -X- _ O
given -X- _ O
test -X- _ O
sample -X- _ O
. -X- _ O

AutoSumm -X- _ B-TaskName
- -X- _ I-TaskName
Distill -X- _ I-TaskName

In -X- _ O
this -X- _ O
approach -X- _ O
, -X- _ O
the -X- _ O
structure -X- _ O
of -X- _ O
the -X- _ O
child -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O
a -X- _ O
mini -X- _ O
- -X- _ O
transformer -X- _ O
( -X- _ O
4 -X- _ O
layers -X- _ O
) -X- _ O
. -X- _ O
A -X- _ O
knowledge -X- _ O
distillation -X- _ O
technique -X- _ O
called -X- _ O
transformer -X- _ O
distillation -X- _ O
( -X- _ O
Jiao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
create -X- _ O
a -X- _ O
generalmini -X- _ O
- -X- _ O
transformer -X- _ O
( -X- _ O
4 -X- _ O
layers -X- _ O
) -X- _ O
from -X- _ O
a -X- _ O
large -X- _ O
transformer -X- _ O
model -X- _ O
( -X- _ O
12 -X- _ O
layers -X- _ O
) -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
the -X- _ O
knowledge -X- _ O
is -X- _ O
distilled -X- _ O
from -X- _ O
a -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
BERT -X- _ O
( -X- _ O
' -X- _ O
teacher -X- _ O
' -X- _ O
) -X- _ O
model -X- _ O
to -X- _ O
the -X- _ O
general -X- _ O
- -X- _ O
mini -X- _ O
- -X- _ O
transformer -X- _ O
. -X- _ O
Figure -X- _ O
3 -X- _ O
illustrates -X- _ O
the -X- _ O
workflow -X- _ O
of -X- _ O
this -X- _ O
method -X- _ O
. -X- _ O
This -X- _ O
method -X- _ O
differs -X- _ O
from -X- _ O
AUTOSUMM -X- _ B-TaskName
- -X- _ I-TaskName
CREATE -X- _ I-TaskName
, -X- _ O
in -X- _ O
the -X- _ O
child -X- _ O
model -X- _ O
architecture -X- _ O
and -X- _ O
the -X- _ O
usage -X- _ O
of -X- _ O
two -X- _ O
transformer -X- _ O
teacher -X- _ O
models -X- _ O
. -X- _ O
The -X- _ O
key -X- _ O
stages -X- _ O
in -X- _ O
this -X- _ O
method -X- _ O
are -X- _ O
detailed -X- _ O
below -X- _ O
. -X- _ O
Knowledge -X- _ O
distillation -X- _ O
: -X- _ O
There -X- _ O
are -X- _ O
two -X- _ O
forms -X- _ O
of -X- _ O
knowledge -X- _ O
distillation -X- _ O
in -X- _ O
this -X- _ O
method -X- _ O
( -X- _ O
1 -X- _ O
and -X- _ O
3 -X- _ O
in -X- _ O
Fig -X- _ O
. -X- _ O
3 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
detail -X- _ O
the -X- _ O
knowledge -X- _ O
distillation -X- _ O
from -X- _ O
a -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
transformer -X- _ O
teacher -X- _ O
( -X- _ O
we -X- _ O
use -X- _ O
BERT -X- _ O
- -X- _ O
Summ -X- _ O
( -X- _ O
Liu -X- _ O
and -X- _ O
Lapata -X- _ O
, -X- _ O
2019b -X- _ O
) -X- _ O
) -X- _ O
to -X- _ O
the -X- _ O
general -X- _ O
- -X- _ O
mini -X- _ O
- -X- _ O
transformer -X- _ O
which -X- _ O
forms -X- _ O
the -X- _ O
encoder -X- _ O
layer -X- _ O
for -X- _ O
the -X- _ O
final -X- _ O
child -X- _ O
model -X- _ O
. -X- _ O
The -X- _ O
decoder -X- _ O
is -X- _ O
pre -X- _ O
- -X- _ O
defined -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
task -X- _ O
, -X- _ O
similar -X- _ O
to -X- _ O
AUTOSUMM -X- _ B-TaskName
- -X- _ I-TaskName
CREATE -X- _ I-TaskName
. -X- _ O
A -X- _ O
transformer -X- _ O
model -X- _ O
has -X- _ O
various -X- _ O
types -X- _ O
of -X- _ O
layers -X- _ O
including -X- _ O
multi -X- _ O
- -X- _ O
headed -X- _ O
attention -X- _ O
, -X- _ O
embedding -X- _ O
layers -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
hidden -X- _ O
layers -X- _ O
. -X- _ O
The -X- _ O
intuition -X- _ O
behind -X- _ O
knowledge -X- _ O
distillation -X- _ O
is -X- _ O
to -X- _ O
teach -X- _ O
the -X- _ O
layers -X- _ O
in -X- _ O
the -X- _ O
child -X- _ O
transformer -X- _ O
to -X- _ O
mimic -X- _ O
the -X- _ O
corresponding -X- _ O
layers -X- _ O
in -X- _ O
the -X- _ O
teacher -X- _ O
transformer -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
implemented -X- _ O
by -X- _ O
introducing -X- _ O
separate -X- _ O
losses -X- _ O
for -X- _ O
each -X- _ O
layer -X- _ O
type -X- _ O
. -X- _ O

Attention -X- _ B-TaskName
- -X- _ I-TaskName
based -X- _ I-TaskName
distillation -X- _ I-TaskName
builds -X- _ O
on -X- _ O
the -X- _ O
intuition -X- _ O
that -X- _ O
the -X- _ O
attention -X- _ O
layers -X- _ O
in -X- _ O
BERT -X- _ O
capture -X- _ O
linguistic -X- _ O
information -X- _ O
such -X- _ O
as -X- _ O
syntax -X- _ O
and -X- _ O
coreference -X- _ O
information -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
the -X- _ O
student -X- _ O
aims -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
matrices -X- _ O
of -X- _ O
the -X- _ O
multi -X- _ O
- -X- _ O
headed -X- _ O
attention -X- _ O
from -X- _ O
teacher -X- _ O
. -X- _ O
This -X- _ O
loss -X- _ O
is -X- _ O
given -X- _ O
by -X- _ O

where -X- _ O
h -X- _ O
is -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
attention -X- _ O
heads -X- _ O
A -X- _ O
i -X- _ O
refers -X- _ O
to -X- _ O
the -X- _ O
attention -X- _ O
matrix -X- _ O
corresponding -X- _ O
to -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
head -X- _ O
of -X- _ O
the -X- _ O
teacher -X- _ O
( -X- _ O
T -X- _ O
) -X- _ O
or -X- _ O
the -X- _ O
student -X- _ O
( -X- _ O
S -X- _ O
) -X- _ O
, -X- _ O
l -X- _ O
is -X- _ O
the -X- _ O
input -X- _ O
text -X- _ O
length -X- _ O
and -X- _ O
M -X- _ O
SE -X- _ O
( -X- _ O
. -X- _ O
) -X- _ O
refers -X- _ O
to -X- _ O
the -X- _ O
mean -X- _ O
squared -X- _ O
error -X- _ O
loss -X- _ O
. -X- _ O
Hidden -X- _ O
- -X- _ O
state -X- _ O
distillation -X- _ O
distills -X- _ O
knowledge -X- _ O
from -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
transformer -X- _ O
hidden -X- _ O
layer -X- _ O
, -X- _ O
with -X- _ O

L -X- _ O
hidn -X- _ O
= -X- _ O
M -X- _ O
SE -X- _ O
( -X- _ O
H -X- _ O
s -X- _ O
W -X- _ O
h -X- _ O
, -X- _ O
H -X- _ O
T -X- _ O
) -X- _ O

where -X- _ O
H -X- _ O
s -X- _ O
and -X- _ O
H -X- _ O
T -X- _ O
refer -X- _ O
to -X- _ O
the -X- _ O
hidden -X- _ O
states -X- _ O
of -X- _ O
the -X- _ O
student -X- _ O
and -X- _ O
teacher -X- _ O
models -X- _ O
. -X- _ O
W -X- _ O
h -X- _ O
is -X- _ O
a -X- _ O
learnable -X- _ O
linear -X- _ O
transformation -X- _ O
. -X- _ O
Embedding -X- _ O
- -X- _ O
layer -X- _ O
distillation -X- _ O
: -X- _ O

Formulated -X- _ O
as -X- _ O
L -X- _ O
embd -X- _ O
= -X- _ O
M -X- _ O
SE -X- _ O
( -X- _ O
E -X- _ O
s -X- _ O
W -X- _ O
e -X- _ O
, -X- _ O
E -X- _ O
T -X- _ O
) -X- _ O
where -X- _ O
E -X- _ O
s -X- _ O
and -X- _ O
E -X- _ O
T -X- _ O
are -X- _ O
embeddings -X- _ O
in -X- _ O
the -X- _ O
student -X- _ O
and -X- _ O
teacher -X- _ O
networks -X- _ O
respectively -X- _ O
. -X- _ O
W -X- _ O
e -X- _ O
plays -X- _ O
a -X- _ O
similar -X- _ O
role -X- _ O
as -X- _ O
W -X- _ O
h -X- _ O
. -X- _ O
Using -X- _ O
these -X- _ O
distillation -X- _ O
objectives -X- _ O
along -X- _ O
with -X- _ O
the -X- _ O
general -X- _ O
distillation -X- _ O
already -X- _ O
done -X- _ O
to -X- _ O
compress -X- _ O
the -X- _ O
transformer -X- _ O
model -X- _ O
to -X- _ O
general -X- _ O
- -X- _ O
mini -X- _ O
- -X- _ O
transformer -X- _ O
, -X- _ O
the -X- _ O
final -X- _ O
loss -X- _ O
is -X- _ O
the -X- _ O
unified -X- _ O
distillation -X- _ O
loss -X- _ O
of -X- _ O
the -X- _ O
corresponding -X- _ O
layers -X- _ O
between -X- _ O
the -X- _ O
teacher -X- _ O
and -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
. -X- _ O
As -X- _ O
a -X- _ O
reminder -X- _ O
, -X- _ O
this -X- _ O
step -X- _ O
helps -X- _ O
auto -X- _ O
- -X- _ O
learn -X- _ O
the -X- _ O
task -X- _ O
specific -X- _ O
encoder -X- _ O
for -X- _ O
extractive -X- _ O
and -X- _ O
abstractive -X- _ O
summarization -X- _ O
. -X- _ O
Pre -X- _ O
- -X- _ O
defined -X- _ O
Model -X- _ O
Specifications -X- _ O
: -X- _ O
For -X- _ O
extractive -X- _ O
summarization -X- _ O
, -X- _ O
we -X- _ O
define -X- _ O
a -X- _ O
single -X- _ O
transformer -X- _ O
layer -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
the -X- _ O
newly -X- _ O
created -X- _ O
encoder -X- _ O
with -X- _ O
a -X- _ O
classification -X- _ O
layer -X- _ O
as -X- _ O
the -X- _ O
decoder -X- _ O
. -X- _ O
For -X- _ O
abstractive -X- _ O
summarization -X- _ O
, -X- _ O
the -X- _ O
decoder -X- _ O
is -X- _ O
6 -X- _ O
- -X- _ O
layer -X- _ O
transformer -X- _ O
. -X- _ O
Training -X- _ O
and -X- _ O
Re -X- _ O
- -X- _ O
training -X- _ O
: -X- _ O
General -X- _ O
distillation -X- _ O
& -X- _ O
Fine -X- _ O
- -X- _ O
tuning -X- _ O
: -X- _ O
The -X- _ O
above -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
in -X- _ O
a -X- _ O
phased -X- _ O
manner -X- _ O
. -X- _ O
The -X- _ O
first -X- _ O
distillation -X- _ O
or -X- _ O
training -X- _ O
is -X- _ O
done -X- _ O
from -X- _ O
a -X- _ O
large -X- _ O
transformer -X- _ O
( -X- _ O
BERT -X- _ O
) -X- _ O
to -X- _ O
the -X- _ O
general -X- _ O
-mini -X- _ O
- -X- _ O
transformer -X- _ O
. -X- _ O
Parallelly -X- _ O
, -X- _ O
a -X- _ O
large -X- _ O
BERT -X- _ O
model -X- _ O
is -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
for -X- _ O
the -X- _ O
specified -X- _ O
tasks -X- _ O
. -X- _ O
Both -X- _ O
these -X- _ O
steps -X- _ O
need -X- _ O
not -X- _ O
be -X- _ O
repeated -X- _ O
for -X- _ O
every -X- _ O
new -X- _ O
dataset -X- _ O
from -X- _ O
the -X- _ O
user -X- _ O
and -X- _ O
every -X- _ O
run -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O
The -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
model -X- _ O
and -X- _ O
the -X- _ O
general -X- _ O
- -X- _ O
mini -X- _ O
- -X- _ O
transformers -X- _ O
may -X- _ O
be -X- _ O
created -X- _ O
once -X- _ O
per -X- _ O
task -X- _ O
and -X- _ O
once -X- _ O
per -X- _ O
a -X- _ O
very -X- _ O
large -X- _ O
benchmark -X- _ O
dataset -X- _ O
. -X- _ O
Task -X- _ O
- -X- _ O
specific -X- _ O
Distillation -X- _ O
: -X- _ O
This -X- _ O
process -X- _ O
of -X- _ O
teaching -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
from -X- _ O
a -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
teacher -X- _ O
model -X- _ O
is -X- _ O
repeated -X- _ O
each -X- _ O
time -X- _ O
a -X- _ O
new -X- _ O
user -X- _ O
dataset -X- _ O
is -X- _ O
given -X- _ O
to -X- _ O
the -X- _ O
system -X- _ O
. -X- _ O
Once -X- _ O
trained -X- _ O
, -X- _ O
this -X- _ O
is -X- _ O
coupled -X- _ O
with -X- _ O
the -X- _ O
specific -X- _ O
decoder -X- _ O
. -X- _ O

Re -X- _ O
- -X- _ O
training -X- _ O
: -X- _ O
Once -X- _ O
the -X- _ O
final -X- _ O
child -X- _ O
model -X- _ O
i.e. -X- _ O
minitransformer -X- _ O
encoder -X- _ O
and -X- _ O
corresponding -X- _ O
decoder -X- _ O
are -X- _ O
created -X- _ O
, -X- _ O
this -X- _ O
complete -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
input -X- _ O
user -X- _ O
dataset -X- _ O
. -X- _ O
The -X- _ O
final -X- _ O
model -X- _ O
is -X- _ O
the -X- _ O
output -X- _ O
for -X- _ O
the -X- _ O
user -X- _ O
along -X- _ O
with -X- _ O
test -X- _ O
summaries -X- _ O
for -X- _ O
any -X- _ O
given -X- _ O
text -X- _ O
input -X- _ O
. -X- _ O

Experiments -X- _ O

We -X- _ O
evaluate -X- _ O
our -X- _ O
proposed -X- _ O
framework -X- _ O
by -X- _ O
performing -X- _ O
experiments -X- _ O
that -X- _ O
test -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
newly -X- _ O
created -X- _ O
models -X- _ O
against -X- _ O
benchmark -X- _ O
summarization -X- _ O
datasets -X- _ O
on -X- _ O
both -X- _ O
extractive -X- _ O
and -X- _ O
abstractive -X- _ O
tasks -X- _ O
. -X- _ O
The -X- _ O
New -X- _ B-DatasetName
York -X- _ I-DatasetName
Times -X- _ I-DatasetName
( -X- _ O
NYT -X- _ B-DatasetName
) -X- _ O
Annotated -X- _ B-DatasetName
Corpus -X- _ I-DatasetName
contains -X- _ O
the -X- _ O
full -X- _ O
text -X- _ O
and -X- _ O
metadata -X- _ O
of -X- _ O
NYT -X- _ B-DatasetName
articles -X- _ O
from -X- _ O
1987 -X- _ O
to -X- _ O
2007 -X- _ O
. -X- _ O
Following -X- _ O
( -X- _ O
Durrett -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
extracted -X- _ O
and -X- _ O
filtered -X- _ O
out -X- _ O
the -X- _ O
articles -X- _ O
from -X- _ O
2000 -X- _ O
- -X- _ O
2007 -X- _ O
, -X- _ O
with -X- _ O
abstractive -X- _ O
summaries -X- _ O
having -X- _ O
more -X- _ O
than -X- _ O
50 -X- _ O
words -X- _ O
. -X- _ O
The -X- _ O
articles -X- _ O
were -X- _ O
split -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
date -X- _ O
of -X- _ O
publication -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
articles -X- _ O
from -X- _ O
January -X- _ O
1 -X- _ O
, -X- _ O
2007 -X- _ O
were -X- _ O
chosen -X- _ O
as -X- _ O
test -X- _ O
set -X- _ O
. -X- _ O

Datasets -X- _ O

X -X- _ B-DatasetName
- -X- _ I-DatasetName
Sum -X- _ I-DatasetName
( -X- _ O
Narayan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018a -X- _ O
) -X- _ O
dataset -X- _ O
is -X- _ O
collected -X- _ O
from -X- _ O
online -X- _ O
BBC -X- _ O
articles -X- _ O
, -X- _ O
with -X- _ O
short -X- _ O
one -X- _ O
sentence -X- _ O
summaries -X- _ O
. -X- _ O
The -X- _ O
Gigaword -X- _ B-DatasetName
( -X- _ O
Rush -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
dataset -X- _ O
contains -X- _ O
4 -X- _ O
M -X- _ O
examples -X- _ O
from -X- _ O
news -X- _ O
articles -X- _ O
for -X- _ O
sentence -X- _ O
summarization -X- _ O
/ -X- _ O
headline -X- _ O
generation -X- _ O
task -X- _ O
. -X- _ O
The -X- _ O
summaries -X- _ O
are -X- _ O
very -X- _ O
short -X- _ O
with -X- _ O
9 -X- _ O
tokens -X- _ O
per -X- _ O
summary -X- _ O
. -X- _ O
The -X- _ O
Contract -X- _ B-DatasetName
dataset -X- _ O
( -X- _ O
Manor -X- _ O
and -X- _ O
Li -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
dataset -X- _ O
compiled -X- _ O
from -X- _ O
two -X- _ O
websites -X- _ O
dedicated -X- _ O
to -X- _ O
explaining -X- _ O
unilateral -X- _ O
contracts -X- _ O
in -X- _ O
plain -X- _ O
English -X- _ O
: -X- _ O
TL -X- _ O
; -X- _ O
DRLegal -X- _ O
1 -X- _ O
and -X- _ O
TOS -X- _ O
; -X- _ O
DR -X- _ O
2 -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
a -X- _ O
small -X- _ O
dataset -X- _ O
with -X- _ O
500 -X- _ O
samples -X- _ O
. -X- _ O

Models -X- _ O

The -X- _ O
generated -X- _ O
models -X- _ O
through -X- _ O
AUTOSUMM -X- _ B-TaskName
- -X- _ I-TaskName
CREATE -X- _ I-TaskName
for -X- _ O
extractive -X- _ O
and -X- _ O
abstractive -X- _ O
are -X- _ O
CHILD -X- _ B-MethodName
- -X- _ I-MethodName
EXT -X- _ I-MethodName
and -X- _ O
CHILD -X- _ B-MethodName
- -X- _ I-MethodName
ABS -X- _ I-MethodName
respectively -X- _ O
. -X- _ O
-KD -X- _ O
denote -X- _ O
the -X- _ O
child -X- _ O
model -X- _ O
variations -X- _ O
trained -X- _ O
through -X- _ O
Knowledge -X- _ O
distillation -X- _ O
( -X- _ O
KD -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
models -X- _ O
through -X- _ O
AUTOSUMM -X- _ B-TaskName
- -X- _ I-TaskName
DISTILL -X- _ I-TaskName
are -X- _ O
FT -X- _ B-MethodName
- -X- _ I-MethodName
TINYBERT -X- _ I-MethodName
- -X- _ I-MethodName
EXT -X- _ I-MethodName
and -X- _ O
FT -X- _ B-MethodName
- -X- _ I-MethodName
TINYBERT -X- _ I-MethodName
- -X- _ I-MethodName
ABS -X- _ I-MethodName
. -X- _ O
We -X- _ O
compare -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
models -X- _ O
against -X- _ O
BERT -X- _ O
- -X- _ O
Summ -X- _ O
( -X- _ O
Liu -X- _ O
and -X- _ O
Lapata -X- _ O
, -X- _ O
2019a -X- _ O
) -X- _ O
, -X- _ O
as -X- _ O
it -X- _ O
had -X- _ O
a -X- _ O
general -X- _ O
framework -X- _ O
for -X- _ O
extractive -X- _ O
and -X- _ O
abstractive -X- _ O
and -X- _ O
was -X- _ O
shown -X- _ O
to -X- _ O
give -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performances -X- _ O
. -X- _ O
These -X- _ O
baseline -X- _ O
models -X- _ O
are -X- _ O
FT -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
- -X- _ I-MethodName
EXT -X- _ I-MethodName
and -X- _ O
FT -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
- -X- _ I-MethodName
ABS -X- _ I-MethodName
. -X- _ O

Implementation -X- _ O
Details -X- _ O

For -X- _ O
all -X- _ O
our -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
existing -X- _ O
splits -X- _ O
if -X- _ O
available -X- _ O
, -X- _ O
otherwise -X- _ O
we -X- _ O
split -X- _ O
the -X- _ O
data -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
statistics -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
and -X- _ O
keep -X- _ O
them -X- _ O
constant -X- _ O
across -X- _ O
all -X- _ O
the -X- _ O
experiments -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
AUTOSUMM -X- _ B-TaskName
- -X- _ I-TaskName
CREATE -X- _ I-TaskName
experiments -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
a -X- _ O
20 -X- _ B-HyperparameterValue
- -X- _ O
layer -X- _ B-HyperparameterName
neural -X- _ O
architectural -X- _ O
search -X- _ O
for -X- _ O
encoder -X- _ O
. -X- _ O
The -X- _ O
decoders -X- _ O
are -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
and -X- _ O
predefined -X- _ O
as -X- _ O
explained -X- _ O
in -X- _ O
our -X- _ O
previous -X- _ O
section -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
GloVe -X- _ O
word -X- _ O
embeddings -X- _ O
while -X- _ O
providing -X- _ O
the -X- _ O
input -X- _ O
to -X- _ O
the -X- _ O
generated -X- _ O
model -X- _ O
. -X- _ O
We -X- _ O
set -X- _ O
the -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
as -X- _ O
128 -X- _ B-HyperparameterValue
, -X- _ O
max -X- _ B-HyperparameterName
input -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
as -X- _ O
64 -X- _ B-HyperparameterValue
, -X- _ O
hidden -X- _ B-HyperparameterName
unit -X- _ I-HyperparameterName
dimension -X- _ I-HyperparameterName
for -X- _ O
each -X- _ O
layer -X- _ O
as -X- _ O
32 -X- _ B-HyperparameterValue
, -X- _ O
dropout -X- _ B-HyperparameterName
ratio -X- _ I-HyperparameterName
as -X- _ O
0.5 -X- _ B-HyperparameterValue
and -X- _ O
L2 -X- _ O
regularization -X- _ B-HyperparameterName
. -X- _ O
We -X- _ O
utilize -X- _ O
Adam -X- _ O
optimizer -X- _ B-HyperparameterName
and -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
decay -X- _ I-HyperparameterName
with -X- _ O
cosine -X- _ B-HyperparameterName
annealing -X- _ I-HyperparameterName
. -X- _ O
The -X- _ O
parameter -X- _ O
of -X- _ O
KD -X- _ O
proportion -X- _ O
α -X- _ B-HyperparameterName
is -X- _ O
varied -X- _ O
in -X- _ O
NAS -X- _ O
module -X- _ O
. -X- _ O
3 -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
perform -X- _ O
experiments -X- _ O
with -X- _ O
varying -X- _ O
layer -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
, -X- _ O
discussed -X- _ O
in -X- _ O
the -X- _ O
later -X- _ O
sections -X- _ O
. -X- _ O

Evaluation -X- _ O
metrics -X- _ O

Summarization -X- _ O
quality -X- _ O
is -X- _ O
evaluated -X- _ O
using -X- _ O
F1 -X- _ B-MetricName
measure -X- _ O
of -X- _ O
ROUGE -X- _ B-MetricName
score -X- _ O
( -X- _ O
Lin -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
calculated -X- _ O
between -X- _ O
generated -X- _ O
and -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
summary -X- _ O
. -X- _ O
4 -X- _ O
We -X- _ O
report -X- _ O
unigram -X- _ O
and -X- _ O
bigram -X- _ O
overlap -X- _ O
( -X- _ O
ROUGE-1 -X- _ B-MetricName
and -X- _ O
ROUGE-2 -X- _ B-MetricName
) -X- _ O
to -X- _ O
assess -X- _ O
informativeness -X- _ O
and -X- _ O
the -X- _ O
longest -X- _ O
common -X- _ O
sub -X- _ O
- -X- _ O
sequence -X- _ O
( -X- _ O
ROUGE -X- _ B-MetricName
- -X- _ I-MetricName
L -X- _ I-MetricName
) -X- _ O
to -X- _ O
access -X- _ O
fluency -X- _ O
. -X- _ O
Additional -X- _ O
metrics -X- _ O
like -X- _ O
number -X- _ B-MetricName
of -X- _ I-MetricName
parameters -X- _ I-MetricName
, -X- _ O
disk -X- _ B-MetricName
- -X- _ I-MetricName
space -X- _ I-MetricName
and -X- _ O
the -X- _ O
inference -X- _ B-MetricName
time -X- _ I-MetricName
taken -X- _ O
are -X- _ O
considered -X- _ O
to -X- _ O
compare -X- _ O
the -X- _ O
computational -X- _ O
efficiency -X- _ O
between -X- _ O
models -X- _ O
. -X- _ O

Results -X- _ O
and -X- _ O
discussion -X- _ O

Extractive -X- _ O
Summarization -X- _ O
: -X- _ O
Table -X- _ O
2 -X- _ O
shows -X- _ O
results -X- _ O
comparing -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
generated -X- _ O
Table -X- _ O
2 -X- _ O
: -X- _ O
A -X- _ O
comparison -X- _ O
of -X- _ O
the -X- _ O
generated -X- _ O
models -X- _ O
for -X- _ O
Extractive -X- _ O
summarization -X- _ O
on -X- _ O
CNN -X- _ B-DatasetName
/ -X- _ I-DatasetName
DM -X- _ I-DatasetName
and -X- _ O
NYT -X- _ B-DatasetName
; -X- _ O
FT -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
- -X- _ I-MethodName
EXT -X- _ I-MethodName
is -X- _ O
used -X- _ O
as -X- _ O
a -X- _ O
baseline -X- _ O
to -X- _ O
compare -X- _ O
against -X- _ O
models -X- _ O
and -X- _ O
the -X- _ O
baseline -X- _ O
for -X- _ O
extractive -X- _ O
summarization -X- _ O
across -X- _ O
different -X- _ O
datasets -X- _ O
. -X- _ O
The -X- _ O
ROUGE -X- _ B-MetricName
scores -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
summaries -X- _ O
by -X- _ O
the -X- _ O
auto -X- _ O
- -X- _ O
generated -X- _ O
models -X- _ O
from -X- _ O
our -X- _ O
proposed -X- _ O
framework -X- _ O
are -X- _ O
close -X- _ O
to -X- _ O
the -X- _ O
state -X- _ B-MethodName
- -X- _ I-MethodName
of -X- _ I-MethodName
- -X- _ I-MethodName
the -X- _ I-MethodName
- -X- _ I-MethodName
art -X- _ I-MethodName
BERT -X- _ I-MethodName
baseline -X- _ O
. -X- _ O
Whereas -X- _ O
, -X- _ O
our -X- _ O
models -X- _ O
gained -X- _ O
significantly -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
computational -X- _ O
efficiency -X- _ O
. -X- _ O
Figure -X- _ O
4 -X- _ O
illustrates -X- _ O
the -X- _ O
samewhen -X- _ O
the -X- _ O
models -X- _ O
trained -X- _ O
on -X- _ O
CNN -X- _ B-DatasetName
/ -X- _ I-DatasetName
DM -X- _ I-DatasetName
dataset -X- _ O
are -X- _ O
compared -X- _ O
along -X- _ O
three -X- _ O
aspects -X- _ O
-Number -X- _ B-MetricName
of -X- _ I-MetricName
parameters -X- _ I-MetricName
( -X- _ O
in -X- _ O
millions -X- _ O
) -X- _ O
, -X- _ O
disk -X- _ B-MetricName
space -X- _ I-MetricName
for -X- _ O
storing -X- _ O
the -X- _ O
model -X- _ O
( -X- _ O
in -X- _ O
MB -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
inference -X- _ O
time -X- _ O
( -X- _ O
in -X- _ O
milliseconds -X- _ O
) -X- _ O
needed -X- _ O
to -X- _ O
generate -X- _ O
the -X- _ O
summary -X- _ O
of -X- _ O
an -X- _ O
input -X- _ O
sample -X- _ O
. -X- _ O
These -X- _ O
graphs -X- _ O
depict -X- _ O
that -X- _ O
the -X- _ O
generated -X- _ O
models -X- _ O
with -X- _ O
comparable -X- _ O
performance -X- _ O
to -X- _ O
FT -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
significantly -X- _ O
reduce -X- _ O
the -X- _ O
disk -X- _ O
space -X- _ O
usage -X- _ O
and -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
parameters -X- _ O
. -X- _ O
We -X- _ O
note -X- _ O
that -X- _ O
the -X- _ O
generated -X- _ O
models -X- _ O
from -X- _ O
AUTOSUMM -X- _ B-TaskName
- -X- _ I-TaskName
CREATE -X- _ I-TaskName
lose -X- _ O
some -X- _ O
performance -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
inference -X- _ O
time -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
because -X- _ O
the -X- _ O
model -X- _ O
architecture -X- _ O
consists -X- _ O
of -X- _ O
RNNs -X- _ O
and -X- _ O
does -X- _ O
not -X- _ O
have -X- _ O
the -X- _ O
advantage -X- _ O
of -X- _ O
parallel -X- _ O
computation -X- _ O
present -X- _ O
in -X- _ O
BERT -X- _ O
models -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
our -X- _ O
FT -X- _ B-MethodName
- -X- _ I-MethodName
TINYBERT -X- _ I-MethodName
- -X- _ I-MethodName
EXT -X- _ I-MethodName
model -X- _ O
overcomes -X- _ O
this -X- _ O
and -X- _ O
significantly -X- _ O
reduces -X- _ O
the -X- _ O
inference -X- _ O
time -X- _ O
. -X- _ O

Abstractive -X- _ O
Summarization -X- _ O
: -X- _ O
Table -X- _ O
3 -X- _ O
compares -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
abstractive -X- _ O
- -X- _ O
summarization -X- _ O
models -X- _ O
on -X- _ O
Gigaword -X- _ O
dataset -X- _ O
, -X- _ O
curated -X- _ O
for -X- _ O
extreme -X- _ O
summarization -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
to -X- _ O
be -X- _ O
noted -X- _ O
that -X- _ O
our -X- _ O
proposed -X- _ O
summarization -X- _ O
model -X- _ O
with -X- _ O
Transformer -X- _ O
distillation -X- _ O
FT -X- _ B-MethodName
- -X- _ I-MethodName
TINYBERT -X- _ I-MethodName
- -X- _ I-MethodName
ABS -X- _ I-MethodName
beats -X- _ O
the -X- _ O
FT -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
- -X- _ I-MethodName
ABS -X- _ I-MethodName
with -X- _ O
a -X- _ O
huge -X- _ O
margin -X- _ O
, -X- _ O
across -X- _ O
all -X- _ O
R-1 -X- _ B-MetricName
, -X- _ O
R-2 -X- _ B-MetricName
, -X- _ O
R -X- _ B-MetricName
- -X- _ I-MetricName
L. -X- _ I-MetricName
The -X- _ O
other -X- _ O
dataset -X- _ O
for -X- _ O
extreme -X- _ O
summarization -X- _ O
is -X- _ O
the -X- _ O
Contract -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O
Table -X- _ O
4 -X- _ O
shows -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
generated -X- _ O
CHILD -X- _ B-MethodName
- -X- _ I-MethodName
ABS -X- _ I-MethodName
model -X- _ O
on -X- _ O
contracts -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O
We -X- _ O
compare -X- _ O
our -X- _ O
results -X- _ O
against -X- _ O
the -X- _ O
reported -X- _ O
best -X- _ O
performing -X- _ O
Lead -X- _ O
- -X- _ O
K -X- _ O
scores -X- _ O
by -X- _ O
Cohen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
the -X- _ O
limited -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
dataset -X- _ O
was -X- _ O
a -X- _ O
bottleneck -X- _ O
to -X- _ O
train -X- _ O
FT -X- _ B-MethodName
- -X- _ I-MethodName
TINYBERT -X- _ I-MethodName
- -X- _ I-MethodName
ABS -X- _ I-MethodName
model -X- _ O
. -X- _ O

The -X- _ O
AUTOSUMM -X- _ B-TaskName
- -X- _ I-TaskName
CREATE -X- _ I-TaskName
approach -X- _ O
generates -X- _ O
a -X- _ O
new -X- _ O
encoder -X- _ O
architecture -X- _ O
from -X- _ O
scratch -X- _ O
for -X- _ O
a -X- _ O
desired -X- _ O
task -X- _ O
and -X- _ O
dataset -X- _ O
. -X- _ O

It -X- _ O
is -X- _ O
an -X- _ O
interesting -X- _ O
study -X- _ O
to -X- _ O
dive -X- _ O
deeper -X- _ O
into -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
the -X- _ O
cells -X- _ O
in -X- _ O
the -X- _ O
generated -X- _ O
models -X- _ O
. -X- _ O
Table -X- _ O
5 -X- _ O
shows -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
cell -X- _ O
type -X- _ O
in -X- _ O
the -X- _ O
generated -X- _ O
models -X- _ O
with -X- _ O
a -X- _ O
10 -X- _ O
layer -X- _ O
encoder -X- _ O
architecture -X- _ O
, -X- _ O
on -X- _ O
extractive -X- _ O
( -X- _ O
on -X- _ O
CNN -X- _ B-DatasetName
/ -X- _ I-DatasetName
DM -X- _ I-DatasetName
) -X- _ O
and -X- _ O
abstractive -X- _ O
( -X- _ O
on -X- _ O
Gigaword -X- _ B-DatasetName
) -X- _ O
tasks -X- _ O
. -X- _ O
It -X- _ O
can -X- _ O
be -X- _ O
observed -X- _ O
that -X- _ O
the -X- _ O
pooling -X- _ O
and -X- _ O
the -X- _ O
attention -X- _ O
layers -X- _ O
are -X- _ O
sparse -X- _ O
in -X- _ O
the -X- _ O
extractive -X- _ O
models -X- _ O
, -X- _ O
but -X- _ O
are -X- _ O
major -X- _ O
contributors -X- _ O
in -X- _ O
the -X- _ O
abstractive -X- _ O
architecture -X- _ O
. -X- _ O
Most -X- _ O
recent -X- _ O
models -X- _ O
use -X- _ O
the -X- _ O
multi -X- _ O
- -X- _ O
head -X- _ O
attention -X- _ O
from -X- _ O
transformer -X- _ O
to -X- _ O
get -X- _ O
good -X- _ O
results -X- _ O
in -X- _ O
the -X- _ O
language -X- _ O
generation -X- _ O
task -X- _ O
. -X- _ O
A -X- _ O
similar -X- _ O
pattern -X- _ O
is -X- _ O
observed -X- _ O
in -X- _ O
the -X- _ O
models -X- _ O
generated -X- _ O
through -X- _ O
our -X- _ O
AutoSumm -X- _ B-TaskName
framework -X- _ O
. -X- _ O

Ablation -X- _ O
Study -X- _ O

Variation -X- _ O
in -X- _ O
Layer -X- _ B-HyperparameterName
Size -X- _ I-HyperparameterName
: -X- _ O
We -X- _ O
analyze -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
framework -X- _ O
across -X- _ O
varying -X- _ O
sizes -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
model -X- _ O
i.e. -X- _ O
varying -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
layers -X- _ I-HyperparameterName
to -X- _ O
be -X- _ O
generated -X- _ O
by -X- _ O
the -X- _ O
RNN -X- _ O
- -X- _ O
controller -X- _ O
. -X- _ O
We -X- _ O
experiment -X- _ O
with -X- _ O
CHILD -X- _ B-MethodName
- -X- _ I-MethodName
EXT -X- _ I-MethodName
models -X- _ O
. -X- _ O
Figure -X- _ O
5 -X- _ O
illustrates -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
this -X- _ O
experiment -X- _ O
for -X- _ O
extractive -X- _ O
summarization -X- _ O
on -X- _ O
the -X- _ O
CNN -X- _ B-DatasetName
/ -X- _ I-DatasetName
DM -X- _ I-DatasetName
dataset -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
CNN -X- _ O
and -X- _ O
RNN -X- _ O
layers -X- _ O
are -X- _ O
the -X- _ O
major -X- _ O
constituents -X- _ O
in -X- _ O
these -X- _ O
architectures -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
see -X- _ O
that -X- _ O
RNN -X- _ O
cells -X- _ O
are -X- _ O
more -X- _ O
preferred -X- _ O
when -X- _ O
the -X- _ O
architecture -X- _ O
is -X- _ O
restricted -X- _ O
to -X- _ O
fewer -X- _ O
layers -X- _ O
( -X- _ O
like -X- _ O
2 -X- _ B-HyperparameterValue
, -X- _ O
5 -X- _ B-HyperparameterValue
, -X- _ O
6 -X- _ B-HyperparameterValue
) -X- _ O
, -X- _ O
but -X- _ O
as -X- _ O
we -X- _ O
increase -X- _ O
the -X- _ O
layers -X- _ O
, -X- _ O
Convolutional -X- _ O
layers -X- _ O
with -X- _ O
larger -X- _ O
stride -X- _ O
( -X- _ O
7 -X- _ O
) -X- _ O
are -X- _ O
preferred -X- _ O
. -X- _ O
Table -X- _ O
6 -X- _ O
refers -X- _ O
to -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
these -X- _ O
models -X- _ O
. -X- _ O
While -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
15 -X- _ B-HyperparameterValue
layers -X- _ O
gives -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
does -X- _ O
not -X- _ O
drop -X- _ O
too -X- _ O
much -X- _ O
with -X- _ O
varying -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
layers -X- _ I-HyperparameterName
. -X- _ O

Hence -X- _ O
, -X- _ O
a -X- _ O
smaller -X- _ O
model -X- _ O
, -X- _ O
with -X- _ O
fewer -X- _ O
layers -X- _ O
and -X- _ O
in -X- _ O
turn -X- _ O
lesser -X- _ O
number -X- _ B-MetricName
of -X- _ I-MetricName
parameters -X- _ I-MetricName
can -X- _ O
be -X- _ O
efficiently -X- _ O
generated -X- _ O
for -X- _ O
extractive -X- _ O
summarization -X- _ O
through -X- _ O
our -X- _ O
approach -X- _ O
. -X- _ O

Figure -X- _ O
5 -X- _ O
: -X- _ O
Cell -X- _ O
distribution -X- _ O
across -X- _ O
varying -X- _ O
layer -X- _ O
size -X- _ O
Table -X- _ O
7 -X- _ O
and -X- _ O
Figure -X- _ O
6 -X- _ O
presents -X- _ O
the -X- _ O
results -X- _ O
when -X- _ O
the -X- _ O
same -X- _ O
experiment -X- _ O
is -X- _ O
conducted -X- _ O
on -X- _ O
XSUM -X- _ B-DatasetName
and -X- _ O
Contract -X- _ B-DatasetName
datasets -X- _ O
with -X- _ O
the -X- _ O
layer -X- _ B-HyperparameterName
sizes -X- _ I-HyperparameterName
5 -X- _ B-HyperparameterValue
, -X- _ O
10 -X- _ B-HyperparameterValue
, -X- _ O
12 -X- _ B-HyperparameterValue
and -X- _ O
15 -X- _ B-HyperparameterValue
. -X- _ O
While -X- _ O
the -X- _ O
trend -X- _ O
in -X- _ O
RNN -X- _ O
preference -X- _ O
for -X- _ O
fewer -X- _ O
layers -X- _ O
and -X- _ O
CNN -X- _ O
preference -X- _ O
for -X- _ O
more -X- _ O
layers -X- _ O
still -X- _ O
continues -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
noted -X- _ O
that -X- _ O
the -X- _ O
larger -X- _ O
architectures -X- _ O
generated -X- _ O
use -X- _ O
the -X- _ O
pooling -X- _ O
and -X- _ O
attention -X- _ O
layers -X- _ O
. -X- _ O

Cross -X- _ O
- -X- _ O
Dataset -X- _ O
Experiments -X- _ O
: -X- _ O
periments -X- _ O
with -X- _ O
CHILD -X- _ B-MethodName
- -X- _ I-MethodName
EXT -X- _ I-MethodName
- -X- _ I-MethodName
KD -X- _ I-MethodName
- -X- _ I-MethodName
X -X- _ I-MethodName
models -X- _ O
trained -X- _ O
on -X- _ O
one -X- _ O
dataset -X- _ O
( -X- _ O
X -X- _ O
) -X- _ O
and -X- _ O
tested -X- _ O
on -X- _ O
another -X- _ O
. -X- _ O
The -X- _ O
visualisations -X- _ O
of -X- _ O
these -X- _ O
results -X- _ O
as -X- _ O
in -X- _ O
Figure -X- _ O
7 -X- _ O
, -X- _ O
also -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
architectures -X- _ O
trained -X- _ O
on -X- _ O
one -X- _ O
dataset -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
generate -X- _ O
summaries -X- _ O
on -X- _ O
a -X- _ O
different -X- _ O
dataset -X- _ O
without -X- _ O
significant -X- _ O
loss -X- _ O
in -X- _ O
performance -X- _ O
, -X- _ O
establishing -X- _ O
the -X- _ O
generalizability -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
approach -X- _ O
making -X- _ O
it -X- _ O
usable -X- _ O
by -X- _ O
non -X- _ O
- -X- _ O
experts -X- _ O
for -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
applications -X- _ O
. -X- _ O
06,18.91,27.04 -X- _ O
16.78,1.83,12.35 -X- _ O
24.07,6.42,2.7,13.52 -X- _ O
20.84,3.64,13.68 -X- _ O
24.07,6.42,17.84,25.57 -X- _ O
18.52,2.43,11.93 -X- _ O
21.22,6.07,15.95 -X- _ O
33.84,15.72,24.88 -X- _ O
43.58,20.69,28.08 -X- _ O
39.85,19.26,14.95,24.07 -X- _ O
42.29,19.53,26.76 -X- _ O
38.48,18.04,23.87 -X- _ O
Figure -X- _ O
8 -X- _ O
illustrates -X- _ O
the -X- _ O
result -X- _ O
of -X- _ O
this -X- _ O
experiment -X- _ O
, -X- _ O
where -X- _ O
we -X- _ O
vary -X- _ O
the -X- _ O
amount -X- _ O
of -X- _ O
training -X- _ O
data -X- _ O
( -X- _ O
from -X- _ O
0 -X- _ O
% -X- _ O
to -X- _ O
100 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
total -X- _ O
available -X- _ O
data -X- _ O
) -X- _ O
, -X- _ O
used -X- _ O
to -X- _ O
re -X- _ O
- -X- _ O
train -X- _ O
an -X- _ O
architecture -X- _ O
searched -X- _ O
for -X- _ O
extractive -X- _ O
summarization -X- _ O
on -X- _ O
CNN -X- _ B-DatasetName
/ -X- _ I-DatasetName
DM -X- _ I-DatasetName
dataset -X- _ O
. -X- _ O
Here -X- _ O
, -X- _ O
0 -X- _ O
% -X- _ O
data -X- _ O
refers -X- _ O
to -X- _ O
randomly -X- _ O
initialized -X- _ O
model -X- _ O
that -X- _ O
has -X- _ O
not -X- _ O
been -X- _ O
re -X- _ O
- -X- _ O
trained -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
the -X- _ O
Rouge -X- _ B-MetricName
scores -X- _ I-MetricName
( -X- _ O
R-1 -X- _ B-MetricName
, -X- _ O
R-2 -X- _ B-MetricName
, -X- _ O
R -X- _ B-MetricName
- -X- _ I-MetricName
L -X- _ I-MetricName
) -X- _ O
reported -X- _ O
for -X- _ O
all -X- _ O
these -X- _ O
model -X- _ O
variations -X- _ O
are -X- _ O
calculated -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
. -X- _ O
While -X- _ O
it -X- _ O
is -X- _ O
intuitive -X- _ O
that -X- _ O
, -X- _ O
more -X- _ O
training -X- _ O
data -X- _ O
results -X- _ O
in -X- _ O
improved -X- _ O
performance -X- _ O
, -X- _ O
we -X- _ O
note -X- _ O
that -X- _ O
even -X- _ O
with -X- _ O
10 -X- _ O
% -X- _ O
data -X- _ O
the -X- _ O
decent -X- _ O
performance -X- _ O
value -X- _ O
is -X- _ O
achieved -X- _ O
. -X- _ O
We -X- _ O
believe -X- _ O
such -X- _ O
an -X- _ O
observation -X- _ O
can -X- _ O
help -X- _ O
support -X- _ O
the -X- _ O
hypothesis -X- _ O
that -X- _ O
the -X- _ O
using -X- _ O
the -X- _ O
proposed -X- _ O
framework -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
build -X- _ O
usable -X- _ O
models -X- _ O
with -X- _ O
limited -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O

Decoding -X- _ O
Size -X- _ O
variation -X- _ O
: -X- _ O
Table -X- _ O
9 -X- _ O
denotes -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
varying -X- _ O
ROUGE -X- _ B-MetricName
scores -X- _ O
with -X- _ O
the -X- _ O
decoding -X- _ O
summary -X- _ O
sizes -X- _ O
( -X- _ O
1,3,5 -X- _ O
) -X- _ O
on -X- _ O
CNN -X- _ B-DatasetName
/ -X- _ I-DatasetName
DM -X- _ I-DatasetName
extractive -X- _ O
summarization -X- _ O
task -X- _ O
. -X- _ O
While -X- _ O
, -X- _ O
a -X- _ O
summary -X- _ O
size -X- _ O
of -X- _ O
3 -X- _ O
sentences -X- _ O
yields -X- _ O
best -X- _ O
result -X- _ O
( -X- _ O
some -X- _ O
of -X- _ O
it -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
nature -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
proposed -X- _ O
framework -X- _ O
allows -X- _ O
generating -X- _ O
shorter -X- _ O
or -X- _ O
longer -X- _ O
summaries -X- _ O
without -X- _ O
significant -X- _ O
loss -X- _ O
in -X- _ O
performance -X- _ O
, -X- _ O
again -X- _ O
establishing -X- _ O
the -X- _ O
generalizability -X- _ O
. -X- _ O

Table -X- _ O
10 -X- _ O
shows -X- _ O
qualitative -X- _ O
examples -X- _ O
of -X- _ O
the -X- _ O
output -X- _ O
summaries -X- _ O
for -X- _ O
a -X- _ O
couple -X- _ O
of -X- _ O
newly -X- _ O
generated -X- _ O
models -X- _ O
. -X- _ O
Through -X- _ O
the -X- _ O
above -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
establish -X- _ O
that -X- _ O
the -X- _ O
auto -X- _ O
- -X- _ O
generated -X- _ O
models -X- _ O
generated -X- _ O
using -X- _ O
the -X- _ O
proposed -X- _ O
NAS -X- _ O
and -X- _ O
transformer -X- _ O
- -X- _ O
distillation -X- _ O
based -X- _ O
frameworks -X- _ O
report -X- _ O
near -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performance -X- _ O
for -X- _ O
both -X- _ O
extractive -X- _ O
and -X- _ O
abstractive -X- _ O
summarization -X- _ O
. -X- _ O
We -X- _ O
establish -X- _ O
the -X- _ O
generalizability -X- _ O
of -X- _ O
the -X- _ O
models -X- _ O
through -X- _ O
various -X- _ O
experiments -X- _ O
, -X- _ O
while -X- _ O
also -X- _ O
showing -X- _ O
the -X- _ O
efficacy -X- _ O
when -X- _ O
learning -X- _ O
with -X- _ O
limited -X- _ O
data -X- _ O
. -X- _ O

Conclusions -X- _ O

We -X- _ O
present -X- _ O
a -X- _ O
framework -X- _ O
for -X- _ O
auto -X- _ O
- -X- _ O
generation -X- _ O
of -X- _ O
ML -X- _ O
models -X- _ O
for -X- _ O
extract -X- _ O
and -X- _ O
generate -X- _ O
tasks -X- _ O
by -X- _ O
leveraging -X- _ O
knowledge -X- _ O
distillation -X- _ O
, -X- _ O
NAS -X- _ O
, -X- _ O
and -X- _ O
transformerdistillation -X- _ O
techniques -X- _ O
. -X- _ O
The -X- _ O
proposed -X- _ O
approach -X- _ O
successfully -X- _ O
creates -X- _ O
new -X- _ O
model -X- _ O
architectures -X- _ O
that -X- _ O
are -X- _ O
more -X- _ O
efficient -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
inference -X- _ O
time -X- _ O
and -X- _ O
space -X- _ O
while -X- _ O
achieving -X- _ O
near -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performance -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
accuracies -X- _ O
across -X- _ O
datasets -X- _ O
for -X- _ O
extractive -X- _ O
and -X- _ O
abstractive -X- _ O
summarization -X- _ O
. -X- _ O
We -X- _ O
believe -X- _ O
our -X- _ O
work -X- _ O
can -X- _ O
help -X- _ O
create -X- _ O
the -X- _ O
foundation -X- _ O
towards -X- _ O
democratizing -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
deep -X- _ O
- -X- _ O
learning -X- _ O
for -X- _ O
NLP -X- _ O
applications -X- _ O
for -X- _ O
non -X- _ O
- -X- _ O
experts -X- _ O
in -X- _ O
practice -X- _ O
. -X- _ O

