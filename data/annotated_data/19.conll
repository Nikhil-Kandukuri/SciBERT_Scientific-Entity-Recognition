-DOCSTART- -X- O
Causal -X- _ O
Direction -X- _ O
of -X- _ O
Data -X- _ B-TaskName
Collection -X- _ I-TaskName
Matters -X- _ O
: -X- _ O
Implications -X- _ O
of -X- _ O
Causal -X- _ O
and -X- _ O
Anticausal -X- _ O
Learning -X- _ O
for -X- _ O
NLP -X- _ O

The -X- _ O
principle -X- _ O
of -X- _ O
independent -X- _ O
causal -X- _ O
mechanisms -X- _ O
( -X- _ O
ICM -X- _ O
) -X- _ O
states -X- _ O
that -X- _ O
generative -X- _ O
processes -X- _ O
of -X- _ O
real -X- _ O
world -X- _ O
data -X- _ O
consist -X- _ O
of -X- _ O
independent -X- _ O
modules -X- _ O
which -X- _ O
do -X- _ O
not -X- _ O
influence -X- _ O
or -X- _ O
inform -X- _ O
each -X- _ O
other -X- _ O
. -X- _ O
While -X- _ O
this -X- _ O
idea -X- _ O
has -X- _ O
led -X- _ O
to -X- _ O
fruitful -X- _ O
developments -X- _ O
in -X- _ O
the -X- _ O
field -X- _ O
of -X- _ O
causal -X- _ O
inference -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
widely -X- _ O
- -X- _ O
known -X- _ O
in -X- _ O
the -X- _ O
NLP -X- _ O
community -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
argue -X- _ O
that -X- _ O
the -X- _ O
causal -X- _ O
direction -X- _ O
of -X- _ O
the -X- _ O
data -X- _ B-TaskName
collection -X- _ I-TaskName
process -X- _ O
bears -X- _ O
nontrivial -X- _ O
implications -X- _ O
that -X- _ O
can -X- _ O
explain -X- _ O
a -X- _ O
number -X- _ O
of -X- _ O
published -X- _ O
NLP -X- _ O
findings -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
differences -X- _ O
in -X- _ O
semi -X- _ O
- -X- _ O
supervised -X- _ O
learning -X- _ O
( -X- _ O
SSL -X- _ O
) -X- _ O
and -X- _ O
domain -X- _ O
adaptation -X- _ O
( -X- _ O
DA -X- _ O
) -X- _ O
performance -X- _ O
across -X- _ O
different -X- _ O
settings -X- _ O
. -X- _ O
We -X- _ O
categorize -X- _ O
common -X- _ O
NLP -X- _ O
tasks -X- _ O
according -X- _ O
to -X- _ O
their -X- _ O
causal -X- _ O
direction -X- _ O
and -X- _ O
empirically -X- _ O
assay -X- _ O
the -X- _ O
validity -X- _ O
of -X- _ O
the -X- _ O
ICM -X- _ O
principle -X- _ O
for -X- _ O
text -X- _ O
data -X- _ O
using -X- _ O
minimum -X- _ B-MetricName
description -X- _ I-MetricName
length -X- _ I-MetricName
. -X- _ O
We -X- _ O
conduct -X- _ O
an -X- _ O
extensive -X- _ O
meta -X- _ O
- -X- _ O
analysis -X- _ O
of -X- _ O
over -X- _ O
100 -X- _ O
published -X- _ O
SSL -X- _ O
and -X- _ O
30 -X- _ O
DA -X- _ O
studies -X- _ O
, -X- _ O
and -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
results -X- _ O
are -X- _ O
consistent -X- _ O
with -X- _ O
our -X- _ O
expectations -X- _ O
based -X- _ O
on -X- _ O
causal -X- _ O
insights -X- _ O
. -X- _ O
This -X- _ O
work -X- _ O
presents -X- _ O
the -X- _ O
first -X- _ O
attempt -X- _ O
to -X- _ O
analyze -X- _ O
the -X- _ O
ICM -X- _ O
principle -X- _ O
in -X- _ O
NLP -X- _ O
, -X- _ O
and -X- _ O
provides -X- _ O
constructive -X- _ O
suggestions -X- _ O
for -X- _ O
future -X- _ O
modeling -X- _ O
choices -X- _ O
. -X- _ O
1 -X- _ O
* -X- _ O
Equal -X- _ O
contribution -X- _ O
. -X- _ O
1 -X- _ O
The -X- _ O
codes -X- _ O
are -X- _ O
at -X- _ O
https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
github.com -X- _ O
/ -X- _ O
zhijing-jin -X- _ O
/ -X- _ O
icm4nlp -X- _ O
. -X- _ O

Introduction -X- _ O

NLP -X- _ O
practitioners -X- _ O
typically -X- _ O
do -X- _ O
not -X- _ O
pay -X- _ O
great -X- _ O
attention -X- _ O
to -X- _ O
the -X- _ O
causal -X- _ O
direction -X- _ O
of -X- _ O
the -X- _ O
data -X- _ B-TaskName
collection -X- _ I-TaskName
process -X- _ O
. -X- _ O
As -X- _ O
a -X- _ O
motivating -X- _ O
example -X- _ O
, -X- _ O
consider -X- _ O
the -X- _ O
case -X- _ O
of -X- _ O
collecting -X- _ O
a -X- _ O
dataset -X- _ O
to -X- _ O
train -X- _ O
a -X- _ O
machine -X- _ O
translation -X- _ O
( -X- _ O
MT -X- _ O
) -X- _ O
model -X- _ O
to -X- _ O
translate -X- _ O
from -X- _ O
English -X- _ O
( -X- _ O
En -X- _ O
) -X- _ O
to -X- _ O
Spanish -X- _ O
( -X- _ O
Es -X- _ O
) -X- _ O
: -X- _ O
it -X- _ O
is -X- _ O
common -X- _ O
practice -X- _ O
to -X- _ O
mix -X- _ O
all -X- _ O
available -X- _ O
En -X- _ O
- -X- _ O
Es -X- _ O
sentence -X- _ O
pairs -X- _ O
together -X- _ O
and -X- _ O
train -X- _ O
the -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
entire -X- _ O
pooled -X- _ O
data -X- _ O
set -X- _ O
( -X- _ O
Bahdanau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Cho -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
such -X- _ O
mixed -X- _ O
corpora -X- _ O
actually -X- _ O
consist -X- _ O
of -X- _ O
two -X- _ O
distinct -X- _ O
types -X- _ O
of -X- _ O
data -X- _ O
: -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
sentences -X- _ O
that -X- _ O
originated -X- _ O
in -X- _ O
English -X- _ O
and -X- _ O
have -X- _ O
been -X- _ O
translated -X- _ O
( -X- _ O
by -X- _ O
human -X- _ O
translators -X- _ O
) -X- _ O
into -X- _ O
Spanish -X- _ O
( -X- _ O
En→Es -X- _ O
) -X- _ O
; -X- _ O
and -X- _ O
( -X- _ O
ii -X- _ O
) -X- _ O
sentences -X- _ O
that -X- _ O
originated -X- _ O
in -X- _ O
Given -X- _ O
the -X- _ O
English -X- _ O
sentence -X- _ O
above -X- _ O
, -X- _ O
can -X- _ O
you -X- _ O
write -X- _ O
its -X- _ O
Spanish -X- _ O
translation -X- _ O
? -X- _ O

Prompt -X- _ O
for -X- _ O
annotators -X- _ O

[ -X- _ O
En -X- _ O
] -X- _ O
This -X- _ O
is -X- _ O
a -X- _ O
beautiful -X- _ O
world -X- _ O
. -X- _ O

[ -X- _ O
Es -X- _ O
] -X- _ O
Este -X- _ O
es -X- _ O
un -X- _ O
mundo -X- _ O
hermoso -X- _ O
. -X- _ O

Cause -X- _ O
: -X- _ O

Effect -X- _ O
: -X- _ O

Annotation -X- _ O
process -X- _ O
( -X- _ O
Noise -X- _ O
) -X- _ O
Effect -X- _ O
= -X- _ O
CausalMechanism -X- _ O
( -X- _ O
Cause -X- _ O
, -X- _ O
Noise -X- _ O
) -X- _ O

Figure -X- _ O
1 -X- _ O
: -X- _ O
Annotation -X- _ O
process -X- _ O
for -X- _ O
NLP -X- _ O
data -X- _ O
: -X- _ O
the -X- _ O
random -X- _ O
variable -X- _ O
that -X- _ O
exists -X- _ O
first -X- _ O
is -X- _ O
typically -X- _ O
the -X- _ O
cause -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
a -X- _ O
given -X- _ O
prompt -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
one -X- _ O
generated -X- _ O
afterwards -X- _ O
is -X- _ O
typically -X- _ O
the -X- _ O
effect -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
the -X- _ O
annotated -X- _ O
answer -X- _ O
) -X- _ O
. -X- _ O

Spanish -X- _ O
and -X- _ O
have -X- _ O
subsequently -X- _ O
been -X- _ O
translated -X- _ O
into -X- _ O
English -X- _ O
( -X- _ O
Es→En -X- _ O
) -X- _ O
. -X- _ O
2 -X- _ O
Intuitively -X- _ O
, -X- _ O
these -X- _ O
two -X- _ O
subsets -X- _ O
are -X- _ O
qualitatively -X- _ O
different -X- _ O
, -X- _ O
and -X- _ O
an -X- _ O
increasing -X- _ O
number -X- _ O
of -X- _ O
observations -X- _ O
by -X- _ O
the -X- _ O
NLP -X- _ O
community -X- _ O
indeed -X- _ O
suggests -X- _ O
that -X- _ O
they -X- _ O
exhibit -X- _ O
different -X- _ O
properties -X- _ O
( -X- _ O
Freitag -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Edunov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Riley -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Shen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
case -X- _ O
of -X- _ O
MT -X- _ O
, -X- _ O
for -X- _ O
example -X- _ O
, -X- _ O
researchers -X- _ O
find -X- _ O
that -X- _ O
training -X- _ O
models -X- _ O
on -X- _ O
each -X- _ O
of -X- _ O
these -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
data -X- _ O
separately -X- _ O
leads -X- _ O
to -X- _ O
different -X- _ O
test -X- _ O
performance -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
different -X- _ O
performance -X- _ O
improvement -X- _ O
by -X- _ O
semi -X- _ O
- -X- _ O
supervised -X- _ O
learning -X- _ O
( -X- _ O
SSL -X- _ O
) -X- _ O
( -X- _ O
Bogoychev -X- _ O
and -X- _ O
Sennrich -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Graham -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Edunov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Motivated -X- _ O
by -X- _ O
this -X- _ O
observation -X- _ O
that -X- _ O
the -X- _ O
data -X- _ B-TaskName
collection -X- _ I-TaskName
process -X- _ O
seems -X- _ O
to -X- _ O
matter -X- _ O
for -X- _ O
model -X- _ O
performance -X- _ O
, -X- _ O
in -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
provide -X- _ O
an -X- _ O
explanation -X- _ O
of -X- _ O
this -X- _ O
phenomenon -X- _ O
from -X- _ O
the -X- _ O
perspective -X- _ O
of -X- _ O
causality -X- _ O
( -X- _ O
Pearl -X- _ O
, -X- _ O
2009 -X- _ O
; -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

First -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
the -X- _ O
notion -X- _ O
of -X- _ O
the -X- _ O
causal -X- _ O
direction -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
NLP -X- _ O
task -X- _ O
, -X- _ O
see -X- _ O
Fig -X- _ O
. -X- _ O
1 -X- _ O
for -X- _ O
an -X- _ O
example -X- _ O
. -X- _ O
Throughout -X- _ O
, -X- _ O
we -X- _ O
denote -X- _ O
the -X- _ O
input -X- _ O
of -X- _ O
a -X- _ O
learning -X- _ O
task -X- _ O
by -X- _ O
X -X- _ O
and -X- _ O
the -X- _ O
output -X- _ O
which -X- _ O
is -X- _ O
to -X- _ O
be -X- _ O
predicted -X- _ O
by -X- _ O
Y -X- _ O
. -X- _ O
If -X- _ O
, -X- _ O
during -X- _ O
the -X- _ O
data -X- _ O
collection -X- _ O
process -X- _ O
, -X- _ O
X -X- _ O
is -X- _ O
generated -X- _ O
first -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
Y -X- _ O
is -X- _ O
collected -X- _ O
based -X- _ O
on -X- _ O
X -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
through -X- _ O
annotation -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
say -X- _ O
that -X- _ O
X -X- _ O
causes -X- _ O
Y -X- _ O
, -X- _ O
and -X- _ O
denote -X- _ O
this -X- _ O
by -X- _ O
X -X- _ O
→ -X- _ O
Y -X- _ O
. -X- _ O
If -X- _ O
, -X- _ O
on -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
Y -X- _ O
is -X- _ O
Figure -X- _ O
2 -X- _ O
: -X- _ O
( -X- _ O
Top -X- _ O
) -X- _ O
A -X- _ O
causal -X- _ O
graph -X- _ O
C -X- _ O
→ -X- _ O
E -X- _ O
, -X- _ O
where -X- _ O
C -X- _ O
is -X- _ O
the -X- _ O
cause -X- _ O
and -X- _ O
E -X- _ O
is -X- _ O
the -X- _ O
effect -X- _ O
. -X- _ O
The -X- _ O
function -X- _ O
f -X- _ O
( -X- _ O
• -X- _ O
, -X- _ O
N -X- _ O
E -X- _ O
) -X- _ O
denotes -X- _ O
the -X- _ O
causal -X- _ O
process -X- _ O
, -X- _ O
or -X- _ O
mechanism -X- _ O
, -X- _ O
P -X- _ O
E|C -X- _ O
by -X- _ O
which -X- _ O
the -X- _ O
effect -X- _ O
E -X- _ O
is -X- _ O
generated -X- _ O
from -X- _ O
C -X- _ O
and -X- _ O
unobserved -X- _ O
noise -X- _ O
N -X- _ O
E -X- _ O
. -X- _ O
( -X- _ O
Bottom -X- _ O
) -X- _ O
Based -X- _ O
on -X- _ O
whether -X- _ O
the -X- _ O
direction -X- _ O
of -X- _ O
prediction -X- _ O
aligns -X- _ O
with -X- _ O
the -X- _ O
direction -X- _ O
of -X- _ O
causation -X- _ O
or -X- _ O
not -X- _ O
, -X- _ O
we -X- _ O
distinguish -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
tasks -X- _ O
: -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
causal -X- _ O
learning -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
predicting -X- _ O
the -X- _ O
effect -X- _ O
from -X- _ O
the -X- _ O
cause -X- _ O
; -X- _ O
and -X- _ O
( -X- _ O
ii -X- _ O
) -X- _ O
anticausal -X- _ O
learning -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
predicting -X- _ O
the -X- _ O
cause -X- _ O
from -X- _ O
the -X- _ O
effect -X- _ O
. -X- _ O
generated -X- _ O
first -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
X -X- _ O
is -X- _ O
collected -X- _ O
based -X- _ O
on -X- _ O
Y -X- _ O
, -X- _ O
we -X- _ O
say -X- _ O
that -X- _ O
Y -X- _ O
causes -X- _ O
X -X- _ O
( -X- _ O
Y -X- _ O
→ -X- _ O
X -X- _ O
) -X- _ O
. -X- _ O
3 -X- _ O
Based -X- _ O
on -X- _ O
whether -X- _ O
the -X- _ O
direction -X- _ O
of -X- _ O
prediction -X- _ O
aligns -X- _ O
with -X- _ O
the -X- _ O
causal -X- _ O
direction -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
collection -X- _ O
process -X- _ O
or -X- _ O
not -X- _ O
, -X- _ O
Schölkopf -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2012 -X- _ O
) -X- _ O
categorize -X- _ O
these -X- _ O
types -X- _ O
of -X- _ O
tasks -X- _ O
as -X- _ O
causal -X- _ O
learning -X- _ O
( -X- _ O
X -X- _ O
→ -X- _ O
Y -X- _ O
) -X- _ O
, -X- _ O
or -X- _ O
anticausal -X- _ O
learning -X- _ O
( -X- _ O
Y -X- _ O
→ -X- _ O
X -X- _ O
) -X- _ O
, -X- _ O
respectively -X- _ O
; -X- _ O
see -X- _ O
Fig -X- _ O
. -X- _ O
2 -X- _ O
for -X- _ O
an -X- _ O
illustration -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
context -X- _ O
of -X- _ O
our -X- _ O
motivating -X- _ O
MT -X- _ O
example -X- _ O
this -X- _ O
means -X- _ O
that -X- _ O
, -X- _ O
if -X- _ O
the -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
translate -X- _ O
from -X- _ O
English -X- _ O
( -X- _ O
X -X- _ O
= -X- _ O
En -X- _ O
) -X- _ O
into -X- _ O
Spanish -X- _ O
( -X- _ O
Y -X- _ O
= -X- _ O
Es -X- _ O
) -X- _ O
, -X- _ O
training -X- _ O
only -X- _ O
on -X- _ O
subset -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
consisting -X- _ O
of -X- _ O
En→Es -X- _ O
pairs -X- _ O
corresponds -X- _ O
to -X- _ O
causal -X- _ O
learning -X- _ O
( -X- _ O
X -X- _ O
→ -X- _ O
Y -X- _ O
) -X- _ O
, -X- _ O
whereas -X- _ O
training -X- _ O
only -X- _ O
on -X- _ O
subset -X- _ O
( -X- _ O
ii -X- _ O
) -X- _ O
consisting -X- _ O
of -X- _ O
Es→En -X- _ O
pairs -X- _ O
is -X- _ O
categorised -X- _ O
as -X- _ O
anticausal -X- _ O
learning -X- _ O
( -X- _ O
Y -X- _ O
→ -X- _ O
X -X- _ O
) -X- _ O
. -X- _ O

Based -X- _ O
on -X- _ O
the -X- _ O
principle -X- _ O
of -X- _ O
independent -X- _ O
causal -X- _ O
mechanisms -X- _ O
( -X- _ O
ICM -X- _ O
) -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
it -X- _ O
has -X- _ O
been -X- _ O
hypothesized -X- _ O
that -X- _ O
the -X- _ O
causal -X- _ O
direction -X- _ O
of -X- _ O
data -X- _ B-TaskName
collection -X- _ I-TaskName
( -X- _ O
i.e. -X- _ O
, -X- _ O
whether -X- _ O
a -X- _ O
given -X- _ O
NLP -X- _ O
learning -X- _ O
task -X- _ O
can -X- _ O
be -X- _ O
classified -X- _ O
as -X- _ O
causal -X- _ O
or -X- _ O
anticausal -X- _ O
) -X- _ O
has -X- _ O
implications -X- _ O
for -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
commonly -X- _ O
used -X- _ O
techniques -X- _ O
such -X- _ O
as -X- _ O
SSL -X- _ O
and -X- _ O
domain -X- _ O
adaptation -X- _ O
( -X- _ O
DA -X- _ O
) -X- _ O
( -X- _ O
Schölkopf -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
will -X- _ O
argue -X- _ O
that -X- _ O
this -X- _ O
can -X- _ O
explain -X- _ O
performance -X- _ O
differences -X- _ O
reported -X- _ O
by -X- _ O
the -X- _ O
NLP -X- _ O
community -X- _ O
across -X- _ O
different -X- _ O
data -X- _ O
collection -X- _ O
processes -X- _ O
and -X- _ O
tasks -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
we -X- _ O
make -X- _ O
the -X- _ O
following -X- _ O
contributions -X- _ O
: -X- _ O

1 -X- _ O
. -X- _ O
We -X- _ O
categorize -X- _ O
a -X- _ O
number -X- _ O
of -X- _ O
common -X- _ O
NLP -X- _ O
tasks -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
causal -X- _ O
direction -X- _ O
of -X- _ O
the -X- _ O
underlying -X- _ O
data -X- _ B-TaskName
collection -X- _ I-TaskName
process -X- _ O
( -X- _ O
§ -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O
2 -X- _ O
. -X- _ O
We -X- _ O
review -X- _ O
the -X- _ O
ICM -X- _ O
principle -X- _ O
and -X- _ O
its -X- _ O
implications -X- _ O
for -X- _ O
common -X- _ O
techniques -X- _ O
of -X- _ O
using -X- _ O
unlabelled -X- _ O
data -X- _ O
such -X- _ O
as -X- _ O
SSL -X- _ O
and -X- _ O
DA -X- _ O
in -X- _ O
the -X- _ O
context -X- _ O
of -X- _ O
causal -X- _ O
and -X- _ O
anticausal -X- _ O
NLP -X- _ O
tasks -X- _ O
( -X- _ O
§ -X- _ O
3 -X- _ O
) -X- _ O
. -X- _ O
3 -X- _ O
. -X- _ O
We -X- _ O
empirically -X- _ O
assay -X- _ O
the -X- _ O
validity -X- _ O
of -X- _ O
ICM -X- _ O
for -X- _ O
NLP -X- _ O
data -X- _ O
using -X- _ O
minimum -X- _ B-MetricName
description -X- _ I-MetricName
length -X- _ I-MetricName
in -X- _ O
a -X- _ O
machine -X- _ O
translation -X- _ O
setting -X- _ O
( -X- _ O
§ -X- _ O
4 -X- _ O
) -X- _ O
. -X- _ O
4 -X- _ O
. -X- _ O
We -X- _ O
verify -X- _ O
experimentally -X- _ O
and -X- _ O
through -X- _ O
a -X- _ O
metastudy -X- _ O
of -X- _ O
over -X- _ O
respectively -X- _ O
100 -X- _ O
( -X- _ O
SSL -X- _ O
) -X- _ O
and -X- _ O
30 -X- _ O
( -X- _ O
DA -X- _ O
) -X- _ O
published -X- _ O
findings -X- _ O
that -X- _ O
the -X- _ O
difference -X- _ O
in -X- _ O
SSL -X- _ O
( -X- _ O
§ -X- _ O
5 -X- _ O
) -X- _ O
and -X- _ O
domain -X- _ O
adaptation -X- _ O
( -X- _ O
DA -X- _ O
) -X- _ O
( -X- _ O
§ -X- _ O
6 -X- _ O
) -X- _ O
performance -X- _ O
on -X- _ O
causal -X- _ O
vs -X- _ O
anticausal -X- _ O
datasets -X- _ O
reported -X- _ O
in -X- _ O
the -X- _ O
literature -X- _ O
is -X- _ O
consistent -X- _ O
with -X- _ O
what -X- _ O
is -X- _ O
predicted -X- _ O
by -X- _ O
the -X- _ O
ICM -X- _ O
principle -X- _ O
. -X- _ O
5 -X- _ O
. -X- _ O
We -X- _ O
make -X- _ O
suggestions -X- _ O
on -X- _ O
how -X- _ O
to -X- _ O
use -X- _ O
findings -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
for -X- _ O
future -X- _ O
work -X- _ O
in -X- _ O
NLP -X- _ O
( -X- _ O
§ -X- _ O
7 -X- _ O
) -X- _ O
. -X- _ O

Categorization -X- _ O
of -X- _ O
Common -X- _ O
NLP -X- _ O
Tasks -X- _ O
into -X- _ O
Causal -X- _ O
and -X- _ O
Anticausal -X- _ O
Learning -X- _ O

We -X- _ O
start -X- _ O
by -X- _ O
categorizing -X- _ O
common -X- _ O
NLP -X- _ O
tasks -X- _ O
which -X- _ O
use -X- _ O
an -X- _ O
input -X- _ O
variable -X- _ O
X -X- _ O
to -X- _ O
predict -X- _ O
a -X- _ O
target -X- _ O
or -X- _ O
output -X- _ O
variable -X- _ O
Y -X- _ O
into -X- _ O
causal -X- _ O
learning -X- _ O
( -X- _ O
X -X- _ O
→ -X- _ O
Y -X- _ O
) -X- _ O
, -X- _ O
anticausal -X- _ O
learning -X- _ O
( -X- _ O
Y -X- _ O
→ -X- _ O
X -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
other -X- _ O
tasks -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
have -X- _ O
a -X- _ O
clear -X- _ O
underlying -X- _ O
causal -X- _ O
direction -X- _ O
, -X- _ O
or -X- _ O
which -X- _ O
typically -X- _ O
rely -X- _ O
on -X- _ O
mixed -X- _ O
( -X- _ O
causal -X- _ O
and -X- _ O
anticausal -X- _ O
) -X- _ O
types -X- _ O
of -X- _ O
data -X- _ O
, -X- _ O
as -X- _ O
summarised -X- _ O
in -X- _ O
Tab -X- _ O
. -X- _ O
1 -X- _ O
. -X- _ O
Key -X- _ O
to -X- _ O
this -X- _ O
categorization -X- _ O
is -X- _ O
determining -X- _ O
whether -X- _ O
the -X- _ O
input -X- _ O
X -X- _ O
corresponds -X- _ O
to -X- _ O
the -X- _ O
cause -X- _ O
or -X- _ O
the -X- _ O
effect -X- _ O
in -X- _ O
the -X- _ O
data -X- _ B-TaskName
collection -X- _ I-TaskName
process -X- _ O
. -X- _ O
As -X- _ O
illustrated -X- _ O
in -X- _ O
Fig -X- _ O
. -X- _ O
1 -X- _ O
, -X- _ O
if -X- _ O
the -X- _ O
input -X- _ O
X -X- _ O
and -X- _ O
output -X- _ O
Y -X- _ O
are -X- _ O
generated -X- _ O
at -X- _ O
two -X- _ O
different -X- _ O
time -X- _ O
steps -X- _ O
, -X- _ O
then -X- _ O
the -X- _ O
variable -X- _ O
that -X- _ O
is -X- _ O
generated -X- _ O
first -X- _ O
is -X- _ O
typically -X- _ O
the -X- _ O
cause -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
other -X- _ O
that -X- _ O
is -X- _ O
subsequently -X- _ O
generated -X- _ O
is -X- _ O
typically -X- _ O
the -X- _ O
effect -X- _ O
, -X- _ O
provided -X- _ O
it -X- _ O
is -X- _ O
generated -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
previous -X- _ O
one -X- _ O
( -X- _ O
rather -X- _ O
than -X- _ O
, -X- _ O
say -X- _ O
, -X- _ O
on -X- _ O
a -X- _ O
common -X- _ O
confounder -X- _ O
that -X- _ O
causes -X- _ O
both -X- _ O
variables -X- _ O
) -X- _ O
. -X- _ O
If -X- _ O
X -X- _ O
and -X- _ O
Y -X- _ O
are -X- _ O
generated -X- _ O
jointly -X- _ O
, -X- _ O
then -X- _ O
we -X- _ O
need -X- _ O
to -X- _ O
distinguish -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
underlying -X- _ O
generative -X- _ O
process -X- _ O
whether -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
variables -X- _ O
is -X- _ O
causing -X- _ O
the -X- _ O
other -X- _ O
variable -X- _ O
. -X- _ O

Learning -X- _ O
Effect -X- _ O
from -X- _ O
Cause -X- _ O
( -X- _ O
Causal -X- _ O
Learning -X- _ O
) -X- _ O
Causal -X- _ O
( -X- _ O
X -X- _ O
→ -X- _ O
Y -X- _ O
) -X- _ O
NLP -X- _ O
tasks -X- _ O
typically -X- _ O
aim -X- _ O
to -X- _ O
predict -X- _ O
a -X- _ O
post -X- _ O
- -X- _ O
hoc -X- _ O
generated -X- _ O
human -X- _ O
annotation -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
the -X- _ O
target -X- _ O
Y -X- _ O
is -X- _ O
the -X- _ O
effect -X- _ O
) -X- _ O
from -X- _ O
a -X- _ O
given -X- _ O
input -X- _ O
X -X- _ O
( -X- _ O
the -X- _ O
cause -X- _ O
) -X- _ O
. -X- _ O
Examples -X- _ O
include -X- _ O
: -X- _ O
summarization -X- _ O
( -X- _ O
article→summary -X- _ O
) -X- _ O
where -X- _ O
the -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
produce -X- _ O
a -X- _ O
summary -X- _ O
Y -X- _ O
of -X- _ O
a -X- _ O
given -X- _ O
input -X- _ O
text -X- _ O
X -X- _ O
; -X- _ O
parsing -X- _ O
and -X- _ O
tagging -X- _ O
( -X- _ O
text→linguists -X- _ O
' -X- _ O
annotated -X- _ O
structure -X- _ O
) -X- _ O
where -X- _ O
the -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
predict -X- _ O
an -X- _ O
annotated -X- _ O
syntactic -X- _ O
structure -X- _ O
Y -X- _ O
of -X- _ O
a -X- _ O
given -X- _ O
input -X- _ O
sentence -X- _ O
X -X- _ O
; -X- _ O
data -X- _ O
- -X- _ O
totext -X- _ O
generation -X- _ O
( -X- _ O
data→description -X- _ O
) -X- _ O
where -X- _ O
the -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
produce -X- _ O
a -X- _ O
textual -X- _ O
description -X- _ O
Y -X- _ O
of -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
structured -X- _ O
input -X- _ O
data -X- _ O
X -X- _ O
; -X- _ O
and -X- _ O
information -X- _ O
extraction -X- _ O
( -X- _ O
text→entities -X- _ O
/ -X- _ O
relations -X- _ O
/ -X- _ O
etc -X- _ O
) -X- _ O
where -X- _ O
the -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
extract -X- _ O
structured -X- _ O
information -X- _ O
from -X- _ O
a -X- _ O
given -X- _ O
text -X- _ O
. -X- _ O

Learning -X- _ O
Cause -X- _ O
from -X- _ O
Effect -X- _ O
( -X- _ O
Anticausal -X- _ O
Learning -X- _ O
) -X- _ O
Anticausal -X- _ O
( -X- _ O
Y -X- _ O
→ -X- _ O
X -X- _ O
) -X- _ O
NLP -X- _ O
tasks -X- _ O
typically -X- _ O
aim -X- _ O
to -X- _ O
predict -X- _ O
or -X- _ O
infer -X- _ O
some -X- _ O
latent -X- _ O
target -X- _ O
property -X- _ O
Y -X- _ O
such -X- _ O
as -X- _ O
an -X- _ O
unobserved -X- _ O
prompt -X- _ O
from -X- _ O
an -X- _ O
observed -X- _ O
input -X- _ O
X -X- _ O
which -X- _ O
takes -X- _ O
the -X- _ O
form -X- _ O
of -X- _ O
one -X- _ O
of -X- _ O
its -X- _ O
effects -X- _ O
. -X- _ O
Typical -X- _ O
anticausal -X- _ O
NLP -X- _ O
learning -X- _ O
problems -X- _ O
include -X- _ O
, -X- _ O
for -X- _ O
example -X- _ O
, -X- _ O
author -X- _ O
attribute -X- _ O
identification -X- _ O
( -X- _ O
author -X- _ O
attribute→text -X- _ O
) -X- _ O
where -X- _ O
the -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
predict -X- _ O
some -X- _ O
unobserved -X- _ O
attribute -X- _ O
Y -X- _ O
of -X- _ O
the -X- _ O
writer -X- _ O
of -X- _ O
a -X- _ O
given -X- _ O
text -X- _ O
snippet -X- _ O
X -X- _ O
; -X- _ O
and -X- _ O
review -X- _ O
sentiment -X- _ O
classification -X- _ O
( -X- _ O
sentiment→review -X- _ O
text -X- _ O
) -X- _ O
where -X- _ O
the -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
latent -X- _ O
sentiment -X- _ O
Y -X- _ O
that -X- _ O
caused -X- _ O
an -X- _ O
author -X- _ O
to -X- _ O
write -X- _ O
a -X- _ O
particular -X- _ O
review -X- _ O
X -X- _ O
. -X- _ O

Other -X- _ O
/ -X- _ O
Mixed -X- _ O
Some -X- _ O
tasks -X- _ O
can -X- _ O
be -X- _ O
categorized -X- _ O
as -X- _ O
either -X- _ O
causal -X- _ O
or -X- _ O
anticausal -X- _ O
, -X- _ O
depending -X- _ O
on -X- _ O
how -X- _ O
exactly -X- _ O
the -X- _ O
data -X- _ O
is -X- _ O
collected -X- _ O
. -X- _ O
In -X- _ O
§ -X- _ O
1 -X- _ O
, -X- _ O
we -X- _ O
discussed -X- _ O
the -X- _ O
example -X- _ O
of -X- _ O
MT -X- _ O
where -X- _ O
different -X- _ O
types -X- _ O
of -X- _ O
( -X- _ O
causal -X- _ O
and -X- _ O
anticausal -X- _ O
) -X- _ O
data -X- _ O
are -X- _ O
typically -X- _ O
mixed -X- _ O
. -X- _ O
Another -X- _ O
example -X- _ O
is -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
intent -X- _ O
classification -X- _ O
: -X- _ O
if -X- _ O
the -X- _ O
same -X- _ O
author -X- _ O
reveals -X- _ O
their -X- _ O
intent -X- _ O
before -X- _ O
the -X- _ O
writing -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
intent→text -X- _ O
) -X- _ O
, -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
viewed -X- _ O
as -X- _ O
an -X- _ O
anticausal -X- _ O
learning -X- _ O
task -X- _ O
; -X- _ O
if -X- _ O
, -X- _ O
on -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
the -X- _ O
data -X- _ O
is -X- _ O
annotated -X- _ O
by -X- _ O
other -X- _ O
people -X- _ O
who -X- _ O
are -X- _ O
not -X- _ O
the -X- _ O
original -X- _ O
author -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
text→annotated -X- _ O
intent -X- _ O
) -X- _ O
, -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
viewed -X- _ O
as -X- _ O
a -X- _ O
causal -X- _ O
learning -X- _ O
task -X- _ O
. -X- _ O
A -X- _ O
similar -X- _ O
reasoning -X- _ O
applies -X- _ O
to -X- _ O
question -X- _ O
answering -X- _ O
and -X- _ O
generation -X- _ O
tasks -X- _ O
which -X- _ O
respectively -X- _ O
aim -X- _ O
to -X- _ O
provide -X- _ O
an -X- _ O
answer -X- _ O
to -X- _ O
a -X- _ O
given -X- _ O
question -X- _ O
, -X- _ O
or -X- _ O
vice -X- _ O
versa -X- _ O
: -X- _ O
if -X- _ O
first -X- _ O
a -X- _ O
piece -X- _ O
of -X- _ O
informative -X- _ O
text -X- _ O
is -X- _ O
selected -X- _ O
and -X- _ O
annotators -X- _ O
are -X- _ O
then -X- _ O
asked -X- _ O
to -X- _ O
come -X- _ O
up -X- _ O
with -X- _ O
a -X- _ O
corresponding -X- _ O
question -X- _ O
( -X- _ O
answer→question -X- _ O
) -X- _ O
as -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
SQuAD -X- _ O
dataset -X- _ O
( -X- _ O
Rajpurkar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
then -X- _ O
question -X- _ O
answering -X- _ O
is -X- _ O
an -X- _ O
anticausal -X- _ O
and -X- _ O
question -X- _ O
generation -X- _ O
a -X- _ O
causal -X- _ O
learning -X- _ O
task -X- _ O
; -X- _ O
if -X- _ O
, -X- _ O
on -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
a -X- _ O
question -X- _ O
such -X- _ O
as -X- _ O
a -X- _ O
search -X- _ O
query -X- _ O
is -X- _ O
selected -X- _ O
first -X- _ O
and -X- _ O
subsequently -X- _ O
an -X- _ O
answer -X- _ O
is -X- _ O
pro -X- _ O
- -X- _ O
vided -X- _ O
( -X- _ O
question→answer -X- _ O
) -X- _ O
as -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
Natural -X- _ O
Questions -X- _ O
dataset -X- _ O
( -X- _ O
Kwiatkowski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
then -X- _ O
question -X- _ O
answering -X- _ O
is -X- _ O
a -X- _ O
causal -X- _ O
and -X- _ O
question -X- _ O
generation -X- _ O
an -X- _ O
anticausal -X- _ O
learning -X- _ O
task -X- _ O
. -X- _ O
Often -X- _ O
, -X- _ O
multiple -X- _ O
such -X- _ O
datasets -X- _ O
are -X- _ O
combined -X- _ O
without -X- _ O
regard -X- _ O
for -X- _ O
their -X- _ O
causal -X- _ O
direction -X- _ O
. -X- _ O

Implications -X- _ O
of -X- _ O
ICM -X- _ O
for -X- _ O
Causal -X- _ O
and -X- _ O
Anticausal -X- _ O
Learning -X- _ O
Problems -X- _ O

Whether -X- _ O
we -X- _ O
are -X- _ O
in -X- _ O
a -X- _ O
causal -X- _ O
or -X- _ O
anticausal -X- _ O
learning -X- _ O
scenario -X- _ O
has -X- _ O
important -X- _ O
implications -X- _ O
for -X- _ O
semisupervised -X- _ O
learning -X- _ O
( -X- _ O
SSL -X- _ O
) -X- _ O
and -X- _ O
domain -X- _ O
adaptation -X- _ O
( -X- _ O
DA -X- _ O
) -X- _ O
( -X- _ O
Schölkopf -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2012 -X- _ O
; -X- _ O
Sgouritsa -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
, -X- _ O
2015Gong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
von -X- _ O
Kügelgen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019von -X- _ O
Kügelgen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
, -X- _ O
2020 -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
techniques -X- _ O
also -X- _ O
commonly -X- _ O
used -X- _ O
in -X- _ O
NLP -X- _ O
. -X- _ O
These -X- _ O
implications -X- _ O
are -X- _ O
derived -X- _ O
from -X- _ O
the -X- _ O
principle -X- _ O
of -X- _ O
independent -X- _ O
causal -X- _ O
mechanisms -X- _ O
( -X- _ O
ICM -X- _ O
) -X- _ O
( -X- _ O
Schölkopf -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2012 -X- _ O
; -X- _ O
Lemeire -X- _ O
and -X- _ O
Dirkx -X- _ O
, -X- _ O
2006 -X- _ O
) -X- _ O
which -X- _ O
states -X- _ O
that -X- _ O
" -X- _ O
the -X- _ O
causal -X- _ O
generative -X- _ O
process -X- _ O
of -X- _ O
a -X- _ O
system -X- _ O
's -X- _ O
variables -X- _ O
is -X- _ O
composed -X- _ O
of -X- _ O
autonomous -X- _ O
modules -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
inform -X- _ O
or -X- _ O
influence -X- _ O
each -X- _ O
other -X- _ O
" -X- _ O
( -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
bivariate -X- _ O
case -X- _ O
, -X- _ O
this -X- _ O
amount -X- _ O
to -X- _ O
a -X- _ O
type -X- _ O
of -X- _ O
independence -X- _ O
assumption -X- _ O
between -X- _ O
the -X- _ O
distribution -X- _ O
P -X- _ O
C -X- _ O
of -X- _ O
the -X- _ O
cause -X- _ O
C -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
causal -X- _ O
process -X- _ O
, -X- _ O
or -X- _ O
mechanism -X- _ O
, -X- _ O
P -X- _ O
E|C -X- _ O
that -X- _ O
generates -X- _ O
the -X- _ O
effect -X- _ O
from -X- _ O
the -X- _ O
cause -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
for -X- _ O
a -X- _ O
question -X- _ O
answering -X- _ O
task -X- _ O
, -X- _ O
the -X- _ O
generative -X- _ O
process -X- _ O
P -X- _ O
C -X- _ O
by -X- _ O
which -X- _ O
one -X- _ O
person -X- _ O
comes -X- _ O
up -X- _ O
with -X- _ O
a -X- _ O
question -X- _ O
C -X- _ O
is -X- _ O
" -X- _ O
independent -X- _ O
" -X- _ O
of -X- _ O
the -X- _ O
process -X- _ O
P -X- _ O
E|C -X- _ O
by -X- _ O
which -X- _ O
another -X- _ O
person -X- _ O
produces -X- _ O
an -X- _ O
answer -X- _ O
E -X- _ O
for -X- _ O
question -X- _ O
C. -X- _ O
4 -X- _ O
Here -X- _ O
, -X- _ O
" -X- _ O
independent -X- _ O
" -X- _ O
is -X- _ O
not -X- _ O
meant -X- _ O
in -X- _ O
the -X- _ O
sense -X- _ O
of -X- _ O
statistical -X- _ O
independence -X- _ O
of -X- _ O
random -X- _ O
variables -X- _ O
, -X- _ O
but -X- _ O
rather -X- _ O
as -X- _ O
independence -X- _ O
at -X- _ O
the -X- _ O
level -X- _ O
of -X- _ O
generative -X- _ O
processes -X- _ O
or -X- _ O
distributions -X- _ O
in -X- _ O
the -X- _ O
sense -X- _ O
that -X- _ O
P -X- _ O
C -X- _ O
and -X- _ O
P -X- _ O
E|C -X- _ O
do -X- _ O
not -X- _ O
share -X- _ O
information -X- _ O
( -X- _ O
the -X- _ O
person -X- _ O
asking -X- _ O
the -X- _ O
question -X- _ O
and -X- _ O
the -X- _ O
one -X- _ O
answering -X- _ O
may -X- _ O
not -X- _ O
know -X- _ O
each -X- _ O
other -X- _ O
) -X- _ O
and -X- _ O
can -X- _ O
be -X- _ O
manipulated -X- _ O
independently -X- _ O
of -X- _ O
each -X- _ O
other -X- _ O
( -X- _ O
we -X- _ O
can -X- _ O
swap -X- _ O
either -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
for -X- _ O
another -X- _ O
participant -X- _ O
without -X- _ O
the -X- _ O
other -X- _ O
one -X- _ O
being -X- _ O
influenced -X- _ O
by -X- _ O
this -X- _ O
) -X- _ O
. -X- _ O
Crucially -X- _ O
, -X- _ O
this -X- _ O
type -X- _ O
of -X- _ O
independence -X- _ O
is -X- _ O
generally -X- _ O
violated -X- _ O
in -X- _ O
the -X- _ O
opposite -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
anticausal -X- _ O
, -X- _ O
direction -X- _ O
: -X- _ O
P -X- _ O
E -X- _ O
and -X- _ O
P -X- _ O
C|E -X- _ O
may -X- _ O
share -X- _ O
information -X- _ O
and -X- _ O
change -X- _ O
dependently -X- _ O
( -X- _ O
Daniušis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2010 -X- _ O
; -X- _ O
. -X- _ O
This -X- _ O
has -X- _ O
two -X- _ O
important -X- _ O
implications -X- _ O
for -X- _ O
common -X- _ O
learning -X- _ O
tasks -X- _ O
( -X- _ O
Schölkopf -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
which -X- _ O
are -X- _ O
illustrated -X- _ O
in -X- _ O
Fig -X- _ O
. -X- _ O
3 -X- _ O
. -X- _ O
Figure -X- _ O
3 -X- _ O
: -X- _ O
The -X- _ O
ICM -X- _ O
principle -X- _ O
assumes -X- _ O
that -X- _ O
the -X- _ O
generative -X- _ O
process -X- _ O
P -X- _ O
C -X- _ O
of -X- _ O
the -X- _ O
cause -X- _ O
C -X- _ O
is -X- _ O
independent -X- _ O
of -X- _ O
the -X- _ O
causal -X- _ O
mechanism -X- _ O
P -X- _ O
E|C -X- _ O
: -X- _ O
the -X- _ O
two -X- _ O
distributions -X- _ O
share -X- _ O
no -X- _ O
information -X- _ O
and -X- _ O
each -X- _ O
may -X- _ O
be -X- _ O
changed -X- _ O
or -X- _ O
manipulated -X- _ O
without -X- _ O
affecting -X- _ O
the -X- _ O
other -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
anticausal -X- _ O
direction -X- _ O
, -X- _ O
on -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
the -X- _ O
effect -X- _ O
distribution -X- _ O
P -X- _ O
E -X- _ O
is -X- _ O
( -X- _ O
in -X- _ O
the -X- _ O
generic -X- _ O
case -X- _ O
) -X- _ O
not -X- _ O
independent -X- _ O
of -X- _ O
the -X- _ O
inverse -X- _ O
mechanism -X- _ O
P -X- _ O
C|E -X- _ O
: -X- _ O
they -X- _ O
may -X- _ O
share -X- _ O
information -X- _ O
and -X- _ O
change -X- _ O
dependently -X- _ O
. -X- _ O
( -X- _ O
Left -X- _ O
) -X- _ O
SSL -X- _ O
, -X- _ O
which -X- _ O
aims -X- _ O
to -X- _ O
improve -X- _ O
an -X- _ O
estimate -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
conditional -X- _ O
P -X- _ O
Y -X- _ O
|X -X- _ O
given -X- _ O
additional -X- _ O
unlabelled -X- _ O
input -X- _ O
data -X- _ O
from -X- _ O
P -X- _ O
X -X- _ O
, -X- _ O
should -X- _ O
therefore -X- _ O
not -X- _ O
help -X- _ O
for -X- _ O
causal -X- _ O
learning -X- _ O
( -X- _ O
X -X- _ O
→ -X- _ O
Y -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
may -X- _ O
help -X- _ O
in -X- _ O
the -X- _ O
anticausal -X- _ O
direction -X- _ O
( -X- _ O
Y -X- _ O
→ -X- _ O
X -X- _ O
) -X- _ O
. -X- _ O
( -X- _ O
Right -X- _ O
) -X- _ O
DA -X- _ O
, -X- _ O
which -X- _ O
aims -X- _ O
to -X- _ O
adapt -X- _ O
a -X- _ O
model -X- _ O
of -X- _ O
P -X- _ O
Y -X- _ O
|X -X- _ O
from -X- _ O
a -X- _ O
source -X- _ O
domain -X- _ O
to -X- _ O
a -X- _ O
target -X- _ O
domain -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
on -X- _ O
a -X- _ O
smaller -X- _ O
dataset -X- _ O
) -X- _ O
, -X- _ O
should -X- _ O
work -X- _ O
better -X- _ O
for -X- _ O
causal -X- _ O
learning -X- _ O
settings -X- _ O
where -X- _ O
a -X- _ O
change -X- _ O
in -X- _ O
P -X- _ O
C -X- _ O
is -X- _ O
not -X- _ O
expected -X- _ O
to -X- _ O
lead -X- _ O
to -X- _ O
a -X- _ O
change -X- _ O
in -X- _ O
the -X- _ O
mechanism -X- _ O
P -X- _ O
E|C -X- _ O
, -X- _ O
whereas -X- _ O
in -X- _ O
the -X- _ O
anticausal -X- _ O
direction -X- _ O
P -X- _ O
E -X- _ O
and -X- _ O
P -X- _ O
C|E -X- _ O
may -X- _ O
change -X- _ O
in -X- _ O
a -X- _ O
dependent -X- _ O
manner -X- _ O
. -X- _ O

Implications -X- _ O
of -X- _ O
ICM -X- _ O
for -X- _ O
SSL -X- _ O
First -X- _ O
, -X- _ O
if -X- _ O
P -X- _ O
C -X- _ O
shares -X- _ O
no -X- _ O
information -X- _ O
with -X- _ O
P -X- _ O
E|C -X- _ O
, -X- _ O
SSL -X- _ O
- -X- _ O
where -X- _ O
one -X- _ O
has -X- _ O
additional -X- _ O
unlabelled -X- _ O
input -X- _ O
data -X- _ O
from -X- _ O
P -X- _ O
X -X- _ O
and -X- _ O
aims -X- _ O
to -X- _ O
improve -X- _ O
an -X- _ O
estimate -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
conditional -X- _ O
P -X- _ O
Y -X- _ O
|X -X- _ O
-should -X- _ O
not -X- _ O
work -X- _ O
in -X- _ O
the -X- _ O
causal -X- _ O
direction -X- _ O
( -X- _ O
X -X- _ O
→ -X- _ O
Y -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
may -X- _ O
work -X- _ O
in -X- _ O
the -X- _ O
anticausal -X- _ O
direction -X- _ O
( -X- _ O
Y -X- _ O
→ -X- _ O
X -X- _ O
) -X- _ O
, -X- _ O
as -X- _ O
P -X- _ O
E -X- _ O
and -X- _ O
P -X- _ O
C|E -X- _ O
may -X- _ O
share -X- _ O
information -X- _ O
. -X- _ O
Causal -X- _ O
NLP -X- _ O
tasks -X- _ O
should -X- _ O
thus -X- _ O
be -X- _ O
less -X- _ O
likely -X- _ O
to -X- _ O
show -X- _ O
improvements -X- _ O
over -X- _ O
a -X- _ O
supervised -X- _ O
baseline -X- _ O
when -X- _ O
using -X- _ O
SSL -X- _ O
than -X- _ O
anticausal -X- _ O
tasks -X- _ O
. -X- _ O
Traditionally -X- _ O
, -X- _ O
the -X- _ O
ICM -X- _ O
principle -X- _ O
is -X- _ O
thought -X- _ O
of -X- _ O
in -X- _ O
the -X- _ O
context -X- _ O
of -X- _ O
physical -X- _ O
processes -X- _ O
or -X- _ O
mechanisms -X- _ O
, -X- _ O
rather -X- _ O
than -X- _ O
social -X- _ O
or -X- _ O
linguistic -X- _ O
ones -X- _ O
such -X- _ O
as -X- _ O
language -X- _ O
. -X- _ O
Since -X- _ O
ICM -X- _ O
amounts -X- _ O
to -X- _ O
an -X- _ O
independence -X- _ O
assumption -X- _ O
that -X- _ O
- -X- _ O
while -X- _ O
well -X- _ O
motivated -X- _ O
in -X- _ O
principlemay -X- _ O
not -X- _ O
always -X- _ O
hold -X- _ O
in -X- _ O
practice -X- _ O
, -X- _ O
5 -X- _ O
we -X- _ O
now -X- _ O
assay -X- _ O
its -X- _ O
validity -X- _ O
on -X- _ O
NLP -X- _ O
data -X- _ O
. -X- _ O
Recall -X- _ O
, -X- _ O
that -X- _ O
ICM -X- _ O
postulates -X- _ O
a -X- _ O
type -X- _ O
of -X- _ O
independence -X- _ O
between -X- _ O
P -X- _ O
C -X- _ O
and -X- _ O
P -X- _ O
E|C -X- _ O
. -X- _ O
One -X- _ O
way -X- _ O
to -X- _ O
formalize -X- _ O
this -X- _ O
uses -X- _ O
Kolmogorov -X- _ B-MetricName
complexity -X- _ I-MetricName
K -X- _ B-MetricName
( -X- _ I-MetricName
• -X- _ I-MetricName
) -X- _ I-MetricName
as -X- _ O
a -X- _ O
measure -X- _ O
of -X- _ O
algorithmic -X- _ O
information -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
5 -X- _ O
E.g. -X- _ O
, -X- _ O
due -X- _ O
to -X- _ O
confounding -X- _ O
influences -X- _ O
from -X- _ O
unobserved -X- _ O
variables -X- _ O
, -X- _ O
or -X- _ O
mechanisms -X- _ O
which -X- _ O
have -X- _ O
co -X- _ O
- -X- _ O
evolved -X- _ O
to -X- _ O
be -X- _ O
dependent -X- _ O
understood -X- _ O
as -X- _ O
the -X- _ O
length -X- _ O
of -X- _ O
the -X- _ O
shortest -X- _ O
program -X- _ O
that -X- _ O
computes -X- _ O
a -X- _ O
particular -X- _ O
algorithmic -X- _ O
object -X- _ O
such -X- _ O
as -X- _ O
a -X- _ O
distribution -X- _ O
or -X- _ O
a -X- _ O
function -X- _ O
( -X- _ O
Solomonoff -X- _ O
, -X- _ O
1964 -X- _ O
; -X- _ O
Kolmogorov -X- _ O
, -X- _ O
1965 -X- _ O
) -X- _ O
. -X- _ O
ICM -X- _ O
then -X- _ O
reads -X- _ O

) -X- _ O
: -X- _ O
6 -X- _ O
K -X- _ B-MetricName
( -X- _ O
P -X- _ O
C -X- _ O
, -X- _ O
E -X- _ O
) -X- _ O
+ -X- _ O
= -X- _ O
K -X- _ B-MetricName
( -X- _ O
P -X- _ O
C -X- _ O
) -X- _ O
+ -X- _ O
K -X- _ B-MetricName
( -X- _ O
P -X- _ O
E|C -X- _ O
) -X- _ O
+ -X- _ O
≤ -X- _ O
K -X- _ B-MetricName
( -X- _ O
P -X- _ O
E -X- _ O
) -X- _ O
+ -X- _ O
K -X- _ B-MetricName
( -X- _ O
P -X- _ O
C|E -X- _ O
) -X- _ O
. -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O

In -X- _ O
other -X- _ O
words -X- _ O
, -X- _ O
the -X- _ O
shortest -X- _ O
description -X- _ O
of -X- _ O
the -X- _ O
joint -X- _ O
distribution -X- _ O
P -X- _ O
C -X- _ O
, -X- _ O
E -X- _ O
corresponds -X- _ O
to -X- _ O
describing -X- _ O
P -X- _ O
C -X- _ O
and -X- _ O
P -X- _ O
E|C -X- _ O
separately -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
they -X- _ O
share -X- _ O
no -X- _ O
information -X- _ O
) -X- _ O
, -X- _ O
whereas -X- _ O
there -X- _ O
may -X- _ O
be -X- _ O
redundant -X- _ O
( -X- _ O
shared -X- _ O
) -X- _ O
information -X- _ O
in -X- _ O
the -X- _ O
non -X- _ O
- -X- _ O
causal -X- _ O
direction -X- _ O
such -X- _ O
that -X- _ O
a -X- _ O
separate -X- _ O
description -X- _ O
of -X- _ O
P -X- _ O
E -X- _ O
and -X- _ O
P -X- _ O
C|E -X- _ O
will -X- _ O
generally -X- _ O
be -X- _ O
longer -X- _ O
than -X- _ O
that -X- _ O
of -X- _ O
the -X- _ O
joint -X- _ O
distribution -X- _ O
P -X- _ O
C -X- _ O
, -X- _ O
E -X- _ O
. -X- _ O

Estimation -X- _ O
by -X- _ O
MDL -X- _ B-MetricName

Since -X- _ O
Kolmogorov -X- _ B-MetricName
complexity -X- _ I-MetricName
is -X- _ O
not -X- _ O
computable -X- _ O
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
a -X- _ O
commonly -X- _ O
used -X- _ O
proxy -X- _ O
, -X- _ O
the -X- _ O
minimum -X- _ B-MetricName
description -X- _ I-MetricName
length -X- _ I-MetricName
( -X- _ O
MDL -X- _ B-MetricName
) -X- _ O
( -X- _ O
Grünwald -X- _ O
, -X- _ O
2007 -X- _ O
) -X- _ O
, -X- _ O
to -X- _ O
test -X- _ O
the -X- _ O
applicability -X- _ O
of -X- _ O
ICM -X- _ O
for -X- _ O
NLP -X- _ O
data -X- _ O
. -X- _ O
Given -X- _ O
an -X- _ O
input -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
a -X- _ O
collection -X- _ O
of -X- _ O
observations -X- _ O
{ -X- _ O
( -X- _ O
c -X- _ O
i -X- _ O
, -X- _ O
e -X- _ O
i -X- _ O
) -X- _ O
} -X- _ O
n -X- _ O
i=1 -X- _ O
∼ -X- _ O
P -X- _ O
C -X- _ O
, -X- _ O
E -X- _ O
, -X- _ O
MDL -X- _ B-MetricName
returns -X- _ O
the -X- _ O
shortest -X- _ O
codelength -X- _ O
( -X- _ O
in -X- _ O
bits -X- _ O
) -X- _ O
needed -X- _ O
to -X- _ O
compress -X- _ O
the -X- _ O
input -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
parameters -X- _ O
needed -X- _ O
to -X- _ O
decompress -X- _ O
it -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
MDL -X- _ B-MetricName
to -X- _ O
approximate -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

MDL -X- _ B-MetricName
( -X- _ O
c -X- _ O
1 -X- _ O
: -X- _ O
n -X- _ O
, -X- _ O
e -X- _ O
1 -X- _ O
: -X- _ O
n -X- _ O
) -X- _ O
= -X- _ O
MDL -X- _ B-MetricName
( -X- _ O
c -X- _ O
1 -X- _ O
: -X- _ O
n -X- _ O
) -X- _ O
+ -X- _ O
MDL -X- _ B-MetricName
( -X- _ O
e -X- _ O
1 -X- _ O
: -X- _ O
n -X- _ O
|c -X- _ O
1 -X- _ O
: -X- _ O
n -X- _ O
) -X- _ O
≤ -X- _ O
MDL -X- _ B-MetricName
( -X- _ O
e -X- _ O
1 -X- _ O
: -X- _ O
n -X- _ O
) -X- _ O
+ -X- _ O
MDL -X- _ B-MetricName
( -X- _ O
c -X- _ O
1 -X- _ O
: -X- _ O
n -X- _ O
|e -X- _ O
1 -X- _ O
: -X- _ O
n -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O

where -X- _ O
MDL -X- _ B-MetricName
( -X- _ O
•|• -X- _ O
) -X- _ O
denotes -X- _ O
a -X- _ O
conditional -X- _ O
compression -X- _ O
where -X- _ O
the -X- _ O
second -X- _ O
argument -X- _ O
is -X- _ O
treated -X- _ O
as -X- _ O
" -X- _ O
free -X- _ O
parameters -X- _ O
" -X- _ O
which -X- _ O
do -X- _ O
not -X- _ O
count -X- _ O
towards -X- _ O
the -X- _ O
compression -X- _ O
length -X- _ O
of -X- _ O
the -X- _ O
first -X- _ O
argument -X- _ O
. -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
can -X- _ O
thus -X- _ O
6 -X- _ O
Here -X- _ O
, -X- _ O
be -X- _ O
interpreted -X- _ O
as -X- _ O
a -X- _ O
comparison -X- _ O
between -X- _ O
two -X- _ O
ways -X- _ O
of -X- _ O
compressing -X- _ O
the -X- _ O
same -X- _ O
data -X- _ O
( -X- _ O
c -X- _ O
1 -X- _ O
: -X- _ O
n -X- _ O
, -X- _ O
e -X- _ O
1 -X- _ O
: -X- _ O
n -X- _ O
) -X- _ O
: -X- _ O
either -X- _ O
we -X- _ O
first -X- _ O
compress -X- _ O
c -X- _ O
1 -X- _ O
: -X- _ O
n -X- _ O
and -X- _ O
then -X- _ O
compress -X- _ O
e -X- _ O
1 -X- _ O
: -X- _ O
n -X- _ O
conditional -X- _ O
on -X- _ O
c -X- _ O
1 -X- _ O
: -X- _ O
n -X- _ O
, -X- _ O
or -X- _ O
vice -X- _ O
versa -X- _ O
. -X- _ O
According -X- _ O
to -X- _ O
the -X- _ O
ICM -X- _ O
principle -X- _ O
, -X- _ O
the -X- _ O
first -X- _ O
way -X- _ O
should -X- _ O
tend -X- _ O
to -X- _ O
be -X- _ O
more -X- _ O
" -X- _ O
concise -X- _ O
" -X- _ O
than -X- _ O
the -X- _ O
second -X- _ O
. -X- _ O

Calculating -X- _ O
MDL -X- _ B-MetricName
Using -X- _ O
Machine -X- _ O
Translation -X- _ O
as -X- _ O
a -X- _ O
Case -X- _ O
Study -X- _ O

To -X- _ O
empirically -X- _ O
assess -X- _ O
the -X- _ O
validity -X- _ O
of -X- _ O
ICM -X- _ O
for -X- _ O
NLP -X- _ O
data -X- _ O
using -X- _ O
MDL -X- _ B-MetricName
as -X- _ O
a -X- _ O
proxy -X- _ O
, -X- _ O
we -X- _ O
turn -X- _ O
to -X- _ O
MT -X- _ O
as -X- _ O
a -X- _ O
case -X- _ O
study -X- _ O
. -X- _ O
We -X- _ O
choose -X- _ O
MT -X- _ O
because -X- _ O
the -X- _ O
input -X- _ O
and -X- _ O
output -X- _ O
spaces -X- _ O
of -X- _ O
MT -X- _ O
are -X- _ O
relatively -X- _ O
symmetric -X- _ O
, -X- _ O
as -X- _ O
opposed -X- _ O
to -X- _ O
other -X- _ O
NLP -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
text -X- _ O
classification -X- _ O
where -X- _ O
the -X- _ O
input -X- _ O
space -X- _ O
is -X- _ O
sequences -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
output -X- _ O
space -X- _ O
is -X- _ O
a -X- _ O
small -X- _ O
set -X- _ O
of -X- _ O
labels -X- _ O
. -X- _ O
There -X- _ O
are -X- _ O
only -X- _ O
very -X- _ O
few -X- _ O
studies -X- _ O
which -X- _ O
calculate -X- _ O
MDL -X- _ B-MetricName
on -X- _ O
NLP -X- _ O
data -X- _ O
, -X- _ O
so -X- _ O
we -X- _ O
extend -X- _ O
the -X- _ O
method -X- _ O
of -X- _ O
Voita -X- _ O
and -X- _ O
Titov -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
to -X- _ O
calculate -X- _ O
MDL -X- _ B-MetricName
using -X- _ O
online -X- _ O
codes -X- _ O
( -X- _ O
Rissanen -X- _ O
, -X- _ O
1984 -X- _ O
) -X- _ O
for -X- _ O
deep -X- _ O
learning -X- _ O
tasks -X- _ O
( -X- _ O
Blier -X- _ O
and -X- _ O
Ollivier -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
Since -X- _ O
the -X- _ O
original -X- _ O
calculation -X- _ O
method -X- _ O
for -X- _ O
MDL -X- _ B-MetricName
by -X- _ O
Voita -X- _ O
and -X- _ O
Titov -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
was -X- _ O
developed -X- _ O
for -X- _ O
classification -X- _ O
, -X- _ O
we -X- _ O
extend -X- _ O
it -X- _ O
to -X- _ O
sequence -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
sequence -X- _ O
( -X- _ O
Seq2Seq -X- _ O
) -X- _ O
generation -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
given -X- _ O
a -X- _ O
translation -X- _ O
dataset -X- _ O
D -X- _ O
= -X- _ O
{ -X- _ O
( -X- _ O
x -X- _ O
1 -X- _ O
, -X- _ O
y -X- _ O
1 -X- _ O
) -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
( -X- _ O
x -X- _ O
n -X- _ O
, -X- _ O
y -X- _ O
n -X- _ O
) -X- _ O
} -X- _ O
of -X- _ O
n -X- _ O
pairs -X- _ O
of -X- _ O
sentences -X- _ O
x -X- _ O
i -X- _ O
with -X- _ O
translation -X- _ O
y -X- _ O
i -X- _ O
, -X- _ O
denote -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
vocabulary -X- _ O
of -X- _ O
the -X- _ O
source -X- _ O
language -X- _ O
by -X- _ O
V -X- _ O
x -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
vocabulary -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
by -X- _ O
V -X- _ O
y -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
assess -X- _ O
whether -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
holds -X- _ O
, -X- _ O
we -X- _ O
need -X- _ O
to -X- _ O
calculate -X- _ O
four -X- _ O
different -X- _ O
terms -X- _ O
: -X- _ O
two -X- _ O
marginal -X- _ O
terms -X- _ O
MDL -X- _ O
( -X- _ O
x -X- _ O
1 -X- _ O
: -X- _ O
n -X- _ O
) -X- _ O
and -X- _ O
MDL -X- _ O
( -X- _ O
y -X- _ O
1 -X- _ O
: -X- _ O
n -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
two -X- _ O
conditional -X- _ O
terms -X- _ O
MDL -X- _ B-MetricName
( -X- _ O
y -X- _ O
1 -X- _ O
: -X- _ O
n -X- _ O
|x -X- _ O
1 -X- _ O
: -X- _ O
n -X- _ O
) -X- _ O
and -X- _ O
MDL -X- _ B-MetricName
( -X- _ O
x -X- _ O
1 -X- _ O
: -X- _ O
n -X- _ O
|y -X- _ O
1 -X- _ O
: -X- _ O
n -X- _ O
) -X- _ O
. -X- _ O

Codelength -X- _ B-MetricName
of -X- _ O
the -X- _ O
Conditional -X- _ O
Terms -X- _ O

To -X- _ O
calculate -X- _ O
the -X- _ O
codelength -X- _ B-MetricName
of -X- _ O
the -X- _ O
two -X- _ O
conditional -X- _ O
terms -X- _ O
, -X- _ O
we -X- _ O
extend -X- _ O
the -X- _ O
method -X- _ O
of -X- _ O
Voita -X- _ O
and -X- _ O
Titov -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
from -X- _ O
classification -X- _ O
to -X- _ O
Seq2Seq -X- _ O
generation -X- _ O
. -X- _ O
Following -X- _ O
the -X- _ O
setting -X- _ O
of -X- _ O
Voita -X- _ O
and -X- _ O
Titov -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
break -X- _ O
the -X- _ O
dataset -X- _ O
D -X- _ O
into -X- _ O
10 -X- _ O
disjoint -X- _ O
subsets -X- _ O
with -X- _ O
increasing -X- _ O
sizes -X- _ O
and -X- _ O
denote -X- _ O
the -X- _ O
end -X- _ O
index -X- _ O
of -X- _ O
each -X- _ O
subset -X- _ O
as -X- _ O
t -X- _ O
i -X- _ O
. -X- _ O
7 -X- _ O
We -X- _ O
then -X- _ O
estimate -X- _ O
MDL -X- _ B-MetricName
( -X- _ O
y -X- _ O

1 -X- _ O
: -X- _ O
n -X- _ O
|x -X- _ O
1 -X- _ O
: -X- _ O
n -X- _ O
) -X- _ O
as -X- _ O
' -X- _ O
MDL -X- _ B-MetricName
( -X- _ O
y -X- _ O
1 -X- _ O
: -X- _ O
n -X- _ O
|x -X- _ O
1 -X- _ O
: -X- _ O
n -X- _ O
) -X- _ O
= -X- _ O
t -X- _ O
1 -X- _ O
i=1 -X- _ O
length -X- _ O
( -X- _ O
y -X- _ O
i -X- _ O
) -X- _ O
• -X- _ O
log -X- _ O
2 -X- _ O
V -X- _ O
y -X- _ O
− -X- _ O
n−1 -X- _ O
i=1 -X- _ O
log -X- _ O
2 -X- _ O
p -X- _ O
θ -X- _ O
i -X- _ O
( -X- _ O
y -X- _ O
1+t -X- _ O
i -X- _ O
: -X- _ O
t -X- _ O
i+1 -X- _ O
|x -X- _ O
1+t -X- _ O
i -X- _ O
: -X- _ O
t -X- _ O
i+1 -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O

where -X- _ O
length -X- _ O
( -X- _ O
y -X- _ O
i -X- _ O
) -X- _ O
refers -X- _ O
to -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
sequence -X- _ O
y -X- _ O
i -X- _ O
, -X- _ O
θ -X- _ O
i -X- _ O
are -X- _ O
the -X- _ O
parameters -X- _ O
of -X- _ O
a -X- _ O
translation -X- _ O
model -X- _ O
h -X- _ O
i -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
first -X- _ O
t -X- _ O
i -X- _ O
data -X- _ O
points -X- _ O
, -X- _ O
and -X- _ O
seq -X- _ O
idx -X- _ O
1 -X- _ O
: -X- _ O
idx -X- _ O
2 -X- _ O
refers -X- _ O
to -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
sequences -X- _ O
from -X- _ O
7 -X- _ O
The -X- _ O
sizes -X- _ O
of -X- _ O
the -X- _ O
10 -X- _ O
subsets -X- _ O
are -X- _ O
0.1 -X- _ O
, -X- _ O
0.2 -X- _ O
, -X- _ O
0.4 -X- _ O
, -X- _ O
0.8 -X- _ O
, -X- _ O
1.6 -X- _ O
, -X- _ O
3.2 -X- _ O
, -X- _ O
6.25 -X- _ O
, -X- _ O
12.5 -X- _ O
, -X- _ O
25 -X- _ O
, -X- _ O
and -X- _ O
50 -X- _ O
percent -X- _ O
of -X- _ O
the -X- _ O
dataset -X- _ O
size -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
E.g. -X- _ O
, -X- _ O
t1 -X- _ O
= -X- _ O
0.1 -X- _ O
% -X- _ O
n -X- _ O
, -X- _ O
t2 -X- _ O
= -X- _ O
( -X- _ O
0.1 -X- _ O
% -X- _ O
+ -X- _ O
0.2 -X- _ O
% -X- _ O
) -X- _ O
n -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
the -X- _ O
idx -X- _ O
1 -X- _ O
-th -X- _ O
to -X- _ O
the -X- _ O
idx -X- _ O
2 -X- _ O
-th -X- _ O
sample -X- _ O
in -X- _ O
the -X- _ O
dataset -X- _ O
D -X- _ O
, -X- _ O
where -X- _ O
seq -X- _ O
∈ -X- _ O
{ -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
} -X- _ O
and -X- _ O
idx -X- _ O
i -X- _ O
∈ -X- _ O
{ -X- _ O
1 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
n -X- _ O
} -X- _ O
. -X- _ O

Similarly -X- _ O
, -X- _ O
when -X- _ O
calculating -X- _ O
MDL -X- _ B-MetricName
( -X- _ O
x -X- _ O
1 -X- _ O
: -X- _ O
n -X- _ O
|y -X- _ O
1 -X- _ O
: -X- _ O
n -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
simply -X- _ O
swap -X- _ O
the -X- _ O
roles -X- _ O
of -X- _ O
x -X- _ O
and -X- _ O
y -X- _ O
. -X- _ O

Codelength -X- _ B-MetricName
of -X- _ O
the -X- _ O
Marginal -X- _ O
Terms -X- _ O
When -X- _ O
calculating -X- _ O
the -X- _ O
two -X- _ O
marginal -X- _ O
terms -X- _ O
, -X- _ O
MDL -X- _ B-MetricName
( -X- _ O
x -X- _ O
1 -X- _ O
: -X- _ O
n -X- _ O
) -X- _ O
and -X- _ O
MDL -X- _ B-MetricName
( -X- _ O
y -X- _ O
1 -X- _ O
: -X- _ O
n -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
make -X- _ O
two -X- _ O
changes -X- _ O
from -X- _ O
the -X- _ O
above -X- _ O
calculation -X- _ O
of -X- _ O
conditional -X- _ O
terms -X- _ O
: -X- _ O
first -X- _ O
, -X- _ O
we -X- _ O
replace -X- _ O
the -X- _ O
translation -X- _ O
models -X- _ O
h -X- _ O
i -X- _ O
with -X- _ O
language -X- _ O
models -X- _ O
; -X- _ O
second -X- _ O
, -X- _ O
we -X- _ O
remove -X- _ O
the -X- _ O
conditional -X- _ O
distribution -X- _ O
. -X- _ O

That -X- _ O
is -X- _ O
, -X- _ O
we -X- _ O
calculate -X- _ O
MDL -X- _ B-MetricName
( -X- _ O
x -X- _ O
1 -X- _ O
: -X- _ O
n -X- _ O
) -X- _ O
as -X- _ O

' -X- _ O
MDL -X- _ B-MetricName
( -X- _ O
x -X- _ O
1 -X- _ O
: -X- _ O
n -X- _ O
) -X- _ O
= -X- _ O
t -X- _ O
1 -X- _ O
i=1 -X- _ O
length -X- _ O
( -X- _ O
x -X- _ O
i -X- _ O
) -X- _ O
• -X- _ O
log -X- _ O
2 -X- _ O
V -X- _ O
x -X- _ O
− -X- _ O
n−1 -X- _ O
i=1 -X- _ O
log -X- _ O
2 -X- _ O
p -X- _ O
θ -X- _ O
i -X- _ O
( -X- _ O
x -X- _ O
1+t -X- _ O
i -X- _ O
: -X- _ O
t -X- _ O
i+1 -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O

where -X- _ O
θ -X- _ O
i -X- _ O
are -X- _ O
the -X- _ O
parameters -X- _ O
of -X- _ O
a -X- _ O
language -X- _ O
model -X- _ O
h -X- _ O
i -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
first -X- _ O
t -X- _ O
i -X- _ O
data -X- _ O
points -X- _ O
. -X- _ O
We -X- _ O
apply -X- _ O
the -X- _ O
same -X- _ O
method -X- _ O
to -X- _ O
calculate -X- _ O
MDL -X- _ B-MetricName
( -X- _ O
y -X- _ O
1 -X- _ O
: -X- _ O
n -X- _ O
) -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
GPT2 -X- _ B-MethodName
( -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
for -X- _ O
the -X- _ O
translation -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
Marian -X- _ B-MethodName
neural -X- _ O
machine -X- _ O
translation -X- _ O
model -X- _ O
( -X- _ O
Junczys -X- _ O
- -X- _ O
Dowmunt -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
OPUS -X- _ O
Corpus -X- _ O
( -X- _ O
Tiedemann -X- _ O
and -X- _ O
Nygaard -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
fair -X- _ O
comparison -X- _ O
, -X- _ O
all -X- _ O
models -X- _ O
adopt -X- _ O
the -X- _ O
transformer -X- _ O
architecture -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
have -X- _ O
roughly -X- _ O
the -X- _ O
same -X- _ O
number -X- _ O
of -X- _ O
parameters -X- _ O
. -X- _ O
See -X- _ O
Appendix -X- _ O
B -X- _ O
for -X- _ O
more -X- _ O
experimental -X- _ O
details -X- _ O
. -X- _ O

CausalMT -X- _ B-DatasetName
Corpus -X- _ O

For -X- _ O
our -X- _ O
MDL -X- _ B-MetricName
experiment -X- _ O
, -X- _ O
we -X- _ O
need -X- _ O
datasets -X- _ O
for -X- _ O
which -X- _ O
the -X- _ O
causal -X- _ O
direction -X- _ O
of -X- _ O
data -X- _ O
collection -X- _ O
is -X- _ O
known -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
for -X- _ O
which -X- _ O
we -X- _ O
have -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
annotation -X- _ O
of -X- _ O
which -X- _ O
text -X- _ O
is -X- _ O
the -X- _ O
original -X- _ O
and -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
translation -X- _ O
, -X- _ O
instead -X- _ O
of -X- _ O
a -X- _ O
mixture -X- _ O
of -X- _ O
both -X- _ O
. -X- _ O
Since -X- _ O
existing -X- _ O
MT -X- _ O
corpora -X- _ O
do -X- _ O
not -X- _ O
have -X- _ O
this -X- _ O
property -X- _ O
as -X- _ O
discussed -X- _ O
in -X- _ O
§ -X- _ O
1 -X- _ O
, -X- _ O
we -X- _ O
curate -X- _ O
our -X- _ O
own -X- _ O
corpus -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
call -X- _ O
the -X- _ O
CausalMT -X- _ B-DatasetName
corpus -X- _ O
. -X- _ O

Specifically -X- _ O
, -X- _ O
we -X- _ O
consider -X- _ O
the -X- _ O
existing -X- _ O
MT -X- _ O
dataset -X- _ O
WMT'19 -X- _ B-DatasetName
, -X- _ O
8 -X- _ O
and -X- _ O
identify -X- _ O
some -X- _ O
subsets -X- _ O
that -X- _ O
have -X- _ O
a -X- _ O
clear -X- _ O
notion -X- _ O
of -X- _ O
causality -X- _ O
. -X- _ O
The -X- _ O
subsets -X- _ O
we -X- _ O
use -X- _ O
are -X- _ O
the -X- _ O
EuroParl -X- _ B-DatasetName
( -X- _ O
Koehn -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
translation -X- _ O
corpora -X- _ O
. -X- _ O
9 -X- _ O
For -X- _ O
EuroParl -X- _ B-DatasetName
, -X- _ O
each -X- _ O
text -X- _ O
has -X- _ O
meta -X- _ O
information -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
speaker -X- _ O
's -X- _ O
language -X- _ O
; -X- _ O
for -X- _ O
Global -X- _ B-DatasetName
Voices -X- _ I-DatasetName
, -X- _ O
each -X- _ O
text -X- _ O
has -X- _ O
meta -X- _ O
information -X- _ O
about -X- _ O
whether -X- _ O
it -X- _ O
is -X- _ O
translated -X- _ O
or -X- _ O
not -X- _ O
. -X- _ O
We -X- _ O
regard -X- _ O
text -X- _ O
that -X- _ O
is -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
language -X- _ O
as -X- _ O
the -X- _ O
speaker -X- _ O
's -X- _ O
native -X- _ O
language -X- _ O
in -X- _ O
EuroParl -X- _ B-DatasetName
( -X- _ O
and -X- _ O
non -X- _ O
- -X- _ O
translated -X- _ O
text -X- _ O
in -X- _ O
Global -X- _ B-DatasetName
Voices -X- _ I-DatasetName
) -X- _ O
as -X- _ O
the -X- _ O
original -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
the -X- _ O
cause -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
then -X- _ O
retrieve -X- _ O
a -X- _ O
corresponding -X- _ O
effect -X- _ O
by -X- _ O
using -X- _ O
the -X- _ O
cause -X- _ O
text -X- _ O
to -X- _ O
match -X- _ O
the -X- _ O
parallel -X- _ O
pairs -X- _ O
in -X- _ O
the -X- _ O
processed -X- _ O
dataset -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
way -X- _ O
, -X- _ O
we -X- _ O
compile -X- _ O
six -X- _ O
translation -X- _ O
datasets -X- _ O
with -X- _ O
clear -X- _ O
causal -X- _ O
direction -X- _ O
as -X- _ O
summarized -X- _ O
in -X- _ O
Tab -X- _ O
. -X- _ O
2 -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
dataset -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
1 -X- _ O
K -X- _ O
samples -X- _ O
each -X- _ O
as -X- _ O
test -X- _ O
and -X- _ O
validation -X- _ O
sets -X- _ O
, -X- _ O
and -X- _ O
use -X- _ O
the -X- _ O
rest -X- _ O
for -X- _ O
training -X- _ O
. -X- _ O

Results -X- _ O

The -X- _ O
results -X- _ O
of -X- _ O
our -X- _ O
MDL -X- _ B-MetricName
experiment -X- _ O
on -X- _ O
the -X- _ O
six -X- _ O
CausalMT -X- _ B-DatasetName
datasets -X- _ O
are -X- _ O
summarised -X- _ O
in -X- _ O
Tab -X- _ O
. -X- _ O
3 -X- _ O
. -X- _ O
If -X- _ O
ICM -X- _ O
holds -X- _ O
, -X- _ O
we -X- _ O
expect -X- _ O
the -X- _ O
sum -X- _ O
of -X- _ O
codelengths -X- _ B-MetricName
to -X- _ O
be -X- _ O
smaller -X- _ O
for -X- _ O
the -X- _ O
causal -X- _ O
direction -X- _ O
than -X- _ O
for -X- _ O
the -X- _ O
anticausal -X- _ O
one -X- _ O
, -X- _ O
see -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O
As -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
from -X- _ O
the -X- _ O
last -X- _ O
column -X- _ O
, -X- _ O
this -X- _ O
is -X- _ O
the -X- _ O
case -X- _ O
for -X- _ O
five -X- _ O
out -X- _ O
of -X- _ O
the -X- _ O
six -X- _ O
datasets -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
on -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
largest -X- _ O
datasets -X- _ O
( -X- _ O
En→Es -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
MDL -X- _ B-MetricName
difference -X- _ O
is -X- _ O
346 -X- _ O
kbits -X- _ O
. -X- _ O
10 -X- _ O
Comparing -X- _ O
the -X- _ O
dataset -X- _ O
sizes -X- _ O
in -X- _ O
Tab -X- _ O
. -X- _ O
2 -X- _ O
and -X- _ O
results -X- _ O
in -X- _ O
Tab -X- _ O
. -X- _ O
3 -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
absolute -X- _ O
MDL -X- _ B-MetricName
values -X- _ O
are -X- _ O
roughly -X- _ O
proportional -X- _ O
to -X- _ O
dataset -X- _ O
size -X- _ O
, -X- _ O
but -X- _ O
other -X- _ O
factors -X- _ O
such -X- _ O
as -X- _ O
language -X- _ O
and -X- _ O
task -X- _ O
complexity -X- _ O
also -X- _ O
play -X- _ O
a -X- _ O
role -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
inherent -X- _ O
to -X- _ O
the -X- _ O
nature -X- _ O
of -X- _ O
MDL -X- _ B-MetricName
being -X- _ O
the -X- _ O
sum -X- _ O
of -X- _ O
codelengths -X- _ B-MetricName
of -X- _ O
the -X- _ O
model -X- _ O
and -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
given -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O
Since -X- _ O
we -X- _ O
use -X- _ O
equally -X- _ O
- -X- _ O
sized -X- _ O
datasets -X- _ O
for -X- _ O
each -X- _ O
language -X- _ O
pair -X- _ O
in -X- _ O
the -X- _ O
CausalMT -X- _ B-DatasetName
corpus -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
in -X- _ O
both -X- _ O
the -X- _ O
X -X- _ O
→ -X- _ O
Y -X- _ O
and -X- _ O
Y -X- _ O
→ -X- _ O
X -X- _ O
directions -X- _ O
, -X- _ O
see -X- _ O
Tab -X- _ O
. -X- _ O
2 -X- _ O
) -X- _ O
, -X- _ O
numbers -X- _ O
for -X- _ O
the -X- _ O
same -X- _ O
language -X- _ O
pair -X- _ O
in -X- _ O
Tab -X- _ O
. -X- _ O
3 -X- _ O
, -X- _ O
including -X- _ O
the -X- _ O
most -X- _ O
important -X- _ O
column -X- _ O
" -X- _ O
MDL -X- _ B-MetricName
( -X- _ O
X -X- _ O
) -X- _ O
+MDL -X- _ B-MetricName
( -X- _ O
Y|X -X- _ O
) -X- _ O
vs. -X- _ O
MDL -X- _ B-MetricName
( -X- _ O
Y -X- _ O
) -X- _ O
+MDL -X- _ B-MetricName
( -X- _ O
X|Y -X- _ O
) -X- _ O
" -X- _ O
, -X- _ O
form -X- _ O
a -X- _ O
valid -X- _ O
comparison -X- _ O
. -X- _ O
That -X- _ O
is -X- _ O
, -X- _ O
En -X- _ O
& -X- _ O
Es -X- _ O
experiments -X- _ O
are -X- _ O
comparable -X- _ O
within -X- _ O
themselves -X- _ O
, -X- _ O
so -X- _ O
are -X- _ O
the -X- _ O
other -X- _ O
language -X- _ O
pairs -X- _ O
. -X- _ O
For -X- _ O
some -X- _ O
of -X- _ O
the -X- _ O
smaller -X- _ O
differences -X- _ O
in -X- _ O
the -X- _ O
last -X- _ O
column -X- _ O
in -X- _ O
Tab -X- _ O
. -X- _ O
3 -X- _ O
, -X- _ O
and -X- _ O
, -X- _ O
in -X- _ O
particular -X- _ O
the -X- _ O
reversed -X- _ O
inequality -X- _ O
in -X- _ O
row -X- _ O
4 -X- _ O
, -X- _ O
a -X- _ O
potential -X- _ O
explanation -X- _ O
may -X- _ O
be -X- _ O
the -X- _ O
relatively -X- _ O
small -X- _ O
dataset -X- _ O
size -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
text -X- _ O
data -X- _ O
may -X- _ O
be -X- _ O
confounded -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
through -X- _ O
shared -X- _ O
grammar -X- _ O
and -X- _ O
semantics -X- _ O
) -X- _ O
. -X- _ O

SSL -X- _ O
for -X- _ O
Causal -X- _ O
vs. -X- _ O
Anticausal -X- _ O
Models -X- _ O

In -X- _ O
semi -X- _ O
- -X- _ O
supervised -X- _ O
learning -X- _ O
( -X- _ O
SSL -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
are -X- _ O
given -X- _ O
a -X- _ O
typically -X- _ O
- -X- _ O
small -X- _ O
set -X- _ O
of -X- _ O
k -X- _ O
labeled -X- _ O
observations -X- _ O
D -X- _ O
L -X- _ O
= -X- _ O
{ -X- _ O
( -X- _ O
x -X- _ O
1 -X- _ O
, -X- _ O
y -X- _ O
1 -X- _ O
) -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
( -X- _ O
x -X- _ O
k -X- _ O
, -X- _ O
y -X- _ O
k -X- _ O
) -X- _ O
} -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
typicallylarge -X- _ O
set -X- _ O
of -X- _ O
m -X- _ O
unlabeled -X- _ O
observations -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O

D -X- _ O
U -X- _ O
= -X- _ O
{ -X- _ O
x -X- _ O
( -X- _ O
u -X- _ O
) -X- _ O
1 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
x -X- _ O
( -X- _ O
u -X- _ O
) -X- _ O

m -X- _ O
} -X- _ O
. -X- _ O
SSL -X- _ O
then -X- _ O
aims -X- _ O
to -X- _ O
use -X- _ O
the -X- _ O
additional -X- _ O
information -X- _ O
about -X- _ O
the -X- _ O
input -X- _ O
distribution -X- _ O
P -X- _ O
X -X- _ O
from -X- _ O
the -X- _ O
unlabeled -X- _ O
dataset -X- _ O
D -X- _ O
U -X- _ O
to -X- _ O
improve -X- _ O
a -X- _ O
model -X- _ O
of -X- _ O
P -X- _ O
Y -X- _ O
|X -X- _ O
learned -X- _ O
on -X- _ O
the -X- _ O
labeled -X- _ O
dataset -X- _ O
D -X- _ O
L -X- _ O
. -X- _ O

As -X- _ O
explained -X- _ O
in -X- _ O
§ -X- _ O
3 -X- _ O
, -X- _ O
SSL -X- _ O
should -X- _ O
only -X- _ O
work -X- _ O
for -X- _ O
anticausal -X- _ O
( -X- _ O
or -X- _ O
confounded -X- _ O
) -X- _ O
learning -X- _ O
tasks -X- _ O
, -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
ICM -X- _ O
principle -X- _ O
. -X- _ O
Schölkopf -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2012 -X- _ O
) -X- _ O
have -X- _ O
observed -X- _ O
this -X- _ O
trend -X- _ O
on -X- _ O
a -X- _ O
number -X- _ O
of -X- _ O
classification -X- _ O
and -X- _ O
regression -X- _ O
tasks -X- _ O
on -X- _ O
small -X- _ O
- -X- _ O
scale -X- _ O
numerical -X- _ O
inputs -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
predicting -X- _ O
Boston -X- _ O
housing -X- _ O
prices -X- _ O
from -X- _ O
quantifiable -X- _ O
neighborhood -X- _ O
features -X- _ O
( -X- _ O
causal -X- _ O
learning -X- _ O
) -X- _ O
, -X- _ O
or -X- _ O
breast -X- _ O
cancer -X- _ O
from -X- _ O
lab -X- _ O
statistics -X- _ O
( -X- _ O
anticausal -X- _ O
learning -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
there -X- _ O
exist -X- _ O
no -X- _ O
studies -X- _ O
investigating -X- _ O
the -X- _ O
implications -X- _ O
of -X- _ O
ICM -X- _ O
for -X- _ O
SSL -X- _ O
on -X- _ O
NLP -X- _ O
data -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
of -X- _ O
a -X- _ O
more -X- _ O
complex -X- _ O
nature -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
high -X- _ O
dimensionality -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
and -X- _ O
output -X- _ O
spaces -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
potentially -X- _ O
large -X- _ O
confounding -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
following -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
sequence -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
sequence -X- _ O
decipherment -X- _ O
experiment -X- _ O
( -X- _ O
§ -X- _ O
5.1 -X- _ O
) -X- _ O
and -X- _ O
a -X- _ O
meta -X- _ O
- -X- _ O
study -X- _ O
of -X- _ O
existing -X- _ O
literature -X- _ O
( -X- _ O
§ -X- _ O
5.2 -X- _ O
) -X- _ O
to -X- _ O
showcase -X- _ O
that -X- _ O
the -X- _ O
same -X- _ O
phenomenon -X- _ O
also -X- _ O
occurs -X- _ O
in -X- _ O
NLP -X- _ O
. -X- _ O

Decipherment -X- _ O
Experiment -X- _ O

To -X- _ O
have -X- _ O
control -X- _ O
over -X- _ O
causal -X- _ O
direction -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
collection -X- _ O
process -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
synthetic -X- _ O
decipherment -X- _ O
dataset -X- _ O
to -X- _ O
test -X- _ O
the -X- _ O
difference -X- _ O
in -X- _ O
SSL -X- _ O
improvement -X- _ O
between -X- _ O
causal -X- _ O
and -X- _ O
anticausal -X- _ O
learning -X- _ O
tasks -X- _ O
. -X- _ O

Dataset -X- _ O
We -X- _ O
create -X- _ O
a -X- _ O
synthetic -X- _ O
dataset -X- _ O
of -X- _ O
encrypted -X- _ O
sequences -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
adopt -X- _ O
a -X- _ O
monolingual -X- _ O
English -X- _ O
corpus -X- _ O
( -X- _ O
for -X- _ O
which -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
English -X- _ O
corpus -X- _ O
of -X- _ O
the -X- _ O
En→Es -X- _ O
in -X- _ O
the -X- _ O
CausalMT -X- _ B-DatasetName
dataset -X- _ O
, -X- _ O
for -X- _ O
convenience -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
ii -X- _ O
) -X- _ O
apply -X- _ O
the -X- _ O
ROT13 -X- _ O
encryption -X- _ O
algorithm -X- _ O
( -X- _ O
Schneier -X- _ O
, -X- _ O
1996 -X- _ O
) -X- _ O
to -X- _ O
obtain -X- _ O
the -X- _ O
encrypted -X- _ O
corpus -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
( -X- _ O
iii -X- _ O
) -X- _ O
apply -X- _ O
noise -X- _ O
on -X- _ O
the -X- _ O
corpus -X- _ O
that -X- _ O
is -X- _ O
chosen -X- _ O
to -X- _ O
be -X- _ O
the -X- _ O
effect -X- _ O
corpus -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
encryption -X- _ O
step -X- _ O
( -X- _ O
ii -X- _ O
) -X- _ O
, -X- _ O
for -X- _ O
each -X- _ O
English -X- _ O
sentence -X- _ O
x -X- _ O
, -X- _ O
its -X- _ O
encryption -X- _ O
ROT13 -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
replaces -X- _ O
each -X- _ O
letter -X- _ O
with -X- _ O
the -X- _ O
13th -X- _ O
letter -X- _ O
after -X- _ O
it -X- _ O
in -X- _ O
the -X- _ O
alphabet -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
" -X- _ O
A -X- _ O
" -X- _ O
→ -X- _ O
" -X- _ O
N -X- _ O
, -X- _ O
" -X- _ O
" -X- _ O
B -X- _ O
" -X- _ O
→ -X- _ O
" -X- _ O
O. -X- _ O
" -X- _ O
Note -X- _ O
that -X- _ O
we -X- _ O
choose -X- _ O
ROT13 -X- _ O
due -X- _ O
to -X- _ O
its -X- _ O
invertibility -X- _ O
, -X- _ O
since -X- _ O
ROT13 -X- _ O
( -X- _ O
ROT13 -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
) -X- _ O
= -X- _ O
x. -X- _ O
Therefore -X- _ O
, -X- _ O
without -X- _ O
any -X- _ O
noises -X- _ O
, -X- _ O
the -X- _ O
corpus -X- _ O
of -X- _ O
English -X- _ O
and -X- _ O
the -X- _ O
corpus -X- _ O
of -X- _ O
encrypted -X- _ O
sequences -X- _ O
by -X- _ O
ROT13 -X- _ O
are -X- _ O
symmetric -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
noising -X- _ O
step -X- _ O
( -X- _ O
iii -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
noise -X- _ O
either -X- _ O
to -X- _ O
the -X- _ O
English -X- _ O
text -X- _ O
or -X- _ O
to -X- _ O
the -X- _ O
ciphertext -X- _ O
, -X- _ O
thus -X- _ O
creating -X- _ O
two -X- _ O
datasets -X- _ O
Cipher→En -X- _ B-DatasetName
, -X- _ O
and -X- _ O
En→Cipher -X- _ B-DatasetName
, -X- _ O
respectively -X- _ O
. -X- _ O
When -X- _ O
applying -X- _ O
noise -X- _ O
to -X- _ O
a -X- _ O
sequence -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
implementation -X- _ O
of -X- _ O
the -X- _ O
Fairseq -X- _ O
library -X- _ O
. -X- _ O
11 -X- _ O
Namely -X- _ O
, -X- _ O
we -X- _ O
mask -X- _ O
some -X- _ O
random -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
sequence -X- _ O
( -X- _ O
word -X- _ O
masking -X- _ O
) -X- _ O
, -X- _ O
permute -X- _ O
a -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
sequence -X- _ O
( -X- _ O
permuted -X- _ O
noise -X- _ O
) -X- _ O
, -X- _ O
randomly -X- _ O
shift -X- _ O
the -X- _ O
endings -X- _ O
of -X- _ O
the -X- _ O
sequence -X- _ O
to -X- _ O
the -X- _ O
beginning -X- _ O
( -X- _ O
rolling -X- _ O
noise -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
insert -X- _ O
some -X- _ O
random -X- _ O
characters -X- _ O
or -X- _ O
masks -X- _ O
to -X- _ O
the -X- _ O
sequence -X- _ O
( -X- _ O
insertion -X- _ O
noise -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
set -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
all -X- _ O
noises -X- _ O
to -X- _ O
p -X- _ O
= -X- _ O
5 -X- _ O
% -X- _ O
. -X- _ O

Results -X- _ O
For -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
datasets -X- _ O
En→Cipher -X- _ B-DatasetName
and -X- _ O
Cipher→En -X- _ B-DatasetName
, -X- _ O
we -X- _ O
perform -X- _ O
SSL -X- _ O
in -X- _ O
the -X- _ O
causal -X- _ O
and -X- _ O
anticausal -X- _ O
direction -X- _ O
by -X- _ O
either -X- _ O
treating -X- _ O
the -X- _ O
input -X- _ O
X -X- _ O
as -X- _ O
the -X- _ O
cause -X- _ O
and -X- _ O
the -X- _ O
target -X- _ O
Y -X- _ O
as -X- _ O
the -X- _ O
effect -X- _ O
, -X- _ O
or -X- _ O
vice -X- _ O
versa -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
standard -X- _ O
Transformer -X- _ O
architecture -X- _ O
for -X- _ O
the -X- _ O
supervised -X- _ O
model -X- _ O
, -X- _ O
and -X- _ O
for -X- _ O
SSL -X- _ O
, -X- _ O
we -X- _ O
multitask -X- _ O
the -X- _ O
translation -X- _ O
task -X- _ O
with -X- _ O
an -X- _ O
additional -X- _ O
denoising -X- _ O
autoencoder -X- _ O
( -X- _ O
Vincent -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
using -X- _ O
the -X- _ O
Fairseq -X- _ O
Python -X- _ O
package -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Tab -X- _ O
. -X- _ O
4 -X- _ O
. -X- _ O
It -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
that -X- _ O
in -X- _ O
both -X- _ O
cases -X- _ O
, -X- _ O
anticausal -X- _ O
models -X- _ O
show -X- _ O
a -X- _ O
substantially -X- _ O
larger -X- _ O
SSL -X- _ O
improvement -X- _ O
than -X- _ O
causal -X- _ O
models -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
note -X- _ O
that -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
substantial -X- _ O
gap -X- _ O
in -X- _ O
the -X- _ O
supervised -X- _ O
performance -X- _ O
between -X- _ O
causal -X- _ O
and -X- _ O
anticausal -X- _ O
learning -X- _ O
tasks -X- _ O
on -X- _ O
the -X- _ O
same -X- _ O
underlying -X- _ O
data -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
also -X- _ O
expected -X- _ O
as -X- _ O
causal -X- _ O
learning -X- _ O
is -X- _ O
typically -X- _ O
easier -X- _ O
than -X- _ O
anticausal -X- _ O
learning -X- _ O
since -X- _ O
it -X- _ O
corresponds -X- _ O
to -X- _ O
learning -X- _ O
the -X- _ O
" -X- _ O
natural -X- _ O
" -X- _ O
forward -X- _ O
function -X- _ O
, -X- _ O
or -X- _ O
causal -X- _ O
mechanism -X- _ O
, -X- _ O
while -X- _ O
anticausal -X- _ O
learning -X- _ O
cor-11 -X- _ O
Link -X- _ O
to -X- _ O
the -X- _ O
Fairseq -X- _ O
implementation -X- _ O
. -X- _ O
responds -X- _ O
to -X- _ O
learning -X- _ O
the -X- _ O
less -X- _ O
natural -X- _ O
, -X- _ O
non -X- _ O
- -X- _ O
causal -X- _ O
inverse -X- _ O
mechanism -X- _ O
. -X- _ O

SSL -X- _ O
Improvements -X- _ O
in -X- _ O
Existing -X- _ O
Work -X- _ O

After -X- _ O
verifying -X- _ O
the -X- _ O
different -X- _ O
behaviour -X- _ O
in -X- _ O
SSL -X- _ O
improvement -X- _ O
predicted -X- _ O
by -X- _ O
the -X- _ O
ICM -X- _ O
principle -X- _ O
on -X- _ O
the -X- _ O
decipherment -X- _ O
experiment -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
an -X- _ O
extensive -X- _ O
meta -X- _ O
- -X- _ O
study -X- _ O
to -X- _ O
survey -X- _ O
whether -X- _ O
this -X- _ O
trend -X- _ O
is -X- _ O
also -X- _ O
reflected -X- _ O
in -X- _ O
published -X- _ O
NLP -X- _ O
findings -X- _ O
. -X- _ O
To -X- _ O
this -X- _ O
end -X- _ O
, -X- _ O
we -X- _ O
consider -X- _ O
a -X- _ O
diverse -X- _ O
set -X- _ O
of -X- _ O
tasks -X- _ O
, -X- _ O
and -X- _ O
SSL -X- _ O
methods -X- _ O
. -X- _ O
The -X- _ O
tasks -X- _ O
covered -X- _ O
in -X- _ O
our -X- _ O
meta -X- _ O
- -X- _ O
study -X- _ O
include -X- _ O
machine -X- _ O
translation -X- _ O
, -X- _ O
summarization -X- _ O
, -X- _ O
parsing -X- _ O
, -X- _ O
tagging -X- _ O
, -X- _ O
information -X- _ O
extraction -X- _ O
, -X- _ O
review -X- _ O
sentiment -X- _ O
classification -X- _ O
, -X- _ O
text -X- _ O
category -X- _ O
classification -X- _ O
, -X- _ O
word -X- _ O
sense -X- _ O
disambiguation -X- _ O
, -X- _ O
and -X- _ O
chunking -X- _ O
. -X- _ O
The -X- _ O
SSL -X- _ O
methods -X- _ O
include -X- _ O
self -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
co -X- _ O
- -X- _ O
training -X- _ O
( -X- _ O
Blum -X- _ O
andMitchell -X- _ O
, -X- _ O
1998 -X- _ O
) -X- _ O
, -X- _ O
tri -X- _ O
- -X- _ O
training -X- _ O
( -X- _ O
Zhou -X- _ O
andLi -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
, -X- _ O
transductive -X- _ O
support -X- _ O
vector -X- _ O
machines -X- _ O
( -X- _ O
Joachims -X- _ O
, -X- _ O
1999 -X- _ O
) -X- _ O
, -X- _ O
expectation -X- _ O
maximization -X- _ O
( -X- _ O
Nigam -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2006 -X- _ O
) -X- _ O
, -X- _ O
multitasking -X- _ O
with -X- _ O
language -X- _ O
modeling -X- _ O
( -X- _ O
Dai -X- _ O
and -X- _ O
Le -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
, -X- _ O
multitasking -X- _ O
with -X- _ O
sentence -X- _ O
reordering -X- _ O
( -X- _ O
as -X- _ O
used -X- _ O
in -X- _ O
Zhang -X- _ O
and -X- _ O
Zong -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
crossview -X- _ O
training -X- _ O
( -X- _ O
Clark -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
Further -X- _ O
details -X- _ O
on -X- _ O
our -X- _ O
meta -X- _ O
study -X- _ O
are -X- _ O
explained -X- _ O
in -X- _ O
Appendix -X- _ O
A -X- _ O
. -X- _ O

We -X- _ O
covered -X- _ O
55 -X- _ O
instances -X- _ O
of -X- _ O
causal -X- _ O
learning -X- _ O
and -X- _ O
50 -X- _ O
instances -X- _ O
of -X- _ O
anticausal -X- _ O
learning -X- _ O
. -X- _ O
A -X- _ O
summary -X- _ O
of -X- _ O
the -X- _ O
trends -X- _ O
of -X- _ O
causal -X- _ O
SSL -X- _ O
and -X- _ O
anticausal -X- _ O
SSL -X- _ O
are -X- _ O
listed -X- _ O
in -X- _ O
Tab -X- _ O
. -X- _ O
5 -X- _ O
. -X- _ O
Echoing -X- _ O
with -X- _ O
the -X- _ O
implications -X- _ O
of -X- _ O
ICM -X- _ O
stated -X- _ O
in -X- _ O
§ -X- _ O
3 -X- _ O
, -X- _ O
for -X- _ O
causal -X- _ O
learning -X- _ O
tasks -X- _ O
, -X- _ O
the -X- _ O
average -X- _ O
improvement -X- _ O
by -X- _ O
SSL -X- _ O
is -X- _ O
only -X- _ O
very -X- _ O
small -X- _ O
, -X- _ O
0.04 -X- _ B-MetricValue
% -X- _ I-MetricValue
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
the -X- _ O
anticausal -X- _ O
SSL -X- _ O
improvement -X- _ O
is -X- _ O
larger -X- _ O
, -X- _ O
1.70 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
average -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
Welch -X- _ O
's -X- _ O
t -X- _ O
- -X- _ O
test -X- _ O
( -X- _ O
Welch -X- _ O
, -X- _ O
1947 -X- _ O
) -X- _ O
to -X- _ O
assess -X- _ O
whether -X- _ O
the -X- _ O
difference -X- _ O
in -X- _ O
mean -X- _ O
between -X- _ O
the -X- _ O
two -X- _ O
distributions -X- _ O
of -X- _ O
SSL -X- _ O
improvment -X- _ O
( -X- _ O
with -X- _ O
unequal -X- _ O
variance -X- _ O
) -X- _ O
is -X- _ O
significant -X- _ O
and -X- _ O
obtain -X- _ O
a -X- _ O
p -X- _ O
- -X- _ O
value -X- _ O
of -X- _ O
0.011 -X- _ B-MetricValue
. -X- _ O

DA -X- _ O
for -X- _ O
Causal -X- _ O
vs. -X- _ O
Anticausal -X- _ O
Models -X- _ O

We -X- _ O
also -X- _ O
consider -X- _ O
a -X- _ O
supervised -X- _ O
domain -X- _ O
adaptation -X- _ O
( -X- _ O
DA -X- _ O
) -X- _ O
setting -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
adapt -X- _ O
a -X- _ O
model -X- _ O
trained -X- _ O
on -X- _ O
a -X- _ O
large -X- _ O
labeled -X- _ O
data -X- _ O
set -X- _ O
from -X- _ O
a -X- _ O
source -X- _ O
domain -X- _ O
, -X- _ O
to -X- _ O
a -X- _ O
potentially -X- _ O
different -X- _ O
target -X- _ O
domain -X- _ O
from -X- _ O
which -X- _ O
we -X- _ O
only -X- _ O
have -X- _ O
a -X- _ O
a -X- _ O
small -X- _ O
labeled -X- _ O
data -X- _ O
set -X- _ O
. -X- _ O
As -X- _ O
explained -X- _ O
in -X- _ O
§ -X- _ O
3 -X- _ O
, -X- _ O
DA -X- _ O
should -X- _ O
only -X- _ O
work -X- _ O
well -X- _ O
for -X- _ O
causal -X- _ O
learning -X- _ O
, -X- _ O
but -X- _ O
not -X- _ O
necessarily -X- _ O
for -X- _ O
anticausal -X- _ O
learning -X- _ O
, -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
ICM -X- _ O
principle -X- _ O
. -X- _ O
Similar -X- _ O
to -X- _ O
the -X- _ O
meta -X- _ O
- -X- _ O
study -X- _ O
on -X- _ O
SSL -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
review -X- _ O
existing -X- _ O
NLP -X- _ O
literature -X- _ O
on -X- _ O
DA -X- _ O
. -X- _ O
We -X- _ O
focus -X- _ O
on -X- _ O
DA -X- _ O
improvement -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
gain -X- _ O
of -X- _ O
using -X- _ O
DA -X- _ O
over -X- _ O
an -X- _ O
unadapted -X- _ O
baseline -X- _ O
that -X- _ O
only -X- _ O
learns -X- _ O
from -X- _ O
the -X- _ O
source -X- _ O
data -X- _ O
and -X- _ O
is -X- _ O
tested -X- _ O
on -X- _ O
the -X- _ O
target -X- _ O
domain -X- _ O
. -X- _ O
Since -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
studies -X- _ O
on -X- _ O
DA -X- _ O
that -X- _ O
we -X- _ O
can -X- _ O
find -X- _ O
is -X- _ O
smaller -X- _ O
than -X- _ O
for -X- _ O
SSL -X- _ O
, -X- _ O
we -X- _ O
cover -X- _ O
22 -X- _ O
instances -X- _ O
of -X- _ O
DA -X- _ O
on -X- _ O
causal -X- _ O
tasks -X- _ O
, -X- _ O
and -X- _ O
11 -X- _ O
instances -X- _ O
of -X- _ O
DA -X- _ O
on -X- _ O
anticausal -X- _ O
tasks -X- _ O
. -X- _ O

The -X- _ O
results -X- _ O
are -X- _ O
summarised -X- _ O
in -X- _ O
Tab -X- _ O
. -X- _ O
6 -X- _ O
. -X- _ O
We -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
observations -X- _ O
again -X- _ O
echo -X- _ O
with -X- _ O
our -X- _ O
expectations -X- _ O
( -X- _ O
according -X- _ O
to -X- _ O
ICM -X- _ O
) -X- _ O
that -X- _ O
DA -X- _ O
should -X- _ O
work -X- _ O
better -X- _ O
for -X- _ O
causal -X- _ O
, -X- _ O
than -X- _ O
for -X- _ O
anticausal -X- _ O
learning -X- _ O
tasks -X- _ O
. -X- _ O
Again -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
Welch -X- _ O
's -X- _ O
t -X- _ O
- -X- _ O
test -X- _ O
( -X- _ O
Welch -X- _ O
, -X- _ O
1947 -X- _ O
) -X- _ O
to -X- _ O
verify -X- _ O
that -X- _ O
the -X- _ O
DA -X- _ O
improvements -X- _ O
of -X- _ O
causal -X- _ O
learning -X- _ O
and -X- _ O
anticausal -X- _ O
learning -X- _ O
are -X- _ O
statistically -X- _ O
different -X- _ O
, -X- _ O
and -X- _ O
obtain -X- _ O
a -X- _ O
p -X- _ O
- -X- _ O
value -X- _ O
of -X- _ O
0.023 -X- _ B-MetricValue
. -X- _ O

How -X- _ O
to -X- _ O
Use -X- _ O
the -X- _ O
Findings -X- _ O
in -X- _ O
this -X- _ O
Study -X- _ O

Data -X- _ O
Collection -X- _ O
Practice -X- _ O
in -X- _ O
NLP -X- _ O
Due -X- _ O
to -X- _ O
the -X- _ O
different -X- _ O
implications -X- _ O
of -X- _ O
causal -X- _ O
and -X- _ O
anticausal -X- _ O
learning -X- _ O
tasks -X- _ O
, -X- _ O
we -X- _ O
strongly -X- _ O
suggest -X- _ O
annotating -X- _ O
the -X- _ O
causal -X- _ O
direction -X- _ O
when -X- _ O
collecting -X- _ O
new -X- _ O
NLP -X- _ O
data -X- _ O
. -X- _ O
One -X- _ O
way -X- _ O
to -X- _ O
do -X- _ O
this -X- _ O
is -X- _ O
to -X- _ O
only -X- _ O
collect -X- _ O
data -X- _ O
from -X- _ O
one -X- _ O
causal -X- _ O
direction -X- _ O
and -X- _ O
to -X- _ O
mention -X- _ O
this -X- _ O
in -X- _ O
the -X- _ O
meta -X- _ O
information -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
summarization -X- _ O
data -X- _ O
collected -X- _ O
from -X- _ O
the -X- _ O
TL -X- _ O
; -X- _ O
DR -X- _ O
of -X- _ O
scientific -X- _ O
papers -X- _ O
SciTldr -X- _ O
( -X- _ O
Cachola -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
should -X- _ O
be -X- _ O
causal -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
TL -X- _ O
; -X- _ O
DR -X- _ O
summaries -X- _ O
on -X- _ O
OpenReview -X- _ O
( -X- _ O
some -X- _ O
from -X- _ O
authors -X- _ O
when -X- _ O
submitting -X- _ O
the -X- _ O
paper -X- _ O
, -X- _ O
others -X- _ O
derived -X- _ O
from -X- _ O
the -X- _ O
beginning -X- _ O
of -X- _ O
peer -X- _ O
reviews -X- _ O
) -X- _ O
were -X- _ O
likely -X- _ O
composed -X- _ O
after -X- _ O
the -X- _ O
original -X- _ O
papers -X- _ O
or -X- _ O
reviews -X- _ O
were -X- _ O
written -X- _ O
. -X- _ O
Alternatively -X- _ O
, -X- _ O
one -X- _ O
may -X- _ O
allow -X- _ O
mixed -X- _ O
corpora -X- _ O
, -X- _ O
but -X- _ O
label -X- _ O
the -X- _ O
causal -X- _ O
direction -X- _ O
for -X- _ O
each -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
pair -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
original -X- _ O
vs. -X- _ O
translated -X- _ O
text -X- _ O
in -X- _ O
a -X- _ O
translation -X- _ O
pair -X- _ O
. -X- _ O
Since -X- _ O
more -X- _ O
data -X- _ O
often -X- _ O
leads -X- _ O
to -X- _ O
better -X- _ O
model -X- _ O
performance -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
common -X- _ O
to -X- _ O
mix -X- _ O
data -X- _ O
from -X- _ O
both -X- _ O
causal -X- _ O
directions -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
training -X- _ O
on -X- _ O
both -X- _ O
En→Es -X- _ O
and -X- _ O
Es→En -X- _ O
data -X- _ O
. -X- _ O
Annotating -X- _ O
the -X- _ O
causal -X- _ O
direction -X- _ O
for -X- _ O
each -X- _ O
pair -X- _ O
allows -X- _ O
future -X- _ O
users -X- _ O
of -X- _ O
the -X- _ O
dataset -X- _ O
to -X- _ O
potentially -X- _ O
handle -X- _ O
the -X- _ O
causal -X- _ O
and -X- _ O
anticausal -X- _ O
parts -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
differently -X- _ O
. -X- _ O

Causality -X- _ O
- -X- _ O
Aware -X- _ O
Modeling -X- _ O
When -X- _ O
building -X- _ O
NLP -X- _ O
models -X- _ O
, -X- _ O
the -X- _ O
causal -X- _ O
direction -X- _ O
provides -X- _ O
additional -X- _ O
information -X- _ O
that -X- _ O
can -X- _ O
potentially -X- _ O
be -X- _ O
built -X- _ O
into -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
MT -X- _ O
case -X- _ O
, -X- _ O
since -X- _ O
causal -X- _ O
and -X- _ O
anticausal -X- _ O
learning -X- _ O
can -X- _ O
lead -X- _ O
to -X- _ O
different -X- _ O
performance -X- _ O
( -X- _ O
Ni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
one -X- _ O
way -X- _ O
to -X- _ O
take -X- _ O
advantage -X- _ O
of -X- _ O
the -X- _ O
known -X- _ O
causal -X- _ O
direction -X- _ O
is -X- _ O
to -X- _ O
add -X- _ O
a -X- _ O
prefix -X- _ O
such -X- _ O
as -X- _ O
" -X- _ O
[ -X- _ O
Modeling -X- _ O
- -X- _ O
Effect -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
Cause -X- _ O
] -X- _ O
" -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
input -X- _ O
, -X- _ O
so -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
can -X- _ O
learn -X- _ O
from -X- _ O
causally -X- _ O
- -X- _ O
annotated -X- _ O
input -X- _ O
- -X- _ O
output -X- _ O
pairs -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
Riley -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
use -X- _ O
labels -X- _ O
of -X- _ O
the -X- _ O
causal -X- _ O
direction -X- _ O
to -X- _ O
elicit -X- _ O
different -X- _ O
behavior -X- _ O
at -X- _ O
inference -X- _ O
time -X- _ O
. -X- _ O
Another -X- _ O
option -X- _ O
is -X- _ O
to -X- _ O
carefully -X- _ O
design -X- _ O
a -X- _ O
combination -X- _ O
of -X- _ O
different -X- _ O
modeling -X- _ O
techniques -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
limiting -X- _ O
self -X- _ O
- -X- _ O
training -X- _ O
( -X- _ O
a -X- _ O
method -X- _ O
for -X- _ O
SSL -X- _ O
) -X- _ O
only -X- _ O
to -X- _ O
the -X- _ O
anticausal -X- _ O
direction -X- _ O
and -X- _ O
allowing -X- _ O
back -X- _ O
- -X- _ O
translation -X- _ O
in -X- _ O
both -X- _ O
directions -X- _ O
, -X- _ O
as -X- _ O
preliminarily -X- _ O
explored -X- _ O
by -X- _ O
Shen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

Causal -X- _ O
Discovery -X- _ O
Suppose -X- _ O
that -X- _ O
we -X- _ O
are -X- _ O
given -X- _ O
measurements -X- _ O
of -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
NLP -X- _ O
data -X- _ O
X -X- _ O
and -X- _ O
Y -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
text -X- _ O
, -X- _ O
parse -X- _ O
tree -X- _ O
, -X- _ O
intent -X- _ O
type -X- _ O
) -X- _ O
whose -X- _ O
collection -X- _ O
process -X- _ O
is -X- _ O
unknown -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
cause -X- _ O
and -X- _ O
which -X- _ O
the -X- _ O
effect -X- _ O
. -X- _ O
One -X- _ O
key -X- _ O
finding -X- _ O
of -X- _ O
our -X- _ O
study -X- _ O
is -X- _ O
that -X- _ O
there -X- _ O
is -X- _ O
typically -X- _ O
a -X- _ O
causal -X- _ O
footprint -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
collection -X- _ O
process -X- _ O
which -X- _ O
manifests -X- _ O
itself -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
when -X- _ O
computing -X- _ O
the -X- _ O
description -X- _ O
length -X- _ O
in -X- _ O
different -X- _ O
directions -X- _ O
( -X- _ O
§ -X- _ O
4 -X- _ O
) -X- _ O
or -X- _ O
when -X- _ O
performing -X- _ O
SSL -X- _ O
( -X- _ O
§ -X- _ O
5 -X- _ O
) -X- _ O
or -X- _ O
DA -X- _ O
( -X- _ O
§ -X- _ O
6 -X- _ O
) -X- _ O
. -X- _ O
Based -X- _ O
on -X- _ O
which -X- _ O
direction -X- _ O
has -X- _ O
the -X- _ O
shorter -X- _ O
MDL -X- _ B-MetricName
, -X- _ O
or -X- _ O
allows -X- _ O
better -X- _ O
SSL -X- _ O
or -X- _ O
DA -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
thus -X- _ O
infer -X- _ O
one -X- _ O
causal -X- _ O
direction -X- _ O
over -X- _ O
the -X- _ O
other -X- _ O
. -X- _ O

Prediction -X- _ O
of -X- _ O
SSL -X- _ O
and -X- _ O
DA -X- _ O
Effectiveness -X- _ O
Being -X- _ O
able -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
SSL -X- _ O
or -X- _ O
DA -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
NLP -X- _ O
task -X- _ O
can -X- _ O
be -X- _ O
very -X- _ O
useful -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
to -X- _ O
set -X- _ O
the -X- _ O
weights -X- _ O
in -X- _ O
an -X- _ O
ensemble -X- _ O
of -X- _ O
different -X- _ O
models -X- _ O
( -X- _ O
Søgaard -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
. -X- _ O
While -X- _ O
predicting -X- _ O
SSL -X- _ O
performance -X- _ O
has -X- _ O
previously -X- _ O
been -X- _ O
studied -X- _ O
from -X- _ O
a -X- _ O
non -X- _ O
- -X- _ O
causal -X- _ O
perspective -X- _ O
( -X- _ O
Nigam -X- _ O
and -X- _ O
Ghani -X- _ O
, -X- _ O
2000 -X- _ O
; -X- _ O
Asch -X- _ O
and -X- _ O
Daelemans -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
our -X- _ O
findings -X- _ O
suggest -X- _ O
that -X- _ O
a -X- _ O
simple -X- _ O
qualitative -X- _ O
description -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
collection -X- _ O
process -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
its -X- _ O
causal -X- _ O
direction -X- _ O
( -X- _ O
as -X- _ O
summarised -X- _ O
for -X- _ O
the -X- _ O
most -X- _ O
common -X- _ O
NLP -X- _ O
tasks -X- _ O
in -X- _ O
Tab -X- _ O
. -X- _ O
1 -X- _ O
) -X- _ O
can -X- _ O
also -X- _ O
be -X- _ O
surprisingly -X- _ O
effective -X- _ O
to -X- _ O
evaluate -X- _ O
whether -X- _ O
SSL -X- _ O
or -X- _ O
DA -X- _ O
should -X- _ O
be -X- _ O
expected -X- _ O
to -X- _ O
work -X- _ O
well -X- _ O
. -X- _ O

Limitations -X- _ O
and -X- _ O
Future -X- _ O
Work -X- _ O

We -X- _ O
note -X- _ O
that -X- _ O
ICM -X- _ O
- -X- _ O
when -X- _ O
taken -X- _ O
strictly -X- _ O
- -X- _ O
is -X- _ O
an -X- _ O
idealized -X- _ O
assumption -X- _ O
that -X- _ O
may -X- _ O
be -X- _ O
violated -X- _ O
and -X- _ O
thus -X- _ O
may -X- _ O
not -X- _ O
hold -X- _ O
exactly -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
data -X- _ O
set -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
due -X- _ O
to -X- _ O
confounding -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
when -X- _ O
both -X- _ O
variables -X- _ O
are -X- _ O
influenced -X- _ O
by -X- _ O
a -X- _ O
third -X- _ O
, -X- _ O
unobserved -X- _ O
variable -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
case -X- _ O
, -X- _ O
one -X- _ O
may -X- _ O
observe -X- _ O
less -X- _ O
of -X- _ O
a -X- _ O
difference -X- _ O
between -X- _ O
causal -X- _ O
and -X- _ O
anticausal -X- _ O
learning -X- _ O
tasks -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
note -X- _ O
that -X- _ O
, -X- _ O
while -X- _ O
we -X- _ O
have -X- _ O
made -X- _ O
an -X- _ O
effort -X- _ O
to -X- _ O
classify -X- _ O
different -X- _ O
NLP -X- _ O
tasks -X- _ O
as -X- _ O
typically -X- _ O
causal -X- _ O
or -X- _ O
anticausal -X- _ O
, -X- _ O
our -X- _ O
categorization -X- _ O
should -X- _ O
not -X- _ O
be -X- _ O
ap -X- _ O
- -X- _ O
plied -X- _ O
blindly -X- _ O
without -X- _ O
regard -X- _ O
for -X- _ O
the -X- _ O
specific -X- _ O
generative -X- _ O
process -X- _ O
at -X- _ O
hand -X- _ O
: -X- _ O
deviations -X- _ O
are -X- _ O
possible -X- _ O
as -X- _ O
explained -X- _ O
in -X- _ O
the -X- _ O
Mixed -X- _ O
/ -X- _ O
Other -X- _ O
category -X- _ O
. -X- _ O

Another -X- _ O
limitation -X- _ O
is -X- _ O
that -X- _ O
the -X- _ O
SSL -X- _ O
and -X- _ O
DA -X- _ O
settings -X- _ O
considered -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
are -X- _ O
only -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
the -X- _ O
various -X- _ O
settings -X- _ O
that -X- _ O
exist -X- _ O
in -X- _ O
NLP -X- _ O
. -X- _ O
Our -X- _ O
study -X- _ O
does -X- _ O
not -X- _ O
cover -X- _ O
, -X- _ O
for -X- _ O
example -X- _ O
, -X- _ O
SSL -X- _ O
that -X- _ O
uses -X- _ O
additional -X- _ O
output -X- _ O
data -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
Jean -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2015 -X- _ O
) -X- _ O
; -X- _ O
Gülçehre -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2015 -X- _ O
) -X- _ O
; -X- _ O
Sennrich -X- _ O
and -X- _ O
Zhang -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
or -X- _ O
unsupervised -X- _ O
DA -X- _ O
( -X- _ O
as -X- _ O
reviewed -X- _ O
by -X- _ O
Ramponi -X- _ O
and -X- _ O
Plank -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
in -X- _ O
our -X- _ O
meta -X- _ O
- -X- _ O
study -X- _ O
of -X- _ O
published -X- _ O
SSL -X- _ O
and -X- _ O
DA -X- _ O
findings -X- _ O
, -X- _ O
the -X- _ O
improvements -X- _ O
of -X- _ O
causal -X- _ O
vs. -X- _ O
anticausal -X- _ O
learning -X- _ O
might -X- _ O
be -X- _ O
amplified -X- _ O
by -X- _ O
the -X- _ O
scale -X- _ O
of -X- _ O
research -X- _ O
efforts -X- _ O
on -X- _ O
different -X- _ O
tasks -X- _ O
and -X- _ O
potentially -X- _ O
suffer -X- _ O
from -X- _ O
selection -X- _ O
bias -X- _ O
. -X- _ O

Finally -X- _ O
, -X- _ O
we -X- _ O
remark -X- _ O
that -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
present -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
focused -X- _ O
on -X- _ O
bivariate -X- _ O
prediction -X- _ O
tasks -X- _ O
with -X- _ O
an -X- _ O
input -X- _ O
X -X- _ O
and -X- _ O
output -X- _ O
Y -X- _ O
. -X- _ O
Future -X- _ O
work -X- _ O
may -X- _ O
also -X- _ O
apply -X- _ O
ICM -X- _ O
- -X- _ O
based -X- _ O
reasoning -X- _ O
to -X- _ O
more -X- _ O
complex -X- _ O
NLP -X- _ O
settings -X- _ O
, -X- _ O
for -X- _ O
example -X- _ O
, -X- _ O
by -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
incorporating -X- _ O
additional -X- _ O
( -X- _ O
sequential -X- _ O
/ -X- _ O
temporal -X- _ O
) -X- _ O
structure -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
for -X- _ O
MT -X- _ O
or -X- _ O
language -X- _ O
modeling -X- _ O
) -X- _ O
or -X- _ O
( -X- _ O
ii -X- _ O
) -X- _ O
considering -X- _ O
settings -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
input -X- _ O
X -X- _ O
consists -X- _ O
of -X- _ O
both -X- _ O
cause -X- _ O
X -X- _ O
CAU -X- _ O
and -X- _ O
effect -X- _ O
X -X- _ O
EFF -X- _ O
features -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
Y -X- _ O
( -X- _ O
von -X- _ O
Kügelgen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019Kügelgen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
, -X- _ O
2020 -X- _ O
. -X- _ O

Related -X- _ O
Work -X- _ O

NLP -X- _ O
and -X- _ O
Causality -X- _ O
Existing -X- _ O
work -X- _ O
on -X- _ O
NLP -X- _ O
and -X- _ O
causality -X- _ O
mainly -X- _ O
focuses -X- _ O
on -X- _ O
the -X- _ O
extracting -X- _ O
text -X- _ O
features -X- _ O
for -X- _ O
causal -X- _ O
inference -X- _ O
. -X- _ O
Researchers -X- _ O
first -X- _ O
propose -X- _ O
a -X- _ O
causal -X- _ O
graph -X- _ O
based -X- _ O
on -X- _ O
domain -X- _ O
knowledge -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
use -X- _ O
text -X- _ O
features -X- _ O
to -X- _ O
represent -X- _ O
some -X- _ O
elements -X- _ O
in -X- _ O
the -X- _ O
causal -X- _ O
graph -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
the -X- _ O
cause -X- _ O
( -X- _ O
Egami -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
effect -X- _ O
Grimmer -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
andconfounders -X- _ O
( -X- _ O
Roberts -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Veitch -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Keith -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Another -X- _ O
line -X- _ O
of -X- _ O
work -X- _ O
mines -X- _ O
causal -X- _ O
relations -X- _ O
among -X- _ O
events -X- _ O
from -X- _ O
textual -X- _ O
expressions -X- _ O
, -X- _ O
and -X- _ O
uses -X- _ O
them -X- _ O
to -X- _ O
perform -X- _ O
relation -X- _ O
extraction -X- _ O
( -X- _ O
Do -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011 -X- _ O
; -X- _ O
Mirza -X- _ O
and -X- _ O
Tonelli -X- _ O
, -X- _ O
2014 -X- _ O
; -X- _ O
Dunietz -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Hosseini -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
question -X- _ O
answering -X- _ O
( -X- _ O
Oh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
or -X- _ O
commonsense -X- _ O
reasoning -X- _ O
Bosselut -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
a -X- _ O
recent -X- _ O
survey -X- _ O
, -X- _ O
we -X- _ O
refer -X- _ O
to -X- _ O
Feder -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

Usage -X- _ O
of -X- _ O
MDL -X- _ B-MetricName
in -X- _ O
NLP -X- _ O
Although -X- _ O
MDL -X- _ B-MetricName
has -X- _ O
been -X- _ O
used -X- _ O
for -X- _ O
causal -X- _ O
discovery -X- _ O
for -X- _ O
low -X- _ O
- -X- _ O
dimensional -X- _ O
data -X- _ O
( -X- _ O
Budhathoki -X- _ O
and -X- _ O
Vreeken -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Mian -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
, -X- _ O
only -X- _ O
very -X- _ O
few -X- _ O
studies -X- _ O
adopt -X- _ O
MDL -X- _ B-MetricName
on -X- _ O
high -X- _ O
- -X- _ O
dimensional -X- _ O
NLP -X- _ O
data -X- _ O
. -X- _ O
Most -X- _ O
existing -X- _ O
uses -X- _ O
of -X- _ O
MDL -X- _ B-MetricName
on -X- _ O
NLP -X- _ O
are -X- _ O
for -X- _ O
probing -X- _ O
and -X- _ O
interpretability -X- _ O
: -X- _ O
e.g. -X- _ O
, -X- _ O
Voita -X- _ O
and -X- _ O
Titov -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
use -X- _ O
it -X- _ O
for -X- _ O
probing -X- _ O
of -X- _ O
a -X- _ O
small -X- _ O
Bayesian -X- _ O
model -X- _ O
and -X- _ O
network -X- _ O
pruning -X- _ O
, -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
method -X- _ O
proposed -X- _ O
by -X- _ O
Blier -X- _ O
and -X- _ O
Ollivier -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
to -X- _ O
calculate -X- _ O
MDL -X- _ B-MetricName
for -X- _ O
deep -X- _ O
learning -X- _ O
. -X- _ O
We -X- _ O
are -X- _ O
not -X- _ O
aware -X- _ O
of -X- _ O
existing -X- _ O
work -X- _ O
using -X- _ O
MDL -X- _ B-MetricName
for -X- _ O
causal -X- _ O
discovery -X- _ O
, -X- _ O
or -X- _ O
to -X- _ O
verify -X- _ O
causal -X- _ O
concepts -X- _ O
such -X- _ O
as -X- _ O
ICM -X- _ O
in -X- _ O
the -X- _ O
context -X- _ O
of -X- _ O
NLP -X- _ O
. -X- _ O

Existing -X- _ O
Discussions -X- _ O
on -X- _ O
SSL -X- _ O
and -X- _ O
DA -X- _ O
in -X- _ O
NLP -X- _ O
SSL -X- _ O
and -X- _ O
DA -X- _ O
has -X- _ O
long -X- _ O
been -X- _ O
used -X- _ O
in -X- _ O
NLP -X- _ O
, -X- _ O
as -X- _ O
reviewed -X- _ O
by -X- _ O
Søgaard -X- _ O
( -X- _ O
2013 -X- _ O
) -X- _ O
and -X- _ O
Ramponi -X- _ O
and -X- _ O
Plank -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
there -X- _ O
have -X- _ O
been -X- _ O
a -X- _ O
number -X- _ O
of -X- _ O
studies -X- _ O
that -X- _ O
report -X- _ O
negative -X- _ O
results -X- _ O
for -X- _ O
SSL -X- _ O
Steedman -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2003 -X- _ O
; -X- _ O
Reichart -X- _ O
and -X- _ O
Rappoport -X- _ O
, -X- _ O
2007 -X- _ O
; -X- _ O
Abney -X- _ O
, -X- _ O
2007 -X- _ O
; -X- _ O
Spreyer -X- _ O
and -X- _ O
Kuhn -X- _ O
, -X- _ O
2009 -X- _ O
; -X- _ O
Søgaard -X- _ O
and -X- _ O
Rishøj -X- _ O
, -X- _ O
2010 -X- _ O
) -X- _ O
and -X- _ O
DA -X- _ O
( -X- _ O
Plank -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O
Our -X- _ O
works -X- _ O
constitutes -X- _ O
the -X- _ O
first -X- _ O
explanation -X- _ O
of -X- _ O
the -X- _ O
ineffectiveness -X- _ O
of -X- _ O
SSL -X- _ O
and -X- _ O
DA -X- _ O
on -X- _ O
certain -X- _ O
NLP -X- _ O
tasks -X- _ O
from -X- _ O
the -X- _ O
perspective -X- _ O
of -X- _ O
causal -X- _ O
and -X- _ O
anticausal -X- _ O
learning -X- _ O
. -X- _ O

Conclusion -X- _ O

This -X- _ O
work -X- _ O
presents -X- _ O
the -X- _ O
first -X- _ O
effort -X- _ O
to -X- _ O
use -X- _ O
causal -X- _ O
concepts -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
ICM -X- _ O
principle -X- _ O
and -X- _ O
the -X- _ O
distinction -X- _ O
between -X- _ O
causal -X- _ O
and -X- _ O
anticausal -X- _ O
learning -X- _ O
to -X- _ O
shed -X- _ O
light -X- _ O
on -X- _ O
some -X- _ O
commonly -X- _ O
observed -X- _ O
trends -X- _ O
in -X- _ O
NLP -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
provide -X- _ O
an -X- _ O
explanation -X- _ O
of -X- _ O
observed -X- _ O
differences -X- _ O
in -X- _ O
SSL -X- _ O
( -X- _ O
Tabs -X- _ O
. -X- _ O
4 -X- _ O
and -X- _ O
5 -X- _ O
) -X- _ O
and -X- _ O
DA -X- _ O
( -X- _ O
Tab -X- _ O
. -X- _ O
6 -X- _ O
) -X- _ O
performance -X- _ O
on -X- _ O
a -X- _ O
number -X- _ O
of -X- _ O
NLP -X- _ O
tasks -X- _ O
: -X- _ O
DA -X- _ O
tends -X- _ O
to -X- _ O
work -X- _ O
better -X- _ O
for -X- _ O
causal -X- _ O
learning -X- _ O
tasks -X- _ O
, -X- _ O
whereas -X- _ O
SSL -X- _ O
typically -X- _ O
only -X- _ O
works -X- _ O
for -X- _ O
anticausal -X- _ O
learning -X- _ O
tasks -X- _ O
, -X- _ O
as -X- _ O
predicted -X- _ O
by -X- _ O
the -X- _ O
ICM -X- _ O
principle -X- _ O
. -X- _ O
These -X- _ O
insights -X- _ O
, -X- _ O
together -X- _ O
with -X- _ O
our -X- _ O
categorization -X- _ O
of -X- _ O
common -X- _ O
NLP -X- _ O
tasks -X- _ O
( -X- _ O
Tab -X- _ O
. -X- _ O
1 -X- _ O
) -X- _ O
into -X- _ O
causal -X- _ O
and -X- _ O
anticausal -X- _ O
learning -X- _ O
, -X- _ O
may -X- _ O
prove -X- _ O
useful -X- _ O
for -X- _ O
future -X- _ O
NLP -X- _ O
efforts -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
we -X- _ O
empirically -X- _ O
confirm -X- _ O
using -X- _ O
MDL -X- _ B-MetricName
that -X- _ O
the -X- _ O
description -X- _ O
of -X- _ O
data -X- _ O
is -X- _ O
typically -X- _ O
shorter -X- _ O
in -X- _ O
the -X- _ O
causal -X- _ O
than -X- _ O
in -X- _ O
the -X- _ O
anticausal -X- _ O
direction -X- _ O
( -X- _ O
Tab -X- _ O
. -X- _ O
3 -X- _ O
) -X- _ O
, -X- _ O
suggesting -X- _ O
that -X- _ O
a -X- _ O
causal -X- _ O
footprint -X- _ O
can -X- _ O
also -X- _ O
be -X- _ O
observed -X- _ O
for -X- _ O
text -X- _ O
data -X- _ O
. -X- _ O
This -X- _ O
has -X- _ O
interesting -X- _ O
potential -X- _ O
implications -X- _ O
for -X- _ O
discovering -X- _ O
causal -X- _ O
relations -X- _ O
between -X- _ O
different -X- _ O
types -X- _ O
of -X- _ O
NLP -X- _ O
data -X- _ O
. -X- _ O

Ethical -X- _ O
Considerations -X- _ O

Use -X- _ O
of -X- _ O
Data -X- _ O
This -X- _ O
paper -X- _ O
uses -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
data -X- _ O
, -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
existing -X- _ O
machine -X- _ O
translation -X- _ O
dataset -X- _ O
, -X- _ O
and -X- _ O
synthetic -X- _ O
decipherment -X- _ O
data -X- _ O
. -X- _ O
As -X- _ O
far -X- _ O
as -X- _ O
we -X- _ O
are -X- _ O
concerned -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
no -X- _ O
sensitive -X- _ O
issues -X- _ O
such -X- _ O
as -X- _ O
privacy -X- _ O
regarding -X- _ O
the -X- _ O
data -X- _ O
usage -X- _ O
. -X- _ O

Potential -X- _ O
Stakeholders -X- _ O
This -X- _ O
research -X- _ O
focuses -X- _ O
on -X- _ O
meta -X- _ O
properties -X- _ O
of -X- _ O
two -X- _ O
commonly -X- _ O
applied -X- _ O
methodologies -X- _ O
, -X- _ O
SSL -X- _ O
and -X- _ O
DA -X- _ O
in -X- _ O
NLP -X- _ O
. -X- _ O
Although -X- _ O
this -X- _ O
research -X- _ O
is -X- _ O
not -X- _ O
directly -X- _ O
connected -X- _ O
to -X- _ O
specific -X- _ O
applications -X- _ O
in -X- _ O
society -X- _ O
, -X- _ O
the -X- _ O
usage -X- _ O
of -X- _ O
this -X- _ O
study -X- _ O
can -X- _ O
benefit -X- _ O
future -X- _ O
research -X- _ O
in -X- _ O
SSL -X- _ O
and -X- _ O
DA -X- _ O
. -X- _ O

Acknowledgements -X- _ O

We -X- _ O
thank -X- _ O
Simon -X- _ O
Buchholz -X- _ O
for -X- _ O
helpful -X- _ O
discussions -X- _ O
, -X- _ O
Nasim -X- _ O
Rahaman -X- _ O
, -X- _ O
Shehzaad -X- _ O
Dhuliawala -X- _ O
, -X- _ O
Yifan -X- _ O
Hou -X- _ O
, -X- _ O
Tiago -X- _ O
Pimentel -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
anonymous -X- _ O
reviewers -X- _ O
for -X- _ O
feedback -X- _ O
on -X- _ O
the -X- _ O
manuscript -X- _ O
, -X- _ O
and -X- _ O
Di -X- _ O
Jin -X- _ O
for -X- _ O
helping -X- _ O
with -X- _ O
computational -X- _ O
resources -X- _ O
. -X- _ O
This -X- _ O
work -X- _ O
was -X- _ O
supported -X- _ O
by -X- _ O
the -X- _ O
German -X- _ O
Federal -X- _ O
Ministry -X- _ O
of -X- _ O
Education -X- _ O
and -X- _ O
Research -X- _ O
( -X- _ O
BMBF -X- _ O
) -X- _ O
: -X- _ O
Tübingen -X- _ O
AI -X- _ O
Center -X- _ O
, -X- _ O
FKZ -X- _ O
: -X- _ O
01IS18039B -X- _ O
, -X- _ O
and -X- _ O
by -X- _ O
the -X- _ O
Machine -X- _ O
Learning -X- _ O
Cluster -X- _ O
of -X- _ O
Excellence -X- _ O
, -X- _ O
EXC -X- _ O
number -X- _ O
2064 -X- _ O
/ -X- _ O
1 -X- _ O
-Project -X- _ O
number -X- _ O
390727645 -X- _ O
. -X- _ O

A -X- _ O
Meta -X- _ O
Study -X- _ O
Settings -X- _ O
of -X- _ O
SSL -X- _ O
and -X- _ O
DA -X- _ O

For -X- _ O
the -X- _ O
meta -X- _ O
study -X- _ O
of -X- _ O
SSL -X- _ O
, -X- _ O
we -X- _ O
covered -X- _ O
but -X- _ O
are -X- _ O
not -X- _ O
limited -X- _ O
to -X- _ O
all -X- _ O
relevant -X- _ O
papers -X- _ O
cited -X- _ O
by -X- _ O
the -X- _ O
review -X- _ O
on -X- _ O
NLP -X- _ O
SSL -X- _ O
by -X- _ O
Søgaard -X- _ O
( -X- _ O
2013 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
went -X- _ O
through -X- _ O
the -X- _ O
leaderboard -X- _ O
of -X- _ O
many -X- _ O
NLP -X- _ O
tasks -X- _ O
and -X- _ O
covered -X- _ O
the -X- _ O
SSL -X- _ O
papers -X- _ O
listed -X- _ O
on -X- _ O
the -X- _ O
leaderboards -X- _ O
. -X- _ O
The -X- _ O
papers -X- _ O
covered -X- _ O
by -X- _ O
our -X- _ O
meta -X- _ O
study -X- _ O
are -X- _ O
available -X- _ O
on -X- _ O
our -X- _ O
GitHub -X- _ O
. -X- _ O

For -X- _ O
supervised -X- _ O
DA -X- _ O
, -X- _ O
we -X- _ O
searched -X- _ O
papers -X- _ O
with -X- _ O
the -X- _ O
keyword -X- _ O
domain -X- _ O
adaptation -X- _ O
and -X- _ O
task -X- _ O
names -X- _ O
from -X- _ O
a -X- _ O
wide -X- _ O
range -X- _ O
of -X- _ O
tasks -X- _ O
that -X- _ O
use -X- _ O
supervised -X- _ O
DA -X- _ O
. -X- _ O

Note -X- _ O
that -X- _ O
for -X- _ O
fair -X- _ O
comparison -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
consider -X- _ O
papers -X- _ O
without -X- _ O
a -X- _ O
comparable -X- _ O
supervised -X- _ O
baseline -X- _ O
corresponding -X- _ O
to -X- _ O
the -X- _ O
SSL -X- _ O
, -X- _ O
or -X- _ O
a -X- _ O
comparable -X- _ O
unadapted -X- _ O
baseline -X- _ O
corresponding -X- _ O
to -X- _ O
the -X- _ O
DA -X- _ O
. -X- _ O
We -X- _ O
do -X- _ O
not -X- _ O
consider -X- _ O
MT -X- _ O
DA -X- _ O
which -X- _ O
tackles -X- _ O
the -X- _ O
out -X- _ O
- -X- _ O
ofvocabulary -X- _ O
( -X- _ O
OOV -X- _ O
) -X- _ O
problem -X- _ O
because -X- _ O
P -X- _ O
( -X- _ O
E|C -X- _ O
) -X- _ O
may -X- _ O
be -X- _ O
different -X- _ O
for -X- _ O
OOV -X- _ O
( -X- _ O
Habash -X- _ O
, -X- _ O
2008 -X- _ O
; -X- _ O
III -X- _ O
and -X- _ O
Jagarlamudi -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
. -X- _ O

B -X- _ O
Experimental -X- _ O
Details -X- _ O
of -X- _ O
Minimum -X- _ B-MetricName
Description -X- _ I-MetricName
Length -X- _ I-MetricName

We -X- _ O
calculate -X- _ O
the -X- _ O
MDL -X- _ B-MetricName
( -X- _ O
X -X- _ O
) -X- _ O
and -X- _ O
MDL -X- _ B-MetricName
( -X- _ O
Y -X- _ O
) -X- _ O
by -X- _ O
a -X- _ O
language -X- _ O
model -X- _ O
, -X- _ O
and -X- _ O
obtain -X- _ O
MDL -X- _ B-MetricName
( -X- _ O
X|Y -X- _ O
) -X- _ O
and -X- _ O
MDL -X- _ B-MetricName
( -X- _ O
Y|X -X- _ O
) -X- _ O
using -X- _ O
translation -X- _ O
models -X- _ O
. -X- _ O
For -X- _ O
language -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
autoregressive -X- _ O
GPT2 -X- _ B-MethodName
( -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
for -X- _ O
the -X- _ O
translation -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
the -X- _ O
Marian -X- _ B-MethodName
Neural -X- _ O
Machine -X- _ O
Translation -X- _ O
model -X- _ O
( -X- _ O
Junczys -X- _ O
- -X- _ O
Dowmunt -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
OPUS -X- _ O
Corpus -X- _ O
( -X- _ O
Tiedemann -X- _ O
and -X- _ O
Nygaard -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
. -X- _ O
Both -X- _ O
these -X- _ O
models -X- _ O
use -X- _ O
the -X- _ O
layers -X- _ O
from -X- _ O
the -X- _ O
transformer -X- _ O
model -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
autoregressive -X- _ O
language -X- _ O
model -X- _ O
consists -X- _ O
only -X- _ O
of -X- _ O
decoder -X- _ O
layers -X- _ O
, -X- _ O
whereas -X- _ O
the -X- _ O
translation -X- _ O
model -X- _ O
used -X- _ O
six -X- _ O
encoder -X- _ O
and -X- _ O
six -X- _ O
decoder -X- _ O
layers -X- _ B-HyperparameterName
. -X- _ O
Both -X- _ O
of -X- _ O
these -X- _ O
models -X- _ O
have -X- _ O
roughly -X- _ O
the -X- _ O
same -X- _ O
number -X- _ O
of -X- _ O
parameters -X- _ O
. -X- _ O
We -X- _ O
used -X- _ O
the -X- _ O
huggingface -X- _ O
implementation -X- _ O
( -X- _ O
Wolf -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
of -X- _ O
these -X- _ O
models -X- _ O
for -X- _ O
their -X- _ O
respective -X- _ O
set -X- _ O
of -X- _ O
languages -X- _ O
. -X- _ O

