Are Representations Built from the Ground Up ? An Empirical Examination of Local Composition in Language Models
Compositionality , the phenomenon where the meaning of a phrase can be derived from its constituent parts , is a hallmark of human language . At the same time , many phrases are non - compositional , carrying a meaning beyond that of each part in isolation . Representing both of these types of phrases is critical for language understanding , but it is an open question whether modern language models ( LMs ) learn to do so ; in this work we examine this question . We first formulate a problem of predicting the LM - internal representations of longer phrases given those of their constituents . We find that the representation of a parent phrase can be predicted with some accuracy given an affine transformation of its children . While we would expect the predictive accuracy to correlate with human judgments of semantic compositionality , we find this is largely not the case , indicating that LMs may not accurately distinguish between compositional and non - compositional phrases . We perform a variety of analyses , shedding light on when different varieties of LMs do and do not generate compositional representations , and discuss implications for future modeling work . 1   
Introduction
Compositionality is argued to be a hallmark of linguistic generalization ( Szabó , 2020 ) . However , some phrases are non - compositional , and can not be reconstructed from individual constituents ( Dankers et al . , 2022a ) . Intuitively , a phrase like " I own cats and dogs " is locally compositional , whereas " It 's raining cats and dogs " is not . Therefore , any representation of language must be easily composable , but it must also correctly handle cases that deviate from compositional rules .
Both lack ( Hupkes et al . , 2020;Lake and Baroni , 2017 ) and excess ( Dankers et al . , 2022b ) of compositionality have been cited as common sources of 1 Code and data available at https://github.com/ nightingal3 / lm - compositionality   errors in NLP models , indicating that models may handle phrase composition in an unexpected way .
In general form , the compositionality principle is simply " the meaning of an expression is a function of the meanings of its parts and of the way they are syntactically combined " ( Pelletier , 1994 ) . However , this definition is underspecified ( Partee , 1984 ) . Recent efforts to evaluate the compositional abilities of neural networks have resulted in several testable definitions of compositionality ( Hupkes et al . , 2020 ) .
Previous work on compositionality in natural language focuses largely on the definition of substitutivity , by focusing on changes to the constituents of a complex phrase and how they change its representation ( Dankers et al . , 2022a;Garcia et al . , 2021;Yu and Ettinger , 2020 ) . The definition we examine is localism : whether or not the representation of a complex phrase is derivable only from its local structure and the representations of its immediate " children " ( Hupkes et al . , 2020 ) . A similar concept has been proposed separately to measure the compositionality of learned representations , which we use in this work ( Andreas , 2019 ) . We focus on localism because it is a more direct definition and does not rely on the collection of contrastive pairs of phrases . This allows us to examine a wider range of phrases of different types and lengths .
In this paper , we ask whether reasonable compo - sitional probes can predict an LM 's representation of a phrase from its children in a syntax tree , and if so , which kinds of phrase are more or less compositional . We also ask whether this corresponds to human judgements of compositionality .
We first establish a method to examine local compositionality on phrases through probes that try to predict the representation of a parent given its children ( section 2 ) . We create two Englishlanguage datasets upon which to experiment : a large - scale dataset of 823 K phrases mined from the Penn Treebank , and a new dataset of idioms and paired non - idiomatic phrases for which we elicit human compositionality judgements , which we call the Compositionality of Human - annotated Idiomatic Phrases dataset ( CHIP ) ( section 3 ) .
For multiple models and phrase types , we find that phrase embeddings across models and representation types have a fairly predictable affine compositional structure based on embeddings of their constituents ( section 4 ) . We find that there are significant differences in compositionality across phrase types , and analyze these trends in detail , contributing to understanding how LMs represent phrases ( section 5 ) . Interestingly , we find that human judgments do not generally align well with the compositionality level of model representations ( section 6 ) . This implies there is still work to be done at the language modelling level to capture a proper level of compositionality in representations .
Methods and Experimental Details
Tree Reconstruction Error
We follow Andreas ( 2019 ) in defining deviance from compositionality as tree reconstruction error . Consider a phrase x = [ a ] [ b ] , where a and b can be any length > 0 . Assume we always have some way of knowing how x should be divided into a and b. Assume we also have some way of producing representations for x , a , and b , which we represent as a function r. Given representations r(x ) , r(a ) and r(b ) , we wish to find the function which most closely approximates how r(x ) is constructed from r(a ) and r(b ) .
f = arg min f ∈F 1 |X | x∈X δ x , ab(1 )
δ x , ab = d(r(x ) , f ( r(a ) , r(b ) ) ( 2 )
Where X is the set of possible phrases in the language that can be decomposed into two parts , F is the set of functions under consideration , and d is a distance function . An example scenario is depicted in Figure 1 .
For d , we use cosine distance as this is the most common function used to compare semantic vectors . The division of x into a and b is specified by syntactic structure ( Chomsky , 1959 ) . Namely , we use a phrase 's annotated constituency structure and convert its constituency tree to a binary tree with the right - factored Chomsky Normal Form conversion included in NLTK ( Bird and Loper , 2004 ) .
Language Models
We study representations produced by a variety of widely used language models , specifically the base-(uncased ) variants of Transformer - based models : BERT , RoBERTa , DeBERTa , and GPT-2 ( He et al . , 2021;Liu et al . , 2019;Devlin et al . , 2019;Radford et al . , 2019 ) .
Representation extraction
Let [ x 0 , ... , x N ] be a sequence of N + 1 input tokens , where x 0 is the [ CLS ] token if applicable , and
x N is the end token if applicable . Let [ h ( i ) 0 , ... , h ( i ) N ]
be the embeddings of the input tokens after the i - th layer .
For models with the [ CLS ] beginning of sequence token ( BERT , RoBERTa , and DeBERTa ) , we extracted the embedding of the [ CLS ] token from the last layer , which we refer to as the CLS representation . For GPT-2 , we extracted the last token , which serves a similar purpose . This corresponds to h ( 12 ) 0 and h ( 12 ) N respectively . Alternately , we also averaged all embeddings from the last layer , including special tokens . We refer to this as the AVG representation .
1 N + 1 N +1 i=0 h ( 12 ) i ( 3 )
Approximating a Composition Function
To use this definition , we need a composition functionf . We examine choices detailed in this section .
For parameterized probes , we follow the probing literature in training several probes to predict a property of the phrase given a representation of the phrase . However , in this case , we are not predicting a categorical attribute such as part of speech . Instead , the probes that we use aim to predict the parent representation r(x ) based on the child representations r(a ) and r(b ) . We call this an approximative probe to distinguish it from the usual use of the word probe .
Arithmetic Probes
In the simplest probes , the phrase representation r(x ) is computed by a single arithmetic operation on r(a ) and r(b ) . We consider three arithmetic probes : 2 ADD(r(a ) , r(b ) ) = r(a ) + r(b )
( 4 ) W1(r(a ) , r(b ) ) = r(a )
( 5 ) W2(r(a ) , r(b ) = r(b )
( 6 )
Learned Probes
We consider three types of learned probes . The linear probe expresses r(x ) as a linear combination of r(a ) and r(b ) . The affine probe adds a bias term . The MLP probe is a simple feedforward neural network with 3 layers , using the ReLU activation .
LIN(r(a ) , r(b ) ) = α 1 r(a ) + α 2 r(b ) ( 7 ) AFF(r(a ) , r(b ) ) = α 1 r(a ) + α 2 r(b ) + β ( 8) MLP(r(a ) , r(b ) ) = W 3 h 2 ( 9 )
Where
h 1 = σ(W 1 [ r(a ) ; r(b ) ] ) h 2 = σ(W 2 h 1 ) ,
W 1 is ( 300 × 2 ) , W 2 is ( 768 × 300 ) , and W 3 is ( 1 × 768 ) . We do not claim that this is the best MLP possible , but use it as a simple architecture to contrast with the linear models .
3 Data and Compositionality Judgments
Treebank
To collect a large set of phrases with syntactic structure annotations , we collected all unique subphrases ( ≥ 2 words ) from WSJ and Brown sections of the Penn Treebank ( v3 ) ( Marcus et al . , 1993 ) . 3 The final dataset consists of 823 K phrases after excluding null values and duplicates . We collected the length of the left child in words , the length of the right child in words , and the tree 's production rule , which we refer to as tree type . There were 50260 tree types in total , but many of these are unique . Examples and phrase length distribution can be found in Appendix A , and Appendix B.
English Idioms and Matched Phrase Set
Previous datasets center around notable bigrams , some of which are compositional and some of which are non - compositional ( Ramisch et al . , 2016b;Reddy et al . , 2011 ) . However , there is a positive correlation between bigram frequency and human compositionality scores in these datasets , which means that it is unclear whether models are capturing compositionality or merely frequency effects if they correlate well with the human scores .
Because models are likely more sensitive to surface features of language than humans , we gathered a more controlled set of phrases to compare with human judgments .
Since non - compositional phrases are somewhat rare , we began with a set of seed idioms and bigrams from previous studies ( Jhamtani et al . , 2021;Ramisch et al . , 2016b;Reddy et al . , 2011 ) . We used idioms because they are a common source of noncompositional phrases . Duplicates after lemmatization were removed .
For each idiom , we used Google Syntactic NGrams to find three phrases with an identical part of speech and dependency structure to that idiom , and frequency that was as close as possible relative to others in Syntactic Ngrams ( Goldberg and Orwant , 2013 ) . 4 For example , the idiom " sail under false colors " was matched with " distribute among poor parishioners " . More examples can be found in Table 1 . An author of this paper inspected the idioms and removed those that were syntactically analyzed incorrectly or offensive .
Approximating a Composition Function 4.1 Methods
To approximate the composition functions of models , we extract the CLS and AVG representations from each model on the Treebank dataset . We used 10 - fold cross - validation and trained the learned probes on the 90 % training set in each fold . The   Note that the frequency is based on the most common dependency and constituency pattern found in Syntactic NGrams . Humans were asked to rate each phrase for its compositionality .
remaining 10 % were divided into a test set ( 5 % ) and dev set ( 5 % ) . 5 To fairly compare probes , we used minimum description length probing ( Voita and Titov , 2020).This approximates the length of the online code needed to transmit both the model and data , which is related to the area under the learning curve . Specifically , we recorded average cosine similarity of the predicted vector and actual vector on the test set while varying the size of the training set from 0.005 % to 100 % of the original . 6 We compare the AUC of each probe under these conditions to select the most parsimonious approximation for each model .
Results
We find that affine probes are best able to capture the composition of phrase embeddings from their left and right subphrases . A depiction of probe performance at approximating representations across models and representation types is in Figure 2 . However , we note that scores for most models are very high , due to the anisotropy phenomenon . This describes the tendency for most embeddings from pretrained language models to be clustered in a narrow cone , rather than distributed evenly in all directions ( Li et al . , 2020;Ethayarajh , 2019 ) . We note that it is true for both word and phrase embeddings .
Since we are comparing the probes to each other relative to the same anisotropic vectors , this is not necessarily a problem . However , in order to com - pare each probe 's performance compared to chance , we correct for anisotropy using a control task . This task is using the trained probe to predict a random phrase embedding from the set of treebank phrase embeddings for that model , and recording the distance between the compositional probe 's prediction and the random embedding . This allows us to calculate an error ratio dist probe dist control , where dist probe represents the original average distance from the true representation , and dist control is the average distance on the control task . This quantifies how much the probe improves over a random baseline that takes anisotropy into account , where a smaller value is better . These results can be found in Appendix E. The results without anisotropy correction can be found in Appendix G. In most cases , the affine probe still performs the best , so we continue to use it for consistency on all the model and representation types .
We also compare the AUC of training curves for each probe and find that the affine probe remains the best in most cases , except RoBERTa CLS and DeBERTa CLS . Training curves are depicted in Appendix C. AUC values are listed in Appendix H. Interestingly , there was a trend of the right child being weighted more heavily than the left child , and each model / representation type combination had its own characteristic ratio of the left child to the right child . For instance , in BERT , the weight on the left child was 12 , whereas it was 20 for the right child .
For example , the approximation for the phrase " green eggs and ham " with BERT [ CLS ] embeddings would be : r CLS ( " green eggs and ham " ) = 12r CLS ( " green eggs " ) + 20r CLS ( " and ham " ) + β . 5 Examining Compositionality across Phrase Types
Methods
Intuitively , we expect the phrases whose representations are close to their predicted representation to be more compositional . We call similarity to the expected representation , sim(r(x),f ( r(a ) , r(b ) ) ) , the compositionality score of a phrase . We record the mean reconstruction error for each tree type and report the results . In addition to comparing tree types to each other , we also examine the treatment of named entities in subsubsection 5.2.1 . We examine the relationship between length of a phrase in words and its compositionality score in subsubsection 5.2.2 .
Results
There is a significant difference between the mean compositionality score of phrase types . Particularly , the AVG representation assigns a lower compositionality score to NP → NNP NNP phrases , which is expected since this phrase type often corresponds to named entities . By contrast , the CLS representation assigns a low compositionality score to NP → DT NN , which is unexpected given that such phrases are generally seen as compositional . The reconstruction error for the most common phrase types is shown in Figure 5 .
Because different phrase types may be treated differently by the model , we examine the relative compositionality of phrases within each phrase type . Examples of the most and least compositional phrases from several phrase types are shown in Table 2 for RoBERTa CLS . Patterns vary for model and representation types , but long phrases are generally represented more compositionally .
Named Entities
We used SpaCy to tag and examine named entities ( Honnibal and Montani , 2017 ) , as they are expected to be less compositional . We find that named entities indeed have a lower compositionality score in all cases except RoBERTa CLS , indicating that they are correctly represented as less compositional . A representative example is shown in Figure 3 . Full results can be found in Appendix J. We break down the compositionality scores of named entities by type and find surprising variation within categories of named entities . For numerical examples , this often depends on the unit used . For example , in RoBERTa AVG representations , numbers with " million " and " billion " are grouped together as compositional , whereas numbers with quantifiers ( " about " , " more than " , " some " ) are grouped together as not compositional . The compositionality score distributions for types of named entities are presented in Figure 4 .
Examining Compositionality and Phrase Length
There is no consistent relationship between phrase length and compositionality score across models and representation types . However , CLS and AVG representations show divergent trends . There is a strong positive correlation between phrase length and compositionality score in the AVG representations , while no consistent trend exists for the CLS representations . This indicates that longer phrases are better approximated as an affine transformation of their subphrase representations . This trend is summarized in Appendix D. All correlations are highly significant .
Phrase type
Most compositional
Least compositional PP → IN NP ( " of " , " two perilous day spent among the planters of Attakapas , . . . ) ( " of " , " September " ) ( " of " , " the cloth bandoleers that marked the upper part of his body . . . ) ( " like " , " the Standard & Poor 's 500 " ) S → NP - SBJ VP ( " him " , " to suggest it 's the difference between the ' breakup ' value . . . ) ( " other things " , " being more equal " ) ( " it " , " was doing a brisk business in computer power - surge protectors . . . " ) ( " less " , " is more " ) NP → NNP NNP ( " M. " , " Bluthenzweig " ) ( " Edward " , " Thompson " ) ( " Dr. " , " Volgelstein " ) ( " Alexander " , " Hamilton " )   6 Comparing Compositionality Judgments of Humans and Models 6.1 Methods
Human Annotation
Human annotators assigned labels to each phrase in the matched dataset from subsection 3.2 : 1 for not compositional , 2 for somewhat compositional , and 3 for fully compositional . They could also decline to answer if they felt that the phrase did n't make sense on its own . Furthermore , they were asked how much each subphrase ( left and right ) contributed to the final meaning , from 1 for not at all , to 3 for a great deal . The Likert scale of 1 - 3 was chosen based on analysis of previous compositionality annotation tasks , which found that extreme values of compositionality were the most reliable ( Ramisch et al . , 2016a ) . Initially , six English - speaking graduate students were recruited . The six initial annotators all annotated the first 101 examples and the subset of three annotators with the highest agreement who agreed to continue ( Krippendorff α = 0.5750 ) were recruited for the full study , annotating 1001 examples . For the full study , the agreement was higher ( α = 0.6633 ) . We took the mean of compositionality judgments to be the final score for phrases . The instructions shown to annotators are in Appendix F. Examples judgments from an annotator can be found in Table 3 .    3 : Example judgments of one annotator on the pilot set . Annotators were asked to rate each phrase from 1 to 3 , where 1 meant not compositional and 3 meant fully compositional . They were also asked how much each subphrase contributed to the meaning .
Model Comparison
To compare human judgments to model compositionality scores , we use the best trained approxi - mative probe for each model and representation type to predict a vector for the full phrase based on its left and right subphrases ( taking the probe trained on the first fold ) . We use cosine similarity to the expected representation as the measure of how compositional a phrase is for a model and representation type .
We take the Spearman correlation between model compositionality scores and human compositionality judgments and observe differences between human judgments and compositionality scores from model representations .
Results
Correlation with human judgments
There is a weak correlation between model and human compositionality scores . The most promising trend is found in RoBERTa , where both CLS and AVG representations have a significant positive correlation with human judgments . Results are in Table 4 , with corrected p - values ( Holm , 1979
Subphrase Contribution Test
Annotators indicated to what extent they believed each part of the phrase contributed to the final meaning . We examined examples in which annotators rated one part of the phrase , for example a , as contributing more to the final meaning , and checked how often d cos ( r(x ) , r(a ) ) > d cos ( r(x ) , r(b ) ) . Models do surprisingly poorly at this test , with most performing below chance . Results are presented in Table 5 . An error analysis on RoBERTa AVG indicated that in many cases , errors were due to idiomaticity failures . For example , " noble gas " is a type of gas that was rated as being more similar to " gas " by humans , but " noble " by RoBERTa . 7
7 Similar errors were made for phrases such as " grandfather clock " , " as right as rain " , " ballpark estimate " . A " grandfather  
Idiomaticity Test
Because idioms were matched with non - idiomatic expressions , we tested for correctly identifying the idioms . We limited the analysis to pairs where the idiomatic expression was rated as less compositional than the matched expression . Results are shown in Table 5 . Results are better than the subphrase contribution test , but models do not achieve good results , the best performing representation being RoBERTa CLS .
Correlations with Other Factors
We examine correlations of model and human compositionality scores with the frequency and length of the phrase in words . As noted before , there is a strong correlation between length and compositionality score in models but not in human results . Results are in Appendix K. A comparison of phrases rated as most and least compositional by humans , as well as RoBERTa , is presented in Table 6 .
7 Related work
Background on Compositionality
Compositionality has been debated in the philosophy of language , with opposing views ( Herbelot , 2020 ): the bottom - up view that the meaning of a larger phrase is a function of the meaning of its parts ( Cresswell , 1973 ) , and the top - down view clock " is a type of clock , " as right as rain " indicates that something is alright , and a " ballpark estimate " is a rough estimate .
Model & representation
Most compositional
Least compositional Human " population growth " " gravy train " " few weeks away " " shrinking violet " " railroad monopoly "
" revolving door syndrome "
RoBERTaCLS " two small sticks " " worse than none " " dark glass bottle " " cases apart " " annual music festival " " arch'd eyebrow "
RoBERTaAVG " look with open eyes " " advertisement revenue " " be of equal importance "
" taking it upon oneself " " come after breakfast " " all paces " that smaller parts only have meaning as a function of the larger phrase ( Fodor and LePore , 1992 ) . It is likely that there is a blend of bottom - up and top - down processing corresponding to compositional and non - compositional phrases respectively ( Dankers et al . , 2022a ) . Hupkes et al . have proposed several compositionality tests based on previous interpretations : ( Hupkes et al . , 2020 ) . We focus on localism , corresponding to the bottom - up view .
Other Definitions of Compositionality
Other works do other tests for compositionality , notably substitutivity ( Hupkes et al . , 2020 ) . Evidence suggests that models may be unable to modulate the bottom - up and top - down processing of phrases ( Dankers et al . , 2022b , a ) . Substitutivity effects appear to not be represented well ( Garcia et al . , 2021;Yu and Ettinger , 2020 ) . This indicates that phrases are not being composed as expected and motivates our study of how local composition is carried out in these models , and which types of phrase are processed top - down and bottom - up .
Studies of Localism
Previous studies of local composition focus on bigrams , particularly adjective - noun and noun - noun bigrams ( Nandakumar et al . , 2019;Cordeiro et al . , 2019;Salehi et al . , 2015;Reddy et al . , 2011;Mitchell and Lapata , 2010 ) . However , many of these studies assume an additive composition function or only fit a composition function on the bi - grams in their datasets .
A study finds some evidence for successful local composition in the case of mathematical expressions , but used a constrained test set on a domain that is expected to be perfectly locally compositional ( Russin et al . , 2021 ) .
Approximating LM Representations
There has been recent interest in understanding the compositionality of continuous representations generated by neural models ( Smolensky et al . , 2022 ) . LM representations have been approximated as the output of explicitly compositional networks based on tensor products ( McCoy et al . , , 2019Soulos et al . , 2020 ) . These are typically evaluated based on compositional domains , such as the SCAN dataset ( Lake and Baroni , 2017 ) .
Previous work on the geometry of word embeddings within a sentence shows that language models can encode hierarchical structure ( Coenen et al . , 2019;Manning et al . , 2020;Jawahar et al . , 2019 ) . However , it is an open question as to why LMs do not tend to generalize well compositionally ( Lake and Baroni , 2017;Keysers et al . , 2020 ) .
Conclusion
We analyze the compositionality of representations from several language models and find that there is an effective affine approximation in terms of a phrase 's syntactic children for many phrases . Although LM representations may be surprisingly predictable , we find that human compositionality judgments do not align well with how LM representations are structured .
In this work , we study the representations produced after extensive training . However , the consistency of several trends we observed suggests that there may be theoretical reasons why LM representations are structured in certain ways . Future work could investigate the evolution of compositionality through training , or motivate methods that would allow LMs to achieve improved compositional generalization while representing non - compositionality .
Limitations
One limitation of this work is that it was conducted on a relatively small set of language models trained on English , and the diversity of patterns within even this set of language models and representation types is great . However , we note that the experiments can be easily repeated for any language that has a treebank or good - quality syntactic parsers . A related limitation is that these analyses are dependent on what we take to be the " child " constituents of a parent phrase . It may be harder to examine compositionality for languages that differ substantially from English , or that can not be easily parsed using existing tools .
Although we try to carefully catalog behaviour observed on natural language phrases , it is likely that smaller - scale experiments providing a more mechanistic understanding of model behaviour would be easier to parse for readers . Although this would be ideal , we leave this for future work , as our main goal was to examine how language models represent phrases considered to be compositional and non - compositional in natural language .
Another limitation is that although we diagnose a problem in language models , we do not provide a clear avenue to fix it . Further work could be done to understand what data distributions or training methods encourage model representations to be more aligned with human judgments . Additionally , although compositionality is linguistically important , more effort could be put towards understanding the downstream tasks for which it is more important . For instance , there could be clear issues in machine translation if non - compositional phrases are not represented properly , but these phrases may not be important in other areas such as instruction following or code generation .
Ethics Statement Potential Risks and Impacts
Although we aim to document compositionality effects in English , we acknowledge that this perpetuates the problem of English being the dominant language in NLP research . It is possible that conclusions here do not hold for other languages , and further work is needed to understand whether these conclusions transfer .
Additionally , although we tried to filter out offensive idioms from CHIP , this was based on one person 's best judgment , and it is possible that some of the terms in the dataset may be offensive to some people . Overall , phrases in the dataset tend to be benign , but some idioms are meant to have a perjorative meaning .
Computational Infrastructure and Computing Budget
To run our computational experiments , we made use of a shared compute cluster . We used approximately 100 GPU hours to run experiments , mainly due to running results for different language models and representation types . We did not have any computational budget besides that already used to maintain the cluster .
A Treebank dataset tree types
Due to space constraints , we only show the top 20 tree types . This can be found in Table 7 .
B Treebank dataset phrase lengths
Figure 6 : Length distribution of phrases mined from the treebank , in number of words . The modal length was 3 words , followed closely by 2 words . Few phrases contained more than 50 words .
C Probe learning curves
Learning curves of the approximative probes ( across 10 folds ) are shown in Figure 7 .
D Length Correlation
The correlations of the phrase length ( in words ) and compositionality scores in Treebank are shown in Table 8 .     
E Error ratio of probes
F Annotation setup and instructions
Annotators were recruited from a population of graduate students . Initially , 6 annotators completed the pilot experiment , which consisted of 101 examples . The subset of three annotators with highest agreement was asked if they would like to complete the full study . One annotator in the highestagreement group could not continue to the full study , so this annotator was excluded , and the next group with highest agreement was chosen . The agreement values in subsubsection 6.1.1 are for the final group of annotators chosen .
The experiment was implemented on the Qualtrics platform , and participants were first presented with a consent form , linking to more background information on the study , and informing them that their participation was entirely voluntary . After agreeing to the terms , participants were shown some examples and went through 3 practice questions . The example given are shown in Figure 8 , and the annotation interface is shown in Figure 9
G Compositionality scores without anisotropy correction
The raw compositionality scores can be found in Table 10 .  
I Mean deviation of phrase types by tree type
The mean deviation of the most common tree types can be found in Figure 11 .
J Further named entity results
Named entity results can be found in Figure 12 and Figure 13 .  
Acknowledgments
Thank you to Amanda Bertsch , Ting - Rui Chiang , Varun Gangal , Perez Ogayo , and Zora Wang for participating in compositionality annotations . This work was supported in part by a CMU Presidential Fellowship to the first author , and the Tang Family AI Innovation Fund .
