Zero - Shot Cross - lingual Semantic Parsing
Recent work in cross - lingual semantic parsing has successfully applied machine translation to localize parsers to new languages . However , these advances assume access to highquality machine translation systems and word alignment tools . We remove these assumptions and study cross - lingual semantic parsing as a zero - shot problem , without parallel data ( i.e. , utterance - logical form pairs ) for new languages . We propose a multi - task encoderdecoder model to transfer parsing knowledge to additional languages using only Englishlogical form paired data and in - domain natural language corpora in each new language . Our model encourages language - agnostic encodings by jointly optimizing for logical - form generation with auxiliary objectives designed for cross - lingual latent representation alignment . Our parser performs significantly above translation - based baselines and , in some cases , competes with the supervised upper - bound . 1   
Introduction
Executable semantic parsing maps a natural language utterance to a logical form ( LF ) for execution in some knowledge base to return a denotation . The parsing task renders an utterance as a semantically identical , but machine - interpretable , expression grounded in a denotation . The transduction between natural and formal languages has allowed semantic parsers to become critical infrastructure in building human - computer interfaces for question answering , ( Berant et al . , 2013;Liang , 2016;Kollar et al . , 2018 ) , dialog systems ( Artzi and Zettlemoyer , 2011 ) , and robotics ( Dukes , 2014 ) .
Recent advances in semantic parsing have improved accuracy for neural parsers ( Jia and Liang , 2016;Dong and Lapata , 2016;Wang et al . , 2020a ) and examined their generalization capabilities with new dataset challenges ( Zhong et al . , 2017;Yu 1 Our code and data are available at github.com/tomsherborne/zx-parse . The encoder generates a representation of the English utterance ( blue points ) to condition upon during decoding . Producing the same logical form from the equivalent Chinese utterance requires a similar encoding . However , without alignment , the representation may partially match ( purple points ) or not at all ( red points ) , leading the decoder to generate an inaccurate , ill - formed query . et al . , 2018 ) , in addition to considering languages other than English ( Duong et al . , 2017;inter alia . ) .
Prior work largely assumes that utterance - logical form training data is parallel in all languages ( Jie and Lu , 2014 ) , or must be created with human translation ( Susanto and Lu , 2017a ) . This entry barrier to localization for new languages has motivated the exploration of machine translation ( MT ) as an economical alternative ( Sherborne et al . , 2020;Moradshahi et al . , 2020 ) . However , MT can introduce performance - limiting artifacts and struggle to accurately model native speakers ( Riley et al . , 2020 ) . Additionally , high - quality machine translation is less viable for lower resource languages , further limiting the appeal of MT - based approaches .
In this work , we propose a new approach for zero - shot executable semantic parsing . Our method maximizes the success of cross - lingual transfer for a parser , trained on English paired data ( EN → LF ) , to accurately generate logical forms from new languages ( X → LF ) . Our goal is to parse utterances in a new language , l , without observing paired training data for this language , suitable machine translation , or bilingual dictionaries between l and English . Our critical dependencies are a pre - trained language model and utterancelogical form paired data for a source language ( i.e. , English ) . Aside from the zero - shot problem which is hard on its own ( since paired data is not available for new languages ) , our semantic parsing challenge is further compounded with the difficulties inherent to structured prediction and the deficiency of copying strategies without gold tokenlevel alignment ( Zhu et al . , 2020 ) .
We conceptualize cross - lingual semantic parsing as a latent representation alignment problem . As illustrated in Figure 1 , we wish to encode different languages to an overlapping latent space for the decoder to have any chance at generating accurate logical forms . To achieve this , we train a decoder , conditioned upon encodings from a source language ( e.g. , English ) , to generate logical forms and simultaneously train encodings of a new language ( e.g. , Chinese ) to be maximally similar to English . We hypothesize that if latent representations are aligned from a language - agnostic encoder , one can generate accurate logical forms from a new language without semantic parsing training data and thus eliminate the errors outlined in Figure 1 .
Our approach adopts a multi - task learning paradigm and trains a parser with auxiliary objectives , optimized to converge representations of additional new languages . We encourage languageagnostic representations by jointly optimizing for generating logical forms , reconstructing natural language , and promoting language invariance . Our intuition is that auxiliary losses can be exploited to induce similarity in a multi - lingual latent space . The effect of such alignment is that a decoder , trained only on English , can recognize an encoding from another language and generate the relevant logical form . Similar multi - task approaches have been successful in spoken - language understanding ( van der Goot et al . , 2021 ) , text simplification ( Mallinson et al . , 2020;Zhao et al . , 2020b ) , dependency parsing ( Ahmad et al . , 2019b ) , and machine translation ( Arivazhagan et al . , 2019 ) . This work , to our knowledge is the first attempt to devise auxiliary objectives for executable semantic parsing as a zero - shot task . Our framework and hypothesis are also sufficiently flexible for application in additional zero - shot sequence transduction tasks .
Our motivation is to improve parsing for non - English languages with maximal resource efficiency and minimal external dependencies beyond native - speaker utterances . We , therefore , induce a shared multilingual space without resorting to machine translation ( Sherborne et al . , 2020;Moradshahi et al . , 2020 ) and argue that our approach is superior because it ( a ) nullifies the introduction of translation or word alignment errors and ( b ) scales to low - resource languages without reliable MT . Experimental results on Overnight ( Wang et al . , 2015;Sherborne et al . , 2020 ) and a new executable version of MultiATIS++ show that our parser generates more accurate logical forms with a minimized cross - lingual transfer penalty from English to French ( FR ) , Portuguese ( PT ) , Spanish ( ES ) , German ( DE ) , Chinese ( ZH ) , Hindi ( HI ) , and Turkish ( TR ) .
Related Work
Cross - lingual Modeling This area has recently gained increased interest across several natural language understanding settings ( Zhao et al . , 2020a;Nooralahzadeh et al . , 2020 ) with benchmarks such as XGLUE ( Liang et al . , 2020 ) and XTREME ( Hu et al . , 2020 ) allowing to study classification and generation tasks for multiple languages . Crosslingual approaches have also been developed for dependency parsing ( Tiedemann et al . , 2014;Schuster et al . , 2019 ) , sentence simplification ( Mallinson et al . , 2020 ) , and spoken - language understanding ( SLU ; He et al . , 2013;Upadhyay et al . , 2018 ) .
Pre - training has shown to be widely beneficial for a wide range of cross - lingual models Conneau et al . , 2020a ) . By virtue of being trained on massive corpora , these models purportedly learn an overlapping cross - lingual latent space ( Conneau et al . , 2020b ) but have also been identified as under - trained for some tasks ( Li et al . , 2021 ) , shown poor zero - shot performance , especially for languages dissimilar to English ( Pires et al . , 2019 ) , and high variance ( Keung et al . , 2020 ) .
Semantic Parsing Most previous work ( Lu , 2014;Susanto and Lu , 2017b , a ) has focused on multilingual semantic parsing , i.e. , learning from multiple natural languages in parallel , largely affirming the benefit of " high - resource " multilingual data and multi - language ensemble training ( Jie and Lu , 2014 ) . Shao et al . ( 2020 ) further improved cross - lingual similarity with adversarial language identification across such ensembled training data . Code - switching in multilingual parsing has also been explored through mixed - language training datasets ( Duong et al . , 2017;Einolghozati et al . , 2021 ) . To adapt a parser to new languages , machine translation has been used as a reasonable proxy for in - language data ( Sherborne et al . , 2020;Moradshahi et al . , 2020 ) . However , machine translation , in either direction can introduce limiting artifacts ( Artetxe et al . , 2020 ) with poor generalization due to how " translationese " training data diverges from gold test utterances ( Riley et al . , 2020 ) .
Zero - shot parsing has primarily focused on ' cross - domain ' challenges to improve generalization across varying query structures and lexicons ( Herzig and Berant , 2018;Givoli and Reichart , 2019 ) or different databases ( Zhong et al . , 2020;Suhr et al . , 2020;Yu et al . , 2018 ) . The combination of zero - shot parsing with cross - lingual modeling has also been examined for the UCCA formalism ( Hershcovich et al . , 2019 ) and for task - oriented dialogue systems ( see below ) .
Dialog Modeling Cross - lingual transfer has been studied in the context of goal - oriented dialog for the spoken language understanding ( SLU ) tasks of intent classification and slot labeling ( i.e. , parsing an utterance into a semantic frame identifying the user 's intent and its arguments ) . Recently released multilingual datasets like MultiATIS++   and MTOP ( Li et al . , 2021 ) have facilitated the study of zero - shot transfer through the combination of pre - training , machine translation , and word alignment ( to project annotations between languages ) . Recent work in this setting ( Zhu et al . , 2020;Li et al . , 2021;Krishnan et al . , 2021;Nicosia et al . , 2021 ) identifies a penalty for cross - lingual transfer that neither pre - training nor machine translation can fully overcome .
Problem Formulation
The primary challenge for cross - lingual parsing is learning parameters that can parse an utterance , x , from an unseen test language to an accurate logical form ( LF ) . Typically , a parser trained on language l , or multiple languages { l 1 , . . . , l N } , is only capable for these languages and performs poorly outside this set . For a new language , prior approaches require parallel datasets and models ( Jie and Lu , 2014;Haas and Riezler , 2016;Duong et al . , 2017 ) .
In our work , zero - shot parsing refers to parsing utterances in new languages without paired data during training , For some language , l , there exists no pairing of x l to a logical form , y , except for English . 2 This setting also excludes " silver - standard " training pairs created using machine - translation . As these models have ultimately observed some form of utterance - logical form pairs for each new language , we do not consider such approaches here and refer to Sherborne et al . ( 2020 ) as an example of using MT for this task .
It might be tempting to approach this problem as a case of fine - tuning a pre - trained ( English ) decoder for LF generation . Problematically , the output target is expressed in a formally defined language ( e.g. , SQL or λ−DCS ) which models the semantics of questions very differently to natural language ( e.g. , without presumption or co - operation ; Kaplan 1978 ) . Formal languages ( Kamp and Reyle , 1993 ) additionally present artifacts which render fine - tuning challenging such as unfamiliar syntax ( e.g. , table aliases or explicit recursion ) and long output sequences . In practice , we observed finetuning leads to poor performance ( e.g. , < 1 % accuracy on all languages ) , with the model insisting on hallucinating natural language . This is seemingly at odds with adjacent work in dialog modeling , which has found pre - trained decoders to be beneficial ( Li et al . , 2021 ) . However , SLU requires learning a lightweight label vocabulary compared to the 200 + tokens required in LFs . Additionally , SLU typically maintains output sequences of similar size to natural language inputs ( with tightly coupled syntactic compositionality between the two ) , whereas the syntactic and structural demands of LF generation are largely divorced from the input utterance .
In our solution , the model is trained to parse from utterance - logical forms pairs only in English . Other languages are incorporated using auxiliary objectives and data detailed in Section 4 . We explore the hypothesis that an overlapping multi - lingual latent space can be learned through auxiliary objectives in tandem with logical form generation ( see Figure 2 ) . Our intuition is that introducing these additional losses minimizes cross - lingual variance in latent encoding space by optimizing for language - agnostic representations with high similarity to the source language ( i.e. , English ) . Our approach minimizes the cross - lingual transfer penalty such that the zeroshot parser predicts logical forms from test inputs regardless of utterance language . By framing the cross - lingual parsing task as a latent representation alignment challenge , we explore a possible upper bound of parsing accuracy without errors from external dependencies . Section 6 demonstrates that our zero - shot model , using only English paired data and a small additional corpus , can generate accurate logical forms above translation baselines to compete with fully supervised in - language training .
Our Zero - shot Model : ZX - PARSE
We adopt a multi - task sequence - to - sequence model ( Luong et al . , 2016 ) which combines logical form generation with two auxiliary objectives . The first is a language identification discriminator and the second is a reconstruction or translation decoder . An overview of our semantic parser is given in Figure 2 ; we describe each component below .
Generating Logical Forms Predicting logical forms is the primary objective for our model . Given an utterance x = ( x 1 , x 2 , . . . , x T ) , we wish to generate logical form y = ( y 1 , y 2 , . . . , y M ) representing the same meaning in a machine - executable language . We model this transduction task using an encoder - decoder neural network ( Sutskever et al . , 2014 ) based upon the Transformer architecture ( Vaswani et al . , 2017 ) .
The sequence x is encoded to a latent representation z = ( z 1 , z 2 , . . . , z T ) through Equation ( 1 ) using a stacked self - attention Transformer encoder , E , with weights θ E .
z = E ( x|θ E ) ( 1 ) p ( y|x ) = M i=0 p ( y i |y < i , x ) ( 2 ) p ( y i |y < i , x ) = soft ( D LF ( y < i |z , θ D LF ) ) ( 3 ) L LF = − ( x , y)∈S LF log p ( y|x)(4 )
The conditional probability of the output sequence y is expressed in Equation ( 2 ) as each token y i is autoregressively generated based upon z and prior outputs , y < i . Equation ( 3 ) models distribution p ( y i |y < i , x ) using a Transformer decoder for logical forms , D LF , with associated weights θ D LF where soft is the softmax function .
We predict an output , ŷ , for semantic parsing dataset S LF = { x n , y n } N n=0 , through the encoder and logical form decoder , { E , D LF } . Equation ( 4 ) describes the loss objective minimizing the crossentropy between y andŷ .
Language Prediction Our first additional objective encourages language - agnostic representations by reducing the discriminability of the source language , l , from z. Equation ( 5 ) defines a Language Prediction ( LP ) network to predict l from z using a linear classifier over L training languages :
LP ( x ) = W i x + b i ( 5 )
where W i ∈ R L×|z| and b i ∈ R L are a weight and bias respectively . We follow the best model from Ahmad et al . ( 2019b ) . Equation ( 6 ) describes the conditional model for the output distribution where a language label is predicted using the time - average of the input encoding z of length T :
p ( l|x ) = soft LP 1 T t z t ( 6 )
Finally , Equation ( 7 ) describes the objective function for the LP network :
L LP = − x log p ( l|x)(7 )
However , we reverse this gradient in the backward pass before the LP network , to encourage the encoder to produce language invariant representations ( Ganin et al . , 2016 ) . The LP network is optimized to discriminate the source language from z , but the encoder is now optimized adversarially against this objective . Our intuition is that discouraging language discriminability in z encourages latent representation similarity across languages , and therefore reduces the penalty for cross - lingual transfer .
Generating Natural Language The final objective acts towards both regularization and crosslingual similarity . Motivated by domain - adaptive pre - training ( Gururangan et al . , 2020 ) , we further adapt the encoder towards question - style utterances from native speakers of each test language lacking task - specific training data . We add an additional Transformer decoder optimized to reconstruct a noisy input from latent representation z , in Equation ( 1 ) . Utterance , x , is input to the encoder , E , and a separate decoder , D NL , then reconstructs x from z. We follow the denoising objective from   and replace x with noised inputx = N ( x ) with noising function N. The output probability of reconstruction is given in Equation ( 9 ) with each token predicted through Equation ( 10 ) using decoder , D NL , with weights θ D NL :
z = E ( x|θ E ) ( 8)
p ( x|x ) = T i=0 p ( x i |x < i , x ) ( 9 ) p ( x i |x < i , x)=soft ( D NL ( x < i |ẑ , θ D NL ) ) ( 10 )
The auxiliary objectives are trained using both the utterances from S LF and monolingual data ,
S NL = { { x n } N n=0 } L l=0
, in L languages ( see Section 5 ) . Submodel , { E , D NL } , predicts the reconstruction of x fromx with the following objective :
L NL = − x log p ( x|x)(11 )
In the form described above , this objective requires only unlabeled , monolingual utterances in each target language . However , we can also augment it with a translation component to exploit natural language bi - text between the new language and English ( e.g. ,
S NL = { { x n EN , x n l } N n=0 } L l=0
) to further promote cross - lingual similarity . According to some sampling factor τ , we randomly choose whether to reconstruct an utterance ( as above ) or translate to the parallel English utterance ( i.e. , replace x in Equation ( 11 ) with x EN ) .
Combined Model
The combined model uses a single encoder , E , and the three objective decoders { D LF , D NL , LP } ( see Figure 2 ) . During training , an English query is encoded and input to all three objectives to express output loss as L LF + L NL + L LP . For new languages without ( x , y ) pairs , the utterance is encoded and input only to the auxiliary objectives for a combined loss as L NL + L LP . During inference , an utterance is encoded and always input to D LF to predict a logical form , ŷ , regardless of test language , l. During the backward pass , each output loss back - propagates the gradient signal from the respective objective function . For the encoder , these signals are combined as :
∂L ∂θ E = ∂L LF ∂θ E − λα LP ∂L LP ∂θ E + α NL ∂L NL ∂θ E ( 12 ) λ = 2 1 + e −γp − 1 ( 13
)
where α { LP , NL } are loss weightings for auxiliary objectives and λ is the reversed gradient scheduling parameter from Ganin et al . ( 2016 ) . The λ value increments with training progress p , scaled by γ , according to Equation ( 13 ) , to limit the impact of noisy predictions during early training .
We expect that the parser will adapt and recognize an encoding from an unfamiliar language through our joint training process , and successfully connect new language representations to the logical - form decoder at test time . This sequenceto - sequence approach is highly flexible and may be useful for zero - shot approaches to additional generation tasks ( e.g. , paraphrasing ) .
Experimental Setup
Semantic Parsing Datasets Our experiments examine whether our zero - shot approach generalizes across languages and domains . We evaluate performance on a new version of the ATIS dataset of travel queries ( Hemphill et al . , 1990;Dahl et al . , 1994 ) . We align existing English utterances and SQL logical forms from Iyer et al . ( 2017 ) to the multi - lingual utterances from the MultiATIS++ dataset for spoken language understanding . This alignment adds executable SQL queries to utterances in Chinese ( ZH ) , German ( DE ) , French ( FR ) , Spanish ( ES ) , and Portuguese ( PT ) . We use the same 4,473/493/448 dataset split for training / validation / test as Kwiatkowski et al . ( 2011 ) . We also add to the test set Hindi ( HI ) and Turkish ( TR ) utterances from Upadhyay et al . ( 2018 ) . 3 We can now predict SQL from the ATIS test questions in eight natural languages . The Multi - ATIS++ Japanese set was excluded as the utterance alignment to this language was not recoverable .
We also examine Overnight ( Wang et al . , 2015 ) , an eight - domain dataset covering Basketball , Blocks , Calendar , Housing , Publications , Recipes , Restaurants , and Social Network domains . Overnight comprises 13,682 English utterances paired with λ−DCS logical forms , executable in SEMPRE ( Berant et al . , 2013 ) We measure performance with denotation accuracy as all inferred logical forms are executable in some knowledge base . This metric compares the retrieved denotation from the prediction , ŷ , to that from executing the gold - standard logical form . Dataset sizes are outlined in Appendix A.
Natural Language Data For the reconstruction objective , we used the MKQA corpus ( Longpre et al . , 2020 ) , a multi - lingual translation of 10,000 samples from NaturalQuestions ( Kwiatkowski et al . , 2019 ) . This is suitable for our auxiliary objective as the utterances are native - speaker question surface forms , matching our test set while varying in subject . MKQA is also balanced across new languages to limit overexposure bias to one new language . For bi - text , we use the original English and the professionally translated question as a pair .
We also report experiments using a sample of crawled data from ParaCrawl 7.1 ( Bañón et al . , 2020 ) . The sample comprises 10,000 web scraped sentences paired with equivalent English to form bitext . Note that these samples are mostly declarative sentences and as such do not match the surface form of our test inputs ( i.e. , questions ) and are also not parallel between sampled languages . We contrast this to MKQA to examine how the style of natural language data influences performance .
For ATIS experiments , we use 60,000 utterances from each source in languages with training data ( EN , FR , PT , ES , DE , ZH ) . For Overnight , we use 3 Misalignment between ATIS versions result in the test sets containing 442 and 381 utterances for HI and TR respectively .
30,000 utterances in EN , DE , and ZH .
Model Configuration
The implementation of ZX - PARSE ( see Section 4 ) largely follows parameter settings from   for Transformer encoder and decoder layers ( see Appendix A for details on model configuration ) . ZX - PARSE requires an encoder model to generate multi - lingual latent representations for all objectives . Our main results use only the encoder component of mBART50 ( Tang et al . , 2020 ) and we present experiments using other pre - trained models in Appendix B. We use all pre - trained encoder layers and append one additional learnable layer . All decoders are randomly initialized six - layer stacks . Early experiments found this approach superior to any pretrained decoder initialization .
The language predictor follows from Ahmad et al . ( 2019b ) as a single linear classification layer mapping from 1,024 inputs to L output languages . Earlier findings supported that if the LP network is larger , then the reversed gradient signal is too strong and therefore less useful as the LP network can memorize the language .
Comparison Models We primarily compare to a " Translate - Test " back - translation baseline wherein the new language test set is translated to English using Google Translate ( Wu et al . , 2016 ) and input to a reference sequence - to - sequence model trained on English . We also compare to " Translate - Train " , where we use MT from English to generate a proxy dataset in each new language ( e.g. , French , Portuguese , Spanish , German , Chinese , Hindi and Turkish ) to train a monolingual parser . We consider improving upon these " minimum effort " baselines as a lower bound for justifying our approach .
Additionally , we compare to an upper - bound monolingual model trained on professional translations of the new languages . We report results on MultiATIS++ for FR , PT , ES , DE , and ZH ( professional translations are not available for Overnight training data ) . This is the " maximum effort " strategy that we desire to avoid . Parameters for these reference systems match those outlined above e.g. , mBART50 encoder to logical form decoder .
Results
Our results are outlined to answer four core questions , with additional ablations in Appendix B. Our findings support the hypothesis that we can minimize the cross - lingual transfer penalty by im-   ( Dahl et al . , 1994 ) and Overnight ( eight - domain average ; Wang et al . , 2015 ) for supervised monolingual upper - bound , Translate - Test , and our best ZX - PARSE model . Results for English ( EN ) , French ( FR ) , Portuguese ( PT ) , Spanish ( ES ) , German ( DE ) , Chinese ( ZH ) , Hindi ( HI ) and Turkish ( TR ) ranked by similarity to English ( Ahmad et al . , 2019a ) . Best results compared to baselines are bolded .   proving latent alignment with auxiliary objectives . We also examine the latent space directly and find ZX - PARSE learns more similar representations between languages . Our parser achieves state - of - theart zero - shot results for all non - English languages in the MultiATIS++ and Overnight benchmarks .
Better than Translation ? We compare between ZX - PARSE and the upper - and lower - bounds in Table 1 . Our multi - task approach significantly improves upon " Translate - Test " for all languages included within the auxiliary objectives ( p < 0.01 ) . For ATIS , we find that " Translate - Train " performs below " Translate - Test " for languages similar to English ( FR , ES , PT ) but worse for more distant languages ( DE , ZH ) . ZX - PARSE performance improves on " Translate - Train " for all languages included in reconstruction ( EN , FR , PT , ES , DE , ZH ) , however , the general cross - lingual improvement insufficiently extends to additional languages ( HI , TR ) to perform above baselines .
Within ZX - PARSE , French and German demonstrate the strongest zero - shot accuracy -+2.4 % and +2.7 % above the monolingual upper bound for ATIS . We do not observe similar improvement for Portuguese or Spanish despite their similarity to English . This may be a result of German and French dominating the pre - training corpora com - pared to other new languages . ( Tang et al . , 2020 , their Table 6 ) .
Our model demonstrates similar significant improvement for Overnight ( p < 0.01 ) , however , we find lesser gain compared to ATIS . This may be a consequence of the compounded challenge of evaluating eight varied domains of complex linguistic constructs . Here , we find that " Translate - Train " is a stronger approach than " Translate - Test " , which may be a consequence of machine - translation direction . Our best approach on German still improves above " Translate - Train " ( +4.0 % ) , however , we find performance on Chinese to be only marginally improved by comparison ( +0.6 % ) . We also observe some contrast in ZX - PARSE performance related to orthographic similarity to English . Parsing accuracy on Overnight in German is +6.2 % above Chinese , with a similar +9.1 % gap between these same languages for ATIS .
Which Objective Matters ? Ablations to the model are shown in Table 2 , identifying the contributions of different objectives . Model ( a ) shows that without auxiliary objectives , performance in new languages is generally below Translate - Test . This is unsurprising , as this approach uses only pre - trained cross - lingual information without additional effort to improve similarity . Such efforts are incorporated in Model ( b ) using the additional reconstruction decoder . Even without the LP loss , domain targeted adaptation ( with translation ) improves cross - lingual parsing by an average across new languages of +9.3 % for ATIS and +2.9 % for Overnight . Notably , we identified an optimal ratio of translation to reconstruction of 50 % ( i.e. , τ = 0.5 ) . This suggests that both monolingual utterances ( for domain - adaptive tuning ) and bi - text ( for translation ) contribute to the utility of our method beyond reliance on one technique .
Evaluating the LP objective within Model ( c ) and ( d ) , we find the reversed gradient successfully reduces language discriminability . For Model ( d ) , language prediction accuracy during training peaks at 93 % after 2 % progress and subsequently decreases to < 8 % beyond 10 % of training . Language prediction accuracy for the test set is 7.2 % . We observe a similar trend for Model ( c ) . Comparing individual objectives , we find the addition of the language predictor alone less helpful than the reconstruction decoder . Comparing Model ( a ) and ( c ) , we observe a smaller average improvement on new languages of +4.3 % for ATIS and +1.8 % for Overnight . This suggests adaptation towards specific surface form patterns can be more effective here than modeling languages as discrete labels .
Considering the combination of objectives in Model ( d ) , we identify cumulative benefit to parsing with both objectives . Compared to Model ( a ) , the full model improves by an average of +16.3 % for ATIS and +9.9 % for Overnight across new languages . Our findings support our claim that latent cross - lingual similarity can be improved using auxiliary objectives and we specifically identify that a combination of approaches yields superior parsing . We suggest that this combination benefits from constructive interference , as the language prediction loss promotes invariance in tandem with multilingual generation tasks adapting the encoder to improve modeling the surface form ( e.g. , questions from native speakers ) of the new language test data .
Additional objectives also improve parsing for Hindi and Turkish despite neither being included within auxiliary training data ( see HI and TR columns in Table 3 ) . By adapting our latent representation to encourage similarity , we improve parsing accuracy for two typologically diverse languages without explicit guidance . To further examine this , we visualize the MultiATIS++ test set in Figure 3   from ZX - PARSE compared to mBART50 . Quantitatively , we find the average cosine distance between the sentence - mean of parallel utterances reduces from 0.58 to 0.47 . Similarly , the average tokenlevel symmetric Hausdorff distance ( Taha and Hanbury , 2015 ) between languages reduces from 0.72 to 0.41 . This further supports that we learn more similar representations and our method has wider utility beyond explicitly targeted languages .
Does Language Style Matter ?
In Table 3 we examine whether our auxiliary objectives are influenced by the style of natural language corpora for reconstruction . We find the use of questions positively improves performance compared to crawled sentences . Using questions either as monolingual utterances ( i.e. , no translation in D NL ) or with as a bi - text sample ( i.e. , reconstruction and translation in D NL ) improves above the Translate - Test baseline . We observe modest improvements with ParaCrawl , especially when introducing bitext into D NL , but this is less consistent across languages . Overall , our results suggest that ZX - PARSE is robust even when question - style data is unavailable but can be particularly effective when adapting towards both new languages and domains . We also examined the influence of language family on performance ( see Appendix B ) and found that best performance utilizes a linguistically varied ensemble of languages .   model and simplest approach ( Model ( a ) in Table 2 ) , we find more well - formed logical forms account for the largest improvement ( 32.5 % fewer ill - formed SQL queries for ATIS and 35.2 % fewer ill - formed λ - DCS queries for Overnight ) . This supports our notion in Figure 1 that better latent alignment can minimize cross - lingual penalty . However , improved structure prediction is insufficient to solve this task on its own ; 58.7 % of remaining errors in the best model are due to mishandled entities with the highest entity errors for Chinese ( 60.2 % ) and lowest for French ( 36.7 % ) . This suggests that aligning entities across languages might be necessary for further improvement .
Conclusion
We presented a multi - task model for zero - shot cross - lingual semantic parsing which combines logical form generation with auxiliary objectives that require only modest natural language corpora for localization . Through aligning latent representations , ZX - PARSE minimizes the error from cross - lingual transfer and improves accuracy across languages unseen during training .
Although we focused exclusively on executable semantic parsing , our approach is general and potentially relevant for linguistically motivated frameworks such as Abstract Meaning Representation ( Banarescu et al . , 2013;Damonte and Cohen , 2018 ) or Discourse Representation Theory ( Kamp and Reyle , 1993;Evang and Bos , 2016 ) . In the future , we will investigate a few - shot scenario and study sample efficient cross - lingual transfer by explicitly promoting generalization using techniques such as meta - learning ( Finn et al . , 2017 ) .
Ethics Statement
A key limitation of our work is the limited coverage of eight higher - resource languages . As such , we are unable to test our approach in a genuinely lowresource scenario . We must also consider the risk of over - generalization to dominant dialects within each language as we lack an evaluation of additional dialects ( e.g. our English dataset is representative of American English but not Indian English ) . We hope that such issues can be addressed with additional data collection .
Our training requirements are detailed in Appendix A. We hope our work contributes to further usage and development of singular multilingual models as opposed to learning N monolingual models for N languages .    ( Dahl et al . , 1994;Upadhyay et al . , 2018 ; and Overnight ( Wang et al . , 2015;Sherborne et al . , 2020 ) . Each example is an utterance paired with a logical form . Table 5 : Pretrained model configurations and configuration for the trainable components of ZX - PARSE ( e.g. , the objectives ) . All models use a hidden dimension of 1,024 , a feed - forward hidden projection of 4,096 and 16 heads per multi - head attention layer . For natural language , all models use byte - level BPE tokenization ( Wang et al . , 2020b ) and logical forms are tokenized using whitespace .
A Experimental Setup
Zero - shot Model Configuration The encoder , E , decoders , { D LF , D NL } , and embedding matrices all use a dimension size of 1,024 with the self - attention projection of 4,096 and 16 heads per layer . Both decoders are 6 - layer stacks .
Weights were initialized by sampling from normal distribution N ( 0 , 0.02 ) . The language prediction network is a two - layer feed - forward network projecting from z to 1,024 hidden units then to |L| for L languages . L is six for experiments on ATIS and three for experiments on Overnight .
Configurations for models used in this work are reported in Table 5 with similar details for the objective components of ZX - PARSE . Initial experiments examined XLM - R - base , which is 12 layers opposed to 24 , however , performance was significantly worse and , therefore , this model was not considered further . Experiments reported in Section 6 all use mBART50 as the pre - trained encoder as all other pre - trained models performed significantly worse ( see Appendix B ) . In all our experiments , we found that a randomly initialized decoder was superior to using pre - trained weights .
A complete outline of dataset partitions per language is shown in Table 4 for both datasets . ZX - PARSE uses only English training and validation data and tests on all additional languages . We did not use multi - lingual validation data as recommended in Keung et al . ( 2020 ) as this approach did not prove critically beneficial in early experiments and doing so would explode the data requirements for a multi - lingual system .
Experimental Setting
The system was trained using the Adam optimizer ( Kingma and Ba , 2015 ) with a learning rate of 1 × 10 −4 , and a weight decay factor of 0.1 . We use a " Noam " schedule for the learning rate ( Vaswani et al . , 2017 ) with a warmup of 5,000 steps . For pre - trained components , we fine - tune XLM - R and mBART encoders with learning rate 1 × 10 −5 but freeze the encoder when using mBART50 . Loss weighting values for α { LP , NL } were empirically optimized to { 0.33 , 0.1 } respectively from a range { 0.5 , 0.33 , 0.1 , 0.05 , 0.01 , 0.005 , 0.001 } . Batches during training were size 50 and homogeneously sampled from either S LF or S NL , with an epoch consuming one pass over both . Models were trained for a maximum of 100 epochs with early stopping . Model selection and hyper - parameters were tuned on the S LF validation set in English e.g. , validation only evaluates performance on logical - form generation and not additional objectives . Test predictions were generated using beam search with 5 hypotheses .
For the reconstruction noising function , we use token masking to randomly replace u tokens in x with " < mask > " where u is sampled from U ( 0 , v ) . We found v = 3 as the empirically optimal maximum tokens to mask in an input . Similarly , we found γ = 40 optimal for the language prediction loss and τ = 0.5 as the optimal sampling factor for translation versus reconstruction . This value of τ corresponds to using half the reconstruction data as mono - lingual utterances and half as bi - text paired with English .
Reproducibility All models were implemented using AllenNLP ( Gardner et al . , 2018 ) and Py - Torch ( Paszke et al . , 2019 ) , using pre - trained models from HuggingFace ( Wolf et al . , 2019 ) . Each model is trained on 1 NVIDIA RTX3090 GPU in a cluster configuration , with no model requiring over 24 hours to complete training . Hyperparameters were chosen by training a reference model for parsing English utterances and selecting the system with minimum validation loss . Our optimization grid - search explored : { 6 , 9 , 12 } decoder layers ; freezing or unfreezing the pre - trained encoder ; { 0 , 1 , 2 } additional encoder layers ap - pended to the pre - trained encoder ; learning rates of 1 × 10 { −3 , −4 , −5 } and a weight decay factor of { 0 , 0.1 , 0.01 } . Optimal parameters in these early tests were carried through for all additional models .
Additionally , we optimized hyper - parameters for auxiliary objectives through linear search with all other factors fixed . The upper limit , v , for the number of tokens to mask during reconstruction , U ( 0 , v ) , was optimized from integers 1 - 6 . The MKQA dataset used for auxiliary tasks contains shorter sentences than prior work using masking , such as , and we observed that high levels of masking ultimately destroys the input sentence and handicaps the overall task . τ was optimized between values of 0.0 ( e.g. ignore bi - text ) to 1.0 ( e.g. all data is used as bi - text ) in increments of 0.1 . Finally , we optimize the γ parameter within Equation 7 between { 0 , 5 , 10 , 20 , 40 , 50 , 100 } on an approximately logarithmic scale . The optimal value of γ = 40 results in loss L LF reaching 99 % of the maximum value at approximately 13.6 % of training progress .
B Additional Results
We extend the results in Section 6 to include additional ablations for all pre - trained models . Table 6 details all results for ATIS across eight test languages . Additionally , complete results across all domains in Overnight are reported for English in Table 7 , German in Table 8 , and Chinese in Table 9 . Table 3 , comparing between reconstruction data sources , is expanded on for Overnight in Table 10 . Finally , we present additional ablations to our model considering reconstruction language families in Table 11 and 12 . Which Pre - trained Encoder ? Our full results using three different pre - trained encoders are outlined in Tables 6 - 9 . Our experiments identify mBART as the weakest pre - trained model , reporting the lowest accuracies for all ATIS test languages . ZX - PARSE using XLM - R generally improved upon mBART for ATIS but proved worse for Overnight . As XLM - R is not pre - trained for sequence - to - sequence tasks , this result suggests this model could be poorer at representing input content in more complex queries . Despite being half the size of XLM - R , mBART50 is the only pre - trained encoder able to perform competitively across all languages . Despite lower performance with different pre - trained models , we identify that introducing additional objectives yields improved accuracy in most cases . Similar to our results using mBART50 , we find that combining tasks is the optimal strategy for ZX - PARSE using either XLM - R or mBART as an encoder .
We additionally explored if pre - training is required for our approach by training a comparable model from scratch . While performance on English was similar to our best results , we found that cross - lingual transfer was extremely poor and these results are omitted due to negligible accuracies ( < 2 % ) for non - English languages . Overall , this suggests that our methodology is optimal when aligning an existing multi - lingual latent space rather than inducing a multi - lingual latent space from scratch .
Ablations of Reconstruction Language Data
We present ablations to our main experiments examining the influence of language similarity in reconstruction data for ATIS in Table 11 and for Overnight in Table 12 . Similar to our results for Hindi and Turkish in Table 2 , we find that using our auxiliary objectives in our model improves overall cross - lingual alignment in languages that we did not intentionally target with reconstruction data .
In our first case , we consider omitting the Romance genus languages ( French , Spanish , Portuguese ) from the reconstruction corpus for experiments on ATIS . The observed reduction in performance across all languages is likely a consequence of reduced training data leading to weaker crosslingual alignment . Notably , this drop is largest for French ( −11.2 % ) and Spanish ( −7.1 % ) . In contrast , the smallest reduction is for Chinese ( −3.9 % ) and English ( −2.8 % ) . We additionally examine the effect of omitting the only Sino - Tibetan language ( Chinese ) from experiments on both ATIS and Overnight . While we observe a similar overall reduction in performance here -our notable finding is a larger reduction in parsing accuracy for Chinese across both ATIS ( −17.0 % ) and Overnight ( −11.1 % ) . Without a similar language to Chinese ( in the same family or with a similar orthography ) in this experiment , we suggest there is little to " support " better cross - lingual alignment for Chinese relative to others . This contrasts with the performance drop for Romance languages , which are still relatively similar to English and German .
Overall , these ablations support that both variety and similarity are important for considering language data for auxiliary objectives . Performance on omitted languages can improve from a base-      ( Wang et al . , 2015 ) ( Wang et al . , 2015 ) ( Wang et al . , 2015 ) compared across reconstruction data usage for English , German and Chinese . We compare between MKQA ( Longpre et al . , 2020 ) and ParaCrawl ( Bañón et al . , 2020 ) with additional contrast between using reconstruction data as monolingual utterances ( e.g. τ = 0.0 ) or with some proportion as bi - text where the target sequence is replaced with the parallel English utterance ( e.g. τ = 0.5 ) . Domains are Basketball , Blocks , Calendar , Housing , Publications , Recipes , Restaurants and Social Network . Best results for each language are bolded .
Acknowledgements
We thank the anonymous reviewers for their feedback and Bailin Wang , Kate McCurdy , and Rui Zhang for insightful discussion . The authors gratefully acknowledge the support of the UK Engineering and Physical Sciences Research Council ( grant EP / L016427/1 ; Sherborne ) and the European Research Council ( award number 681760 ; Lapata ) .
