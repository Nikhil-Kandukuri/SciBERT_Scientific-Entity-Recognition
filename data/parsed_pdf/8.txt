KaFSP : Knowledge - Aware Fuzzy Semantic Parsing for Conversational Question Answering over a Large - Scale Knowledge Base
In this paper , we study two issues of semantic parsing approaches to conversational question answering over a large - scale knowledge base : ( 1 ) The actions defined in grammar are not sufficient to handle uncertain reasoning common in real - world scenarios . ( 2 ) Knowledge base information is not well exploited and incorporated into semantic parsing . To mitigate the two issues , we propose a knowledge - aware fuzzy semantic parsing framework ( KaFSP ) . It defines fuzzy comparison operations in the grammar system for uncertain reasoning based on the fuzzy set theory . In order to enhance the interaction between semantic parsing and knowledge base , we incorporate entity triples from the knowledge base into a knowledgeaware entity disambiguation module . Additionally , we propose a multi - label classification framework to not only capture correlations between entity types and relations but also detect knowledge base information relevant to the current utterance . Both enhancements are based on pre - trained language models . Experiments on a large - scale conversational question answering benchmark demonstrate that the proposed KaFSP achieves significant improvements over previous state - of - the - art models , setting new SOTA results on 8 out of 10 question types , gaining improvements of over 10 % F1 or accuracy on 3 question types , and improving overall F1 from 83.01 % to 85.33 % . The source code of KaFSP is available at https : //github.com / tjunlp - lab / KaFSP .
Introduction
With the growing popularity of intelligent virtual assistants ( e.g. , Alexa , Siri , Cortana ) and the availability of large - scale knowledge bases ( e.g. , DBPedia ( Auer et al . , 2007 ) , Wikidata ( Vrandečić and Krötzsch , 2014 ) , YAGO ( Rebele et al . , 2016 ) ) , conversational question answering ( QA ) over knowledge bases ( KB ) has attracted broad interests . It aims to satisfy users ' information needs by retrieving answers from a given knowledge graph to users ' questions in a multi - turn conversational setting with a wide range of discourse phenomena ( e.g. , ellipsis , coreference , lexical cohesion ) .
While conversational QA over large - scale KBs can be realized without explicit semantic parsing ( e.g. , HRED - KVM ( Kacupaj et al . , 2021 ) ) , the majority of effort is dedicated to the exploration of contextual semantic parsers ( Guo et al . , 2018;Shen et al . , 2019;Thirukovalluru et al . , 2021;Kacupaj et al . , 2021;Lan and Jiang , 2021 ) . The semantic parsing based approaches usually project an utterance into a logical form that can be executed on a given knowledge base . Early semantic parsing method D2A ( Guo et al . , 2018 ) suffers from the stepwise error propagation issue , which is improved by MaSP ( Shen et al . , 2019 ) that jointly learns pointer - equipped semantic parsing and typeaware entity detection in a multi - task learning framework . The very recent work LASAGNE ( Kacupaj et al . , 2021 ) further enhances MaSP via a graph attention network that exploits the correlation ( missing in MaSP ) between entity types and relations and achieves the state - of - the - art results on the CSQA benchmark ( Saha et al . , 2018 ) .
Despite the aforementioned progress , we argue that current semantic parsing approaches to conversational QA over large - scale KBs still suffer from two critical issues . First , grammar rules that form the base for the mapping of questions to logical forms , although being constantly updated in D2A , MaSP , and LASAGNE , are still not sufficient to cover all real - world situations , e.g. , fuzzy inference on numbers . Consider the question " Which nutrients can interact with approximately 89 chemical substances and drugs ? " . It is difficult for existing grammar to represent " approximately 89 " . Second , the interaction between questions and knowledge base is not adequate for entity disambiguation and redundancy detection in semantic parsing . For the question " Which educational institution is the alma mater of Pierre Lefebvre ? " , without using relevant information from KB , it is difficult for semantic parsing to distinguish whether " Pierre Lefebvre " is a French military physician or a French politician as more than one persons named " Pierre Lefebvre " are in the knowledge base .
To address these two issues , we propose a Knowledge - aware Fuzzy Semantic Parsing ( KaFSP ) model to enhance both grammar rules and the interaction between KB and semantic parsing . Particularly , we introduce fuzzy operations into the grammar system used in previous work , enabling the system to perform uncertainty reasoning on numbers . Such updates have a significant impact on answering quantitative and comparative questions . In order to make the knowledge base well facilitate semantic parsing , we incorporate deep entity knowledge in the given knowledge base into different modules in the proposed semantic parsing framework . In the entity disambiguation module , entity triples from the knowledge base are exploited to disambiguate candidate entities . In the entity type and relation prediction module , a multi - label classification framework is proposed to capture correlations between entity types and relations and to pinpoint KB information relevant to the current utterance .
Contributions Our main contributions are as follows :
• We propose a knowledge - aware fuzzy semantic parsing framework for conversational QA over large - scale KBs , which enables the grammar system to model uncertainty reasoning based on the fuzzy set theory , and enhances the interaction between KB and semantic parsing with two knowledge - aware modules .
• Experiment results demonstrate that our proposed model achieves new state - of - the - art results on 8 out of 10 question types on the CSQA dataset ( Saha et al . , 2018 ) , which is to date the largest dataset for complex conversational question answering over a large - scale knowledge base .
Related Work
Semantic parsing approaches have conventionally been used for knowledge base question answering ( KBQA ) . Early efforts parse natural language questions into logical forms typically via dictionary - based parsers or similarity models ( Wong and Mooney , 2007;Collins , 2007 , 2009;Kwiatkowski et al . , 2011;Andreas et al . , 2013;Artzi and Zettlemoyer , 2013;Reddy et al . , 2014;Zhao and Huang , 2015;Dubey et al . , 2016;Long et al . , 2016 ) .
Recent years have witnessed that semantic parsing has been shifted from traditional statistical models with feature engineering to neural approaches that learn continuous representations for generating logical forms ( Yih et al . , 2014;Jia and Liang , 2016;Xiao et al . , 2016;Bao et al . , 2016;Lapata , 2018 , 2016;Bhutani et al . , 2020;Jiang , 2020 , 2021 ) . For example , Dong and Lapata ( 2016 ) use the encoder - decoder framework equipped with a neural attention mechanism to cast semantic parsing into Seq2Seq generation .
As knowledge bases are becoming large , semantic parsing for KBQA is usually performed in a stepwise , modular framework . Guo et al . ( 2018 ) recognize entities in questions and link them to the given large - scale knowledge graph at the first stage and then learn to map the entity - linked questions into logical forms . Dong and Lapata ( 2018 ) propose a coarse - to - fine two - stage decoding method for semantic parsing , which generates a coarse sketch for a question with low - level features at the first stage and then continues to decode the final logical form based on the output of the first stage as well as the question itself .
As mentioned in Section 1 , such stepwise methods are confronted with error propagation across stages ( e.g. , from entity linking to mapping , from coarse parse to fine parse ) . In order to alleviate such problem , Shen et al . ( 2019 ) and Kacupaj et al . ( 2021 ) use a multi - task learning framework to jointly learn entity detection , linking , and semantic parsing in a single model . Kacupaj et al . ( 2021 ) also use a graph attention network ( Veličković et al . , 2018 ) to explore entity type and relation information in the knowledge base .
Due to the superiority of multi - task learning for semantic parsing tailored for KBQA , our work is also based on the multi - task learning framework . However , our model is significantly different from existing works in both fuzzy grammar rules and knowledge - aware entity disambiguation together with entity type and relation prediction .
KaFSP
We use a multi - task learning framework to map an input ( current question concatenated with context ) into a logical form where entities are detected and linked to the given knowledge base . Figure 1 shows the architecture of KaFSP . The backbone network of KaFSP follows LASAGNE ( Kacupaj et al . , 2021 ) consisting of a seq2seq network , an entity recognition module and a graph attention network module ( Section 3.2 ) . Our contributions lie in the fuzzy grammar ( Section 3.1 ) , the knowledgeaware entity disambiguation module ( Section 3.3 ) , and the entity type and relation prediction module ( Section 3.4 ) . The two knowledge - aware modules are shown in the black dashed box in Figure 1 .
Fuzzy Grammar
In semantic parsing approaches tailored for conversational KBQA , a grammar with the minimum number of actions is usually defined to construct KB - executable logical forms ( i.e. , semantic parse trees ) . The actions defined in the previous grammar system ( Guo et al . , 2018;Kacupaj et al . , 2021 ) are all deterministic operations . However , vague and fuzzy questions are common in real - world scenarios , e.g. , " How many works of art did approximately the same number of people do the dubbing for as Another ? " , which can not be answered by previous deterministic grammars . The grammar of LASAGNE includes an action termed " approx " , which aims to perform the operation of " approximately equal to " . However , how two numbers are measured to be roughly equal to each other is not defined . Therefore , we take the grammar of LASAGNE as a starting point for building our own grammar and add fuzzy actions to the grammar to make it to adapt to real - world vague questions mentioned above . The new grammar is briefly summarized in Table 1 .
We further give a " precise " ( measurable ) definition for these added fuzzy actions based on the fuzzy set theory ( Zadeh , 1965 ) . For a number a , we define its fuzzy set as A = { x , µ(x)|x ∈ R } . µ(x ) is the membership function of set A , which indicates the degree of similarity between x and a , and is defined based on a generalized bell - shaped membership function as :
µ(x ) = 1 1 + | x−a c | 2b , ( 1 )
where c ∈ R and b ∈ N + . When µ(x ) = 1 , x and a are strictly equal ; and when µ(x ) = 0 , x and a are strictly not equal .
A threshold λ ∈ ( 0 , 1 ] can be defined to get three    fuzzy sets :
A ≈ λ = { µ(x ) > λ|x ∈ R } , A ≳ λ = { x > a|x ∈ R } ∪ A ≈ λ , A ≲ λ = { x < a|x ∈ R } ∪ A ≈ λ .
( 2 )
When µ(x ) > λ , then x ∈ A ≈ λ , which denotes that x and a is approximately equal to each other . When x ∈ A ≳ λ , x is considered to be greater than or approximately equal to a. When x ∈ A ≲ λ , x is considered to be less than or approximately equal to a.
It is worth noting that all the parameters in Eq . ( 1 ) and the threshold λ can be flexibly predefined , which makes our grammar adjustable to different fuzzy scenarios .
Backbone Network
We follow the multi - task learning framework of LASAGNE ( Kacupaj et al . , 2021 ) to build the backbone network for our KaFSP .
Encoder and Decoder
The skeleton of the entire model is a Transformer - based encoder - decoder network . The input x fed into the encoder is formed in a way similar to LASAGNE , which is composed of the previous question , the answer to the previous question , and the current question separated by a symbol " [ SEP ] " . A special token " [ CTX ] " is appended to the input for encoding the input representation h enc ctx , as shown in Figure 1 . Both the encoder and decoder use a two - layer multi - head attention Transformer block , which can be formulated as :
h enc = encoder(x ; θ enc ) , z dec = decoder(h enc ; θ dec ) , P ( y dec |x ) = t softmax(W dec z dec t ) , ( 3 )
where
z dec t ∈ R |V dec |
is the hidden state of the decoder at time step t , and W dec is the linear projection matrix at the targe side . The key task of the decoder is to generate an action ( listed in Table 1 ) at each time step to obtain the logical form y dec corresponding to the input x.
Entity Recognition Inspired by Shen et al . ( 2019 ) , we jointly detect entities and their types in a BIO sequence labeling way . The labels for the input sequence x are in { O , { B , I } × { T i } Ntp 1 } . T i stands for the i - th entity type label , and N tp denotes the number of the distinct entity types in the knowledge base . An LSTM network , stacked over the encoder , is used to perform the sequence labeling task . To make the outputs of the sequence labeling task compatible with logical forms , we follow LASAGNE to use a feedforward layer stacked over the LSTM layer . The entire module of entity recognition is hence formulated as follows :
h LSTM = LSTM(h enc ; θ LSTM ) , h FFN = LeakyReLU(W FFN 1 [ h enc ; h LSTM ] ) , P ( y ER |x ) = t softmax(W FFN 2 h FFN t ) , ( 4 )
where h LSTM is the LSTM hidden state at time step t , h FFN is the FFN - transformed version of h LSTM , and P ( y ER |x ) denotes the probability distribution over entity tags .
Graph Attention Network ( GAT ) We follow LASAGNE to use the GAT module to learn the correlations between entity types and their relations in the knowledge base . It can be defined as :
h GAT = GAT(e node ; θ GAT ) , ( 5 )
where e node are the embeddings of nodes in the type - relation graph constructed from the knowledge base . Please refer to Kacupaj et al . ( 2021 ) for more details on the GAT module .
Entity Disambiguation
In a large - scale knowledge base , it is common that entities with different meanings share the same surface forms . Predicting entity types could help differentiate them . However , when candidates have both the same type and surface form , it is difficult for entity type prediction to distinguish them again .
In order to address this issue , we incorporate more information about these ambiguous entities from the knowledge base to disambiguate them . We model the entity disambiguation problem as a binary classification problem :
y = f ( c , s , K(e)),(6 )
where s is the surface form of a candidate entity e , c is the context where e occurs , and K(e ) denotes relevant information of the candidate entity e from the knowledge base . If y = 1 the entity e is disambiguated and linked to the true entity in the knowledge base defined by K(e ) . The purpose of this is to maximize both the true positive and true negative .
We define the context of e as the entire input x. To define K(e ) , we use all triples that are relevant to e in the knowledge base , regardless of whether the entity is a subject or an object in triples . That is , K(e ) is an ordered set of KB triples . Each triple in K(e ) can be formulated as ( e h , r , e t ) , where the candidate entity e is either the head entity ( e h ) or tail entity ( e t ) .
In Eq . ( 6 ) , f is the classifier to disambiguate candidate entities . We use a pre - trained language model XLNet ( Yang et al . , 2019 ) fine - tuned in the training dataset as the classifier .
In order to feed s , c , and K(e ) into the pretrained and fine - tuned classifier , we reorganize them into a concatenated textual sequence , with components be separated by the token " [ SEP ] " . KB triples are all instantiated with corresponding words in the knowledge base , where e h , r , and e t are separated by blanks . We use the top 3 triples in K(e ) and feed them into the classifier , where the triples are sorted by their IDs . Such a choice is a trade - off between knowledge graph coverage and memory consumption in practice . If the number of relevant triples retrieved from the knowledge base is less than 3 , we use the candidate entity itself to fill in the empty triples .
Type and Relation Prediction
This module mainly performs two subtasks : the unified recognition of entity types and relations , and the KB - guided prediction of correct entity types and relations stacked over the first subtask , as shown in the Type & Relation Prediction module in Figure 1 .
Let G ⊆ E × R × E denote the knowledge base , where E is the entity set and R is the relation set .
Each entity e ∈ E has an entity type τ ∈ T ( entity type set ) .
We model the type and relation recognition subtask as a multi - label classification task and use a classifier to predict the probability of an output sequence from a given input sequence .
To obtain neural representations of both entity types and entity relations for the recognition subtask , we use a pre - trained language model BERT ( Devlin et al . , 2019 ) . The input fed into BERT is formed in a way similar to the entity disambiguation module . The difference is that we replace the entity with its entity type . Formally , the neural representation e τ of an entity type is computed as follows :
e τ = BERT [ CLS ] ( [ CLS]s(τ ) [ SEP]K(τ ) [ SEP ] ) ,
where [ CLS ] indicates that we use the representation of the prepended artificial [ CLS ] token as the representation of the entity type τ , s(τ ) and K(τ ) represent the surface form and triples of τ , respectively . Similarly , the neural representation e r of a relation is formulated as : Kacupaj et al . ( 2021 ) find that modeling the correlations between entity types and relations is crucial for semantic parsing . In our KaFSP , we use a single classifier to predict both entity types and relations , instead of using two separate classifiers that share no common information ( Shen et al . , 2019;Kacupaj et al . , 2021 ) . Hence , the prediction space of our classifier is T ∪R , and the correlations between types and relations are naturally captured in the same single classifier . We use a sigmoid function to output probabilities as follows :
e r = BERT [ CLS ] ( [ CLS]s(r)[SEP]K(r)[SEP ] ) .
P ( y MLC |x ) = Sigmoid(h enc ctx × W MLC ( e τ r ) ⊤ ) , ( 7 )
where W MLC ∈ R |T ∪R|×d is a linear projection matrix , and e τ r are the concatenation of the embeddings of τ ∈ T and r ∈ R.
The KB - guided prediction of entity types and relations is actually to make final decisions on them with relevant information from the knowledge base . Since KB contains a lot of triples irrelevant to the current utterance u , in order to make the knowledge graph embedding provide the information related to u , we use the output probabilities from the proposed multi - label classifier to pinpoint relevant information from the knowledge base encoded by GAT . Particularly , we calculate the Hadamard product of P ( y MLC |x ) and h GAT :
h MLC = W TRP ( h GAT ⊙ P ( y MLC |x)),(8 )
where W TRP ∈ R 2d×d is a linear projection matrix .
Given the hidden states of the decoder z dec and last hidden state of the encoder h enc ctx , we use a feedforward network to predict the sequence of types and relations :
P ( y TRP |x ) = t softmax((h MLC ) ⊤ FFN(h enc ctx ; z dec t ) ) , ( 9
)
where FFN(h enc ctx ; z dec t ) is the projection of the concatenation of the context representation and the hidden state of the decoder at time step t.
Learning and Inference
KaFSP Training
Before training KaFSP , we use weak supervisions ( only the final answers ) to obtain golden standard logical forms of questions in the training set through BFS , following Guo et al . ( 2018 ) .
In KaFSP , we have 6 subtasks : the encoderdecoder subtask ( DEC ) , the entity recognition subtask ( ER ) , the filtering and permutation subtask from LASAGNE ( FP ) , the multi - label classification subtask ( MLC ) described in Section 3.4 , the type and relation prediction subtask ( TRP ) and the entity disambiguation subtask ( ED ) . We a mixed training strategy to train these subtasks . The first 5 subtasks are jointly trained in a multi - task learning way while the last subtask is separately trained . Reasons for this strategy are twofold : 1 ) Entity disambiguation is a relatively independent subtask compared with other subtasks . 2 ) We fine - tune a huge pre - trained language model XLNet ( Yang et al . , 2019 ) on this subtask . Direct incorporation of the fine - tuning procedure into multi - task learning may make it difficult for the entire model to converge .
The joint loss J for the multi - task learning training is formulated as :
J = m∈M γ m L m , ( 10 )
where M = { DEC , ER , FP , MLC , TRP } is the set of subtasks and γs are the weights of these subtasks , which are learned during training . In learning these weights , we take into account the difference in magnitude among the 5 losses according to the log standard deviation ( Kendall et al . , 2018 ) . L DEC , L ER , L FP and L TRP are the negative log - likelihood losses of 4 subtasks , which are defined as follows :
L DEC = − m k=1 log P ( y DEC k |x ) , L ER = − n j=1 log P ( y ER j |x ) , L FP = − n j=1 log P ( y FP j |x ) , L TRP = − m k=1,y dec k ∈P log P ( y TRP k |x),(11 )
where n and m are the length of the input utterance x and the golden standard logical form , respec - tively . P is the set of placeholders for relations and types . y * are ground - truth labels for corresponding subtasks .
The loss for the multi - label classification L MLC is a binary cross - entropy loss , defined as :
L MLC = − 1 l l i=1 y MLC i log(P ( y MLC i |x ) ) + ȳ i MLC log(P ( ȳ i MLC |x ) ) , ( 12
)
where l is the size of T ∪ R , ȳ MLC = 1 − y MLC , y MLC is defined in Eq . ( 7 ) . The entity disambiguation is trained separately , and its loss function is defined as :
L ED = e∈Ex y ED i log(P ( y ED i |x ) ) + ȳ i ED log(P ( ȳ i ED |x)),(13 )
where E x is the set of entities that appear in x and y ED is defined in Eq . ( 6 ) .
To train this subtask , we retrieve all entities that are present in the current input from the knowledge base . Note that we only construct 500,000 and 40,000 samples respectively for training and validation of the entity disambiguation module .
Grammar - Guided Inference
The grammar defined in Table 1 is used to guide the decoding step . The decoder generates a sequence mixed with actions and placeholders . Placeholders are instantiated with specific entities , types , relations , and numbers . The decoding process for a logical form terminates when no nonterminals remain . After decoding , we use a shift - reduce method to check the logical form sequence and delete or correct wrong placeholders .
Once the BIO tags and entity types are identified , entity spans can be located from the input utterance . We search from the inverted index constructed for the knowledge base for each predicted entity span to obtain an entity candidate list . After filtering the retrieved entity candidate list according to the corresponding entity type , if there are still multiple candidate entities , the entity disambiguation module is activated to calculate the conditional probability of each candidate entity . The candidate entity with the highest probability is selected .
Finally , we use the relation and type prediction results and disambiguated entities to instantiate the placeholders to get final logical forms .
Experiments
We carried out experiments and analyses to validate the effectiveness of the proposed KaFSP .
Experimental Settings Dataset
We evaluated the proposed model on the CSQA dataset ( Saha et al . , 2018 ) , a standard dataset for complex sequential question answering . The dataset is composed of 200 K dialogues with 1.6 M turns , and over 12.8 M entities from Wikidata , where 153 K , 16 K , and 28 K dialogues are used for training , verification , and test , respectively . The questions cover a wide range of linguistic phenomena , such as co - reference , ellipsis , and reasoning .
Evaluation Metrics
We used the same evaluation metrics as Saha et al . ( 2018 ) . When answers are composed of one or more entities , F1 score is used as the evaluation metric . When answers are a Boolean value or number , accuracy is used as the metric . Following previous works ( Guo et al . , 2018;Shen et al . , 2019;Kacupaj et al . , 2021 ) , we also calculated overall scores for all types of questions under each evaluation metric .
Baselines We compared KaFSP against 5 stateof - the - art baselines on the CSQA . The first baseline is HRED+KVM ( Saha et al . , 2018 ) , which combines the HRED model with the key - value memory network . The other four baselines are D2A ( Guo et al . , 2018 ) , MaSP ( Shen et al . , 2019 ) , KISP ( Thirukovalluru et al . , 2021 ) , LASAGNE ( Kacupaj et al . , 2021 , which achieve state - of - the - art results on different types of questions on the CSQA dataset . More details for model settings can be found in Appendix A.
Results
Table 2 shows experiment results on the CSQA dataset . Our model outperforms LASAGNE on all types of questions and achieves new SOTA results in 8 out of 10 question types . Additionally , our model outperforms all previous baselines in terms of " overall " results .
For question types that involve one or more entities , namely Logical Reasoning ( All ) , Simple Question ( Direct ) , and Verification ( Boolean ) , the improvements over LASAGNE on these question types are 3.14 % , 2.78 % , and 1.29 % respectively . This is mainly because we have added a knowledgeaware entity disambiguation module to improve the accuracy of entity linking .   For question types Clarification , Comparative Reasoning ( All ) , and Comparative Reasoning ( Count ) , they usually involve multiple entity types and relations . KaFSP achieves huge improvements of 11.91 % , 16.23 % , and 19.45 % on these question types over LASAGNE . This is mainly due to fuzzy comparison rules in the new grammar system and the proposed knowledge - aware type and relation prediction module . The module benefits from the multi - label classification with a single classifier that not only helps to capture correlations between entity types and relations but also pinpoints and incorporates only relevant information from the knowledge base into relation and type prediction , which makes the predictions of types and relations more accurate .
Our model does not outperform previous SOTA results on only 2 question types , i.e. , Simple Question ( Co - referenced ) and Simple Question ( Ellipsis ) . Although KaFSP is lower than KISP on these two question types , it is 0.55 % and 1.66 % higher than LASAGNE . We conjecture that the reasons for being not superior to KISP on these question types are twofold . First , spurious logical forms may have a negative impact on the decoder when it is trained on data indeed with false logical forms . Second , in conversational QA , not only entities but also entity relations can be omitted in questions . For example , " How many people acted as an influence on Thomas Aquinas ? And also tell me about Walt Whitman ? " . In KaFSP , we replace the real ID of an omitted entity with " previous - entity " . However , this strategy is not used for omitted relations when producing logic forms , which may have neg-   ative impacts on the two question types mentioned above . Furthermore , although KaFSP increases the number of parameters , most added parameters are from the pretrained XLNet ( base ) model included for entity disambiguation . This does not have a big impact on the inference speed of KaFSP compared to LASAGNE .
Ablation Study
Table 3 summarizes experiment results of ablation study on our major contributions : fuzzy grammar , the knowledge - aware entity disambiguation module , and the multi - label classification framework . We observe that all three key components make substantial contributions to our proposed model .
For the ablation study on the entity disambiguation module , we compared KaFSP against " w/o ED " that directly selects the first entity from the ordered candidate list retrieved from the knowledge   base as the disambiguated entity . When ED module is n't used , candidate entities are sorted lexicographically by their IDs . This was done to be consistent with previous approaches in our baselines . We find that for all types of questions , the application of the proposed knowledge - aware ED improves the results to various degrees . This is because entity ambiguity is present in a wide range of questions .
For Simple Question ( Direct ) questions , our further analysis shows that 14.11 % of entities are updated by our knowledge - aware ED , which leads to an improvement of 2.60 % . Both natural language questions and the knowledge base contain information that can be used to disambiguate entities . The proposed knowledge - aware ED incorporates both types of information for disambiguation . Table 4 shows the total number of entities , the total number of disambiguated entities , and their proportions in the logical forms of different types of questions . It can be seen that overall , the disambiguated entities account for 13.98 % . For Logical Reasoning and Verification questions where the proportion of disambiguated entities is relatively high , correspondingly , the improvements achieved by adding the entity disambiguation module is high . This further validates the effectiveness of the proposed entity disambiguation module .
Similarly , our ablation study validates the effectiveness of both the fuzzy grammar and the knowledge - aware multi - label classification ( case study on the multi - label classification can be found in Appendix B ) .
Error Analysis
For error analysis , we randomly sampled 100 incorrect predictions and summarized the following two types of typical errors : Entity Ambiguity ( 54 % ) Although our entity disambiguation model can achieve a prediction accuracy of 95.16 % , ambiguous entities still exist in some questions . Take the question " What lead to the death of Jerry Stephenson ? " as an example . Both entity Q6184489 and Q100927364 are found in the knowledge base , which matches the surface form " Jerry Stephenson " . However , it is difficult to determine whether the real entity in the question is Q100927364 ( college basketball player   Austin Peay ) or Q6184489 ( American baseball player ) with only information of three triples and insufficient context . Spurious Logical Forms ( 6 % ) Similar to previous works ( Shen et al . , 2019;Kacupaj et al . , 2021 ) , we find that our model can infer correct answers even with wrong " ground - truth " logical forms generated with the algorithm taken from previous work ( Guo et al . , 2018 ) . This will affect the overall performance of the model . Such a phenomenon is especially common in complex reasoning questions .
Conclusion
In this paper , we have presented a knowledgeaware fuzzy semantic parsing framework KaFSP for conversational question answering over a largescale knowledge base . KaFSP defines fuzzy comparison actions in grammar based on the fuzzy set theory to cover approximately comparative reasoning . In addition to this , we propose two knowledgeaware components in KaFSP to incorporate information from the knowledge base for entity disambiguation and entity type & relation prediction . Experiment results demonstrate that KaFSP is substantially better than all previous state - of - the - art models , setting new SOTA results on 8 out of 10 question types on the CSQA dataset and achieving over 90 % F1 or accuracy in 3 question types for the first time .  
A Hyperparamters and Module Configurations
Table 5 summarizes the hyperparameters used in the KaFSP framework . For the Transformer module , we used the standard configurations from Vaswani et al . ( 2017 ) . Following the setting for Transformer base , we used residual dropout ( Srivastava et al . , 2014 ) in the summation of word embeddings and positional encodings in both the encoder and decoder with a rate of 0.1 .
B Case Study on the Multi - Label Classification
We sample 12 questions and list the ground - truth labels ( i.e. , entity types and relations ) corresponding to each question in Table 6 . Through the proposed knowledge - aware multi - label classification module , we get the probabilities of different labels for each question , which are visualized in Figure 2 . We observe that the knowledge - aware multilabel classification module can effectively recognize entity types and relations in the questions . Take Question 10 and 11 as examples . Both questions contain type T2 and relation R1 , while Question 11 has another relation R4 . In Figure 2 , we observe that this module can recognize these types and relations correctly . Applying the proposed multi - label classification module to the type and relation prediction module will hence effectively filter information irrelevant to the current question   6 .
and help the model make better predictions . We also find that some questions have a higher probability on a very small number of irrelevant labels . However , as the number of labels in KBs is large , having a high probability of only a few irrelevant labels will not greatly affect the results of the entire model .
ID
Question
Ground - truth Labels  
Acknowledgments
The present research was supported by Zhejiang Lab ( No . 2022KH0AB01 ) and Huawei ( No . TC20210528011 ) . We would like to thank the anonymous reviewers for their insightful comments . We also want to thank MindSpore 1 for the partial suppoort of this work , which is a new deep learning computing framework .
